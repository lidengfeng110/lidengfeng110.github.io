{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"介绍 MYSQL的事务日志","slug":"介绍 MYSQL的事务日志","date":"2017-05-31T16:00:00.000Z","updated":"2018-06-18T11:19:04.651Z","comments":true,"path":"2017/06/01/介绍 MYSQL的事务日志/","link":"","permalink":"http://yoursite.com/2017/06/01/介绍 MYSQL的事务日志/","excerpt":"innodb事务日志包括redo log和undo log。redo log是重做日志，提供前滚操作，undo log是回滚日志，提供回滚操作undo log不是redo log的逆向过程，其实它们都算是用来恢复的日志： 1.redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。 2.undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。 redo log","text":"innodb事务日志包括redo log和undo log。redo log是重做日志，提供前滚操作，undo log是回滚日志，提供回滚操作undo log不是redo log的逆向过程，其实它们都算是用来恢复的日志： 1.redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。 2.undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。 redo log redo log和二进制日志的区别 二进制日志相关内容，参考：MariaDB/MySQL的二进制日志。 redo log不是二进制日志。虽然二进制日志中也记录了innodb表的很多操作，也能实现重做的功能，但是它们之间有很大区别。 二进制日志是在存储引擎的上层产生的，不管是什么存储引擎，对数据库进行了修改都会产生二进制日志。而redo log是innodb层产生的，只记录该存储引擎中表的修改。并且二进制日志先于redo log被记录。具体的见后文group commit小结。 二进制日志记录操作的方法是逻辑性的语句。即便它是基于行格式的记录方式，其本质也还是逻辑的SQL设置，如该行记录的每列的值是多少。而redo log是在物理格式上的日志，它记录的是数据库中每个页的修改。 二进制日志只在每次事务提交的时候一次性写入缓存中的日志”文件”。而redo log在数据准备修改前写入缓存中的redo log中，然后才对缓存中的数据执行修改操作；而且保证在发出事务提交指令时，先向缓存中的redo log写入日志，写入完成后才执行提交动作。 因为二进制日志只在提交的时候一次性写入，所以二进制日志中的记录方式和提交顺序有关，且一次提交对应一次记录。而redo log中是记录的物理页的修改，redo log文件中同一个事务可能多次记录，最后一个提交的事务记录会覆盖所有未提交的事务记录。例如事务T1，可能在redo log中记录了 T1-1,T1-2,T1-3，T1 共4个操作，其中 T1 表示最后提交时的日志记录，所以对应的数据页最终状态是 T1 对应的操作结果。而且redo log是并发写入的，不同事务之间的不同版本的记录会穿插写入到redo log文件中，例如可能redo log的记录方式如下： T1-1,T1-2,T2-1,T2-2,T2,T1-3,T1* 。 事务日志记录的是物理页的情况，它具有幂等性，因此记录日志的方式及其简练。幂等性的意思是多次操作前后状态是一样的，例如新插入一行后又删除该行，前后状态没有变化。而二进制日志记录的是所有影响数据的操作，记录的内容较多。例如插入一行记录一次，删除该行又记录一次。 redo log的基本概念 redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。 在概念上，innodb通过force log at commit机制实现事务的持久性，即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化。 为了确保每次日志都能写入到事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。因为MariaDB/MySQL是工作在用户空间的，MariaDB/MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中(redo:ib_logfileN文件,undo:share tablespace或.ibd文件)，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将OS buffer中的日志刷到磁盘上的log file中。 也就是说，从redo log buffer写日志到磁盘的redo log file中，过程如下： 在此处需要注意一点，一般所说的log file并不是磁盘上的物理日志文件，而是操作系统缓存中的log file，官方手册上的意思也是如此(例如：With a value of 2, the contents of the InnoDB log buffer are written to the log file after each transaction commit and the log file is flushed to disk approximately once per second)。但说实话，这不太好理解，既然都称为file了，应该已经属于物理文件了。所以在本文后续内容中都以os buffer或者file system buffer来表示官方手册中所说的Log file，然后log file则表示磁盘上的物理日志文件，即log file on disk。 MySQL支持用户自定义在commit时如何将log buffer中的日志刷log file中。这种控制通过变量 innodb_flush_log_at_trx_commit 的值来决定。该变量有3种值：0、1、2，默认为1。但注意，这个变量只是控制commit动作是否刷新log buffer到磁盘。 当设置为1的时候，事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file on disk中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。 当设置为0的时候，事务提交时不会将log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到log file on disk中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。 当设置为2的时候，每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到log file on disk。 注意，有一个变量 innodb_flush_log_at_timeout 的值为1秒，该变量表示的是刷日志的频率，很多人误以为是控制 innodb_flush_log_at_trx_commit 值为0和2时的1秒频率，实际上并非如此。测试时将频率设置为5和设置为1，当 innodb_flush_log_at_trx_commit 设置为0和2的时候性能基本都是不变的。关于这个频率是控制什么的，在后面的”刷日志到磁盘的规则”中会说。 在主从复制结构中，要保证事务的持久性和一致性，需要对日志相关变量设置为如下： 如果启用了二进制日志，则设置sync_binlog=1，即每提交一次事务同步写到磁盘中。 总是设置innodb_flush_log_at_trx_commit=1，即每提交一次事务都写到磁盘中。 上述两项变量的设置保证了：每次提交事务都写入二进制日志和事务日志，并在提交时将它们刷新到磁盘中。 选择刷日志的时间会严重影响数据修改时的性能，特别是刷到磁盘的过程。下例就测试了 innodb_flush_log_at_trx_commit 分别为0、1、2时的差距。 12345678910111213141516171819#创建测试表drop table if exists test_flush_log;create table test_flush_log(id int,name char(50))engine=innodb;#创建插入指定行数的记录到测试表中的存储过程drop procedure if exists proc;delimiter $$create procedure proc(i int)begin declare s int default 1; declare c char(50) default repeat(&apos;a&apos;,50); while s&lt;=i do start transaction; insert into test_flush_log values(null,c); commit; set s=s+1; end while;end$$delimiter ; 当前环境下， innodb_flush_log_at_trx_commit 的值为1，即每次提交都刷日志到磁盘。测试此时插入10W条记录的时间。 12mysql&gt; call proc(100000);Query OK, 0 rows affected (15.48 sec) 结果是15.48秒。 再测试值为2的时候，即每次提交都刷新到os buffer，但每秒才刷入磁盘中。 12345mysql&gt; set @@global.innodb_flush_log_at_trx_commit=2; mysql&gt; truncate test_flush_log;mysql&gt; call proc(100000);Query OK, 0 rows affected (3.41 sec) 结果插入时间大减，只需3.41秒。 最后测试值为0的时候，即每秒才刷到os buffer和磁盘。 12345mysql&gt; set @@global.innodb_flush_log_at_trx_commit=0;mysql&gt; truncate test_flush_log;mysql&gt; call proc(100000);Query OK, 0 rows affected (2.10 sec) 结果只有2.10秒。 最后可以发现，其实值为2和0的时候，它们的差距并不太大，但2却比0要安全的多。它们都是每秒从os buffer刷到磁盘，它们之间的时间差体现在log buffer刷到os buffer上。因为将log buffer中的日志刷新到os buffer只是内存数据的转移，并没有太大的开销，所以每次提交和每秒刷入差距并不大。可以测试插入更多的数据来比较，以下是插入100W行数据的情况。从结果可见，值为2和0的时候差距并不大，但值为1的性能却差太多。 尽管设置为0和2可以大幅度提升插入性能，但是在故障的时候可能会丢失1秒钟数据，这1秒钟很可能有大量的数据，从上面的测试结果看，100W条记录也只消耗了20多秒，1秒钟大约有4W-5W条数据，尽管上述插入的数据简单，但却说明了数据丢失的大量性。更好的插入数据的做法是将值设置为1，然后修改存储过程，将每次循环都提交修改为只提交一次，这样既能保证数据的一致性，也能提升性能，修改如下： 1234567891011121314drop procedure if exists proc;delimiter $$create procedure proc(i int)begin declare s int default 1; declare c char(50) default repeat(&apos;a&apos;,50); start transaction; while s&lt;=i DO insert into test_flush_log values(null,c); set s=s+1; end while; commit;end$$delimiter ; 测试值为1时的情况。12345mysql&gt; set @@global.innodb_flush_log_at_trx_commit=1;mysql&gt; truncate test_flush_log;mysql&gt; call proc(1000000);Query OK, 0 rows affected (11.26 sec) 日志块(log block) innodb存储引擎中，redo log以块为单位进行存储的，每个块占512字节，这称为redo log block。所以不管是log buffer中还是os buffer中以及redo log file on disk中，都是这样以512字节的块存储的。 每个redo log block由3部分组成：日志块头、日志块尾和日志主体。其中日志块头占用12字节，日志块尾占用8字节，所以每个redo log block的日志主体部分只有512-12-8=492字节。 因为redo log记录的是数据页的变化，当一个数据页产生的变化需要使用超过492字节()的redo log来记录，那么就会使用多个redo log block来记录该数据页的变化。 日志块头包含4部分：  log_block_hdr_no：(4字节)该日志块在redo log buffer中的位置ID。  log_block_hdr_data_len：(2字节)该log block中已记录的log大小。写满该log block时为0x200，表示512字节。  log_block_first_rec_group：(2字节)该log block中第一个log的开始偏移位置。  lock_block_checkpoint_no：(4字节)写入检查点信息的位置。 关于log block块头的第三部分 log_block_first_rec_group ，因为有时候一个数据页产生的日志量超出了一个日志块，这是需要用多个日志块来记录该页的相关日志。例如，某一数据页产生了552字节的日志量，那么需要占用两个日志块，第一个日志块占用492字节，第二个日志块需要占用60个字节，那么对于第二个日志块来说，它的第一个log的开始位置就是73字节(60+12)。如果该部分的值和 log_block_hdr_data_len 相等，则说明该log block中没有新开始的日志块，即表示该日志块用来延续前一个日志块。 日志尾只有一个部分： log_block_trl_no ，该值和块头的 log_block_hdr_no 相等。 上面所说的是一个日志块的内容，在redo log buffer或者redo log file on disk中，由很多log block组成。如下图： log group和redo log file log group表示的是redo log group，一个组内由多个大小完全相同的redo log file组成。组内redo log file的数量由变量 innodb_log_files_group 决定，默认值为2，即两个redo log file。这个组是一个逻辑的概念，并没有真正的文件来表示这是一个组，但是可以通过变量 innodb_log_group_home_dir 来定义组的目录，redo log file都放在这个目录下，默认是在datadir下。 123456789101112131415mysql&gt; show global variables like &quot;innodb_log%&quot;;+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| innodb_log_buffer_size | 8388608 || innodb_log_compressed_pages | ON || innodb_log_file_size | 50331648 || innodb_log_files_in_group | 2 || innodb_log_group_home_dir | ./ |+-----------------------------+----------+[root@xuexi data]# ll /mydata/data/ib*-rw-rw---- 1 mysql mysql 79691776 Mar 30 23:12 /mydata/data/ibdata1-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 /mydata/data/ib_logfile0-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 /mydata/data/ib_logfile1 可以看到在默认的数据目录下，有两个ib_logfile开头的文件，它们就是log group中的redo log file，而且它们的大小完全一致且等于变量 innodb_log_file_size 定义的值。第一个文件ibdata1是在没有开启 innodb_file_per_table 时的共享表空间文件，对应于开启 innodb_file_per_table 时的.ibd文件。 在innodb将log buffer中的redo log block刷到这些log file中时，会以追加写入的方式循环轮训写入。即先在第一个log file（即ib_logfile0）的尾部追加写，直到满了之后向第二个log file（即ib_logfile1）写。当第二个log file满了会清空一部分第一个log file继续写入。 由于是将log buffer中的日志刷到log file，所以在log file中记录日志的方式也是log block的方式。 在每个组的第一个redo log file中，前2KB记录4个特定的部分，从2KB之后才开始记录log block。除了第一个redo log file中会记录，log group中的其他log file不会记录这2KB，但是却会腾出这2KB的空间。如下： redo log file的大小对innodb的性能影响非常大，设置的太大，恢复的时候就会时间较长，设置的太小，就会导致在写redo log的时候循环切换redo log file。 redo log的格式 因为innodb存储引擎存储数据的单元是页(和SQL Server中一样)，所以redo log也是基于页的格式来记录的。默认情况下，innodb的页大小是16KB(由 innodb_page_size 变量控制)，一个页内可以存放非常多的log block(每个512字节)，而log block中记录的又是数据页的变化。 其中log block中492字节的部分是log body，该log body的格式分为4部分： redo_log_type：占用1个字节，表示redo log的日志类型。 space：表示表空间的ID，采用压缩的方式后，占用的空间可能小于4字节。 page_no：表示页的偏移量，同样是压缩过的。 redo_log_body表示每个重做日志的数据部分，恢复时会调用相应的函数进行解析。例如insert语句和delete语句写入redo log的内容是不一样的。 如下图，分别是insert和delete大致的记录方式。 日志刷盘的规则 log buffer中未刷到磁盘的日志称为脏日志(dirty log)。 在上面的说过，默认情况下事务每次提交的时候都会刷事务日志到磁盘中，这是因为变量 innodb_flush_log_at_trx_commit 的值为1。但是innodb不仅仅只会在有commit动作后才会刷日志到磁盘，这只是innodb存储引擎刷日志的规则之一。 刷日志到磁盘有以下几种规则： 1.发出commit动作时。已经说明过，commit发出后是否刷日志由变量 innodb_flush_log_at_trx_commit 控制。 2.每秒刷一次。这个刷日志的频率由变量 innodb_flush_log_at_timeout 值决定，默认是1秒。要注意，这个刷日志频率和commit动作无关。 3.当log buffer中已经使用的内存超过一半时。 4.当有checkpoint时，checkpoint在一定程度上代表了刷到磁盘时日志所处的LSN位置。 数据页刷盘的规则及checkpoint 内存中(buffer pool)未刷到磁盘的数据称为脏数据(dirty data)。由于数据和日志都以页的形式存在，所以脏页表示脏数据和脏日志。 上一节介绍了日志是何时刷到磁盘的，不仅仅是日志需要刷盘，脏数据页也一样需要刷盘。 在innodb中，数据刷盘的规则只有一个：checkpoint。但是触发checkpoint的情况却有几种。不管怎样，checkpoint触发后，会将buffer中脏数据页和脏日志页都刷到磁盘。 innodb存储引擎中checkpoint分为两种： sharp checkpoint：在重用redo log文件(例如切换日志文件)的时候，将所有已记录到redo log中对应的脏数据刷到磁盘。fuzzy checkpoint：一次只刷一小部分的日志到磁盘，而非将所有脏日志刷盘。有以下几种情况会触发该检查点：master thread checkpoint：由master线程控制，每秒或每10秒刷入一定比例的脏页到磁盘。flush_lru_list checkpoint：从MySQL5.6开始可通过 innodb_page_cleaners 变量指定专门负责脏页刷盘的page cleaner线程的个数，该线程的目的是为了保证lru列表有可用的空闲页。async/sync flush checkpoint：同步刷盘还是异步刷盘。例如还有非常多的脏页没刷到磁盘(非常多是多少，有比例控制)，这时候会选择同步刷到磁盘，但这很少出现；如果脏页不是很多，可以选择异步刷到磁盘，如果脏页很少，可以暂时不刷脏页到磁盘dirty page too much checkpoint：脏页太多时强制触发检查点，目的是为了保证缓存有足够的空闲空间。too much的比例由变量 innodb_max_dirty_pages_pct 控制，MySQL 5.6默认的值为75，即当脏页占缓冲池的百分之75后，就强制刷一部分脏页到磁盘。由于刷脏页需要一定的时间来完成，所以记录检查点的位置是在每次刷盘结束之后才在redo log中标记的。 1MySQL停止时是否将脏数据和脏日志刷入磁盘，由变量innodb_fast_shutdown=&#123; 0|1|2 &#125;控制，默认值为1，即停止时忽略所有flush操作，在下次启动的时候再flush，实现fast shutdown。 LSN超详细分析 LSN称为日志的逻辑序列号(log sequence number)，在innodb存储引擎中，lsn占用8个字节。LSN的值会随着日志的写入而逐渐增大。 根据LSN，可以获取到几个有用的信息： 1.数据页的版本信息。2.写入的日志总量，通过LSN开始号码和结束号码可以计算出写入的日志量。3.可知道检查点的位置。 实际上还可以获得很多隐式的信息。 LSN不仅存在于redo log中，还存在于数据页中，在每个数据页的头部，有一个fil_page_lsn记录了当前页最终的LSN值是多少。通过数据页中的LSN值和redo log中的LSN值比较，如果页中的LSN值小于redo log中LSN值，则表示数据丢失了一部分，这时候可以通过redo log的记录来恢复到redo log中记录的LSN值时的状态。 redo log的lsn信息可以通过 show engine innodb status 来查看。MySQL 5.5版本的show结果中只有3条记录，没有pages flushed up to。12345678910mysql&gt; show engine innodb stauts---LOG---Log sequence number 2225502463Log flushed up to 2225502463Pages flushed up to 2225502463Last checkpoint at 22255024630 pending log writes, 0 pending chkp writes3201299 log i/o&apos;s done, 0.00 log i/o&apos;s/second 其中： log sequence number就是当前的redo log(in buffer)中的lsn； log flushed up to是刷到redo log file on disk中的lsn； pages flushed up to是已经刷到磁盘数据页上的LSN；last checkpoint at是上一次检查点所在位置的LSN。 innodb从执行修改语句开始： (1).首先修改内存中的数据页，并在数据页中记录LSN，暂且称之为data_in_buffer_lsn； (2).并且在修改数据页的同时(几乎是同时)向redo log in buffer中写入redo log，并记录下对应的LSN，暂且称之为redo_log_in_buffer_lsn； (3).写完buffer中的日志后，当触发了日志刷盘的几种规则时，会向redo log file on disk刷入重做日志，并在该文件中记下对应的LSN，暂且称之为redo_log_on_disk_lsn； (4).数据页不可能永远只停留在内存中，在某些情况下，会触发checkpoint来将内存中的脏页(数据脏页和日志脏页)刷到磁盘，所以会在本次checkpoint脏页刷盘结束时，在redo log中记录checkpoint的LSN位置，暂且称之为checkpoint_lsn。 (5).要记录checkpoint所在位置很快，只需简单的设置一个标志即可，但是刷数据页并不一定很快，例如这一次checkpoint要刷入的数据页非常多。也就是说要刷入所有的数据页需要一定的时间来完成，中途刷入的每个数据页都会记下当前页所在的LSN，暂且称之为data_page_on_disk_lsn。 详细说明如下图： 上图中，从上到下的横线分别代表：时间轴、buffer中数据页中记录的LSN(data_in_buffer_lsn)、磁盘中数据页中记录的LSN(data_page_on_disk_lsn)、buffer中重做日志记录的LSN(redo_log_in_buffer_lsn)、磁盘中重做日志文件中记录的LSN(redo_log_on_disk_lsn)以及检查点记录的LSN(checkpoint_lsn)。 假设在最初时(12:0:00)所有的日志页和数据页都完成了刷盘，也记录好了检查点的LSN，这时它们的LSN都是完全一致的。 假设此时开启了一个事务，并立刻执行了一个update操作，执行完成后，buffer中的数据页和redo log都记录好了更新后的LSN值，假设为110。这时候如果执行 show engine innodb status 查看各LSN的值，即图中①处的位置状态，结果会是： 1log sequence number(110) &gt; log flushed up to(100) = pages flushed up to = last checkpoint at 之后又执行了一个delete语句，LSN增长到150。等到12:00:01时，触发redo log刷盘的规则(其中有一个规则是 innodb_flush_log_at_timeout 控制的默认日志刷盘频率为1秒)，这时redo log file on disk中的LSN会更新到和redo log in buffer的LSN一样，所以都等于150，这时 show engine innodb status ，即图中②的位置，结果将会是： 1log sequence number(150) = log flushed up to &gt; pages flushed up to(100) = last checkpoint at 再之后，执行了一个update语句，缓存中的LSN将增长到300，即图中③的位置 。 假设随后检查点出现，即图中④的位置，正如前面所说，检查点会触发数据页和日志页刷盘，但需要一定的时间来完成，所以在数据页刷盘还未完成时，检查点的LSN还是上一次检查点的LSN，但此时磁盘上数据页和日志页的LSN已经增长了，即： 1log sequence number &gt; log flushed up to 和 pages flushed up to &gt; last checkpoint at 但是log flushed up to和pages flushed up to的大小无法确定，因为日志刷盘可能快于数据刷盘，也可能等于，还可能是慢于。但是checkpoint机制有保护数据刷盘速度是慢于日志刷盘的：当数据刷盘速度超过日志刷盘时，将会暂时停止数据刷盘，等待日志刷盘进度超过数据刷盘。 等到数据页和日志页刷盘完毕，即到了位置⑤的时候，所有的LSN都等于300。 随着时间的推移到了12:00:02，即图中位置⑥，又触发了日志刷盘的规则，但此时buffer中的日志LSN和磁盘中的日志LSN是一致的，所以不执行日志刷盘，即此时 show engine innodb status 时各种lsn都相等。 随后执行了一个insert语句，假设buffer中的LSN增长到了800，即图中位置⑦。此时各种LSN的大小和位置①时一样。 随后执行了提交动作，即位置⑧。默认情况下，提交动作会触发日志刷盘，但不会触发数据刷盘，所以 show engine innodb status 的结果是： 1log sequence number = log flushed up to &gt; pages flushed up to = last checkpoint at 最后随着时间的推移，检查点再次出现，即图中位置⑨。但是这次检查点不会触发日志刷盘，因为日志的LSN在检查点出现之前已经同步了。假设这次数据刷盘速度极快，快到一瞬间内完成而无法捕捉到状态的变化，这时 show engine innodb status 的结果将是各种LSN相等。 innodb的恢复行为 在启动innodb的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。 因为redo log记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如二进制日志)要快很多。而且，innodb自身也做了一定程度的优化，让恢复速度变得更快。 重启innodb时，checkpoint表示已经完整刷到磁盘上data page上的LSN，因此恢复时仅需要恢复从checkpoint开始的日志部分。例如，当数据库在上一次checkpoint的LSN为10000时宕机，且事务是已经提交过的状态。启动数据库时会检查磁盘中数据页的LSN，如果数据页的LSN小于日志中的LSN，则会从检查点开始恢复。 还有一种情况，在宕机前正处于checkpoint的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度。这时候一宕机，数据页中记录的LSN就会大于日志页中的LSN，在重启的恢复过程中会检查到这一情况，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。 另外，事务日志具有幂等性，所以多次操作得到同一结果的行为在日志中只记录一次。而二进制日志不具有幂等性，多次操作会全部记录下来，在恢复的时候会多次执行二进制日志中的记录，速度就慢得多。例如，某记录中id初始值为2，通过update将值设置为了3，后来又设置成了2，在事务日志中记录的将是无变化的页，根本无需恢复；而二进制会记录下两次update操作，恢复时也将执行这两次update操作，速度比事务日志恢复更慢。 和redo log有关的几个变量1innodb_flush_log_at_trx_commit=&#123;0|1|2&#125; # 指定何时将事务日志刷到磁盘，默认为1。 10表示每秒将&quot;log buffer&quot;同步到&quot;os buffer&quot;且从&quot;os buffer&quot;刷到磁盘日志文件中。 11表示每事务提交都将&quot;log buffer&quot;同步到&quot;os buffer&quot;且从&quot;os buffer&quot;刷到磁盘日志文件中。 12表示每事务提交都将&quot;log buffer&quot;同步到&quot;os buffer&quot;但每秒才从&quot;os buffer&quot;刷到磁盘日志文件中。 1innodb_log_buffer_size：# log buffer的大小，默认8M 1innodb_log_file_size：#事务日志的大小，默认5M 1innodb_log_files_group =2：# 事务日志组中的事务日志文件个数，默认2个 1innodb_log_group_home_dir =./：# 事务日志组路径，当前目录表示数据目录 1innodb_mirrored_log_groups =1：# 指定事务日志组的镜像组个数，但镜像功能好像是强制关闭的，所以只有一个log group。在MySQL5.7中该变量已经移除。 undo log基本概念 undo log有两个作用：提供回滚和多个行版本控制(MVCC)。 在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。 undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。 当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。 undo log是采用段(segment)的方式来记录的，每个undo操作在记录的时候占用一个undo log segment。 另外，undo log也会产生redo log，因为undo log也要实现持久性保护。 undo log的存储方式 innodb存储引擎对undo的管理采用段的方式。rollback segment称为回滚段，每个回滚段中有1024个undo log segment。 在以前老版本，只支持1个rollback segment，这样就只能记录1024个undo log segment。后来MySQL5.5可以支持128个rollback segment，即支持128*1024个undo操作，还可以通过变量 innodb_undo_logs (5.6版本以前该变量是 innodb_rollback_segments )自定义多少个rollback segment，默认值为128。 undo log默认存放在共享表空间中。 1234[root@xuexi data]# ll /mydata/data/ib*-rw-rw---- 1 mysql mysql 79691776 Mar 31 01:42 /mydata/data/ibdata1-rw-rw---- 1 mysql mysql 50331648 Mar 31 01:42 /mydata/data/ib_logfile0-rw-rw---- 1 mysql mysql 50331648 Mar 31 01:42 /mydata/data/ib_logfile1 如果开启了 innodb_file_per_table ，将放在每个表的.ibd文件中。 在MySQL5.6中，undo的存放位置还可以通过变量 innodb_undo_directory 来自定义存放目录，默认值为”.”表示datadir。 默认rollback segment全部写在一个文件中，但可以通过设置变量 innodb_undo_tablespaces 平均分配到多少个文件中。该变量默认值为0，即全部写入一个表空间文件。该变量为静态变量，只能在数据库示例停止状态下修改，如写入配置文件或启动时带上对应参数。但是innodb存储引擎在启动过程中提示，不建议修改为非0的值，如下： 12342017-03-31 13:16:00 7f665bfab720 InnoDB: Expected to open 3 undo tablespaces but was able2017-03-31 13:16:00 7f665bfab720 InnoDB: to find only 0 undo tablespaces.2017-03-31 13:16:00 7f665bfab720 InnoDB: Set the innodb_undo_tablespaces parameter to the2017-03-31 13:16:00 7f665bfab720 InnoDB: correct value and retry. Suggested value is 0 和undo log相关的变量 undo相关的变量在MySQL5.6中已经变得很少。如下：它们的意义在上文中已经解释了。 12345678mysql&gt; show variables like &quot;%undo%&quot;;+-------------------------+-------+| Variable_name | Value |+-------------------------+-------+| innodb_undo_directory | . || innodb_undo_logs | 128 || innodb_undo_tablespaces | 0 |+-------------------------+-------+ delete/update操作的内部机制 当事务提交的时候，innodb不会立即删除undo log，因为后续还可能会用到undo log，如隔离级别为repeatable read时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即undo log不能删除。 但是在事务提交的时候，会将该事务对应的undo log放入到删除列表中，未来通过purge来删除。并且提交事务时，还会判断undo log分配的页是否可以重用，如果可以重用，则会分配给后面来的事务，避免为每个独立的事务分配独立的undo log页而浪费存储空间和性能。 通过undo log记录delete和update操作的结果发现：(insert操作无需分析，就是插入行而已) delete操作实际上不会直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的。update分为两种情况：update的列是否是主键列。如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。如果是主键列，update分两部执行：先删除该行，再插入一行目标行。 binlog和事务日志的先后顺序及group commit 如果事务不是只读事务，即涉及到了数据的修改，默认情况下会在commit的时候调用fsync()将日志刷到磁盘，保证事务的持久性。 但是一次刷一个事务的日志性能较低，特别是事务集中在某一时刻时事务量非常大的时候。innodb提供了group commit功能，可以将多个事务的事务日志通过一次fsync()刷到磁盘中。 因为事务在提交的时候不仅会记录事务日志，还会记录二进制日志，但是它们谁先记录呢？二进制日志是MySQL的上层日志，先于存储引擎的事务日志被写入。 在MySQL5.6以前，当事务提交(即发出commit指令)后，MySQL接收到该信号进入commit prepare阶段；进入prepare阶段后，立即写内存中的二进制日志，写完内存中的二进制日志后就相当于确定了commit操作；然后开始写内存中的事务日志；最后将二进制日志和事务日志刷盘，它们如何刷盘，分别由变量 sync_binlog 和 innodb_flush_log_at_trx_commit 控制。 但因为要保证二进制日志和事务日志的一致性，在提交后的prepare阶段会启用一个prepare_commit_mutex锁来保证它们的顺序性和一致性。但这样会导致开启二进制日志后group commmit失效，特别是在主从复制结构中，几乎都会开启二进制日志。 在MySQL5.6中进行了改进。提交事务时，在存储引擎层的上一层结构中会将事务按序放入一个队列，队列中的第一个事务称为leader，其他事务称为follower，leader控制着follower的行为。虽然顺序还是一样先刷二进制，再刷事务日志，但是机制完全改变了：删除了原来的prepare_commit_mutex行为，也能保证即使开启了二进制日志，group commit也是有效的。 MySQL5.6中分为3个步骤：flush阶段、sync阶段、commit阶段。 flush阶段：向内存中写入每个事务的二进制日志。 sync阶段：将内存中的二进制日志刷盘。若队列中有多个事务，那么仅一次fsync操作就完成了二进制日志的刷盘操作。这在MySQL5.6中称为BLGC(binary log group commit)。 commit阶段：leader根据顺序调用存储引擎层事务的提交，由于innodb本就支持group commit，所以解决了因为锁 prepare_commit_mutex 而导致的group commit失效问题。 在flush阶段写入二进制日志到内存中，但是不是写完就进入sync阶段的，而是要等待一定的时间，多积累几个事务的binlog一起进入sync阶段，等待时间由变量 binlog_max_flush_queue_time 决定，默认值为0表示不等待直接进入sync，设置该变量为一个大于0的值的好处是group中的事务多了，性能会好一些，但是这样会导致事务的响应时间变慢，所以建议不要修改该变量的值，除非事务量非常多并且不断的在写入和更新。 进入到sync阶段，会将binlog从内存中刷入到磁盘，刷入的数量和单独的二进制日志刷盘一样，由变量 sync_binlog 控制。 当有一组事务在进行commit阶段时，其他新事务可以进行flush阶段，它们本就不会相互阻塞，所以group commit会不断生效。当然，group commit的性能和队列中的事务数量有关，如果每次队列中只有1个事务，那么group commit和单独的commit没什么区别，当队列中事务越来越多时，即提交事务越多越快时，group commit的效果越明显。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"MYSQL","slug":"MYSQL","permalink":"http://yoursite.com/tags/MYSQL/"}]},{"title":"MYSQL 数据库的日志介绍","slug":"MYSQL 数据库的日志介绍","date":"2017-05-21T16:00:00.000Z","updated":"2018-06-18T10:33:47.787Z","comments":true,"path":"2017/05/22/MYSQL 数据库的日志介绍/","link":"","permalink":"http://yoursite.com/2017/05/22/MYSQL 数据库的日志介绍/","excerpt":"不管是哪个数据库产品，一定会有日志文件。在MariaDB/MySQL中，主要有5种日志文件： 1.错误日志(error log)：记录mysql服务的启停时正确和错误的信息，还记录启动、停止、运行过程中的错误信息。 2.查询日志(general log)：记录建立的客户端连接和执行的语句。 3.二进制日志(bin log)：记录所有更改数据的语句，可用于数据复制。 4.慢查询日志(slow log)：记录所有执行时间超过long_query_time的所有查询或不使用索引的查询。 5.中继日志(relay log)：主从复制时使用的日志。","text":"不管是哪个数据库产品，一定会有日志文件。在MariaDB/MySQL中，主要有5种日志文件： 1.错误日志(error log)：记录mysql服务的启停时正确和错误的信息，还记录启动、停止、运行过程中的错误信息。 2.查询日志(general log)：记录建立的客户端连接和执行的语句。 3.二进制日志(bin log)：记录所有更改数据的语句，可用于数据复制。 4.慢查询日志(slow log)：记录所有执行时间超过long_query_time的所有查询或不使用索引的查询。 5.中继日志(relay log)：主从复制时使用的日志。 日志刷新操作 以下操作会刷新日志文件，刷新日志文件时会关闭旧的日志文件并重新打开日志文件。对于有些日志类型，如二进制日志，刷新日志会滚动日志文件，而不仅仅是关闭并重新打开。 123mysql&gt; FLUSH LOGS;shell&gt; mysqladmin flush-logsshell&gt; mysqladmin refresh 错误日志 错误日志是最重要的日志之一，它记录了MariaDB/MySQL服务启动和停止正确和错误的信息，还记录了mysqld实例运行过程中发生的错误事件信息。 可以使用” –log-erroe=[file_name] “来指定mysqld记录的错误日志文件，如果没有指定file_name，则默认的错误日志文件为datadir目录下的 hostname.err ，hostname表示当前的主机名。 也可以在MariaDB/MySQL配置文件中的mysqld配置部分，使用log-error指定错误日志的路径。 如果不知道错误日志的位置，可以查看变量log_error来查看。123456mysql&gt; show variables like &apos;log_error&apos;;+---------------+----------------------------------------+| Variable_name | Value |+---------------+----------------------------------------+| log_error | /var/lib/mysql/node1.longshuai.com.err |+---------------+----------------------------------------+ 在MySQL 5.5.7之前，刷新日志操作(如flush logs)会备份旧的错误日志(以_old结尾)，并创建一个新的错误日志文件并打开，在MySQL 5.5.7之后，执行刷新日志的操作时，错误日志会关闭并重新打开，如果错误日志不存在，则会先创建。 在MariaDB/MySQL正在运行状态下删除错误日志后，不会自动创建错误日志，只有在刷新日志的时候才会创建一个新的错误日志文件。 以下是MySQL 5.6.35启动的日志信息。 123456789101112131415161718192021222017-03-29 01:15:14 2362 [Note] Plugin &apos;FEDERATED&apos; is disabled.2017-03-29 01:15:14 2362 [Note] InnoDB: Using atomics to ref count buffer pool pages2017-03-29 01:15:14 2362 [Note] InnoDB: The InnoDB memory heap is disabled2017-03-29 01:15:14 2362 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins2017-03-29 01:15:14 2362 [Note] InnoDB: Memory barrier is not used2017-03-29 01:15:14 2362 [Note] InnoDB: Compressed tables use zlib 1.2.32017-03-29 01:15:14 2362 [Note] InnoDB: Using Linux native AIO2017-03-29 01:15:14 2362 [Note] InnoDB: Using CPU crc32 instructions2017-03-29 01:15:14 2362 [Note] InnoDB: Initializing buffer pool, size = 128.0M2017-03-29 01:15:14 2362 [Note] InnoDB: Completed initialization of buffer pool2017-03-29 01:15:14 2362 [Note] InnoDB: Highest supported file format is Barracuda.2017-03-29 01:15:14 2362 [Note] InnoDB: 128 rollback segment(s) are active.2017-03-29 01:15:14 2362 [Note] InnoDB: Waiting for purge to start2017-03-29 01:15:14 2362 [Note] InnoDB: 5.6.35 started; log sequence number 39116102017-03-29 01:15:14 2362 [Note] Server hostname (bind-address): &apos;*&apos;; port: 33062017-03-29 01:15:14 2362 [Note] IPv6 is available.2017-03-29 01:15:14 2362 [Note] - &apos;::&apos; resolves to &apos;::&apos;;2017-03-29 01:15:14 2362 [Note] Server socket created on IP: &apos;::&apos;.2017-03-29 01:15:14 2362 [Warning] &apos;proxies_priv&apos; entry &apos;@ root@xuexi.longshuai.com&apos; ignored in --skip-name-resolve mode.2017-03-29 01:15:14 2362 [Note] Event Scheduler: Loaded 0 events2017-03-29 01:15:14 2362 [Note] /usr/local/mysql/bin/mysqld: ready for connections.Version: &apos;5.6.35&apos; socket: &apos;/mydata/data/mysql.sock&apos; port: 3306 MySQL Community Server (GPL) 一般查询日志 查询日志分为一般查询日志和慢查询日志，它们是通过查询是否超出变量 long_query_time 指定时间的值来判定的。在超时时间内完成的查询是一般查询，可以将其记录到一般查询日志中，但是建议关闭这种日志（默认是关闭的），超出时间的查询是慢查询，可以将其记录到慢查询日志中。 使用” –general_log={0|1} “来决定是否启用一般查询日志，使用” –general_log_file=file_name “来指定查询日志的路径。不给定路径时默认的文件名以 hostname.log 命名。 和查询日志有关的变量有： 12341 long_query_time = 10 # 指定慢查询超时时长，超出此时长的属于慢查询，会记录到慢查询日志中 2 log_output=&#123;TABLE|FILE|NONE&#125; # 定义一般查询日志和慢查询日志的输出格式，不指定时默认为file TABLE表示记录日志到表中，FILE表示记录日志到文件中，NONE表示不记录日志。只要这里指定为NONE，即使开启了一般查询日志和慢查询日志，也都不会有任何记 录。 和一般查询日志相关的变量有：123451 general_log=off # 是否启用一般查询日志，为全局变量，必须在global上修改。 2 sql_log_off=off # 在session级别控制是否启用一般查询日志，默认为off，即启用 3 general_log_file=/mydata/data/hostname.log # 默认是库文件路径下主机名加上.log 在MySQL 5.6以前的版本还有一个”log”变量也是决定是否开启一般查询日志的。在5.6版本开始已经废弃了该选项。 默认没有开启一般查询日志，也不建议开启一般查询日志。此处打开该类型的日志，看看是如何记录一般查询日志的。 首先开启一般查询日志。 12345mysql&gt; set @@global.general_log=1;[root@xuexi data]# ll *.log-rw-rw---- 1 mysql mysql 5423 Mar 20 16:29 mysqld.log-rw-rw---- 1 mysql mysql 262 Mar 29 09:31 xuexi.log 执行几个语句。12345mysql&gt; select host,user from mysql.user;mysql&gt; show variables like &quot;%error%&quot;;mysql&gt; insert into ttt values(233);mysql&gt; create table tt(id int);mysql&gt; set @a:=3; 查看一般查询日志的内容。123456789[root@xuexi data]# cat xuexi.log /usr/local/mysql/bin/mysqld, Version: 5.6.35-log (MySQL Community Server (GPL)). started with:Tcp port: 3306 Unix socket: /mydata/data/mysql.sockTime Id Command Argument180421 20:04:41 13 Query select user,host from mysql.user180421 20:06:06 13 Query show variables like &quot;%error%&quot;180421 20:07:28 13 Query insert into ttt values(233)180421 20:11:47 13 Query create table tt(id int)180421 20:12:29 13 Query set @a:=3 由此可知，一般查询日志查询的不止是select语句，几乎所有的语句都会记录。慢查询日志 查询超出变量 long_query_time 指定时间值的为慢查询。但是查询获取锁(包括锁等待)的时间不计入查询时间内。 mysql记录慢查询日志是在查询执行完毕且已经完全释放锁之后才记录的，因此慢查询日志记录的顺序和执行的SQL查询语句顺序可能会不一致(例如语句1先执行，查询速度慢，语句2后执行，但查询速度快，则语句2先记录)。 注意，MySQL 5.1之后就支持微秒级的慢查询超时时长，对于DBA来说，一个查询运行0.5秒和运行0.05秒是非常不同的，前者可能索引使用错误或者走了表扫描，后者可能索引使用正确。 另外，指定的慢查询超时时长表示的是超出这个时间的才算是慢查询，等于这个时间的不会记录。 和慢查询有关的变量：12345678910111 long_query_time=10 # 指定慢查询超时时长(默认10秒)，超出此时长的属于慢查询 2 log_output=&#123;TABLE|FILE|NONE&#125; # 定义一般查询日志和慢查询日志的输出格式，默认为file 3 log_slow_queries=&#123;yes|no&#125; # 是否启用慢查询日志，默认不启用 4 slow_query_log=&#123;1|ON|0|OFF&#125; # 也是是否启用慢查询日志，此变量和log_slow_queries修改一个另一个同时变化 5 slow_query_log_file=/mydata/data/hostname-slow.log #默认路径为库文件目录下主机名加上-slow.log 6 log_queries_not_using_indexes=OFF # 查询没有使用索引的时候是否也记入慢查询日志 现在启用慢查询日志。 1mysql&gt; set @@global.slow_query_log=on; 因为默认超时时长为10秒，所以进行一个10秒的查询。 1mysql&gt; select sleep(10); 查看慢查询日志文件。这里看到虽然sleep了10秒，但是最后查询时间超出了847微秒，因此这里也记录了该查询。 12345678910[root@xuexi data]# cat xuexi-slow.log /usr/local/mysql/bin/mysqld, Version: 5.6.35-log (MySQL Community Server (GPL)). started with:Tcp port: 3306 Unix socket: /mydata/data/mysql.sockTime Id Command Argument# Time: 170329 9:55:58# User@Host: root[root] @ localhost [] Id: 1# Query_time: 10.000847 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use test;SET timestamp=1490752558;select sleep(10); 随着时间的推移，慢查询日志文件中的记录可能会变得非常多，这对于分析查询来说是非常困难的。好在提供了一个专门归类慢查询日志的工具mysqldumpslow。 1234567891011[root@xuexi data]# mysqldumpslow --help -d debug -v verbose：显示详细信息 -t NUM just show the top n queries：仅显示前n条查询 -a don&apos;t abstract all numbers to N and strings to &apos;S&apos;：归类时不要使用N替换数字，S替换字符串 -g PATTERN grep: only consider stmts that include this string：通过grep来筛选select语句。 该工具归类的时候，默认会将同文本但变量值不同的查询语句视为同一类，并使用N代替其中的数值变量，使用S代替其中的字符串变量。可以使用-a来禁用这种替换。如： 123456789[root@xuexi data]# mysqldumpslow xuexi-slow.log Reading mysql slow query log from xuexi-slow.logCount: 1 Time=10.00s (10s) Lock=0.00s (0s) Rows=1.0 (1), root[root]@localhost select sleep(N)[root@xuexi data]# mysqldumpslow -a xuexi-slow.log Reading mysql slow query log from xuexi-slow.logCount: 1 Time=10.00s (10s) Lock=0.00s (0s) Rows=1.0 (1), root[root]@localhost select sleep(10) 显然，这里归类后的结果只是精确到0.01秒的，如果想要显示及其精确的秒数，则使用-d选项启用调试功能。 12345678910111213141516171819202122232425262728293031[root@xuexi data]# mysqldumpslow -d xuexi-slow.log Reading mysql slow query log from xuexi-slow.log[[/usr/local/mysql/bin/mysqld, Version: 5.6.35-log (MySQL Community Server (GPL)). started with:Tcp port: 3306 Unix socket: /mydata/data/mysql.sockTime Id Command Argument# Time: 170329 9:55:58# User@Host: root[root] @ localhost [] Id: 1# Query_time: 10.000847 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use test;SET timestamp=1490752558;select sleep(10);]]&lt;&lt;&gt;&gt;&lt;&lt;# Time: 170329 9:55:58# User@Host: root[root] @ localhost [] Id: 1# Query_time: 10.000847 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use test;SET timestamp=1490752558;select sleep(10);&gt;&gt; at /usr/local/mysql/bin/mysqldumpslow line 97, &lt;&gt; chunk 1.[[# Time: 170329 9:55:58# User@Host: root[root] @ localhost [] Id: 1# Query_time: 10.000847 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use test;SET timestamp=1490752558;select sleep(10);]]&#123;&#123; select sleep(N)&#125;&#125;Count: 1 Time=10.00s (10s) Lock=0.00s (0s) Rows=1.0 (1), root[root]@localhost select sleep(N) 慢查询在SQL语句调优的时候非常有用，应该将它启用起来。二进制日志二进制日志文件 二进制日志包含了引起或可能引起数据库改变(如delete语句但没有匹配行)的事件信息，但绝不会包括select和show这样的查询语句。语句以”事件”的形式保存，所以包含了时间、事件开始和结束位置等信息。 二进制日志是以事件形式记录的，不是事务日志(但可能是基于事务来记录二进制日志)，不代表它只记录innodb日志，myisam表也一样有二进制日志。 二进制日志只在事务提交的时候一次性写入(基于事务的innodb二进制日志)。 MariaDB/MySQL默认没有启动二进制日志，要启用二进制日志使用 –log-bin=[on|off|file_name] 选项指定，如果没有给定file_name，则默认为datadir下的主机名加”-bin”，并在后面跟上一串数字表示日志序列号，如果给定的日志文件中包含了后缀(logname.suffix)将忽略后缀部分。 或者在配置文件中的[mysqld]部分设置log-bin也可以。注意：对于mysql 5.7，直接启动binlog可能会导致mysql服务启动失败，这时需要在配置文件中的mysqld为mysql实例分配server_id。 123[mysqld] # server_id=1234 log-bin=[on|filename] mysqld还创建一个二进制日志索引文件，当二进制日志文件滚动的时候会向该文件中写入对应的信息。所以该文件包含所有使用的二进制日志文件的文件名。默认情况下该文件与二进制日志文件的文件名相同，扩展名为’.index’。要指定该文件的文件名使用 –log-bin-index[=file_name] 选项。当mysqld在运行时不应手动编辑该文件，免得mysqld变得混乱。 当重启mysql服务或刷新日志或者达到日志最大值时，将滚动二进制日志文件，滚动日志时只修改日志文件名的数字序列部分。 二进制日志文件的最大值通过变量 max_binlog_size 设置(默认值为1G)。但由于二进制日志可能是基于事务来记录的(如innodb表类型)，而事务是绝对不可能也不应该跨文件记录的，如果正好二进制日志文件达到了最大值但事务还没有提交则不会滚动日志，而是继续增大日志，所以 max_binlog_size 指定的值和实际的二进制日志大小不一定相等。 因为二进制日志文件增长迅速，但官方说明因此而损耗的性能小于1%，且二进制目的是为了恢复定点数据库和主从复制，所以出于安全和功能考虑，极不建议将二进制日志和datadir放在同一磁盘上。 查看二进制日志 MySQL中查看二进制日志的方法主要有几种。 1.使用mysqlbinlog工具。 2.使用show显示对应的信息。 12345SHOW &#123;BINARY | MASTER&#125; LOGS # 查看使用了哪些日志文件 SHOW BINLOG EVENTS [IN &apos;log_name&apos;] [FROM pos] # 查看日志中进行了哪些操作 SHOW MASTER STATUS # 显式主服务器中的二进制日志信息 mysqlbinlog 二进制日志可以使用mysqlbinlog命令查看。 12mysqlbinlog [option] log-file1 log-file2... 以下是常用的几个选项： 123456789101112131415-d,--database=name：只查看指定数据库的日志操作 -o,--offset=#：忽略掉日志中的前n个操作命令 -r,--result-file=name：将输出的日志信息输出到指定的文件中，使用重定向也一样可以。 -s,--short-form：显示简单格式的日志，只记录一些普通的语句，会省略掉一些额外的信息如位置信息和时间信息以及基于行的日志。可以用来调试，生产环境千万不可使用 --set-charset=char_name：在输出日志信息到文件中时，在文件第一行加上set names char_name --start-datetime,--stop-datetime：指定输出开始时间和结束时间内的所有日志信息 --start-position=#,--stop-position=#：指定输出开始位置和结束位置内的所有日志信息 -v,-vv：显示更详细信息，基于row的日志默认不会显示出来，此时使用-v或-vv可以查看 在进行测试之前，先对日志进行一次刷新，以方便解释二进制日志的信息。 1shell&gt; mysqladmin -uroot -p refresh 假设现在的日志文件是mysql-bin.000001，里面暂时只有一些初始信息，没有记录任何操作过的记录。 下面是每个二进制日志文件的初始信息。可以看到记录了时间和位置信息(at 4)。 12345678910111213141516171819[root@xuexi data]# mysqlbinlog mysql-bin.000001 /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#170329 2:18:10 server id 1 end_log_pos 120 CRC32 0x40f62523 Start: binlog v 4, server v 5.6.35-log created 170329 2:18:10 at startup# Warning: this binlog is either in use or was not closed properly.ROLLBACK/*!*/;BINLOG &apos;4qjaWA8BAAAAdAAAAHgAAAABAAQANS42LjM1LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADiqNpYEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAASMl9kA=&apos;/*!*/;DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 现在在数据库中执行下面的操作：1234use test;create table student(studentid int not null primary key,name varchar(30) not null,gender enum(&apos;female&apos;,&apos;mail&apos;));alter table student change gender gender enum(&apos;female&apos;,&apos;male&apos;);insert into student values(1,&apos;malongshuai&apos;,&apos;male&apos;),(2,&apos;gaoxiaofang&apos;,&apos;female&apos;); 再查看二进制日志信息。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@xuexi data]# mysqlbinlog mysql-bin.000001 /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#170329 2:18:10 server id 1 end_log_pos 120 CRC32 0x40f62523 Start: binlog v 4, server v 5.6.35-log created 170329 2:18:10 at startup# Warning: this binlog is either in use or was not closed properly.ROLLBACK/*!*/;BINLOG &apos;4qjaWA8BAAAAdAAAAHgAAAABAAQANS42LjM1LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADiqNpYEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAASMl9kA=&apos;/*!*/;# at 120#170329 5:20:00 server id 1 end_log_pos 305 CRC32 0xbac43912 Query thread_id=1 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1490736000/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;create table student(studentid int not null primary key,name varchar(30) not null,gender enum(&apos;female&apos;,&apos;mail&apos;))/*!*/;# at 305#170329 5:21:21 server id 1 end_log_pos 441 CRC32 0xde67f702 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736081/*!*/;alter table student change gender gender enum(&apos;female&apos;,&apos;male&apos;)/*!*/;# at 441#170329 5:21:33 server id 1 end_log_pos 520 CRC32 0x05a9c5a1 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;BEGIN/*!*/;# at 520#170329 5:21:33 server id 1 end_log_pos 671 CRC32 0xad9e7dc8 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;insert into student values(1,&apos;malongshuai&apos;,&apos;male&apos;),(2,&apos;gaoxiaofang&apos;,&apos;female&apos;)/*!*/;# at 671#170329 5:21:33 server id 1 end_log_pos 702 CRC32 0xb69b0f7d Xid = 32COMMIT/*!*/;DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 将上述信息整理为下图：其中timestamp记录的是从1970-01-01到现在的总秒数时间戳，可以使用 date -d ‘@1490736093’ 转换。 位置0-120记录的是二进制日志的一些固定信息。 位置120-305记录的是use和create table语句，语句的记录时间为5:20:00。但注意，这里的use不是执行的use语句，而是MySQL发现要操作的数据库为test，而自动进行的操作并记录下来。人为的use语句是不会记录的。 位置305-441记录的是alter table语句，语句的记录时间为5:20:21。 位置441-702记录的是insert操作，因为该操作是DML语句，因此记录了事务的开始BEGIN和提交COMMIT。begin的起止位置为441-520；insert into语句的起止位置为520-671，记录的时间和自动开启事务的begin时间是一样的；commit的起止位置为671-702。 使用-r命令将日志文件导入到指定文件中，使用重定向也可以实现同样的结果。并使用-s查看简化的日志文件。 12[root@xuexi data]# mysqlbinlog mysql-bin.000001 -r /tmp/binlog.000001[root@xuexi data]# mysqlbinlog mysql-bin.000001 -s&gt;/tmp/binlog.sample 比较这两个文件，看看简化的日志文件简化了哪些东西。 从上图中可以看出，使用-s后，少了基于行的日志信息，也少了记录的位置和时间信息。 使用-o可以忽略前N个条目，例如上面的操作涉及了6个操作。忽略掉前3个后的日志显示如下：可以看到直接从位置441开始显示了。 1234567891011121314151617181920212223242526272829[root@xuexi data]# mysqlbinlog mysql-bin.000001 -o 3...前面固定部分省略...&apos;/*!*/;# at 441#170329 5:21:33 server id 1 end_log_pos 520 CRC32 0x05a9c5a1 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 520#170329 5:21:33 server id 1 end_log_pos 671 CRC32 0xad9e7dc8 Query thread_id=1 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1490736093/*!*/;insert into student values(1,&apos;malongshuai&apos;,&apos;male&apos;),(2,&apos;gaoxiaofang&apos;,&apos;female&apos;)/*!*/;# at 671#170329 5:21:33 server id 1 end_log_pos 702 CRC32 0xb69b0f7d Xid = 32COMMIT/*!*/;DELIMITER ;...后面固定部分省略... 使用-d可以只显示指定数据库相关的操作。例如先切换到其他数据库进行一番操作，然后再使用-d查看日志。 1234567891011121314151617181920212223242526272829303132mysql&gt; use mysql;mysql&gt; create table mytest(id int);[root@xuexi data]# mysqlbinlog mysql-bin.000001 -d mysql...前固定部分省略...&apos;/*!*/;# at 120# at 305# at 441#170329 5:21:33 server id 1 end_log_pos 520 CRC32 0x05a9c5a1 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 520# at 671#170329 5:21:33 server id 1 end_log_pos 702 CRC32 0xb69b0f7d Xid = 32COMMIT/*!*/;# at 702#170329 6:27:12 server id 1 end_log_pos 805 CRC32 0x491529ff Query thread_id=1 exec_time=0 error_code=0use `mysql`/*!*/;SET TIMESTAMP=1490740032/*!*/;create table mytest(id int)/*!*/;DELIMITER ;...后面固定部分省略... 可以看到，除了指定的mysql数据库的信息输出了，还非常简化的输出了其他数据库的信息。 mysqlbinlog最有用的两个选项就是指定时间和位置来输出日志。 指定时间时，将输出指定时间范围内的日志。指定的时间可以不和日志中记录的日志相同。 123456789101112131415161718192021222324[root@xuexi data]# mysqlbinlog mysql-bin.000001 --start-datetime=&apos;2017-03-28 00:00:01&apos; --stop-datetime=&apos;2017-03-29 05:21:23&apos;...前面固定部分省略...&apos;/*!*/;# at 120#170329 5:20:00 server id 1 end_log_pos 305 CRC32 0xbac43912 Query thread_id=1 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1490736000/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;create table student(studentid int not null primary key,name varchar(30) not null,gender enum(&apos;female&apos;,&apos;mail&apos;))/*!*/;# at 305#170329 5:21:21 server id 1 end_log_pos 441 CRC32 0xde67f702 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736081/*!*/;alter table student change gender gender enum(&apos;female&apos;,&apos;male&apos;)/*!*/;DELIMITER ;...后面固定部分省略... 同理指定位置也一样，但是指定位置时有个要求是如果指定起始位置，则必须指定日志文件中明确的起始位置。例如，日志文件中有位置120、305、441，可以指定起始和结束位置为120、500，但是不可以指定起止位置为150、500，因为日志文件中不存在150这个位置。 123456789101112131415161718192021222324252627282930[root@xuexi data]# mysqlbinlog mysql-bin.000001 --start-position=150 --stop-position=441...前面固定部分省略...&apos;/*!*/;ERROR: Error in Log_event::read_log_event(): &apos;read error&apos;, data_len: 4202496, event_type: 0...后面固定部分省略... [root@xuexi data]# mysqlbinlog mysql-bin.000001 --start-position=305 --stop-position=500...前面固定部分省略... &apos;/*!*/;# at 305#170329 5:21:21 server id 1 end_log_pos 441 CRC32 0xde67f702 Query thread_id=1 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1490736081/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;alter table student change gender gender enum(&apos;female&apos;,&apos;male&apos;)/*!*/;# at 441#170329 5:21:33 server id 1 end_log_pos 520 CRC32 0x05a9c5a1 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;BEGIN/*!*/;DELIMITER ;...后面固定部分省略... show binary logs 该语句用于查看当前使用了哪些二进制日志文件。 可以通过查看二进制的index文件来查看当前正在使用哪些二进制日志。 12345[root@xuexi data]# cat mysql-bin.index ./mysql-bin.000003./mysql-bin.000004./mysql-bin.000005./mysql-bin.000006 也可以在mysql环境中使用 show {binary | master} logs 来查看。binary和master是同义词。 123456789mysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000003 | 167 || mysql-bin.000004 | 785 || mysql-bin.000005 | 1153 || mysql-bin.000006 | 602 |+------------------+----------- show binlog events 该语句用于查看日志中进行了哪些操作。 1mysql&gt; show binlog events in &apos;mysql-bin.000005&apos;; 可以指定起始位置。同样，起始位置必须指定正确，不能指定不存在的位置。123456789mysql&gt; show binlog events in &apos;mysql-bin.000005&apos; from 961;+------------------+------+------------+-----------+-------------+--------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+------------------+------+------------+-----------+-------------+--------------------------------+| mysql-bin.000005 | 961 | Table_map | 1 | 1019 | table_id: 98 (test.student) || mysql-bin.000005 | 1019 | Write_rows | 1 | 1075 | table_id: 98 flags: STMT_END_F || mysql-bin.000005 | 1075 | Xid | 1 | 1106 | COMMIT /* xid=129 */ || mysql-bin.000005 | 1106 | Rotate | 1 | 1153 | mysql-bin.000006;pos=4 |+------------------+------+------------+-----------+-------------+--------------------------------+ show master status 该语句用于显示主服务器中的二进制日志信息。如果是主从结构，它只会显示主从结构中主服务器的二进制日志信息。 123456mysql&gt; show master status; +------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000006 | 602 | | | |+------------------+----------+--------------+------------------+-------------------+ 可以查看到当前正在使用的日志及下一事件记录的开始位置，还能查看到哪些数据库需要记录二进制日志，哪些数据库不记录二进制日志。 删除二进制日志删除二进制日志有几种方法。不管哪种方法，都会将删除后的信息同步到二进制index文件中。reset master将会删除所有日志，并让日志文件重新从000001开始。1mysql&gt; reset master; PURGE { BINARY | MASTER } LOGS { TO ‘log_name’ | BEFORE datetime_expr } purge master logs to “binlog_name.00000X” 将会清空00000X之前的所有日志文件。例如删除000006之前的日志文件。 12mysql&gt; purge master logs to &quot;mysql-bin.000006&quot;;mysql&gt; purge binary logs to &quot;mysql-bin.000006&quot;; master和binary是同义词 purge master logs before ‘yyyy-mm-dd hh:mi:ss’ 将会删除指定日期之前的所有日志。但是若指定的时间处在正在使用中的日志文件中，将无法进行purge。 12345678mysql&gt; purge master logs before &apos;2017-03-29 07:36:40&apos;;mysql&gt; show warnings;+---------+------+---------------------------------------------------------------------------+| Level | Code | Message |+---------+------+---------------------------------------------------------------------------+| Warning | 1868 | file ./mysql-bin.000003 was not purged because it is the active log file. |+---------+------+---------------------------------------------------------------------------+ 使用–expire_logs_days=N选项指定过了多少天日志自动过期清空。二进制日志的记录格式 在MySQL 5.1之前，MySQL只有一种基于语句statement形式的日志记录格式。即将所有的相关操作记录为SQL语句形式。但是这样的记录方式对某些特殊信息无法同步记录，例如uuid，now()等这样动态变化的值。 从MySQL 5.1开始，MySQL支持statement、row、mixed三种形式的记录方式。row形式是基于行来记录，也就是将相关行的每一列的值都在日志中保存下来，这样的结果会导致日志文件变得非常大，但是保证了动态值的确定性。还有一种mixed形式，表示如何记录日志由MySQL自己来决定。 日志的记录格式由变量 binlog_format 来指定。其值有：row,statement,mixed。innodb引擎的创始人之一在博客上推荐使用row格式。 下面将记录格式改为row。1234mysql&gt; alter table student add birthday datetime default now();mysql&gt; flush logs;mysql&gt; set binlog_format=&apos;row&apos;;mysql&gt; insert into student values(7,&apos;xiaowoniu&apos;,&apos;female&apos;,now()); 查看产生的日志。1234567891011121314151617181920212223242526272829303132[root@xuexi data]# mysqlbinlog mysql-bin.000005...前面固定部分省略...&apos;/*!*/;# at 120#170329 8:06:24 server id 1 end_log_pos 200 CRC32 0x0ac02649 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490745984/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.time_zone=&apos;SYSTEM&apos;/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 200#170329 8:06:24 server id 1 end_log_pos 258 CRC32 0xb8cdfd09 Table_map: `test`.`student` mapped to number 94# at 258#170329 8:06:24 server id 1 end_log_pos 314 CRC32 0x8ce6f72c Write_rows: table id 94 flags: STMT_END_FBINLOG &apos;gPraWBMBAAAAOgAAAAIBAAAAAF4AAAAAAAEABHRlc3QAB3N0dWRlbnQABAMP/hIFHgD3AQAMCf3NuA==gPraWB4BAAAAOAAAADoBAAAAAF4AAAAAAAEAAgAE//AHAAAACXhpYW93b25pdQGZnDqBmCz35ow=&apos;/*!*/;# at 314#170329 8:06:24 server id 1 end_log_pos 345 CRC32 0x7a48c057 Xid = 114COMMIT/*!*/;DELIMITER ;...后面固定部分省略... 发现是一堆看不懂的东西，使用-vv可将这些显示出来。可以看出，结果中记录的非常详细，这也是为什么基于row记录日志会导致日志文件极速变大。 123456789101112131415[root@xuexi data]# mysqlbinlog mysql-bin.000005 -vv...前面省略...BINLOG &apos;gPraWBMBAAAAOgAAAAIBAAAAAF4AAAAAAAEABHRlc3QAB3N0dWRlbnQABAMP/hIFHgD3AQAMCf3NuA==gPraWB4BAAAAOAAAADoBAAAAAF4AAAAAAAEAAgAE//AHAAAACXhpYW93b25pdQGZnDqBmCz35ow=&apos;/*!*/;### INSERT INTO `test`.`student`### SET### @1=7 /* INT meta=0 nullable=0 is_null=0 */### @2=&apos;xiaowoniu&apos; /* VARSTRING(30) meta=30 nullable=0 is_null=0 */### @3=1 /* ENUM(1 byte) meta=63233 nullable=1 is_null=0 */### @4=&apos;2017-03-29 08:06:24&apos; /* DATETIME(0) meta=0 nullable=1 is_null=0 */# at 314...后面省略... 还有一种mixed模式。这种模式下默认会采用statement的方式记录，只有以下几种情况会采用row的形式来记录日志。 1.表的存储引擎为NDB，这时对表的DML操作都会以row的格式记录。 2.使用了uuid()、user()、current_user()、found_rows()、row_count()等不确定函数。但测试发现对now()函数仍会以statement格式记录，而sysdate()函数会以row格式记录。 3.使用了insert delay语句。 4.使用了临时表。 二进制日志相关的变量注意：在配置binlog相关变量的时候，相关变量名总是搞混，因为有的是binlog，有的是log_bin，当他们分开的时候，log在前，当它们一起的时候，bin在前。在配置文件中也同样如此。 log_bin = {on | off | base_name} #指定是否启用记录二进制日志或者指定一个日志路径(路径不能加.否则.后的被忽略) sql_log_bin ={ on | off } #指定是否启用记录二进制日志，只有在log_bin开启的时候才有效 expire_logs_days = #指定自动删除二进制日志的时间，即日志过期时间 binlog_do_db = #明确指定要记录日志的数据库 binlog_ignore_db = #指定不记录二进制日志的数据库 log_bin_index = #指定mysql-bin.index文件的路径 binlog_format = { mixed | row | statement } #指定二进制日志基于什么模式记录 binlog_rows_query_log_events = { 1|0 } # MySQL5.6.2添加了该变量，当binlog format为row时，默认不会记录row对应的SQL语句，设置为1或其他true布尔值时会记录，但需要使用mysqlbinlog -v查看，这些语句是被注释的，恢复时不会被执行。 max_binlog_size = #指定二进制日志文件最大值，超出指定值将自动滚动。但由于事务不会跨文件，所以并不一定总是精确。 binlog_cache_size = 32768 #基于事务类型的日志会先记录在缓冲区，当达到该缓冲大小时这些日志会写入磁盘 max_binlog_cache_size = #指定二进制日志缓存最大大小，硬限制。默认4G，够大了，建议不要改 binlog_cache_use：使用缓存写二进制日志的次数(这是一个实时变化的统计值) binlog_cache_disk_use:使用临时文件写二进制日志的次数，当日志超过了binlog_cache_size的时候会使用临时文件写日志，如果该变量值不为0，则考虑增大binlog_cache_size的值 binlog_stmt_cache_size = 32768 #一般等同于且决定binlog_cache_size大小，所以修改缓存大小时只需修改这个而不用修改binlog_cache_size binlog_stmt_cache_use：使用缓存写二进制日志的次数 binlog_stmt_cache_disk_use: 使用临时文件写二进制日志的次数，当日志超过了binlog_cache_size的时候会使用临时文件写日志，如果该变量值不为0，则考虑增大binlog_cache_size的值 sync_binlog = { 0 | n } #这个参数直接影响mysql的性能和完整性sync_binlog=0:不同步，日志何时刷到磁盘由FileSystem决定，这个性能最好。sync_binlog=n:每写n次二进制日志事件(不是事务)，MySQL将执行一次磁盘同步指令fdatasync()将缓存日志刷新到磁盘日志文件中。Mysql中默认的设置是sync_binlog=0，即不同步，这时性能最好，但风险最大。一旦系统奔溃，缓存中的日志都会丢失。 在innodb的主从复制结构中，如果启用了二进制日志(几乎都会启用)，要保证事务的一致性和持久性的时候，必须将sync_binlog的值设置为1，因为每次事务提交都会写入二进制日志，设置为1就保证了每次事务提交时二进制日志都会写入到磁盘中，从而立即被从服务器复制过去。二进制日志定点还原数据库 只需指定二进制日志的起始位置（可指定终止位置）并将其保存到sql文件中，由mysql命令来载入恢复即可。当然直接通过管道送给mysql命令也可。 至于是基于位置来恢复还是基于时间点来恢复，这两种行为都可以。选择时间点来恢复比较直观些，并且跨日志文件恢复时更方便。 1mysqlbinlog --stop-datetime=&quot;2014-7-2 15:27:48&quot; /tmp/mysql-bin.000008 | mysql -u user -p password 恢复多个二进制日志文件时： 1mysqlbinlog mysql-bin.[*] | mysql -uroot -p password 或者将它们导入到一个文件中后恢复。 123mysqlbinlog mysql-bin.000001 &gt; /tmp/a.sqlmysqlbinlog mysql-bin.000002 &gt;&gt;/tmp/a.sqlmysql -u root -p password -e &quot;source /tmp/a.sql&quot;","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"MYSQL","slug":"MYSQL","permalink":"http://yoursite.com/tags/MYSQL/"}]},{"title":"MYSQL MariaDB 的事务和事务隔离级别","slug":"MYSQL MariaDB 的事务和事务隔离级别","date":"2017-05-14T16:00:00.000Z","updated":"2018-06-18T09:44:33.026Z","comments":true,"path":"2017/05/15/MYSQL MariaDB 的事务和事务隔离级别/","link":"","permalink":"http://yoursite.com/2017/05/15/MYSQL MariaDB 的事务和事务隔离级别/","excerpt":"事务特性事务具有ACID特性：原子性(A,atomicity)、一致性(C,consistency)、隔离性(I,isolation)、持久性(D,durabulity)。原子性：事务内的所有操作要么都执行，要么都不执行。一致性：事务开始和结束前后，数据都满足数据一致性约束，而不是经过事务控制之后数据变得不满足条件或业务规则。隔离性：事务之间不能互影响，它们必须完全的各行其道，互不可见。","text":"事务特性事务具有ACID特性：原子性(A,atomicity)、一致性(C,consistency)、隔离性(I,isolation)、持久性(D,durabulity)。原子性：事务内的所有操作要么都执行，要么都不执行。一致性：事务开始和结束前后，数据都满足数据一致性约束，而不是经过事务控制之后数据变得不满足条件或业务规则。隔离性：事务之间不能互影响，它们必须完全的各行其道，互不可见。 持久性：事务完成后，该事务内涉及的数据必须持久性的写入磁盘保证其持久性。当然，这是从事务的角度来考虑的的持久性，从操作系统故障或硬件故障来说，这是不一定的。事务分类 扁平事务带保存点的扁平事务链事务嵌套事务分布式事务 扁平事务 即最常见的事务。由begin开始，commit或rollback结束，中间的所有操作要么都回滚要么都提交。扁平事务在生产环境中占绝大多数使用情况。因此每一种数据库产品都支持扁平事务。 扁平事务的缺点在于无法回滚或提交一部分，只能全部回滚或全部提交，所以就有了”带有保存点”的扁平事务。 带有保存点的扁平事务通过在事务内部的某个位置使用savepoint，将来可以在事务中回滚到此位置。 MariaDB/MySQL中设置保存点的命令为: 1savepoint [savepoint_name] 回滚到指定保存点的命令为： 1rollback to savepoint_name 删除一个保存点的命令为： 1release savepoint savepoint_name 实际上，扁平事务也是有保存点的，只不过它只有一个隐式的保存点，且自动建立在事务开始的位置，因此扁平事务只能回滚到事务开始处。 链式事务 链式事务是保存点扁平事务的变种。它在一个事务提交的时候自动隐式的将上下文传给下一个事务，也就是说一个事务的提交和下一个事务的开始是原子性的，下一个事务可以看到上一个事务的处理结果。通俗地说，就是事务的提交和事务的开始是链接式下去的。 这样的事务类型，在提交事务的时候，会释放要提交事务内所有的锁和要提交事务内所有的保存点。因此链式事务只能回滚到当前所在事务的保存点，而不能回滚到已提交的事务中的保存点。 嵌套事务 嵌套事务由一个顶层事务控制所有的子事务。子事务的提交完成后不会真的提交，而是等到顶层事务提交才真正的提交。 关于嵌套事务的机制，主要有以下3个结论： 回滚内部事务的同时会回滚到外部事务的起始点。 事务提交时从内向外依次提交。 回滚外部事务的同时会回滚所有事务，包括已提交的内部事务。因为只提交内部事务时没有真的提交。 不管怎么样，最好少用嵌套事务。且MariaDB/MySQL不原生态支持嵌套事务(SQL Server支持)。分布式事务将多个服务器上的事务(节点)组合形成一个遵循事务特性(acid)的分布式事务。 例如在工行atm机转账到建行用户。工行atm机所在数据库是一个事务节点A，建行数据库是一个事务节点B，仅靠工行atm机是无法完成转账工作的，因为它控制不了建行的事务。所以它们组成一个分布式事务： 1.atm机发出转账口令。2.atm机从工行用户减少N元。3.在建行用户增加N元。4.在atm机上返回转账成功或失败。 上面涉及了两个事务节点，这些事务节点之间的事务必须同时具有acid属性，要么所有的事务都成功，要么所有的事务都失败，不能只成功atm机的事务，而建行的事务失败。 MariaDB/MySQL的分布式事务使用两段式提交协议(2-phase commit,2PC)。最重要的是，MySQL 5.7.7之前，MySQL对分布式事务的支持一直都不完善(第一阶段提交后不会写binlog，导致宕机丢失日志)，这个问题持续时间长达数十年，直到MySQL 5.7.7，才完美支持分布式事务。相关内容可参考网上一篇文章：https://www.linuxidc.com/Linux/2016-02/128053.htm。遗憾的是，MariaDB至今(MariaDB 10.3.6)都没有解决这个问题。 事务控制语句 begin 和 start transaction表示显式开启一个事务。它们之间并没有什么区别，但是在存储过程中，begin会被识别成begin…end的语句块，所以存储过程只能使用start transaction来显式开启一个事务。 commit 和 commit work用于提交一个事务。 rollbac 和 rollback work用于回滚一个事务。 savepoint identifier表示在事务中创建一个保存点。一个事务中允许存在多个保存点。 release savepoint identifier表示删除一个保存点。当要删除的保存点不存在的时候会抛出异常。 rollback to savepoint表示回滚到指定的保存点，回滚到保存点后，该保存点之后的所有操纵都被回滚。注意，rollback to不会结束事务，只是回到某一个保存点的状态。 set transaction用来设置事务的隔离级别。可设置的隔离级别有read uncommitted/read committed/repeatable read/serializable。 commit与commit work以及rollback与rollback work作用是一样的。但是他们的作用却和变量 completion_type的值有关。 ######例如将completion_type设置为1，进行测试。 12345678910111213mysql&gt; set completion_type=1;mysql&gt; begin;mysql&gt; insert into ttt values(1000);mysql&gt; commit work;mysql&gt; insert into ttt values(2000);mysql&gt; rollback;mysql&gt; select * from ttt where id&gt;=1000;+------+| id |+------+| 1000 |+------+1 row in set (0.00 sec) begin开始事务后，插入了值为1000的记录，commit work了一次，然后再插入了值为2000的记录后rollback，查询结果结果中只显示了1000，而没有2000，因为commit work提交后自动又开启了一个事务，使用rollback会回滚该事务。 将completion_type设置为2，进行测试。1234mysql&gt; set completion_type=2;mysql&gt; begin;mysql&gt; insert into ttt select 1000;mysql&gt; commit; 提交后，再查询或者进行其他操作，结果提示已经和MariaDB/MySQL服务器断开连接了。123mysql&gt; select * from ttt;ERROR 2006 (HY000): MySQL server has gone awayNo connection. Trying to reconnect... 显式事务的次数统计通过全局状态变量com_commit和com_rollback可以查看当前已经显式提交和显式回滚事务的次数。还可以看到回滚到保存点的次数。12345678910111213mysql&gt; show global status like &quot;%com_commit%&quot;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_commit | 14 |+---------------+-------+mysql&gt; show global status like &quot;%com_rollback%&quot;;+---------------------------+-------+| Variable_name | Value |+---------------------------+-------+| Com_rollback | 24 || Com_rollback_to_savepoint | 0 |+---------------------------+-------+ 一致性非锁定读(快照查询) 在innodb存储引擎中，存在一种数据查询方式：快照查询。因为查询的是快照数据，所以查询时不申请共享锁。 当进行一致性非锁定读查询的时候，查询操作不会去等待记录上的独占锁释放，而是直接去读取快照数据。快照数据是通过undo段来实现的，因此它基本不会产生开销。显然，通过这种方式，可以极大的提高读并发性。 快照数据其实是行版本数据，一个行记录可能会存在多个行版本，并发时这种读取行版本的方式称为多版本并发控制(MVCC)。在隔离级别为read committed和repeatable read时，采取的查询方式就是一致性非锁定读方式。但是，不同的隔离级别下，读取行版本的方式是不一样的。在后面介绍对应的隔离级别时会作出说明。 下面是在innodb默认的隔离级别是repeatable read下的实验，该隔离级别下，事务总是在开启的时候获取最新的行版本，并一直持有该版本直到事务结束。更多的”一致性非锁定读”见后文说明read committed和repeatable read部分。 当前示例表ttt的记录如下：1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 在会话1执行：12mysql&gt; begin;mysql&gt; update ttt set id=100 where id=1 在会话2中执行：12345678mysql&gt; begin;mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 查询的结果和预期的一样，来自开启事务前最新提交的行版本数据。 回到会话1提交事务： 1mysql&gt; commit; 再回到会话2中查询： 1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 再次去会话1更新该记录： 123mysql&gt; begin;mysql&gt; update ttt set id=1000 where id=100;mysql&gt; commit; 再回到会话2执行查询： 1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 这就是repeatable read隔离级别下的一致性非锁定读的特性。 当然，MySQL也支持一致性锁定读的方式。 一致性锁定读 在隔离级别为read committed和repeatable read时，采取的查询方式就是一致性非锁定读方式。但是在某些情况下，需要人为的对读操作进行加锁。MySQL中对这种方式的支持是通过在select语句后加上lock in share mode或者for update。 select … from … where … lock in share mode; select …from … where … for update; 使用lock in share mode会对select语句要查询的记录加上一个共享锁(S)，使用for update语句会对select语句要查询的记录加上独占锁(X)。 另外，对于一致性非锁定读操作，即使要查询的记录已经被for update加上了独占锁，也一样可以读取，就和纯粹的update加的锁一样，只不过此时读取的是快照数据而已。 事务隔离级别 SQL标准定义了4中隔离级别：read uncommitted、read committed、repeatable read、serializable。 MariaDB/MySQL也支持这4种隔离级别。但是要注意的是，MySQL中实现的隔离级别和SQL Server实现的隔离级别在同级别上有些差别。在后面有必要说明地方会给出它们的差异之处。 MariaDB/MySQL中默认的隔离级别是repeatable read，SQL Server和oracle的默认隔离级别都是read committed。 事务特性(ACID)中的隔离性(I,isolation)就是隔离级别，它通过锁来实现。也就是说，设置不同的隔离级别，其本质只是控制不同的锁行为。例如操作是否申请锁，什么时候申请锁，申请的锁是立刻释放还是持久持有直到事务结束才释放等。 设置和查看事务隔离级别 隔离级别是基于会话设置的，当然也可以基于全局进行设置，设置为全局时，不会影响当前会话的级别。设置的方法是： 123set [global | session] transaction isolation level &#123;type&#125;type: read uncommitted | read committed | repeatable read | serializable 或者直接修改变量值也可以： 12set @@global.tx_isolation = &apos;read-uncommitted&apos; | &apos;read-committed&apos; | &apos;repeatable-read&apos; | &apos;serializable&apos;set @@session.tx_isolation = &apos;read-uncommitted&apos; | &apos;read-committed&apos; | &apos;repeatable-read&apos; | &apos;serializable&apos; 查看当前会话的隔离级别方法如下： 12345678910111213mysql&gt; select @@tx_isolation;mysql&gt; select @@global.tx_isolation;mysql&gt; select @@tx_isolation;select @@global.tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------++-----------------------+| @@global.tx_isolation |+-----------------------+| REPEATABLE-READ |+-----------------------+ 注意，事务隔离级别的设置只需在需要的一端设置，不用在两边会话都设置。例如想要让会话2的查询加锁，则只需在会话2上设置serializable，在会话1设置的serializable对会话2是没有影响的，这和SQL Server中一样。但是，MariaDB/MySQL除了serializable隔离级别，其他的隔离级别都默认会读取旧的行版本，所以查询永远不会造成阻塞。而SQL Server中只有基于快照的两种隔离级别才会读取行版本，所以在4种标准的隔离级别下，如果查询加的S锁被阻塞，查询会进入锁等待。 在MariaDB/MySQL中不会出现更新丢失的问题，因为独占锁一直持有直到事务结束。当1个会话开启事务A修改某记录，另一个会话也开启事务B修改该记录，该修改被阻塞，当事务A提交后，事务B中的更新立刻执行成功，但是执行成功后查询却发现数据并没有随着事务B的想法而改变，因为这时候事务B更新的那条记录已经不是原来的记录了。但是事务A回滚的话，事务B是可以正常更新的，但这没有丢失更新。 read uncommitted 该级别称为未提交读，即允许读取未提交的数据。 在该隔离级别下，读数据的时候不会申请读锁，所以也不会出现查询被阻塞的情况。 在会话1执行： 12345create table ttt(id int);insert into ttt select 1;insert into ttt select 2;begin;update ttt set id=10 where id=1; 如果会话1的隔离级别不是默认的，那么在执行update的过程中，可能会遇到以下错误： 1ERROR 1665 (HY000): Cannot execute statement: impossible to write to binary log since BINLOG_FORMAT = STATEMENT and at least one table uses a storage engine limited to row-based logging. InnoDB is limited to row-logging when transaction isolation level is READ COMMITTED or READ UNCOMMITTED. 这是read committed和read uncommitted两个隔离级别只允许row格式的二进制日志记录格式。而当前的二进制日志格式记录方式为statement时就会报错。要解决这个问题，只要将格式设置为row或者mixed即可。 1set @@session.binlog_format=row; 在会话2执行： 12345678set transaction isolation level read uncommitted;select * from ttt;+------+| id |+------+| 10 || 2 |+------+ 发现查询的结果是update后的数据，但是这个数据是会话1未提交的数据。这是脏读的问题，即读取了未提交的脏数据。 如果此时会话1进行了回滚操作，那么会话2上查询的结果又变成了id=1。 在会话1上执行： 1rollback; 在会话2上查询： 1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 这是读不一致问题。即同一个会话中对同一条记录的读取结果不一致。 read uncommitted一般不会在生产环境中使用，因为问题太多，会导致脏读、丢失的更新、幻影读、读不一致的问题。但由于不申请读锁，从理论上来说，它的并发性是最佳的。所以在某些特殊情况下还是会考虑使用该级别。 要解决脏读、读不一致问题，只需在查询记录的时候加上共享锁即可。这样在其他事务更新数据的时候就无法查询到更新前的记录。这就是read commmitted隔离级别。 read committed 对于熟悉SQL Server的人来说，在说明这个隔离级别之前，必须先给个提醒：MariaDB/MySQL中的提交读和SQL Server中的提交读完全不一样，MariaDB/MySQL中该级别基本类似于SQL Server中基于快照的提交读。 在SQL Server中，提交读的查询会申请共享锁，并且在查询结束的一刻立即释放共享锁，如果要查询的记录正好被独占锁锁住，则会进入锁等待，而没有被独占锁锁住的记录则可以正常查询。SQL Server中基于快照的提交读实现的是语句级的事务一致性，每执行一次操作事务序列号加1，并且每次查询的结果都是最新提交的行版本快照。 也就是说，MariaDB/MySQL中read committed级别总是会读取最新提交的行版本。这在MySQL的innodb中算是一个术语:”一致性非锁定读”，即只读取快照数据，不加共享锁。这在前文已经说明过。 MariaDB/MySQL中的read committed隔离级别下，除非是要检查外键约束或者唯一性约束需要用到gap lock算法，其他时候都不会用到。也就是说在此隔离级别下，一般来说只会对行进行锁定，不会锁定范围，所以会导致幻影读问题。 这里要演示的就是在该级别下，会不断的读取最新提交的行版本数据。 当前示例表ttt的记录如下：1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 在会话1中执行： 1begin;update ttt set id=100 where id=1; 在会话2中执行： 123set @@session.tx_isolation=&apos;read-committed&apos;;begin;select * from ttt; 会话2中查询得到的结果为id=1，因为查询的是最新提交的快照数据，而最新提交的快照数据就是id=1。 123456+------+| id |+------+| 1 || 2 |+------+ 现在将会话1中的事务提交。 在会话1中执行： 1commit; 在会话2中查询记录： 1234567select * from ttt;+------+| id |+------+| 100 || 2 |+------+ 结果为id=100，因为这个值是最新提交的。 再次在会话1中修改该值并提交事务。 在会话1中执行： 1begin;update ttt set id=1000 where id=100;commit; 在会话2中执行： 1234567select * from ttt;+------+| id |+------+| 1000 || 2 |+------+ 发现结果变成了1000，因为1000是最新提交的数据。 read committed隔离级别的行版本读取特性，在和repeatable read隔离级别比较后就很容易理解。 repeatable read 同样是和上面一样的废话，对于熟悉SQL Server的人来说，在说明这个隔离级别之前，必须先给个提醒：MariaDB/MySQL中的重复读和SQL Server中的重复读完全不一样，MariaDB/MySQL中该级别基本类似于SQL Server中快照隔离级别。 在SQL Server中，重复读的查询会申请共享锁，并且在查询结束的一刻不释放共享锁，而是持有到事务结束。所以会造成比较严重的读写并发问题。SQL Server中快照隔离级别实现的是事务级的事务一致性，每次事务开启的时候获取最新的已提交行版本，只要事务不结束，读取的记录将一直是该行版本中的数据，不管其他事务是否已经提交过对应的数据了。但是SQL Server中的快照隔离会有更新冲突：当检测到两边都想要更新同一记录时，会检测出更新冲突，这样会提前结束事务(进行的是回滚操作)而不用再显式地commit或者rollback。 也就是说，MariaDB/MySQL中repeatable read级别总是会在事务开启的时候读取最新提交的行版本，并将该行版本一直持有到事务结束。但是MySQL中的repeatable read级别下不会像SQL Server一样出现更新冲突的问题。 前文说过read committed隔离级别下，读取数据时总是会去获取最新已提交的行版本。这是这两个隔离级别在”一致性非锁定读”上的区别。 另外，MariaDB/MySQL中的repeatable read的加锁方式是next-key lock算法，它会进行范围锁定。这就避免了幻影读的问题(官方手册上说无法避免)。在标准SQL中定义的隔离级别中，需要达到serializable级别才能避免幻影读问题，也就是说MariaDB/MySQL中的repeatable read隔离级别已经达到了其他数据库产品(如SQL Server)的serializable级别，而且SQL Server中的serializable加范围锁时，在有索引的时候式锁范围比较不可控(你不知道范围锁锁住哪些具体的范围)，而在MySQL中是可以判断锁定范围的(见innodb锁算法)。 这里要演示的就是在该级别下，读取的行版本数据是不随提交而改变的。 当前示例表ttt的记录如下：1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 | +------+ 在会话1执行： 1begin;update ttt set id=100 where id=1 在会话2中执行： 12345678set @@session.tx_isolation=&apos;repeatable-read&apos;;begin;select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 查询的结果和预期的一样，来自开启事务前最新提交的行版本数据 回到会话1提交事务： 1commit; 再回到会话2中查询： 1234567select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 再次去会话1更新该记录： 1begin;update ttt set id=1000 where id=100;commit; 再回到会话2执行查询： 1234567select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 发现结果根本就不会改变，因为会话2开启事务时获取的行版本的id=1，所以之后读取的一直都是id=1所在的行版本。 serializable 在SQL Server中，serializable隔离级别会将查询申请的共享锁持有到事务结束，且申请的锁是范围锁，范围锁的情况根据表有无索引而不同：无索引时锁定整个表，有索引时锁定某些范围，至于锁定哪些具体的范围我发现是不可控的(至少我无法推测和计算)。这样就避免了幻影读的问题。 这种问题在MariaDB/MySQL中的repeatable read级别就已经实现了，MariaDB/MySQL中的next-key锁算法在加范围锁时也分有无索引：无索引时加锁整个表(实际上不是表而是无穷大区间的行记录)，有索引时加锁部分可控的范围。 MariaDB/MySQL中的serializable其实类似于repeatable read，只不过所有的select语句会自动在后面加上lock in share mode。也就是说会对所有的读进行加锁，而不是读取行版本的快照数据，也就不再支持”一致性非锁定读”。这样就实现了串行化的事务隔离：每一个事务必须等待前一个事务(哪怕是只有查询的事务)结束后才能进行哪怕只是查询的操作。 这个隔离级别对并发性来说，显然是有点太严格了。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"MYSQL","slug":"MYSQL","permalink":"http://yoursite.com/tags/MYSQL/"}]},{"title":"MASQL MariaDB 用户权限管理","slug":"MASQL MariaDB 用户权限管理","date":"2017-05-07T16:00:00.000Z","updated":"2018-06-18T06:20:32.651Z","comments":true,"path":"2017/05/08/MASQL MariaDB 用户权限管理/","link":"","permalink":"http://yoursite.com/2017/05/08/MASQL MariaDB 用户权限管理/","excerpt":"MariaDB/MySQL中的user由用户名和主机名构成，如”root@localhost”，同用户名但不同主机名对MySQL/MariaDB来讲是不同的，也就是说”root@localhost”和”root@127.0.0.1“是不同的用户，尽管它们都是本机的root。权限验证 在MariaDB/MySQL服务器启动后会载入权限表到内存中，当用户要连接服务器，会读取权限表来验证和分配权限，即在内存中进行权限的读取和写入。","text":"MariaDB/MySQL中的user由用户名和主机名构成，如”root@localhost”，同用户名但不同主机名对MySQL/MariaDB来讲是不同的，也就是说”root@localhost”和”root@127.0.0.1“是不同的用户，尽管它们都是本机的root。权限验证 在MariaDB/MySQL服务器启动后会载入权限表到内存中，当用户要连接服务器，会读取权限表来验证和分配权限，即在内存中进行权限的读取和写入。 MariaDB/MySQL中的权限系统经过两步验证： 1.合法性验证：验证user是否合法，合法者允许连接服务器，否则拒绝连接。2.权限验证和分配：对通过合法性验证的用户分配对数据库中各对象的操作权限。 权限表 MariaDB/MySQL中的权限表都存放在mysql数据库中。MySQL5.6以前，权限相关的表有user表、db表、host表、tables_priv表、columns_priv表、procs_priv表(存储过程和函数相关的权限)。从MySQL5.6开始，host表已经没有了。MariaDB中虽然有host表，但却不用。 这几个表用的最多的是user表。user表主要分为几个部分：用户列、权限列、安全列、资源控制列以及杂项列，最需要关注的是用户列和权限列。其中权限列又分为普通权限(上表中红色字体)和管理权限列，如select类的为普通权限，super权限为管理权限。且可以看到，db表中的权限全都是普通权限，user表中除了db表中具有的普通权限还有show_db_pirv和create_tablespace_priv，除此之外还有几个管理员权限。也就是说，db中没有的权限是无法授予到指定数据库的。例如不能授予super权限给test数据库。 另外，usage权限在上表中没有列出，因为该权限是所有用户都有的权限，它只用来表示能否登录数据库，它的一个特殊功能是grant仅指定该权限的时候不会影响现有权限，也就是说可以拿grant来修改密码而不影响现有权限。 需要说明的是，从user表到db表再到tables_priv表最后是columns_priv表，它们的权限是逐层细化的。user表中的普通权限是针对所有数据库的，例如在user表中的select_priv为Y，则对所有数据库都有select权限；db表是针对特定数据库中所有表的，如果只有test数据库中有select权限，那么db表中就有一条记录test数据库的select权限为Y，这样对test数据库中的所有表都有select权限，而此时user表中的select权限就为N(因为为Y的时候是所有数据库都有权限)；同理tables_priv表也一样，是针对特定表中所有列的权限；columns_priv则是针对特定列的权限。 所以对于已经通过身份合法性验证的用户的权限读取和分配的机制如下： 1.读取uesr表，看看user表是否有对应为Y的权限列，有则分配。 2.读取db表，看看db表中是否有哪个数据库分配了对应的权限。 3.读取tables_priv表，看看哪些表中有对应的权限。 4.读取columns_priv表，看看对哪些具体的列有什么权限。 例如，为某一用户授予test数据库的select权限。可以看到user表中的select_priv为N，而db表中的select为Y。123GRANT SELECT ON test.* TO &apos;long&apos;@&apos;192.168.100.1&apos; IDENTIFIED BY &apos;123456&apos;;SELECT host,user,select_priv FROM mysql.user;SELECT * FROM mysql.db; 图解认证和权限分配的两个阶段 权限生效时机 在服务器启动时读取权限表到内存中，从此时开始权限表生效。 之后使用grant、revoke、set password 等命令也会隐含的刷新权限表到内存中。 另外，使用显式的命令flush privileges或mysqladmin flush-privileges或mysqladmin reolad也会将上述几张权限表重新刷到内存中以供后续的身份验证和权限验证、分配。 用户管理用户管理分为几个方面，创建用户、对用户授权、修改和删除用户。创建用户创建账号有几种方法。 1.使用grant直接对账号授权，账号不存在则会创建； 2.向mysql.user表中插入记录； 3.使用create user命令。 后两种方法创建的用户初始时没有任何权限(只有usage登录数据库的权限)，并且修改权限后要使用 FLUSH PRIVILEGES 语句或执行 mysqladmin flush-privileges 或 mysqladmin reload 命令刷新权限表到内存中，而第一种方法简便的多，创建用户后会自动刷新权限表。 grant和revoke语法：1234567891011121314151617181920212223242526GRANT priv_type [(column_list)] [, priv_type [(column_list)]] ... ON [object_type] priv_level TO user [IDENTIFIED [BY [PASSWORD] &apos;password&apos;][WITH with_option [with_option]object_type: TABLE | FUNCTION | PROCEDUREpriv_level: * | *.* | db_name.* | db_name.tbl_name | tbl_name | db_name.routine_namewith_option: GRANT OPTION | MAX_QUERIES_PER_HOUR count | MAX_UPDATES_PER_HOUR count | MAX_CONNECTIONS_PER_HOUR count | MAX_USER_CONNECTIONS count | MAX_STATEMENT_TIME time grant可以在库、表、函数、存储过程、特定列上授权，且一次性可以为多个用户授予多个对象的权限。其中 with grant option 表示拥有该权限后的用户可以给别的用户授予自身所拥有的权限。 revoke表示收回权限，注意revoke无法收回usage权限。 其中user的表示方法是 ‘用户名‘@’主机名’ ，主机名部分可以是主机名，可以是IP地址，可以是localhost，可以是通配符组成的主机名(空的host值也表示所有host，等价于‘user_name‘@’%’)。如下示例： 对于网段地址，可以指定掩码来表示，如192.168.100.1/255.255.255.0，不能使用cidr格式的掩码记录方式，也不能指定非8、16、24、32位的掩码，如192.168.100.1/255.255.255.240是不允许的。 如果在user表中的用户有交叉部分，如root既可以从localhost登录，也可以从127.0.0.1登录，还可以从本机IP192.168.100.61登录，还可以从网段地址192.168.100.%登录，那么到底会从哪个登录？ 在读取权限表user到内存中的时候，首先会根据host列的具体性进行排序，然后再根据user列进行具体性排序(即理解为order by host,user)，然后从上到下扫描，首次扫描到符合的记录就使用该记录登录。具体性的意思是越具体的user优先级越高，通配符范围越宽的user优先级越低。例如root@localhost的具体性比root@’%’的具体性高，后者又比‘%‘@’%’的具体性高。create user和alter user 在MySQL 5.6.7之前，不要使用这两个命令创建用户和修改用户，因为它们会在mysql.user表的password列设置空串。到mysql5.6.7解决了这个问题。MariaDB可随意使用。 语法：C123456789101112131415REATE [OR REPLACE] USER [IF NOT EXISTS] user_specification [,user_specification] ... [WITH resource_option [resource_option] ...]user_specification: username [authentication_option]authentication_option: IDENTIFIED BY &apos;authentication_string&apos; resource_option: MAX_QUERIES_PER_HOUR count | MAX_UPDATE_PER_HOUR count | MAX_CONNECTIONS_PER_HOUR count | MAX_USER_CONNECTIONS count 例如：1create user &apos;longshuai&apos;@&apos;127.0.0.1&apos; identified by &apos;123456&apos;; alter user和create user语法基本一致，但在MySQL中有让密码过期的功能，而在MariaDB中不支持该功能。 123ALTER USER user_specification [, user_specification] ...user_specification: user PASSWORD EXPIRE 例如，让刚才创建的用户过期。1alter user &apos;longshuai&apos;@&apos;127.0.0.1&apos; password expire; 记录创建用户的时间 MariaDB/MySQL中user的元数据信息都存放在mysql.user表中，但是在这个表中的信息分类很少，常用的就只有用户类列和权限类列，没有用户的创建时间。 可以通过新增一列来记录用户的创建时间。 1alter table mysql.user add column create_time timestamp default current_timestamp; 这样以后新建用户都会记录创建时间。但是显然，对于已有的用户是没有记录时间的，它们的值都为’0000-00-00 00:00:00’。 12345678910111213MariaDB [mysql]&gt; select host,user,create_time from mysql.user;+---------------------+-----------+---------------------+| host | user | create_time |+---------------------+-----------+---------------------+| localhost | root | 2018-04-21 05:58:19 || 127.0.0.1 | root | 2018-04-21 05:58:19 || ::1 | root | 2018-04-21 05:58:19 || localhost | | 2018-04-21 05:58:19 || 192.168.100.% | root | 2018-04-21 05:58:19 || 192.168.100.1 | long | 2018-04-21 05:58:19 || 127.0.0.1 | longshuai | 2018-04-21 05:58:19 || 192.168.100.1 | longshuai | 0000-00-00 00:00:00 |+---------------------+-----------+---------------------+ 查看用户权限 可以使用show grants语句查看某个user的权限信息。 例如：123456MariaDB [mysql]&gt; show grants for &apos;root&apos;@&apos;localhost&apos;;Grants for root@localhost -----------------------------------------------------------------------------------------------------------------GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY PASSWORD &apos;*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9&apos; WITH GRANT OPTION GRANT PROXY ON &apos;&apos;@&apos;&apos; TO &apos;root&apos;@&apos;localhost&apos; WITH GRANT OPTION 123456MariaDB [mysql]&gt;SHOW GRANTS FOR &apos;long&apos;@&apos;192.168.100.1&apos;;Grants for long@192.168.100.1 -----------------------------------------------------------------------------------------------------------GRANT USAGE ON *.* TO &apos;long&apos;@&apos;192.168.100.1&apos; IDENTIFIED BY PASSWORD &apos;*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9&apos; GRANT SELECT ON `test`.* TO &apos;long&apos;@&apos;192.168.100.1&apos; revoke命令的严格性 revoke命令回收权限时必须要明确指定回收的数据库对象以及用户名，其中usage权限无法回收。特别要说明的是revoke all，当你以为它会回收所有权限的时候，它可能一点权限都没有回收。也就是说revoke命令的书写非常严格。 用户 ‘long‘@’192.168.100.1’ 在 . 上具有usage权限，在test.*上具有select权限。 12345MariaDB [mysql]&gt; SHOW GRANTS FOR &apos;long&apos;@&apos;192.168.100.1&apos;;Grants for long@192.168.100.1 -----------------------------------------------------------------------------------------------------------GRANT USAGE ON *.* TO &apos;long&apos;@&apos;192.168.100.1&apos; IDENTIFIED BY PASSWORD &apos;*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9&apos; GRANT SELECT ON `test`.* TO &apos;long&apos;@&apos;192.168.100.1&apos; 对该用户在 . 上进行revoke all，再次查看权限，发现权限根本一点变化都没有。因为usage权限无法回收，而select权限是在test.上而非.*上。 1REVOKE ALL ON *.* FROM &apos;long&apos;@&apos;192.168.100.1&apos;; 要回收test.上的select权限，必须在revoke中指定test.，而不能是 . 。以下两个语句都能回收。 12revoke select on test.* from &apos;long&apos;@&apos;192.168.100.1&apos;;revoke all on test.* from &apos;long&apos;@&apos;192.168.100.1&apos;; 删除用户 直接使用drop user命令或者从mysql.user表中删除对应记录。 1drop user user_name1,username2... 注意，删除表中用户记录的时候不会从现有用户中回收对该表的权限，当下次再创建同名表的时候，会自动为用户授予该表的权限造成权限外流。 因此，建议使用drop user语句来删除用户。 设置密码和恢复root密码设置密码12(1)grant all on *.* to &apos;root&apos;@&apos;localhost&apos; identified by &apos;123456&apos; with grant option; (2)grant usage on *.* to &apos;root&apos;@&apos;localhost&apos; identified by &apos;123456&apos; with grant option; 使用usage权限表示在不影响现有权限的情况下使用grant来修改密码。1(3)set password [for &apos;root&apos;@&apos;localhost&apos;] =password(&apos;123456&apos;); password函数中必须加引号，不写user时是为当前用户修改。123(4)alter user root@localhost identified by &apos;123456&apos;; (5)mysqladmin -uroot -h localhost -p&apos;old_password&apos; password &apos;new_password&apos;; (6)update mysql.user set password=password(&apos;123456&apos;) where user=&apos;root&apos; and host=&apos;localhost&apos;; 其中grant和set password语句可以直接刷新权限表，其他语句需要使用 flush privileges 或其他刷新语句。 恢复root密码 可以在启动mysql服务时使用mysqld_safe服务程序并指定”–skip-grant-tables”选项表示跳过授权表，这样登陆mysql服务器将不需要任何权限，包括密码认证也不需要，但是同样受限的是不能操作任何权限相关的内容，比如修改权限，刷新授权表等。这通常是mysql管理员密码忘记的时候使用的选项。由于跳过授权表使得mysql服务器极不安全，任何用户都能直接登录服务器，所以通常和”–skip-networking”选项一起使用来禁止来自网络的服务器连接请求，这样只能使用localhost或者127.0.0.1作为host来登录。 另外，使用mysqld_safe启动无授权表的服务前要停止已有的MySQL实例。由于跳过授权表无法操作权限相关内容，所以修改mysql.user表中的管理员账号的密码字段是唯一修改方法。修改密码后记得重启MySQL服务。 步骤如下：1234567891011121314151617[root@xuexi mysql]# service mysqld stop[root@xuexi mysql]# mysqld_safe --skip-grant-tables --skip-networking &amp;[root@xuexi mysql]# mysqlmysql&gt; update mysql.user set password=password(&quot;123456&quot;) where user=&apos;root&apos; and host=&apos;localhost&apos;;mysql&gt; flush privileges;mysql&gt; select user,host,password from mysql.user where user=&apos;root&apos; and host=&apos;localhost&apos;;+------+-----------+-------------------------------------------+| user | host | password |+------+-----------+-------------------------------------------+| root | localhost | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |+------+-----------+-------------------------------------------+1 row in setmysql&gt; \\q[root@xuexi mysql]# service mysqld stop[root@xuexi mysql]# service mysqld start[root@xuexi mysql]# mysql -uroot -p123456mysql&gt; \\q 如果要找回多实例的密码，则在mysqld_safe命令中使用 –defaults-file 指定对应的配置文件即可。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"MYSQL","slug":"MYSQL","permalink":"http://yoursite.com/tags/MYSQL/"}]},{"title":"ext 文件系统机制原理","slug":"ext 文件系统机制原理","date":"2017-04-19T16:00:00.000Z","updated":"2018-06-25T11:32:23.414Z","comments":true,"path":"2017/04/20/ext 文件系统机制原理/","link":"","permalink":"http://yoursite.com/2017/04/20/ext 文件系统机制原理/","excerpt":"将磁盘进行分区，分区是将磁盘按柱面进行物理上的划分。划分好分区后还要进行格式化，然后再挂载才能使用(不考虑其他方法)。格式化分区的过程其实就是创建文件系统。 文件系统的类型有很多种，如CentOS 5和CentOS 6上默认使用的ext2/ext3/ext4，CentOS 7上默认使用的xfs，windows上的NTFS，光盘类的文件系统ISO9660，MAC上的混合文件系统HFS，网络文件系统NFS，Oracle研发的btrfs，还有老式的FAT/FAT32等。 本文将非常全面且详细地对ext家族的文件系统进行介绍。有ext2/ext3/ext4，ext3是有日志的ext2改进版，ext4对相比ext3做了非常多的改进。虽然xfs/btrfs等文件系统有所不同，但它们只是在实现方式上不太同，再加上属于自己的特性而已。","text":"将磁盘进行分区，分区是将磁盘按柱面进行物理上的划分。划分好分区后还要进行格式化，然后再挂载才能使用(不考虑其他方法)。格式化分区的过程其实就是创建文件系统。 文件系统的类型有很多种，如CentOS 5和CentOS 6上默认使用的ext2/ext3/ext4，CentOS 7上默认使用的xfs，windows上的NTFS，光盘类的文件系统ISO9660，MAC上的混合文件系统HFS，网络文件系统NFS，Oracle研发的btrfs，还有老式的FAT/FAT32等。 本文将非常全面且详细地对ext家族的文件系统进行介绍。有ext2/ext3/ext4，ext3是有日志的ext2改进版，ext4对相比ext3做了非常多的改进。虽然xfs/btrfs等文件系统有所不同，但它们只是在实现方式上不太同，再加上属于自己的特性而已。 文件系统的组成部分block的出现硬盘的读写IO一次是一个扇区512字节，如果要读写大量文件，以扇区为单位肯定很慢很消耗性能，所以Linux中通过文件系统控制使用”块”为读写单元。现在的文件系统上，块的大小一般为1024bytes(1K)或2048bytes(2K)或4096bytes(4K)。比如需要读一个或多个块时，文件系统的IO管理器通知磁盘控制器要读取哪些块的数据，硬盘控制器将这些块按扇区读取出来，再通过硬盘控制器将这些扇区数据重组返回给计算机。 block的出现使得在文件系统层面上读写性能大大提高，也大量减少了碎片。但是它的副作用是可能造成空间浪费。由于文件系统以block为读写单元，即使存储的文件只有1K大小也将占用一个block，剩余的空间完全是浪费的。在某些业务需求下可能大量存储小文件，这会浪费大量的空间。 尽管有缺点，但是其优点足够明显，在当下硬盘容量廉价且追求性能的时代，使用block是一定的。 inode的出现如果存储的1个文件占用了大量的block读取时会如何？假如block大小为1KB，仅仅存储一个10M的文件就需要10240个block，而且这些blocks很可能在位置上是不连续在一起的(不相邻)，读取该文件时难道要从前向后扫描整个文件系统的块，然后找出属于该文件的块吗？显然是不应该这么做的，因为太慢太傻瓜式了。再考虑一下，读取一个只占用1个block的文件，难道只读取一个block就结束了吗？并不是，仍然是扫描整个文件系统的所有block，因为它不知道什么时候扫描到，扫描到了它也不知道这个文件是不是已经完整而不需要再扫描其他的block。 另外，每个文件都有属性(如权限、大小、时间戳等)，这些属性类的元数据存储在哪里呢？难道也和文件的数据部分存储在块中吗？如果一个文件占用多个block那是不是每个属于该文件的block都要存储一份文件元数据？但是如果不在每个block中存储元数据文件系统又怎么知道某一个block是不是属于该文件呢？但是显然，每个数据block中都存储一份元数据太浪费空间。 文件系统设计者当然知道这样的存储方式很不理想，所以需要优化存储方式。如何优化？对于这种类似的问题的解决方法是使用索引，通过扫描索引找到对应的数据，而且索引可以存储部分数据。 在文件系统上索引技术具体化为索引节点(index node)，在索引节点上存储的部分数据即为文件的属性元数据及其他少量信息。一般来说索引占用的空间相比其索引的文件数据而言占用的空间就小得多，扫描它比扫描整个数据要快得多，否则索引就没有存在的意义。这样一来就解决了前面所有的问题。 在文件系统上的术语中，索引节点称为inode。在inode中存储了inode号、文件类型、权限、文件所有者、大小、时间戳等元数据信息，最重要的是还存储了指向属于该文件block的指针，这样读取inode就可以找到属于该文件的block，进而读取这些block并获得该文件的数据。由于后面还会介绍一种指针，为了方便称呼和区分，暂且将这个inode记录中指向文件data block的指针称之为block指针，。 一般inode大小为128字节或256字节，相比那些MB或GB计算的文件数据而言小得多的多，但也要知道可能一个文件大小小于inode大小，例如只占用1个字节的文件。 bmap出现在向硬盘存储数据时，文件系统需要知道哪些块是空闲的，哪些块是已经占用了的。最笨的方法当然是从前向后扫描，遇到空闲块就存储一部分，继续扫描直到存储完所有数据。 优化的方法当然也可以考虑使用索引，但是仅仅1G的文件系统就有1KB的block共1024*1024=1048576个，这仅仅只是1G，如果是100G、500G甚至更大呢，仅仅使用索引索引的数量和空间占用也将极大，这时就出现更高一级的优化方法：使用块位图(bitmap简称bmap)。 位图只使用0和1标识对应block是空闲还是被占用，0和1在位图中的位置和block的位置一一对应，第一位标识第一个块，第二个位标识第二个块，依次下去直到标记完所有的block。 考虑下为什么块位图更优化。在位图中1个字节8个位，可以标识8个block。对于一个block大小为1KB、容量为1G的文件系统而言，block数量有10241024个，所以在位图中使用10241024个位共1024*1024/8=131072字节=128K，即1G的文件只需要128个block做位图就能完成一一对应。通过扫描这100多个block就能知道哪些block是空闲的，速度提高了非常多。 但是要注意，bmap的优化针对的是写优化，因为只有写才需要找到空闲block并分配空闲block。对于读而言，只要通过inode找到了block的位置，cpu就能迅速计算出block在物理磁盘上的地址，cpu的计算速度是极快的，计算block地址的时间几乎可以忽略，那么读速度基本认为是受硬盘本身性能的影响而与文件系统无关。大多数稍大一点的文件可能都会存储在不连续的block上，而且使用了一段时间的文件系统可能会有不少碎片，这时硬盘的随机读取性能直接决定读数据的速度，这也是机械硬盘速度相比固态硬盘慢的多的多的原因之一，而且固态硬盘的随机读和连续读取速度几乎是一致的，对它来说，文件系统碎片的多少并不会影响读取速度。 虽然bmap已经极大的优化了扫描，但是仍有其瓶颈：如果文件系统是100G呢？100G的文件系统要使用128*100=12800个1KB大小的block，这就占用了12.5M的空间了。试想完全扫描12800个很可能不连续的block这也是需要占用一些时间的，虽然快但是扛不住每次存储文件都要扫描带来的巨大开销。 所以需要再次优化，如何优化？简而言之就是将文件系统划分开形成块组，至于块组的介绍放在后文。 inode表的出现回顾下inode相关信息：inode存储了inode号、文件属性元数据、指向文件占用的block的指针；每一个inode占用128字节或256字节。 现在又出现问题了，一个文件系统中可以说有无数多个文件，每一个文件都对应一个inode，难道每一个仅128字节的inode都要单独占用一个block进行存储吗？这太浪费空间了。 所以更优的方法是将多个inode合并存储在block中，对于128字节的inode，一个block存储8个inode，对于256字节的inode，一个block存储4个inode。这就使得每个存储inode的块都不浪费。 在ext文件系统上，将这些物理上存储inode的block组合起来，在逻辑上形成一张inode表(inode table)来记录所有的inode。 举个例子，每一个家庭都要向派出所登记户口信息，通过户口本可以知道家庭住址，而每个镇或街道的派出所将本镇或本街道的所有户口整合在一起，要查找某一户地址时，在派出所就能快速查找到。inode table就是这里的派出所。它的内容如下图所示。 实际上，在文件系统创建完成后所有的inode号都已经分配好并记录到inode table中了，只不过被使用的inode号所在的行还有文件属性的元数据信息和block位置信息，而未被使用的inode号只有一个inode号而已而没有其他信息而已。 再细细一思考，就能发现一个大的文件系统仍将占用大量的块来存储inode，想要找到其中的一个inode记录也需要不小的开销，尽管它们已经形成了一张逻辑上的表，但扛不住表太大记录太多。那么如何快速找到inode，这同样是需要优化的，优化的方法是将文件系统的block进行分组划分，每个组中都存有本组inode table范围、bmap等。 imap的出现前面说bmap是块位图，用于标识文件系统中哪些block是空闲哪些block是占用的。 对于inode也一样，在存储文件(Linux中一切皆文件)时需要为其分配一个inode号。但是在格式化创建文件系统后所有的inode号都是被事先设定好存放在inode table中的，因此产生了问题：要为文件分配哪一个inode号呢？又如何知道某一个inode号是否已经被分配了呢？ 既然是”是否被占用”的问题，使用位图是最佳方案，像bmap记录block的占用情况一样。标识inode号是否被分配的位图称为inodemap简称为imap。这时要为一个文件分配inode号只需扫描imap即可知道哪一个inode号是空闲的。 imap存在着和bmap和inode table一样需要解决的问题：如果文件系统比较大，imap本身就会很大，每次存储文件都要进行扫描，会导致效率不够高。同样，优化的方式是将文件系统占用的block划分成块组，每个块组有自己的imap范围。 块组的出现前面一直提到的优化方法是将文件系统占用的block划分成块组(block group)，解决bmap、inode table和imap太大的问题。 在物理层面上的划分是将磁盘按柱面划分为多个分区，即多个文件系统；在逻辑层面上的划分是将文件系统划分成块组。每个文件系统包含多个块组，每个块组包含多个元数据区和数据区：元数据区就是存储bmap、inode table、imap等的数据；数据区就是存储文件数据的区域。注意块组是逻辑层面的概念，所以并不会真的在磁盘上按柱面、按扇区、按磁道等概念进行划分。 块组的划分块组在文件系统创建完成后就已经划分完成了，也就是说元数据区bmap、inode table和imap等信息占用的block以及数据区占用的block都已经划分好了。那么文件系统如何知道一个块组元数据区包含多少个block，数据区又包含多少block呢？ 它只需确定一个数据——每个block的大小，再根据bmap至多只能占用一个完整的block的标准就能计算出块组如何划分。如果文件系统非常小，所有的bmap总共都不能占用完一个block，那么也只能空闲bmap的block了。 每个block的大小在创建文件系统时可以人为指定，不指定也有默认值。 假如现在block的大小是1KB，一个bmap完整占用一个block能标识1024*8= 8192个block(当然这8192个block是数据区和元数据区共8192个，因为元数据区分配的block也需要通过bmap来标识)。每个block是1K，每个块组是8192K即8M，创建1G的文件系统需要划分1024/8=128个块组，如果是1.1G的文件系统呢？128+12.8=128+13=141个块组。 每个组的block数目是划分好了，但是每个组设定多少个inode号呢？inode table占用多少block呢？这需要由系统决定了，因为描述”每多少个数据区的block就为其分配一个inode号”的指标默认是我们不知道的，当然创建文件系统时也可以人为指定这个指标或者百分比例。见后文”inode深入”。 使用dumpe2fs可以将ext类的文件系统信息全部显示出来，当然bmap是每个块组固定一个block的不用显示，imap比bmap更小所以也只占用1个block不用显示。 下图是一个文件系统的部分信息，在这些信息的后面还有每个块组的信息，其实这里面的很多信息都可以通过几个比较基本的元数据推导出来。 从这张表中能计算出文件系统的大小，该文件系统共4667136个blocks，每个block大小为4K，所以文件系统大小为4667136*4/1024/1024=17.8GB。 也能计算出分了多少个块组，因为每一个块组的block数量为32768，所以块组的数量为4667136/32768=142.4即143个块组。由于块组从0开始编号，所以最后一个块组编号为Group 142。如下图所示是最后一个块组的信息。 文件系统的完整结构将上文描述的bmap、inode table、imap、数据区的blocks和块组的概念组合起来就形成了一个文件系统，当然这还不是完整的文件系统。完整的文件系统如下图。 首先，该图中多了Boot Block、Super Block、GDT、Reserver GDT这几个概念。下面会分别介绍它们。 然后，图中指明了块组中每个部分占用的block数量，除了superblock、bmap、imap能确定占用1个block，其他的部分都不能确定占用几个block。 最后，图中指明了Superblock、GDT和Reserved GDT是同时出现且不一定存在于每一个块组中的，也指明了bmap、imap、inode table和data blocks是每个块组都有的。 引导块即上图中的Boot Block部分，也称为boot sector。它位于分区上的第一个块，占用1024字节，并非所有分区都有这个boot sector，只有装了操作系统的主分区和装了操作系统的逻辑分区才有。里面存放的也是boot loader，这段boot loader称为VBR(主分区装操作系统时)或EBR(扩展分区装操作系统时)，这里的Boot loader和mbr上的boot loader是存在交错关系的。开机启动的时候，首先加载mbr中的bootloader，然后定位到操作系统所在分区的boot serctor上加载此处的boot loader。如果是多系统，加载mbr中的bootloader后会列出操作系统菜单，菜单上的各操作系统指向它们所在分区的boot sector上。它们之间的关系如下图所示。 但是，这种方式的操作系统菜单早已经弃之不用了，而是使用grub来管理启动菜单。尽管如此，在安装操作系统时，仍然有一步是选择boot loader安装位置的步骤。 超级块(superblock)既然一个文件系统会分多个块组，那么文件系统怎么知道分了多少个块组呢？每个块组又有多少block多少inode号等等信息呢？还有，文件系统本身的属性信息如各种时间戳、block总数量和空闲数量、inode总数量和空闲数量、当前文件系统是否正常、什么时候需要自检等等，它们又存储在哪里呢？ 毫无疑问，这些信息必须要存储在block中。存储这些信息占用1024字节，所以也要一个block，这个block称为超级块(superblock)，它的block号可能为0也可能为1。如果block大小为1K，则引导块正好占用一个block，这个block号为0，所以superblock的号为1；如果block大小大于1K，则引导块和超级块同置在一个block中，这个block号为0。总之superblock的起止位置是第二个1024(1024-2047)字节。 使用df命令读取的就是每个文件系统的superblock，所以它的统计速度非常快。相反，用du命令查看一个较大目录的已用空间就非常慢，因为不可避免地要遍历整个目录的所有文件。 12345[root@xuexi ~]# df -hTFilesystem Type Size Used Avail Use% Mounted on/dev/sda3 ext4 18G 1.7G 15G 11% /tmpfs tmpfs 491M 0 491M 0% /dev/shm/dev/sda1 ext4 190M 32M 149M 18% /boot superblock对于文件系统而言是至关重要的，超级块丢失或损坏必将导致文件系统的损坏。所以旧式的文件系统将超级块备份到每一个块组中，但是这又有所空间浪费，所以ext2文件系统只在块组0、1和3、5、7幂次方的块组中保存超级块的信息，如Group9、Group25等。尽管保存了这么多的superblock，但是文件系统只使用第一个块组即Group0中超级块信息来获取文件系统属性，只有当Group0上的superblock损坏或丢失才会找下一个备份超级块复制到Group0中来恢复文件系统。 下图是一个ext4文件系统的superblock的信息，ext家族的文件系统都能使用dumpe2fs -h获取。 块组描述符表(GDT)既然文件系统划分了块组，那么每个块组的信息和属性元数据又保存在哪里呢？ ext文件系统每一个块组信息使用32字节描述，这32个字节称为块组描述符，所有块组的块组描述符组成块组描述符表GDT(group descriptor table)。 虽然每个块组都需要块组描述符来记录块组的信息和属性元数据，但是不是每个块组中都存放了块组描述符。ext文件系统的存储方式是：将它们组成一个GDT，并将该GDT存放于某些块组中，存放GDT的块组和存放superblock和备份superblock的块相同，也就是说它们是同时出现在某一个块组中的。读取时也总是读取Group0中的块组描述符表信息。 假如block大小为4KB的文件系统划分了143个块组，每个块组描述符32字节，那么GDT就需要143*32=4576字节即两个block来存放。这两个GDT block中记录了所有块组的块组信息，且存放GDT的块组中的GDT都是完全相同的。 下图是一个块组描述符的信息(通过dumpe2fs获取)。 保留GDT(Reserved GDT)保留GDT用于以后扩容文件系统使用，防止扩容后块组太多，使得块组描述符超出当前存储GDT的blocks。保留GDT和GDT总是同时出现，当然也就和superblock同时出现了。 例如前面143个块组使用了2个block来存放GDT，但是此时第二个block还空余很多空间，当扩容到一定程度时2个block已经无法再记录块组描述符了，这时就需要分配一个或多个Reserverd GDT的block来存放超出的块组描述符。 由于新增加了GDT block，所以应该让每一个保存GDT的块组都同时增加这一个GDT block，所以将保留GDT和GDT存放在同一个块组中可以直接将保留GDT变换为GDT而无需使用低效的复制手段备份到每个存放GDT的块组。 同理，新增加了GDT需要修改每个块组中superblock中的文件系统属性，所以将superblock和Reserverd GDT/GDT放在一起又能提升效率。 Data Block 如上图，除了Data Blocks其他的部分都解释过了。data block是直接存储数据的block，但事实上并非如此简单。 数据所占用的block由文件对应inode记录中的block指针找到，不同的文件类型，数据block中存储的内容是不一样的。以下是Linux中不同类型文件的存储方式。 对于常规文件，文件的数据正常存储在数据块中。 对于目录，该目录下的所有文件和一级子目录的目录名存储在数据块中。 文件名不是存储在其自身的inode中，而是存储在其所在目录的data block中。 对于符号链接，如果目标路径名较短则直接保存在inode中以便更快地查找，如果目标路径名较长则分配一个数据块来保存。 设备文件、FIFO和socket等特殊文件没有数据块，设备文件的主设备号和次设备号保存在inode中。 常规文件的存储就不解释了，下面分别解释特殊文件的存储方式。 目录文件的data block对于目录文件，其inode记录中存储的是目录的inode号、目录的属性元数据和目录文件的block指针，这里面没有存储目录自身文件名的信息。 而其data block的存储方式则如下图所示。 由图可知，在目录文件的数据块中存储了其下的文件名、目录名、目录本身的相对名称”.”和上级目录的相对名称”..”，还存储了指向inode table中这些文件名对应的inode号的指针(并非直接存储inode号码)、目录项长度rec_len、文件名长度name_len和文件类型file_type。注意到除了文件本身的inode记录了文件类型，其所在的目录的数据块也记录了文件类型。由于rec_len只能是4的倍数，所以需要使用”\\0”来填充name_len不够凑满4倍数的部分。至于rec_len具体是什么，只需知道它是一种偏移即可。 目录的data block中并没有直接存储目录中文件的inode号，它存储的是指向inode table中对应文件inode号的指针，暂且称之为inode指针(至此，已经知道了两种指针：一种是inode table中每个inode记录指向其对应data block的block指针，一个此处的inode指针)。一个很有说服力的例子，在目录只有读而没有执行权限的时候，使用”ls -l”是无法获取到其内文件inode号的，这就表明没有直接存储inode号。实际上，因为在创建文件系统的时候，inode号就已经全部划分好并在每个块组的inode table中存放好，inode table在块组中是有具体位置的，如果使用dumpe2fs查看文件系统，会发现每个块组的inode table占用的block数量是完全相同的，如下图是某分区上其中两个块组的信息，它们都占用249个block。 除了inode指针，目录的data block中还使用数字格式记录了文件类型，数字格式和文件类型的对应关系如下图。 注意到目录的data block中前两行存储的是目录本身的相对名称”.”和上级目录的相对名称”..”，它们实际上是目录本身的硬链接和上级目录的硬链接。硬链接的本质后面说明。 由此也就容易理解目录权限的特殊之处了。目录文件的读权限(r)和写权限(w)，都是针对目录文件的数据块本身。由于目录文件内只有文件名、文件类型和inode指针，所以如果只有读权限，只能获取文件名和文件类型信息，无法获取其他信息，尽管目录的data block中也记录着文件的inode指针，但定位指针是需要x权限的，因为其它信息都储存在文件自身对应的inode中，而要读取文件inode信息需要有目录文件的执行权限通过inode指针定位到文件对应的inode记录上。以下是没有目录x权限时的查询状态，可以看到除了文件名和文件类型，其余的全是”?”。 123456[lisi4@xuexi tmp]$ ll -i dls: cannot access d/hehe: Permission deniedls: cannot access d/haha: Permission deniedtotal 0? d????????? ? ? ? ? ? haha? -????????? ? ? ? ? ? hehe 注意，xfs文件系统和ext文件系统不一样，它连文件类型都无法获取。 符号链接存储方式符号链接即为软链接，类似于Windows操作系统中的快捷方式，它的作用是指向原文件或目录。 软链接之所以也被称为特殊文件的原因是：它一般情况下不占用data block，仅仅通过它对应的inode记录就能将其信息描述完成；符号链接的大小是其指向目标路径占用的字符个数，例如某个符号链接的指向方式为”rmt –&gt; ../sbin/rmt”，则其文件大小为11字节；只有当符号链接指向的目标的路径名较长(60个字节)时文件系统才会划分一个data block给它；它的权限如何也不重要，因它只是一个指向原文件的”工具”，最终决定是否能读写执行的权限由原文件决定，所以很可能ls -l查看到的符号链接权限为777。 注意，软链接的block指针存储的是目标文件名。也就是说，链接文件的一切都依赖于其目标文件名。这就解释了为什么/mnt的软链接/tmp/mnt在/mnt挂载文件系统后，通过软链接就能进入/mnt所挂载的文件系统。究其原因，还是因为其目标文件名”/mnt”并没有改变。 例如以下筛选出了/etc/下的符号链接，注意观察它们的权限和它们占用的空间大小。 1234567891011121314151617[root@xuexi ~]# ll /etc/ | grep &apos;^l&apos;lrwxrwxrwx. 1 root root 56 Feb 18 2016 favicon.png -&gt; /usr/share/icons/hicolor/16x16/apps/system-logo-icon.pnglrwxrwxrwx. 1 root root 22 Feb 18 2016 grub.conf -&gt; ../boot/grub/grub.conflrwxrwxrwx. 1 root root 11 Feb 18 2016 init.d -&gt; rc.d/init.dlrwxrwxrwx. 1 root root 7 Feb 18 2016 rc -&gt; rc.d/rclrwxrwxrwx. 1 root root 10 Feb 18 2016 rc0.d -&gt; rc.d/rc0.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc1.d -&gt; rc.d/rc1.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc2.d -&gt; rc.d/rc2.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc3.d -&gt; rc.d/rc3.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc4.d -&gt; rc.d/rc4.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc5.d -&gt; rc.d/rc5.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc6.d -&gt; rc.d/rc6.dlrwxrwxrwx. 1 root root 13 Feb 18 2016 rc.local -&gt; rc.d/rc.locallrwxrwxrwx. 1 root root 15 Feb 18 2016 rc.sysinit -&gt; rc.d/rc.sysinitlrwxrwxrwx. 1 root root 14 Feb 18 2016 redhat-release -&gt; centos-releaselrwxrwxrwx. 1 root root 11 Apr 10 2016 rmt -&gt; ../sbin/rmtlrwxrwxrwx. 1 root root 14 Feb 18 2016 system-release -&gt; centos-release 设备文件、FIFO、套接字文件关于这3种文件类型的文件只需要通过inode就能完全保存它们的信息，它们不占用任何数据块，所以它们是特殊文件。 设备文件的主设备号和次设备号也保存在inode中。以下是/dev/下的部分设备信息。注意到它们的第5列和第6列信息，它们分别是主设备号和次设备号，主设备号标识每一种设备的类型，次设备号标识同种设备类型的不同编号；也注意到这些信息中没有大小的信息，因为设备文件不占用数据块所以没有大小的概念。 1234567891011[root@xuexi ~]# ll /dev | tailcrw-rw---- 1 vcsa tty 7, 129 Oct 7 21:26 vcsa1crw-rw---- 1 vcsa tty 7, 130 Oct 7 21:27 vcsa2crw-rw---- 1 vcsa tty 7, 131 Oct 7 21:27 vcsa3crw-rw---- 1 vcsa tty 7, 132 Oct 7 21:27 vcsa4crw-rw---- 1 vcsa tty 7, 133 Oct 7 21:27 vcsa5crw-rw---- 1 vcsa tty 7, 134 Oct 7 21:27 vcsa6crw-rw---- 1 root root 10, 63 Oct 7 21:26 vga_arbitercrw------- 1 root root 10, 57 Oct 7 21:26 vmcicrw-rw-rw- 1 root root 10, 56 Oct 7 21:27 vsockcrw-rw-rw- 1 root root 1, 5 Oct 7 21:26 zero inode基础知识每个文件都有一个inode，在将inode关联到文件后系统将通过inode号来识别文件，而不是文件名。并且访问文件时将先找到inode，通过inode中记录的block位置找到该文件。 硬链接虽然每个文件都有一个inode，但是存在一种可能：多个文件的inode相同，也就即inode号、元数据、block位置都相同，这是一种什么样的情况呢？能够想象这些inode相同的文件使用的都是同一条inode记录，所以代表的都是同一个文件，这些文件所在目录的data block中的inode指针目的地都是一样的，只不过各指针对应的文件名互不相同而已。这种inode相同的文件在Linux中被称为”硬链接”。 硬链接文件的inode都相同，每个文件都有一个”硬链接数”的属性，使用ls -l的第二列就是被硬链接数，它表示的就是该文件有几个硬链接。 1234567[root@xuexi ~]# ls -ltotal 48drwxr-xr-x 5 root root 4096 Oct 15 18:07 700-rw-------. 1 root root 1082 Feb 18 2016 anaconda-ks.cfg-rw-r--r-- 1 root root 399 Apr 29 2016 Identity.pub-rw-r--r--. 1 root root 21783 Feb 18 2016 install.log-rw-r--r--. 1 root root 6240 Feb 18 2016 install.log.syslog 例如下图描述的是dir1目录中的文件name1及其硬链接dir2/name2，右边分别是它们的inode和datablock。这里也看出了硬链接文件之间唯一不同的就是其所在目录中的记录不同。注意下图中有一列Link Count就是标记硬链接数的属性。 每创建一个文件的硬链接，实质上是多一个指向该inode记录的inode指针，并且硬链接数加1。 删除文件的实质是删除该文件所在目录data block中的对应的inode指针，所以也是减少硬链接次数，由于block指针是存储在inode中的，所以不是真的删除数据，如果仍有其他指针指向该inode，那么该文件的block指针仍然是可用的。当硬链接次数为1时再删除文件就是真的删除文件了，此时inode记录中block指针也将被删除。 不能跨分区创建硬链接，因为不同文件系统的inode号可能会相同，如果允许创建硬链接，复制到另一个分区时inode可能会和此分区已使用的inode号冲突。 硬链接只能对文件创建，无法对目录创建硬链接。之所以无法对目录创建硬链接，是因为文件系统已经把每个目录的硬链接创建好了，它们就是相对路径中的”.”和”..”，分别标识当前目录的硬链接和上级目录的硬链接。每一个目录中都会包含这两个硬链接，它包含了两个信息：(1)一个没有子目录的目录文件的硬链接数是2，其一是目录本身，即该目录datablock中的”.”，其二是其父目录datablock中该目录的记录，这两者都指向同一个inode号；(2)一个包含子目录的目录文件，其硬链接数是2+子目录数，因为每个子目录都关联一个父目录的硬链接”..”。很多人在计算目录的硬链接数时认为由于包含了”.”和”..”，所以空目录的硬链接数是2，这是错误的，因为”..”不是本目录的硬链接。另外，还有一个特殊的目录应该纳入考虑，即”/“目录，它自身是一个文件系统的入口，是自引用(下文中会解释自引用)的，所以”/“目录下的”.”和”..”的inode号相同，它自身不占用硬链接，因为其datablock中只记录inode号相同的”.”和”..”，不再像其他目录一样还记录一个名为”/“的目录，所以”/“的硬链接数也是2+子目录数，但这个2是”.”和”..”的结果。 12[root@xuexi ~]# ln /tmp /mydataln: `/tmp&apos;: hard link not allowed for directory 为什么文件系统自己创建好了目录的硬链接就不允许人为创建呢？从”.”和”..”的用法上考虑，如果当前目录为/usr，我们可以使用”./local”来表示/usr/local，但是如果我们人为创建了/usr目录的硬链接/tmp/husr，难道我们也要使用”/tmp/husr/local”来表示/usr/local吗？这其实已经是软链接的作用了。若要将其认为是硬链接的功能，这必将导致硬链接维护的混乱。 不过，通过mount工具的”–bind”选项，可以将一个目录挂载到另一个目录下，实现伪”硬链接”，它们的内容和inode号是完全相同的。 硬链接的创建方法： ln file_target link_name 。 软链接软链接就是字符链接，链接文件默认指的就是字符链接文件(注意不是字符设备)，使用”l”表示其类型。 软链接在功能上等价与Windows系统中的快捷方式，它指向原文件，原文件损坏或消失，软链接文件就损坏。可以认为软链接inode记录中的指针内容是目标路径的字符串。 创建方式： ln –s source_file softlink_name ，记住是source_file&lt;–link_name的指向关系(反箭头)，以前我老搞错位置。 查看软链接的值： readlink softlink_name 在设置软链接的时候，source_file虽然不要求是绝对路径，但建议给绝对路径。是否还记得软链接文件的大小？它是根据软链接所指向路径的字符数计算的，例如某个符号链接的指向方式为”rmt –&gt; ../sbin/rmt”，它的文件大小为11字节，也就是说只要建立了软链接后，软链接的指向路径是不会改变的，仍然是”../sbin/rmt”。如果此时移动软链接文件本身，它的指向是不会改变的，仍然是11个字符的”../sbin/rmt”，但此时该软链接父目录下可能根本就不存在/sbin/rmt，也就是说此时该软链接是一个被破坏的软链接。 inode深入inode大小和划分inode大小为128字节的倍数，最小为128字节。它有默认值大小，它的默认值由/etc/mke2fs.conf文件中指定。不同的文件系统默认值可能不同。 12345678910111213141516[root@xuexi ~]# cat /etc/mke2fs.conf[defaults] base_features = sparse_super,filetype,resize_inode,dir_index,ext_attr enable_periodic_fsck = 1 blocksize = 4096 inode_size = 256 inode_ratio = 16384[fs_types] ext3 = &#123; features = has_journal &#125; ext4 = &#123; features = has_journal,extent,huge_file,flex_bg,uninit_bg,dir_nlink,extra_isize inode_size = 256 &#125; 同样观察到这个文件中还记录了blocksize的默认值和inode分配比率inode_ratio。inode_ratio=16384表示每16384个字节即16KB就分配一个inode号，由于默认blocksize=4KB，所以每4个block就分配一个inode号。当然分配的这些inode号只是预分配，并不真的代表会全部使用，毕竟每个文件才会分配一个inode号。但是分配的inode自身会占用block，而且其自身大小256字节还不算小，所以inode号的浪费代表着空间的浪费。 既然知道了inode分配比率，就能计算出每个块组分配多少个inode号，也就能计算出inode table占用多少个block。 如果文件系统中大量存储电影等大文件，inode号就浪费很多，inode占用的空间也浪费很多。但是没办法，文件系统又不知道你这个文件系统是用来存什么样的数据，多大的数据，多少数据。 当然inodesize、inode分配比例、blocksize都可以在创建文件系统的时候人为指定。 ext文件系统预留的inode号Ext预留了一些inode做特殊特性使用，如下：某些可能并非总是准确，具体的inode号对应什么文件可以使用”find / -inum NUM”查看。 123456789101112Ext4的特殊inodeInode号 用途0 不存在0号inode1 虚拟文件系统，如/proc和/sys2 根目录3 ACL索引4 ACL数据5 Boot loader6 未删除的目录7 预留的块组描述符inode8 日志inode11 第一个非预留的inode，通常是lost+found目录 所以在ext4文件系统的dumpe2fs信息中，能观察到fisrt inode号可能为11也可能为12。 并且注意到”/“的inode号为2，这个特性在文件访问时会用上。 需要注意的是，每个文件系统都会分配自己的inode号，不同文件系统之间是可能会出现使用相同inode号文件的。例如： 123456[root@xuexi ~]# find / -ignore_readdir_race -inum 2 -ls 2 4 dr-xr-xr-x 22 root root 4096 Jun 9 09:56 / 2 2 dr-xr-xr-x 5 root root 1024 Feb 25 11:53 /boot 2 0 c--------- 1 root root Jun 7 02:13 /dev/pts/ptmx 2 0 -rw-r--r-- 1 root root 0 Jun 6 18:13 /proc/sys/fs/binfmt_misc/status 2 0 drwxr-xr-x 3 root root 0 Jun 6 18:13 /sys/fs 从结果中可见，除了根的Inode号为2，还有几个文件的inode号也是 2，它们都属于独立的文件系统，有些是虚拟文件系统，如/proc和/sys。 ext2/3的inode直接、间接寻址前文说过，inode中保存了blocks指针，但是一条inode记录中能保存的指针数量是有限的，否则就会超出inode大小(128字节或256字节)。 在ext2和ext3文件系统中，一个inode中最多只能有15个指针，每个指针使用i_block[n]表示。 前12个指针i_block[0]到i_block[11]是直接寻址指针，每个指针指向一个数据区的block。如下图所示。 第13个指针i_block[12]是一级间接寻址指针，它指向一个仍然存储了指针的block即i_block[12] –&gt; Pointerblock –&gt; datablock。 第14个指针i_block[13]是二级间接寻址指针，它指向一个仍然存储了指针的block，但是这个block中的指针还继续指向其他存储指针的block，即i_block[13] –&gt; Pointerblock1 –&gt; PointerBlock2 –&gt; datablock。 第15个指针i_block[14]是三级间接寻址指针，它指向一个任然存储了指针的block，这个指针block下还有两次指针指向。即i_block[13] –&gt; Pointerblock1 –&gt; PointerBlock2 –&gt; PointerBlock3 –&gt; datablock。 其中由于每个指针大小为4字节，所以每个指针block能存放的指针数量为BlockSize/4byte。例如blocksize为4KB，那么一个Block可以存放4096/4=1024个指针。 如下图。 为什么要分间接和直接指针呢？如果一个inode中15个指针全是直接指针，假如每个block的大小为1KB，那么15个指针只能指向15个block即15KB的大小，由于每个文件对应一个inode号，所以就限制了每个文件最大为15*1=15KB，这显然是不合理的。 如果存储大于15KB的文件而又不太大的时候，就占用一级间接指针i_block[12]，这时可以存放指针数量为1024/4+12=268，所以能存放268KB的文件。 如果存储大于268K 的文件而又不太大的时候，就继续占用二级指针i_block[13]，这时可以存放指针数量为[1024/4]^2+1024/4+12=65804，所以能存放65804KB=64M左右的文件。 如果存放的文件大于64M，那么就继续使用三级间接指针i_block[14]，存放的指针数量为[1024/4]^3+[1024/4]^2+[1024/4]+12=16843020个指针，所以能存放16843020KB=16GB左右的文件。 如果blocksize=4KB呢？那么最大能存放的文件大小为([4096/4]^3+[4096/4]^2+[4096/4]+12)*4/1024/1024/1024=4T左右。当然这样计算出来的不一定就是最大能存放的文件大小，它还受到另一个条件的限制。这里的计算只是表明一个大文件是如何寻址和分配的。 其实看到这里的计算数值，就知道ext2和ext3对超大文件的存取效率是低下的，它要核对太多的指针，特别是4KB大小的blocksize时。而ext4针对这一点就进行了优化，ext4使用extent的管理方式取代ext2和ext3的块映射，大大提高了效率也降低了碎片。 单文件系统中文件操作的原理在Linux上执行删除、复制、重命名、移动等操作时，它们是怎么进行的呢？还有访问文件时是如何找到它的呢？其实只要理解了前文中介绍的几个术语以及它们的作用就很容易知道文件操作的原理了。 注：在这一小节所解释的都是在单个文件系统下的行为，在多个文件系统中如何请看下一个小节：多文件系统关联。 读取文件当执行”cat /var/log/messages”命令在系统内部进行了什么样的步骤呢？该命令能被成功执行涉及了cat命令的寻找、权限判断以及messages文件的寻找和权限判断等等复杂的过程。这里只解释和本节内容相关的如何寻找到被cat的/var/log/messages文件。 找到根文件系统的块组描述符表所在的blocks，读取GDT(已在内存中)找到inode table的block号。 因为GDT总是和superblock在同一个块组，而superblock总是在分区的第1024-2047个字节，所以很容易就知道第一个GDT所在的块组以及GDT在这个块组中占用了哪些block。其实GDT早已经在内存中了，在系统开机的时候会挂在根文件系统，挂载的时候就已经将所有的GDT放进内存中。 在inode table的block中定位到根”/“的inode，找出”/“指向的data block。 前文说过，ext文件系统预留了一些inode号，其中”/“的inode号为2，所以可以根据inode号直接定位根目录文件的data block。 在”/“的datablock中记录了var目录名和指向var目录文件inode的指针，并找到该inode记录，inode记录中存储了指向var的block指针，所以也就找到了var目录文件的data block。 通过var目录的inode指针，可以寻找到var目录的inode记录，但是指针定位的过程中，还需要知道该inode记录所在的块组以及所在的inode table，所以需要读取GDT，同样，GDT已经缓存到了内存中。 在var的data block中记录了log目录名和其inode指针，通过该指针定位到该inode所在的块组及所在的inode table，并根据该inode记录找到log的data block。 在log目录文件的data block中记录了messages文件名和对应的inode指针，通过该指针定位到该inode所在的块组及所在的inode table，并根据该inode记录找到messages的data block。 最后读取messages对应的datablock。将上述步骤中GDT部分的步骤简化后比较容易理解。如下:找到GDT–&gt;找到”/“的inode–&gt;找到/的数据块读取var的inode–&gt;找到var的数据块读取log的inode–&gt;找到log的数据块读取messages的inode–&gt;找到messages的数据块并读取它们。 删除、重命名和移动文件注意这里是不跨越文件系统的操作行为。 删除文件分为普通文件和目录文件，知道了这两种类型的文件的删除原理，就知道了其他类型特殊文件的删除方法。 对于删除普通文件：(1)找到文件的inode和data block(根据前一个小节中的方法寻找)；(2)将inode table中该inode记录中的data block指针删除；(3)在imap中将该文件的inode号标记为未使用；(4)在其所在目录的data block中将该文件名所在的记录行删除，删除了记录就丢失了指向inode的指针；(5)将bmap中data block对应的block号标记为未使用。 对于删除目录文件：找到目录和目录下所有文件、子目录、子文件的inode和data block；在imap中将这些inode号标记为未使用；将bmap中将这些文件占用的 block号标记为未使用；在该目录的父目录的data block中将该目录名所在的记录行删除。需要注意的是，删除父目录data block中的记录是最后一步，如果该步骤提前，将报目录非空的错误，因为在该目录中还有文件占用。 关于上面的(2)-(5)：当(2)中删除data block指针后，将无法再找到这个文件的数据；当(3)标记inode号未使用，表示该inode号可以被后续的文件重用；当(4)删除目录data block中关于该文件的记录，真正的删除文件，外界再也定位也无法看到这个文件了；当(5)标记data block为未使用后，表示开始释放空间，这些data block可以被其他文件重用。 注意，在第(5)步之前，由于data block还未被标记为未使用，在superblock中仍然认为这些data block是正在使用中的。这表示尽管文件已经被删除了，但空间却还没有释放，df也会将其统计到已用空间中(df是读取superblock中的数据块数量，并计算转换为空间大小)。 什么时候会发生这种情况呢？当一个进程正在引用文件时将该文件删除，就会出现文件已删除但空间未释放的情况。这时步骤已经进行到(4)，外界无法再找到该文件，但由于进程在加载该文件时已经获取到了该文件所有的data block指针，该进程可以获取到该文件的所有数据，但却暂时不会释放该文件空间。直到该进程结束，文件系统才将未执行的步骤(5)继续完成。这也是为什么有时候du的统计结果比df小的原因，关于du和df统计结果的差别，详细内容见：详细分析du和df的统计结果为什么不一样。 重命名文件分为同目录内重命名和非同目录内重命名。非同目录内重命名实际上是移动文件的过程，见下文。 同目录内重命名文件的动作仅仅只是修改所在目录data block中该文件记录的文件名部分，不是删除再重建的过程。 如果重命名时有文件名冲突(该目录内已经存在该文件名)，则提示是否覆盖。覆盖的过程是覆盖目录data block中冲突文件的记录。例如/tmp/下有a.txt和a.log，若将a.txt重命名为a.log，则提示覆盖，若选择覆盖，则/tmp的data block中关于a.log的记录被覆盖，此时它的指针是指向a.txt的inode。 移动文件同文件系统下移动文件实际上是修改目标文件所在目录的data block，向其中添加一行指向inode table中待移动文件的inode指针，如果目标路径下有同名文件，则会提示是否覆盖，实际上是覆盖目录data block中冲突文件的记录，由于同名文件的inode记录指针被覆盖，所以无法再找到该文件的data block，也就是说该文件被标记为删除(如果多个硬链接数，则另当别论)。 所以在同文件系统内移动文件相当快，仅仅在所在目录data block中添加或覆盖了一条记录而已。也因此，移动文件时，文件的inode号是不会改变的。 对于不同文件系统内的移动，相当于先复制再删除的动作。见后文。 关于文件移动，在Linux环境下有一个非常经典网上却又没任何解释的问题：/tmp/a/a能覆盖为/tmp/a吗？答案是不能，但windows能。为什么不能？见mv的一个经典问题(mv的本质)。 存储和复制文件对于文件存储 (1).读取GDT，找到各个(或部分)块组imap中未使用的inode号，并为待存储文件分配inode号； (2).在inode table中完善该inode号所在行的记录； (3).在目录的data block中添加一条该文件的相关记录； (4).将数据填充到data block中。注意，填充到data block中的时候会调用block分配器：一次分配4KB大小的block数量，当填充完4KB的data block后会继续调用block分配器分配4KB的block，然后循环直到填充完所有数据。也就是说，如果存储一个100M的文件需要调用block分配器100*1024/4=25600次。 另一方面，在block分配器分配block时，block分配器并不知道真正有多少block要分配，只是每次需要分配时就分配，在每存储一个data block前，就去bmap中标记一次该block已使用，它无法实现一次标记多个bmap位。这一点在ext4中进行了优化。 (5)填充完之后，去inode table中更新该文件inode记录中指向data block的寻址指针。 对于复制，完全就是另一种方式的存储文件。步骤和存储文件的步骤一样。 多文件系统关联在单个文件系统中的文件操作和多文件系统中的操作有所不同。本文将对此做出非常详细的说明。 根文件系统的特殊性这里要明确的是，任何一个文件系统要在Linux上能正常使用，必须挂载在某个已经挂载好的文件系统中的某个目录下，例如/dev/cdrom挂载在/mnt上，/mnt目录本身是在”/“文件系统下的。而且任意文件系统的一级挂载点必须是在根文件系统的某个目录下，因为只有”/“是自引用的。这里要说明挂载点的级别和自引用的概念。 假如/dev/sdb1挂载在/mydata上，/dev/cdrom挂载在/mydata/cdrom上，那么/mydata就是一级挂载点，此时/mydata已经是文件系统/dev/sdb1的入口了，而/dev/cdrom所挂载的目录/mydata/cdrom是文件系统/dev/sdb1中的某个目录，那么/mydata/cdrom就是二级挂载点。一级挂载点必须在根文件系统下，所以可简述为：文件系统2挂载在文件系统1中的某个目录下，而文件系统1又挂载在根文件系统中的某个目录下。 再解释自引用。首先要说的是，自引用的只能是文件系统，而文件系统表现形式是一个目录，所以自引用是指该目录的data block中，”.”和”..”的记录中的inode指针都指向inode table中同一个inode记录，所以它们inode号是相同的，即互为硬链接。而根文件系统是唯一可以自引用的文件系统。 1234[root@xuexi /]# ll -ai /total 102 2 dr-xr-xr-x. 22 root root 4096 Jun 6 18:13 . 2 dr-xr-xr-x. 22 root root 4096 Jun 6 18:13 .. 由此也能解释cd /.和cd /..的结果都还是在根下，这是自引用最直接的表现形式。 1234[root@xuexi tmp]# cd /.[root@xuexi /]#[root@xuexi tmp]# cd /..[root@xuexi /]# 注意，根目录下的”.”和”..”都是”/“目录的硬链接，且其datablock中不记录名为”/“的条目，因此除去根目录下子目录数后的硬链接数为2。 1234[root@server2 tmp]# a=$(ls -ld / | awk &apos;&#123;print $2&#125;&apos;)[root@server2 tmp]# b=$(ls -l / | grep &quot;^d&quot; |wc -l)[root@server2 tmp]# echo $((a - b))2 挂载文件系统的细节挂载文件系统到某个目录下，例如”mount /dev/cdrom /mnt”，挂载成功后/mnt目录中的文件全都暂时不可见了，且挂载后权限和所有者(如果指定允许普通用户挂载)等的都改变了，知道为什么吗？ 下面就以通过”mount /dev/cdrom /mnt”为例，详细说明挂载过程中涉及的细节。 在将文件系统/dev/cdrom(此处暂且认为它是文件系统)挂载到挂载点/mnt之前，挂载点/mnt是根文件系统中的一个目录，”/“的data block中记录了/mnt的一些信息，其中包括inode指针inode_n，而在inode table中，/mnt对应的inode记录中又存储了block指针block_n，此时这两个指针还是普通的指针。 当文件系统/dev/cdrom挂载到/mnt上后，/mnt此时就已经成为另一个文件系统的入口了，因此它需要连接两边文件系统的inode和data block。但是如何连接呢？如下图。 在根文件系统的inode table中，为/mnt重新分配一个inode记录m，该记录的block指针block_m指向文件系统/dev/cdrom中的data block。既然为/mnt分配了新的inode记录m，那么在”/“目录的data block中，也需要修改其inode指针为inode_m以指向m记录。同时，原来inode table中的inode记录n就被标记为暂时不可用。 block_m指向的是文件系统/dev/cdrom的data block，所以严格说起来，除了/mnt的元数据信息即inode记录m还在根文件系统上，/mnt的data block已经是在/dev/cdrom中的了。这就是挂载新文件系统后实现的跨文件系统，它将挂载点的元数据信息和数据信息分别存储在不同的文件系统上。 挂载完成后，将在/proc/self/{mounts,mountstats,mountinfo}这三个文件中写入挂载记录和相关的挂载信息，并会将/proc/self/mounts中的信息同步到/etc/mtab文件中，当然，如果挂载时加了-n参数，将不会同步到/etc/mtab。 而卸载文件系统，其实质是移除临时新建的inode记录(当然，在移除前会检查是否正在使用)及其指针，并将指针指回原来的inode记录，这样inode记录中的block指针也就同时生效而找回对应的data block了。由于卸载只是移除inode记录，所以使用挂载点和文件系统都可以实现卸载，因为它们是联系在一起的。 下面是分析或结论。 (1).挂载点挂载时的inode记录是新分配的。 挂载前挂载点/mnt的inode号1234[root@server2 tmp]# ll -id /mnt100663447 drwxr-xr-x. 2 root root 6 Aug 12 2015 /mnt[root@server2 tmp]# mount /dev/cdrom /mnt 挂载后挂载点的inode号12[root@server2 tmp]# ll -id /mnt 1856 dr-xr-xr-x 8 root root 2048 Dec 10 2015 mnt 由此可以验证，inode号确实是重新分配的。 (2).挂载后，挂载点的内容将暂时不可见、不可用，卸载后文件又再次可见、可用。 123# 在挂载前，向挂载点中创建几个文件[root@server2 tmp]# touch /mnt/a.txt[root@server2 tmp]# mkdir /mnt/abcdir 12345678910111213141516171819202122232425# 挂载[root@server2 tmp]# mount /dev/cdrom /mnt# 挂载后，挂载点中将找不到刚创建的文件[root@server2 tmp]# ll /mnttotal 636-r--r--r-- 1 root root 14 Dec 10 2015 CentOS_BuildTagdr-xr-xr-x 3 root root 2048 Dec 10 2015 EFI-r--r--r-- 1 root root 215 Dec 10 2015 EULA-r--r--r-- 1 root root 18009 Dec 10 2015 GPLdr-xr-xr-x 3 root root 2048 Dec 10 2015 imagesdr-xr-xr-x 2 root root 2048 Dec 10 2015 isolinuxdr-xr-xr-x 2 root root 2048 Dec 10 2015 LiveOSdr-xr-xr-x 2 root root 612352 Dec 10 2015 Packagesdr-xr-xr-x 2 root root 4096 Dec 10 2015 repodata-r--r--r-- 1 root root 1690 Dec 10 2015 RPM-GPG-KEY-CentOS-7-r--r--r-- 1 root root 1690 Dec 10 2015 RPM-GPG-KEY-CentOS-Testing-7-r--r--r-- 1 root root 2883 Dec 10 2015 TRANS.TBL# 卸载后，挂载点/mnt中的文件将再次可见[root@server2 tmp]# umount /mnt[root@server2 tmp]# ll /mnttotal 0drwxr-xr-x 2 root root 6 Jun 9 08:18 abcdir-rw-r--r-- 1 root root 0 Jun 9 08:18 a.txt 之所以会这样，是因为挂载文件系统后，挂载点原来的inode记录暂时被标记为不可用，关键是没有指向该inode记录的inode指针了。在卸载文件系统后，又重新启用挂载点原来的inode记录，”/“目录下的mnt的inode指针又重新指向该inode记录。 (3).挂载后，挂载点的元数据和data block是分别存放在不同文件系统上的。 (4).挂载点即使在挂载后，也还是属于源文件系统的文件。 多文件系统操作关联假如下图中的圆代表一块硬盘，其中划分了3个区即3个文件系统。其中根是根文件系统，/mnt是另一个文件系统A的入口，A文件系统挂载在/mnt上，/mnt/cdrom也是一个文件系统B的入口，B文件系统挂载在/mnt/cdrom上。每个文件系统都维护了一些inode table，这里假设图中的inode table是每个文件系统所有块组中的inode table的集合表。 如何读取/var/log/messages呢？这是和”/“在同一个文件系统的文件读取，在前面单文件系统中已经详细说明了。 但如何读取A文件系统中的/mnt/a.log呢？首先，从根文件系统找到/mnt的inode记录，这是单文件系统内的查找；然后根据此inode记录的block指针，定位到/mnt的data block中，这些block是A文件系统的data block；然后从/mnt的data block中读取a.log记录，并根据a.log的inode指针定位到A文件系统的inode table中对应a.log的inode记录；最后从此inode记录的block指针找到a.log的data block。至此，就能读取到/mnt/a.log文件的内容。 下图能更完整的描述上述过程。 那么又如何读取/mnt/cdrom中的/mnt/cdrom/a.rpm呢？这里cdrom代表的文件系统B挂载点位于/mnt下，所以又多了一个步骤。先找到”/“，再找到根中的mnt，进入到mnt文件系统中，找到cdrom的data block，再进入到cdrom找到a.rpm。也就是说，mnt目录文件存放位置是根，cdrom目录文件存放位置是mnt，最后a.rpm存放的位置才是cdrom。 继续完善上图。如下。 ext3文件系统的日志功能相比ext2文件系统，ext3多了一个日志功能。 在ext2文件系统中，只有两个区：数据区和元数据区。如果正在向data block中填充数据时突然断电，那么下一次启动时就会检查文件系统中数据和状态的一致性，这段检查和修复可能会消耗大量时间，甚至检查后无法修复。之所以会这样是因为文件系统在突然断电后，它不知道上次正在存储的文件的block从哪里开始、哪里结束，所以它会扫描整个文件系统进行排除(也许是这样检查的吧)。 而在创建ext3文件系统时会划分三个区：数据区、日志区和元数据区。每次存储数据时，先在日志区中进行ext2中元数据区的活动，直到文件存储完成后标记上commit才将日志区中的数据转存到元数据区。当存储文件时突然断电，下一次检查修复文件系统时，只需要检查日志区的记录，将bmap对应的data block标记为未使用，并把inode号标记未使用，这样就不需要扫描整个文件系统而耗费大量时间。 虽说ext3相比ext2多了一个日志区转写元数据区的动作而导致ext3相比ext2性能要差一点，特别是写众多小文件时。但是由于ext3其他方面的优化使得ext3和ext2性能几乎没有差距。 ext4文件系统回顾前面关于ext2和ext3文件系统的存储格式，它使用block为存储单元，每个block使用bmap中的位来标记是否空闲，尽管使用划分块组的方法优化提高了效率，但是一个块组内部仍然使用bmap来标记该块组内的block。对于一个巨大的文件，扫描整个bmap都将是一件浩大的工程。另外在inode寻址方面，ext2/3使用直接和间接的寻址方式，对于三级间接指针，可能要遍历的指针数量是非常非常巨大的。 ext4文件系统的最大特点是在ext3的基础上使用区(extent，或称为段)的概念来管理。一个extent尽可能的包含物理上连续的一堆block。inode寻址方面也一样使用区段树的方式进行了改进。默认情况下，EXT4不再使用EXT3的block mapping分配方式 ，而改为Extent方式分配。 (1). 关于EXT4的结构特征 EXT4在总体结构上与EXT3相似，大的分配方向都是基于相同大小的块组，每个块组内分配固定数量的inode、可能的superblock(或备份)及GDT。 EXT4的inode 结构做了重大改变，为增加新的信息，大小由EXT3的128字节增加到默认的256字节，同时inode寻址索引不再使用EXT3的”12个直接寻址块+1个一级间接寻址块+1个二级间接寻址块+1个三级间接寻址块”的索引模式，而改为4个Extent片断流，每个片断流设定片断的起始block号及连续的block数量(有可能直接指向数据区，也有可能指向索引块区)。 片段流即下图中索引节点(inde node block)部分的绿色区域，每个15字节，共60字节。 (2). EXT4删除数据的结构更改。 EXT4删除数据后，会依次释放文件系统bitmap空间位、更新目录结构、释放inode空间位。 (3). ext4使用多block分配方式。 在存储数据时，ext3中的block分配器一次只能分配4KB大小的Block数量，而且每存储一个block前就标记一次bmap。假如存储1G的文件，blocksize是4KB，那么每存储完一个Block就将调用一次block分配器，即调用的次数为10241024/4KB=262144次，标记bmap的次数也为10241024/4=262144次。 而在ext4中根据区段来分配，可以实现调用一次block分配器就分配一堆连续的block，并在存储这一堆block前一次性标记对应的bmap。这对于大文件来说极大的提升了存储效率。 ext类的文件系统的缺点最大的缺点是它在创建文件系统的时候就划分好一切需要划分的东西，以后用到的时候可以直接进行分配，也就是说它不支持动态划分和动态分配。对于较小的分区来说速度还好，但是对于一个超大的磁盘，速度是极慢极慢的。例如将一个几十T的磁盘阵列格式化为ext4文件系统，可能你会因此而失去一切耐心。 除了格式化速度超慢以外，ext4文件系统还是非常可取的。当然，不同公司开发的文件系统都各有特色，最主要的还是根据需求选择合适的文件系统类型。 虚拟文件系统VFS每一个分区格式化后都可以建立一个文件系统，Linux上可以识别很多种文件系统，那么它是如何识别的呢？另外，在我们操作分区中的文件时，并没有指定过它是哪个文件系统的，各种不同的文件系统如何被我们用户以无差别的方式操作呢？这就是虚拟文件系统的作用。 虚拟文件系统为用户操作各种文件系统提供了通用接口，使得用户执行程序时不需要考虑文件是在哪种类型的文件系统上，应该使用什么样的系统调用来操作该文件。有了虚拟文件系统，只要将所有需要执行的程序调用VFS的系统调用就可以了，剩下的动作由VFS来帮忙完成。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"Linux分区信息与管理文件系统","slug":"Linux分区信息与管理文件系统","date":"2017-04-14T16:00:00.000Z","updated":"2018-06-22T11:29:44.139Z","comments":true,"path":"2017/04/15/Linux分区信息与管理文件系统/","link":"","permalink":"http://yoursite.com/2017/04/15/Linux分区信息与管理文件系统/","excerpt":"分区分区是为了在逻辑上将某些柱面隔开形成边界。它是以柱面为单位来划分的，首先划分外圈柱面，然后不断向内划分。 由于读写越外圈磁道中的数据比越内圈更快，所以第一个分区在读写性能上比后面的分区更好。在Windows操作系统上，C盘的速度是最快的，越后面的区越慢就是这个原因。 在磁盘数据量非常大的情况下，划分分区的好处是扫描块位图等更快速：不用再扫描整块磁盘的块位图，只需扫描对应分区的块位图。","text":"分区分区是为了在逻辑上将某些柱面隔开形成边界。它是以柱面为单位来划分的，首先划分外圈柱面，然后不断向内划分。 由于读写越外圈磁道中的数据比越内圈更快，所以第一个分区在读写性能上比后面的分区更好。在Windows操作系统上，C盘的速度是最快的，越后面的区越慢就是这个原因。 在磁盘数据量非常大的情况下，划分分区的好处是扫描块位图等更快速：不用再扫描整块磁盘的块位图，只需扫描对应分区的块位图。 分区方法(MBR和GPT)MBR格式的磁盘中，会维护磁盘第一个扇区——MBR扇区，在该扇区中第446字节之后的64字节是分区表，每个分区占用16字节，所以限制了一块磁盘最多只能有4个主分区(Primary,P)，如果多于4个区，只能将主分区少于4个，通过建立扩展分区(Extend,E)，然后在扩展分区建立逻辑分区(Logical,L)的方式来突破4个分区的限制。 在Linux中，MBR格式的磁盘主分区号从1-4，扩展分区号从2-4，逻辑分区号从5-15，也就是最大限制是15个分区。 例如，一块盘想分成6个分区，可以： 1231P+5L：sda1+sda5+sda6+sda7+sda8+sda92P+4L：sda1+sda2+sda5+sda6+sda7+sda83P+3L：sda1+sda2+sda3+sda5+sda6+sda7 而GPT格式突破了MBR的限制，它不再限制只能存储4个分区表条目，而是使用了类似MBR扩展分区表条目的格式，它允许有128个主分区，这也使得它可以对超过2TB的磁盘进行分区。 MBR和GPT分区表信息在MBR格式分区表中，MBR扇区占用512个字节，前446个字节是主引导记录，即boot loader。中间64字节记录着分区表信息，每个主分区信息占用16字节，因此最多只能有4个主分区，最后2个字节是有效标识位。如果使用扩展分区，则扩展分区对应的16字节记录的是指向扩展分区中扩展分区表的指针。 在MBR磁盘上，分区和启动信息是保存在一起的，如果这部分数据被覆盖或破坏，只能重建MBR。而GPT在整个磁盘上保存多个这部分信息的副本，因此它更为健壮，并可以恢复被破坏的这部分信息。GPT还为这些信息保存了循环冗余校验码(CRC)以保证其完整和正确，如果数据被破坏，GPT会发现这些破坏，并从磁盘上的其他地方进行恢复。 下面是GPT格式的分区表信息，大致约占17个字节。EFI部分可以分为4个区域：EFI信息区(GPT头)、分区表、GPT分区区域和备份区域。 EFI信息区(GPT头)：起始于磁盘的LBA1，通常也只占用这个单一扇区。其作用是定义分区表的位置和大小。GPT头还包含头和分区表的校验和，这样就可以及时发现错误。 分区表：分区表区域包含分区表项。这个区域由GPT头定义，一般占用磁盘LBA2～LBA33扇区，每扇区可存储4个主分区的分区信息，所以共能分128个主分区。分区表中的每个分区项由起始地址、结束地址、类型值、名字、属性标志、GUID值组成。分区表建立后，128位的GUID对系统来说是唯一的。 GPT分区：最大的区域，由分配给分区的扇区组成。这个区域的起始和结束地址由GPT头定义。 备份区：备份区域位于磁盘的尾部，包含GPT头和分区表的备份。它占用GPT结束扇区和EFI结束扇区之间的33个扇区。其中最后一个扇区用来备份1号扇区的EFI信息，其余的32个扇区用来备份LBA2～LBA33扇区的分区表。 添加磁盘正常情况下，添加磁盘后需要重启系统才能被内核识别，在/dev/下才有对应的设备号，使用fdisk -l才会显示出来。但是有时候不方便重启，所以下面介绍一种磁盘热插拔方式。更多热插和热拔方法见我的另一篇文章：Linux上磁盘热插拔。 12[root@node1 ~]# ls /sys/class/scsi_host/ # 查看主机scsi总线号host0 host1 host2 重新扫描scsi总线以热插拔方式添加新设备。 1234[root@node1 ~]# echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host0/scan[root@node1 ~]# echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host1/scan[root@node1 ~]# echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host2/scan[root@node1 ~]# fdisk -l # 再查看就有了 如果scsi_host目录系很多hostN目录，则使用循环来完成。 123456[root@xuexi scsi_host]# ls /sys/class/scsi_host/host0 host11 host14 host17 host2 host22 host25 host28 host30 host4 host7host1 host12 host15 host18 host20 host23 host26 host29 host31 host5 host8host10 host13 host16 host19 host21 host24 host27 host3 host32 host6 host9[root@xuexi scsi_host]# for i in /sys/class/scsi_host/host*/scan;do echo &quot;- - -&quot; &gt;$i;done 使用fdisk分区工具fdisk工具用来分MBR磁盘上的区。要分GPT磁盘上的区，可以使用gdisk。parted工具对这两种格式的磁盘分区都支持。 如果一个存储设备已经分过区，那么它可能是mbr格式的，也可能是gpt格式的，如果已经是mbr格式的，则只能继续使用fdisk进行分区，如果已经是gpt格式的，则只能使用gdisk进行分区。当然，无论什么格式的都可以使用parted进行分区，只不过也只能划分和已存在分区格式一样的分区，因为无论何种格式的分区，它的分区表和分区标识是已经固定的。 使用fdisk分区，它只能实现MBR格式的分区。 12345678910111213141516171819[root@xuexi ~]# fdisk /dev/sdb # sdb后没加数字Command (m for help): m # 输入m查看可用命令帮助Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition # 删除分区，如果删除扩展分区同时会删除里面的逻辑分区 l list known partition types # 列出分区类型 m print this menu # 显示帮助信息 n add a new partition # 创建新分区 o create a new empty DOS partition table p print the partition table # 输出分区信息 q quit without saving changes # 不保存退出 s create a new empty Sun disklabel t change a partition&apos;s system id # 修改分区类型 u change display/entry units v verify the partition table w write table to disk and exit # 保存分区信息并退出 x extra functionality (experts only) 新建第一个主分区： 1234567891011121314151617181920Command (m for help): n # 添加分区Command action e extended # 添加扩展分区 p primary partition (1-4) # 添加主分区p # 输入p来创建第一个主分区Partition number (1-4): 1 # 输入分区号，从1开始First cylinder (1-1305, default 1): # 输入柱面号，不输人默认是1Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-1305, default 1305): +2G # 给第一个主分区/dev/sdb1分2G，也可以使用柱面号来指定大小。Command (m for help): p # 第一个分区结束，p查看下已分区信息 Disk /dev/sdb: 10.7 GB, 10737418240 bytes255 heads, 63 sectors/track, 1305 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x2d8d64eb Device Boot Start End Blocks Id System/dev/sdb1 1 262 2104483+ 83 Linux 新建扩展分区： 123456789101112131415161718192021Command (m for help): n # 再建一个分区Command action e extended p primary partition (1-4)e # 创建扩展分区Partition number (1-4): 2 # 扩展分区号为2First cylinder (263-1305, default 263):Using default value 263Last cylinder, +cylinders or +size&#123;K,M,G&#125; (263-1305, default 1305): # 剩余空间全部给扩展分区Using default value 1305Command (m for help): p Disk /dev/sdb: 10.7 GB, 10737418240 bytes255 heads, 63 sectors/track, 1305 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x2d8d64eb Device Boot Start End Blocks Id System/dev/sdb1 1 262 2104483+ 83 Linux/dev/sdb2 263 1305 8377897+ 5 Extended 新建扩展分区： 123456789101112131415161718192021Command (m for help): n # 新建逻辑分区Command action l logical (5 or over) # 这里不再是扩展分区标识e，只有l。 # 如果已有3个主分区，这里连l都没有 p primary partition (1-4)l # 新建逻辑分区First cylinder (263-1305, default 263): # 这里也不能选逻辑分区号了Using default value 263Last cylinder, +cylinders or +size&#123;K,M,G&#125; (263-1305, default 1305): +3GCommand (m for help): pDisk /dev/sdb: 10.7 GB, 10737418240 bytes255 heads, 63 sectors/track, 1305 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x2d8d64eb Device Boot Start End Blocks Id System/dev/sdb1 1 262 2104483+ 83 Linux/dev/sdb2 263 1305 8377897+ 5 Extended/dev/sdb5 263 655 3156741 83 Linux 分区结束，保存。如果不保存，则按q。 12345Command (m for help): w The partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 分区的过程，实质上是划分柱面以及修改分区表。 上面的fdisk操作全部是在内存中执行的，必须保存生效。保存后，内核还未识别该分区，可以查看/proc/partition目录下存在的文件，这些文件是能被内核识别的分区。运行partprobe或partx命令重新读取分区表让内核识别新的分区，内核识别后才可以格式化。而且分区结束时按w保存分区表有时候会失败，提示重启，这时候运行partprobe命令可以代替重启就生效。 12345[root@xuexi ~]# partprobe # 执行partprobe，下面一堆信息，不理它Warning: WARNING: the kernel failed to re-read the partition table on /dev/sda (Device or resource busy). As a result, it may not reflect all of your changes until after reboot.Warning: Unable to open /dev/sr0 read-write (Read-only file system). /dev/sr0 has been opened read-only.Warning: Unable to open /dev/sr0 read-write (Read-only file system). /dev/sr0 has been opened read-only.Error: Invalid partition table - recursive partition on /dev/sr0. 也可指定在/dev/sdb上重加载分区表，省的无法读取正忙的/dev/sda磁盘，给出上面一堆信息。 1[root@xuexi ~]# partprobe /dev/sdb 分区之后再使用fdisk -l查看新的分区状态。 将上面分区所需要使用的命令总结如下，以后便于使用脚本分区。 s fdisk /dev/sdb # 选择要分区的设备n # 创建分区p/e/l # 选择分区类型 如果主分区数有3个，且已经划分了扩展分区，再继续分区时将只能划分逻辑分区，这种情况下l选项会直接跳过进入下一个阶段。 s N # 指定分区号\\n # 指定起始柱面号，使用默认值就直接回车即换行+N # 指定分区大小为Nw # 分区结束保存退出partprobe /dev/sdb &amp;&gt;/dev/null # 重读分区表fdisk -l | grep “^/dev/sdb” &amp;&gt;/dev/null # 检查分区状态 使用gdisk分区工具gdisk用来划分gpt分区，需要单独安装这个工具包。 1shell&gt; yum -y install gdisk 分区的时候直接带上设备即可。以下是对新硬盘划分gpt分区的过程。 12345678910111213141516171819202122232425262728[root@xuexi ~]# gdisk /dev/sdbGPT fdisk (gdisk) version 0.8.10Partition table scan: MBR: not present BSD: not present APM: not present GPT: not presentCreating new GPT entries.Command (? for help): ?b back up GPT data to a filec change a partition&apos;s named delete a partition # 删除分区i show detailed information on a partition # 列出分区详细信息l list known partition types # 列出所以已知的分区类型n add a new partition # 添加新分区o create a new empty GUID partition table (GPT) # 创建一个新的空的guid分区表p print the partition table # 输出分区表信息q quit without saving changes # 退出gdisk工具r recovery and transformation options (experts only) s sort partitions t change a partition&apos;s type code # 修改分区类型v verify diskw write table to disk and exit # 将分区信息写入到磁盘x extra functionality (experts only) ? print this menu 添加一个新分区。 1234567891011121314151617181920212223242526272829Command (? for help): n Partition number (1-128, default 1):First sector (34-41943006, default = 2048) or &#123;+-&#125;size&#123;KMGTP&#125;:Last sector (2048-41943006, default = 41943006) or &#123;+-&#125;size&#123;KMGTP&#125;: +10GCurrent type is &apos;Linux filesystem&apos;Hex code or GUID (L to show codes, Enter = 8300):Changed type of partition to &apos;Linux filesystem&apos; Command (? for help): pDisk /dev/sdb: 41943040 sectors, 20.0 GiBLogical sector size: 512 bytesDisk identifier (GUID): F8AE925F-515F-4807-92ED-4109D0827191Partition table holds up to 128 entriesFirst usable sector is 34, last usable sector is 41943006Partitions will be aligned on 2048-sector boundariesTotal free space is 20971453 sectors (10.0 GiB) Number Start (sector) End (sector) Size Code Name 1 2048 20973567 10.0 GiB 8300 Linux filesystemCommand (? for help): i # 查看分区详细信息Using 1Partition GUID code: 0FC63DAF-8483-4772-8E79-3D69D8477DE4 (Linux filesystem)Partition unique GUID: B2452103-4F32-4B60-AEF7-4BA42B7BF089First sector: 2048 (at 1024.0 KiB)Last sector: 20973567 (at 10.0 GiB)Partition size: 20971520 sectors (10.0 GiB)Attribute flags: 0000000000000000Partition name: &apos;Linux filesystem ‘保存分区表到磁盘。 12345678Command (? for help): w Final checks complete. About to write GPT data. THIS WILL OVERWRITE EXISTINGPARTITIONS!!Do you want to proceed? (Y/N): YOK; writing new GUID partition table (GPT) to /dev/sdb.The operation has completed successfully. 执行partprobe重新读取分区表信息。 1[root@server2 ~]# partprobe /dev/sdb gdisk还有几个expert only的命令，其实没什么专家不专家可用的，咱们需要知道的是命令何时能用，它们的作用是什么？ 在gdisk交互过程命令行下，按下x表示进入扩展功能模式，该模式下的功能大部分都和gpt分区表相关，在不是非常了解gpt分区表结构的时候不建议做修改动作，但是查看信息类是没问题的。以下是扩展功能模式下的命令。 123456789101112131415161718192021222324Command (? for help): xExpert command (? for help): ?a set attributesc change partition GUIDd display the sector alignment valuee relocate backup data structures to the end of the diskg change disk GUIDh recompute CHS values in protective/hybrid MBRi show detailed information on a partitionl set the sector alignment valuem return to main menun create a new protective MBRo print protective MBR datap print the partition tableq quit without saving changesr recovery and transformation options (experts only)s resize partition table # 修改分区表大小，注意不是分区大小t transpose two partition table entriesu Replicate partition table on new device # 将分区表导出v verify diskw write table to disk and exitz zap (destroy) GPT data structures and exit # 损毁gpt上的数据? print this menu 使用parted分区工具parted支持mbr格式和gpt格式的磁盘分区。它的强大在于可以一步到位而不需要不断的交互式输入(也可以交互式)。 parted分区工具是实时的，所以每一步操作都是直接写入磁盘而不是写进内存，它不像fdisk/gdisk还需要w命令将内存中的结果保存到磁盘中。 1234567891011121314151617181920212223242526[root@xuexi ~]# parted /dev/sdcGNU Parted 2.1Using /dev/sdcWelcome to GNU Parted! Type &apos;help&apos; to view a list of commands. (parted) help align-check TYPE N check partition N for TYPE(min|opt) alignment check NUMBER do a simple check on the file system(centos 7上已删除该功能) cp [FROM-DEVICE] FROM-NUMBER TO-NUMBER copy file system to another partition(centos 7上已删除该功能) help [COMMAND] print general help, or help on COMMAND mklabel,mktable LABEL-TYPE create a new disklabel (partition table) mkfs NUMBER FS-TYPE make a FS-TYPE file system on partition NUMBER (centos 7上已删除改该功能) mkpart PART-TYPE [FS-TYPE] START END make a partition mkpartfs PART-TYPE FS-TYPE START END make a partition with a file system(centos 7上已删除该功能) move NUMBER START END move partition NUMBER(centos 7上已删除该功能) name NUMBER NAME name partition NUMBER as NAME print [devices|free|list,all|NUMBER] display the partition table,available devices,free space, all found partitions,or a particular partition quit exit program rescue START END rescue a lost partition near START and END resize NUMBER START END resize partition NUMBER and its file system(修改分区大小(centos 7上已删除该功能)) rm NUMBER delete partition NUMBER (删除分区) select DEVICE choose the device to edit (重选磁盘进入parted状态) set NUMBER FLAG STATE change the FLAG on partition NUMBER(设置分区状态，如将其off或on) toggle [NUMBER [FLAG]] toggle the state of FLAG on partition NUMBER(修改文件系统类型，如swap、lvm) unit UNIT set the default unit to UNIT(修改默认单位，kB/MB/GB等) version display the version number and copyright information of GNU Parted 常用的命令是mklabel/rm/print/mkpart/help/quit，至于parted中一些看上去很好的功能如mkfs/mkpartfs/resize等可能会损毁当前数据而不够安全，所以只要使用它的5个常用命令即可。 parted分区的前提是磁盘已经有分区表(partition table)或磁盘标签(disk label)，否则将显示”unrecognised disk label”，这是和fdisk/gdisk不同的地方，所以需要先使用mklabel创建标签或分区表，最常见的标签(分区表)为”msdos”和”gpt”，其中msdos分区就是MBR格式的分区表，也就是会有主分区、扩展分区和逻辑分区的概念和限制。 下面使用parted对/dev/sdc创建msdos的新分区。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869[root@xuexi ~]# parted /dev/sdcGNU Parted 2.1Using /dev/sdbWelcome to GNU Parted! Type &apos;help&apos; to view a list of commands.(parted) mklabel # 创建磁盘分区标签(分区表类型) New disk label type? msdos # 选择msdos即MBR类型 # 上面的两步也可以直接一步进行：(parted) mklabel msdos (parted) mkpart # 开始进行分区 Partition type? primary/extended? p # 创建主分区File system type? [ext2]? ext4 # 创建ext4文件系统 # (注意，这里虽然指明了文件系统，但没有任何意义，后面还是需要手动格式化并选择文件系统类型)Start? 1 # 分区开始位置，默认是M为单位，表示从1M开始，也可直接指定1G这种方式End? 1024 # 分区结束位置，1024-1=1023M(parted) p # print，查看分区信息Model: VMware, VMware Virtual S (scsi)Disk /dev/sdc: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdosNumber Start End Size Type File system Flags 1 1049kB 1024MB 1023MB primary# 可以一步完成一个命令中的多个动作(parted) mkpart p ext4 1026M 4096M # 可以一步完成，也可以一步完成到任何位置，然后继续交互下一步 # 可能会提示分区未对齐&quot;Warning: The resulting partition is not properly aligned for best performance.&quot;，忽略它(parted) mkpart e 4098 -1 # 创建扩展分区，注意创建扩展分区时不指定文件系统类型；-1表示剩余的全部分配给该分区(parted) p Model: VMware, VMware Virtual S (scsi)Disk /dev/sdc: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdos Number Start End Size Type File system Flags 1 1049kB 1024MB 1023MB primary 2 1026MB 4096MB 3070MB primary 3 4098MB 21.5GB 17.4GB extended lba(parted) mkpart l ext4 4099 8194 # 创建逻辑分区，指定ext4(parted) mkpart l ext4 8195 -1 # 继续创建逻辑分区(parted) pModel: VMware, VMware Virtual S (scsi)Disk /dev/sdc: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdosNumber Start End Size Type File system Flags 1 1049kB 1024MB 1023MB primary 2 1026MB 4096MB 3070MB primary 3 4098MB 21.5GB 17.4GB extended lba 5 4099MB 8194MB 4095MB logical 6 8195MB 21.5GB 13.3GB logical(parted) rm 5 # 删除5号分区(parted) pModel: VMware, VMware Virtual S (scsi)Disk /dev/sdc: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdosNumber Start End Size Type File system Flags 1 1049kB 1024MB 1023MB primary 2 1026MB 4096MB 3070MB primary 3 4098MB 21.5GB 17.4GB extended lba 5 8195MB 21.5GB 13.3GB logical(parted) quit # 退出parted工具Information: You may need to update /etc/fstab. # 提示你要更新/etc/fstab中的配置，说明该工具是可以在线分区的 mkfs和mkpartfs等命令不完善，下面的警告信息已经给出了提示。 123456789101112(parted) mkfs 1 WARNING: you are attempting to use parted to operate on (mkfs) a file system.parted&apos;s file system manipulation code is not as robust as what you&apos;ll find indedicated, file-system-specific packages like e2fsprogs. We recommendyou use parted only to manipulate partition tables, whenever possible.Support for performing most operations on most types of file systemswill be removed in an upcoming release.Warning: The existing file system will be destroyed and all data on the partition will be lost. Do you want tocontinue?parted: invalid token: 1Yes/No? n 使用parted工具进行的分区无需运行partprobe重新读取分区表，内核会即时识别已经分区的分区信息。如下所示。 123456[root@xuexi tmp]# cat /proc/partitions | grep &quot;sdc&quot; 8 32 20971520 sdc 8 33 999424 sdc1 8 34 2998272 sdc2 8 35 1 sdc3 8 37 12967936 sdc5 一定要注意，虽然parted工具中指定了文件系统，但是并没有意义，它仍需要手动进行格式化并指定分区类型。实际上，在parted中文件系统是可以不用指定的，即使是非交互模式下也可以省略。 fdisk/gdisk以及parted非交互式操作分区使用非交互分区时，最重要的是待分的区的起始点不能是已使用的。可以使用lsblk或fdisk -l或parted DEV print来判断将要从哪个地方开始分区。其实parted在非交互分区是最佳的工具，不仅是因为其书写方式简洁，而且待分区的起点如不合理它会自动提示是否要自动调整。 parted实现非交互parted命令只能一次非交互一个命令中的所有动作。如下所示： 123456parted /dev/sdb mklabel msdos # 设置硬盘flagparted /dev/sdb mkpart primary ext4 1 1000 # Mbr格式分区，分别是partition type/fstype/start/endparted /dev/sdb mkpart 1 ext4 1M 10240M # gpt格式分区，分别是name/fstype/start/endparted /dev/sdb mkpart 1 10G 15G # 省略fstype的交互式分区parted /dev/sdb rm 1 # 删除分区parted /dev/sdb p # 输出信息 如果不确定分区的起点大小，可以加上-s选项使用script模式，该模式下parted将回答一切默认值，如yes、no。 12345shell&gt; parted -s /dev/sdb mkpart 3 14G 16GWarning: You requested a partition from 14.0GB to 16.0GB. The closest location we can manage is 15.0GB to 16.0GB.Is this still acceptable to you?Information: You may need to update /etc/fstab. fdisk实现非交互fdisk实现非交互的原理是从标准输入中读取，每读取一行传递一次操作。 所以可以有两种方式：使用echo和管道传递；将操作写入到文件中，从文件中读取。 例如：下面的命令创建了两个分区。使用默认值时传递空行即可。 1echo -e &quot;n\\np\\n1\\n\\n+5G\\nn\\np\\n2\\n\\n+1G\\nw\\n&quot; | fdisk /dev/sdb 如果要传递的操作很多，则可以将它们写入到一个文件中，从文件中读取。 12echo -e &quot;n\\np\\n1\\n\\n+5G\\nn\\np\\n2\\n\\n+1G\\nw\\n&quot; &gt;/tmp/a.txtfdisk /dev/sdb &lt;/tmp/a.txt gdisk实现非交互原理同fdisk。例如： 1echo -e &quot;n\\n1\\n\\n+3G\\n\\nw\\nY\\n&quot; | gdisk /dev/sdb 上面传递的各参数意义为：新建分区，分区number为1，使用默认开始扇区位置，分区大小+3G，使用默认分区类型，保存，确认。 格式化分区分区结束后就需要格式化创建文件系统了，格式化分区的过程就是创建文件系统的过程。可以使用mkfs(make filesystem)工具进行格式化，也可以使用该工具家族的其他工具如mkfs.ext4/mkfs.xfs等专门针对文件系统的工具。 要查看支持的文件系统类型，只需简单的输入mkfs然后按两下tab键，就可以列出各文件系统对应的格式化命令，这些就是支持的文件系统类型。 CentOS 6上支持的： 12[root@xuexi ~]# mkfsmkfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.ext4dev mkfs.msdos mkfs.vfat CentOS 7上支持的： 12[root@server2 ~]# mkfsmkfs mkfs.btrfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.fat mkfs.minix mkfs.msdos mkfs.vfat mkfs.xfs 5.4.1 mkfs工具 mkfs [-t fstype] 分区该工具非常简单，它只需指定一个可选的”-t”选项指定要创建的文件系统类型，如果省略则默认创建ext2文件系统。该工具指定的”-t”选项其实是在调用对应文件系统专属的格式化工具。 mke2fs工具mkfs.ext2/mkfs.ext3/mkfs.ext4或mkfs -t extX其实都是在调用mke2fs工具。 该工具创建文件系统时，会从/etc/mke2fs.conf配置中读取默认的配置项。 1234567891011121314151617181920212223242526272829303132mke2fs [ -c ] [ -b block-size ] [ -f fragment-size ] [ -g blocks-per-group ] [ -G number-of-groups ] [ -i bytes-per-inode ] [ -I inode-size ] [ -j ] [ -N number-of-inodes ] [ -m reserved-blocks-percentage ] [ -q ] [ -r fs-revision-level ] [ -v ] [ -L volume-label ] [ -S ] [ -t fs-type ] device [ blocks-count ]选项说明：-t fs-type ：指定要创建的文件系统类型(ext2,ext3 ext4)，若不指定，则从/etc/mke2fs.conf中获取默认的文件系统类型。-b block-size ：指定每个block的大小，有效值有1024、2048和4096，单位是字节。-I inode-size ：指定inode大小，单位为字节。必须为2的幂次方，且大于等于128字节。值越大，说明inode的集合体inode table占用越多的空 间，这不仅会挤占文件系统中的可用空间，还会降低性能，因为要扫描inode table需要消耗更多时间，但是在linux kernel 2.6.10 之后，由于使用inode存储了很多扩展的额外属性，所以128字节已经不够用了，因此ext4默认的inode size已经变为256，尽管 inode大小增大了，但因为使用inode存储扩展属性带来的性能提升远高于inode size变大导致的负面影响，所以仍建议使用256字 节的inode。-i bytes-per-inode ：指定每多少个字节就为其分配一个inode号。值越大，说明一个文件系统中分配的inode号越少，更适用于存储大量大文件，值越 小，inode号越多，更适用于存储大量小文件。该值不能小于一个block的大小，因为这样会造成inode多余。 注意，创建文件系统后该值就不能再改变了。-c ：创建文件系统前先检查设备是否有bad blocks。-f fragment-size ：指定fragments的大小，单位字节。-g blocks-per-group：指定每个块组中的block数量。不建议修改此项。-G number-of-groups：该选项用于ext4文件系统(严格地说是启用了flex_bg特性)，指定虚拟块组(即一个extent)中包含的块组个数，必须为2的幂次方。 对于ext4文件系统来说，使用extent的功能能极大提升其性能。-j ：创建带有日志功能的文件系统，即ext3。如果要指定关于日志方面的设置，在-j的基础上再使用-J指定，不过一般默认即可，具体可 指定的选项看man文档。 -L new-volume-label：指定卷标名称，名称不得超出16字节。-m reserved-blocks-percentage：指定文件系统保留block数量的比例，保留一部分block，可以降低物理碎片。默认比例为5%。-N number-of-inodes ：强制指定该文件系统应该分配多少个inode号，它会覆盖通过计算得出inode数量的结果(根据block大小、数量和每多少字节分配 一个inode得出Inode数量)，但是不建议这么做。-q ：安静模式，可用于脚本中-S ：重建superblock和group descriptions。在所有的superblock和备份的superblock都损坏时有用。它会重新初始化superblock和 group descriptions，但不会改变inode table、bmap和imap(若真的改变，该分区数据就全丢了，还不如重新格式化)。在重建 superblock后，应该执行e2fsck来保证文件系统的一致性。但要注意，应该完全正确地指定block的大小，其改选项并不能完全保 证数据不丢失。-v ：输出详细执行过程 所以，有可能用到的选项也就”-t”指定文件系统类型，”-b”指定block大小，”-I”指定inode大小，”-i”指定分配inode的比例。 例如： 1234567891011121314151617181920212223shell&gt; mke2fs -t ext4 -I 256 /dev/sdb2 -b 4096mke2fs 1.41.12 (17-May-2010)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks655360 inodes, 2621440 blocks131072 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=268435456080 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632Writing inode tables: done Creating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: doneThis filesystem will be automatically checked every 39 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override. 提示使用tune2fs修改自动检测文件系统的频率。见下文。 tune2fs修改ext文件系统属性该工具其实没什么太大作用，文件系统创建好后很多属性是固定不能修改的，能修改的属性很有限，且都是无关紧要的。 但有些时候还是可以用到它做些事情，例如刚创建完ext文件系统后会提示修改自检时间。 1234tune2fs [ -c max-mount-counts ] [ -i interval-between-checks ] [ -j ] device-j：将ext2文件系统升级为ext3；-c：修改文件系统最多挂载多少次后进行自检，设置为0或-1将永不自检；-i：修改过了多少时间进行自检。时间单位可以指定为天(默认)/月/星期[d|m|w]，设置为0将永不自检。 例如：tune2fs -i 0 /dev/sdb15.5 查看文件系统状态信息 lsblklsblk(list block devices)用于列出设备及其状态，主要列出非空的存储设备。其实它只会列出/sys/dev/block中的主次设备号文件，且默认只列出非空设备。 1[root@server2 ~]# lsblk 其中上面的几列意义如下： NAME：设备名称；MAJ:MIN：主设备号和此设备号；RM：是否为可卸载设备，1表示可卸载设备。可卸载设备如光盘、USB等。并非能够umount的就是可卸载的；SIZE：设备总空间大小；RO：是否为只读；TYPE：是磁盘disk，还是分区part，亦或是rom，还有loop设备；mountpoint：挂载点。 123456789[root@server2 ~]# lsblk /dev/sdbNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsdb 8:16 0 20G 0 disk├─sdb1 8:17 0 9.5G 0 part /mydata/data└─sdb2 8:18 0 3G 0 part[root@server2 ~]# lsblk /dev/sdb1NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsdb1 8:17 0 9.5G 0 part /mydata/data 另外常用的一个选项是”-f”，它可以查看到文件系统类型，和文件系统的uuid和挂载点。 1234567891011[root@xuexi ~]# lsblk -fNAME FSTYPE LABEL UUID MOUNTPOINTsda ├─sda1 ext4 77b5f0da-b0f9-4054-9902-c6cdacf29f5e /boot├─sda2 ext4 f199fcb4-fb06-4bf5-a1b7-a15af0f7cb47 /└─sda3 swap 6ae3975c-1a2a-46e3-87f3-d5bd3f1eff48 [SWAP]sr0 sdb ├─sdb1 ext4 95e5b9d5-be78-43ed-a06a-97fd1de9a3fe├─sdb2 ext2 45da2d94-190a-4548-85bb-b3c46ae6d9a7└─sdb3 每个已经格式化的文件系统都有其类型和uuid，而没有格式化的设备(如/dev/sdb3)，将只显示一个Name结果，表示该设备还未进行格式化。 blkid虽然它有不少比较强大的功能，但一般只用它一个功能，就是查看器文件系统类型和uuid。 123456789[root@xuexi ~]# blkid/dev/sda1: UUID=&quot;77b5f0da-b0f9-4054-9902-c6cdacf29f5e&quot; TYPE=&quot;ext4&quot;/dev/sda2: UUID=&quot;f199fcb4-fb06-4bf5-a1b7-a15af0f7cb47&quot; TYPE=&quot;ext4&quot;/dev/sda3: UUID=&quot;6ae3975c-1a2a-46e3-87f3-d5bd3f1eff48&quot; TYPE=&quot;swap&quot;/dev/sdb1: UUID=&quot;95e5b9d5-be78-43ed-a06a-97fd1de9a3fe&quot; TYPE=&quot;ext4&quot;/dev/sdb2: UUID=&quot;45da2d94-190a-4548-85bb-b3c46ae6d9a7&quot; TYPE=&quot;ext2&quot;[root@xuexi ~]# blkid /dev/sdb1/dev/sdb1: UUID=&quot;95e5b9d5-be78-43ed-a06a-97fd1de9a3fe&quot; TYPE=&quot;ext4&quot; parted /dev/sda print和fdisk -l1234567891011121314151617181920212223shell&gt; parted /dev/sdb pModel: VMware, VMware Virtual S (scsi)Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 1049kB 10.2GB 10.2GB ext4 2 10.2GB 13.5GB 3221MB ext2 Linux filesystemshell&gt; fdisk -l /dev/sdaDisk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x000cb657 Device Boot Start End Blocks Id System/dev/sda1 * 2048 514047 256000 83 Linux/dev/sda2 514048 37847039 18666496 83 Linux/dev/sda3 37847040 41943039 2048000 82 Linux swap / Solaris 虽然fdisk和gdisk分别是mbr和gpt格式的专用工具，但是仅用于查看信息还是可以的。parted能兼容两者，所以也可以。 file -s12[root@xuexi ~]# file -s /dev/sdb2/dev/sdb2: Linux rev 1.0 ext2 filesystem data (large files) dudu命令用于评估文件的空间占用情况，它会统计每个文件的大小，统计时会递归统计目录中的文件，也就是说，它会遍历整个待统计目录，所以统计速度上可能并不理想。 123456789101112du [OPTION]... [FILE]...选项说明：-a, --all：列出目录中所有文件的统计信息，默认只会列出目录中子目录的统计信息，而不列出文件的统计信息-h, --human-readable：人性化显示大小-0, --null：以空字符结尾，即&quot;\\0&quot;而非换行的&quot;\\n&quot;-S, --separate-dirs：不包含子目录的大小-s, --summarize：对目录做总的统计，不列出目录内文件的大小信息-c,--total：对给出的文件或目录做总计。在统计非同一个目录文件大小时非常有用。见下文例子。--max-depth=N：只列出给定层次的目录统计，如果N=0，则等价于&quot;-s&quot;-x, --one-file-system：忽略不同文件系统上的文件，不对它们进行统计-X, --exclude-from=FILE：从文件中读取要排除的文件--exclude=PATTERN：指定要忽略不统计的文件 注意: (1).上面的选项中，有些是不列出某些项，有些是不统计某些项，它们是不一样的。 (2).如果要统计的目录下挂载了一个文件系统，那么这个文件系统的大小也会被计入该目录的大小中。 12[root@xuexi ~]# du -sh /etc29M /etc 12345678[root@xuexi ~]# du -ah /tmp4.0K /tmp/b.txt4.0K /tmp/a4.0K /tmp/.ICE-unix4.0K /tmp/testdir/subdir0 /tmp/testdir/a.log8.0K /tmp/testdir24K /tmp 12345678910111213[root@xuexi ~]# du -h --max-depth=1 /usr15M /usr/include383M /usr/lib64132K /usr/local391M /usr/share4.0K /usr/etc118M /usr/lib44M /usr/libexec49M /usr/src32M /usr/sbin4.0K /usr/games75M /usr/bin1.1G /usr 123456789101112[root@xuexi ~]# du -h --max-depth=1 --exclude=/usr/lib64 /usr15M /usr/include132K /usr/local391M /usr/share4.0K /usr/etc118M /usr/lib44M /usr/libexec49M /usr/src32M /usr/sbin4.0K /usr/games75M /usr/bin721M /usr 搜索符合条件的文件，然后统计它们的总大小。结合find使用，效果极佳。 12345678[root@xuexi ~]# find /boot/ -type f -name &quot;*.img&quot; -print0 | xargs -0 du -ch28K /boot/grub2/i386-pc/core.img4.0K /boot/grub2/i386-pc/boot.img592K /boot/initrd-plymouth.img44M /boot/initramfs-0-rescue-d13bce5e247540a5b5886f2bf8aabb35.img17M /boot/initramfs-3.10.0-327.el7.x86_64.img16M /boot/initramfs-3.10.0-327.el7.x86_64kdump.img76M total 请注意”-c”和”-s”统计的区别。 1234567[root@xuexi ~]# find /boot/ -type f -name &quot;*.img&quot; -print0 | xargs -0 du -sh28K /boot/grub2/i386-pc/core.img4.0K /boot/grub2/i386-pc/boot.img592K /boot/initrd-plymouth.img44M /boot/initramfs-0-rescue-d13bce5e247540a5b5886f2bf8aabb35.img17M /boot/initramfs-3.10.0-327.el7.x86_64.img16M /boot/initramfs-3.10.0-327.el7.x86_64kdump.img dfdf用于报告磁盘空间使用率，默认显示的大小是1K大小block数量，也就是以k为单位。 和du不同的是，df是读取每个文件系统的superblock信息，所以评估速度非常快。由于是读取superblock，所以如果目录下挂载了另一个文件系统，是不会将此挂载的文件系统计入目录大小的。注意，du和df统计的结果是不一样的，如果对它们的结果不同有兴趣，可参考我的另一篇文章：详细分析du和df的统计结果为什么不一样。 如果用df统计某个文件的空间使用情况，将会转而统计该文件所在文件系统的空间使用情况。 12345678df [OPTION]... [FILE]...选项说明：-h：人性化转换大小的显示单位-i：统计inode使用情况而非空间使用情况-l, --local：只列出本地文件系统的使用情况，不列出网络文件系统信息-T, --print-type：同时输出文件系统类型-t, --type=TYPE：只列出给定文件系统的统计信息-x, --exclude-type=TYPE：指定不显示的文件系统类型的统计信息 示例： 12345678910[root@server2 ~]# df -hTFilesystem Type Size Used Avail Use% Mounted on/dev/sda2 xfs 18G 2.3G 16G 13% /devtmpfs devtmpfs 904M 0 904M 0% /devtmpfs tmpfs 913M 0 913M 0% /dev/shmtmpfs tmpfs 913M 8.6M 904M 1% /runtmpfs tmpfs 913M 0 913M 0% /sys/fs/cgroup/dev/sda1 xfs 247M 110M 137M 45% /boottmpfs tmpfs 183M 0 183M 0% /run/user/0/dev/sdb1 ext4 9.3G 37M 8.8G 1% /mydata/data 12345678910[root@server2 ~]# df -iFilesystem Inodes IUsed IFree IUse% Mounted on/dev/sda2 18666496 106474 18560022 1% /devtmpfs 231218 388 230830 1% /devtmpfs 233586 1 233585 1% /dev/shmtmpfs 233586 479 233107 1% /runtmpfs 233586 13 233573 1% /sys/fs/cgroup/dev/sda1 256000 330 255670 1% /boottmpfs 233586 1 233585 1% /run/user/0/dev/sdb1 625856 14 625842 1% /mydata/data dumpe2fs用于查看ext类文件系统的superblock及块组信息。使用-h选项将只显示superblock信息。 以下是ext4文件系统superblock的信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@xuexi ~]# dumpe2fs -h /dev/sda2dumpe2fs 1.41.12 (17-May-2010)Filesystem volume name: &lt;none&gt;Last mounted on: /Filesystem UUID: f199fcb4-fb06-4bf5-a1b7-a15af0f7cb47Filesystem magic number: 0xEF53Filesystem revision #: 1 (dynamic)Filesystem featurs: has_journal ext_attr resize_inode dir_index filetype needs_recovery exent flex_bg sparse_super large_file huge_file uninit_bg dir_nlink extra_isizeFilesystem flags: signed_directory_hashDefault mount options: user_xattr aclFilesystem state: cleanErrors behavior: ContinueFilesystem OS type: LinuxInode count: 1166880Block count: 4666624Reserved block count: 233331Free blocks: 4196335Free inodes: 1111754First block: 0Block size: 4096Fragment size: 4096Reserved GDT blocks: 1022Blocks per group: 32768Fragments per group: 32768Inodes per group: 8160Inode blocks per group: 510Flex block group size: 16Filesystem created: Sat Feb 25 11:48:47 2017Last mount time: Tue Jun 6 18:13:10 2017Last write time: Sat Feb 25 11:53:49 2017Mount count: 6Maximum mount count: -1Last checked: Sat Feb 25 11:48:47 2017Check interval: 0 (&lt;none&gt;)Lifetime writes: 2657 MBReserved blocks uid: 0 (user root)Reserved blocks gid: 0 (group root)First inode: 11Inode size: 256Required extra isize: 28Desired extra isize: 28Journal inode: 8Default directory hash: half_md4Directory Hash Seed: d4e6493a-09ef-41a1-9d66-4020922f1aa9Journal backup: inode blocksJournal features: journal_incompat_revokeJournal size: 128MJournal length: 32768Journal sequence: 0x00001bd9Journal start: 23358 其中一个块组信息。 123456789[root@xuexi ~]# dumpe2fs /dev/sda2 | tail -7dumpe2fs 1.41.12 (17-May-2010)Group 142: (Blocks 4653056-4666623) [INODE_UNINIT, ITABLE_ZEROED] Checksum 0x64ce, unused inodes 8160 Block bitmap at 4194318 (+4294508558), Inode bitmap at 4194334 (+4294508574) Inode table at 4201476-4201985 (+4294515716) 13568 free blocks, 8160 free inodes, 0 directories, 8160 unused inodes Free blocks: 4653056-4666623 Free inodes: 1158721-1166880 挂载和卸载文件系统在此，只简单介绍mount和umount的用法，至于实现挂载和卸载的机制和原理细节，参看挂载文件系统的细节。 mountmount用来显示挂载信息或者进行文件系统挂载，它的功能及其的强大(强大到离谱)，它不仅支持挂载非常多种文件系统，如ext/xfs/nfs/smbfs/cifs (win上的共享目录)等，还支持共享挂载点、继承挂载点(父子关系)、绑定挂载点、移动挂载点等等功能。在本文只介绍其最简单的挂载功能。 不同的文件系统挂载选项是有所差别的，在挂载过程中如果出错，应该man mount并查看对应文件系统的挂载选项。 mount并非只能挂载文件系统，也可以将目录挂载到另一个目录下，其实它实现的是目录”硬链接”，默认情况下，是无法对目录建立硬链接的，但是通过mount可以完成绑定，绑定后两个目录的inode号是完全相同的，但尽管建立的是目录的”硬链接”，但其实也仅是拿来当软链接用。 以下是ext类文件系统的选项，可能有些选项是不支持其他文件系统的。 1234567891011121314151617181920212223242526mount # 将显示当前已挂载信息mount [-t 欲挂载文件系统类型 ] [-o 特殊选项] 设备名 挂载目录选项说明：-a 将/etc/fstab文件里指定的挂载选项重新挂载一遍。-t 支持ext2/ext3/ext4/vfat/fat/iso9660(光盘默认格式)。 不用-t时默认会调用blkid来获取文件系统类型。-n 不把挂载记录写在/etc/mtab文件中，一般挂载会在/proc/mounts中记录下挂载信息，然后同步到/etc/mtab，指定-n表示不同步该挂载信息。-o 指定挂载特殊选项。下面是两个比较常用的： loop 挂载镜像文件，如iso文件 ro 只读挂载 rw 读写挂载 auto 相当于mount -a dev 如果挂载的文件系统中有设备访问入口则启用它，使其可以作为设备访问入口 default rw,suid,dev,exec,auto,nouser,async,and relatime async 异步挂载，只写到内存 sync 同步挂载，通过挂载位置写入对方硬盘 atime 修改访问时间，每次访问都修改atime会导致性能降低，所以默认是noatime noatime 不修改访问时间，高并发时使用这个选项可以减少磁盘IO nodiratime 不修改文件夹访问时间，高并发时使用这个选项可以减少磁盘IO exec/noexec 挂载后的文件系统里的可执行程序是否可执行，默认是可以执行exec， 优先级高于权限的限定 remount 重新挂载，此时可以不用指定挂载点。 suid/nosuid 对挂载的文件系统启用或禁用suid，对于外来设备最好禁用suid _netdev 需要网络挂载时默认将停留在挂载界面直到加载网络了。使用_netdev可以忽略网络正常挂载。如NFS开机挂载。 user 允许普通用户进行挂载该目录，但只允许挂载者进行卸载该目录 users 允许所有用户挂载和卸载该目录 nouser 禁止普通用户挂载和卸载该目录，这是默认的，默认情况下一个目录不指定user/users时，将只有root能挂载 一般user/users/nouser都用在/etc/fstab中，直接在命令行下使用这几个选项意义不是很大。 例如：(1).挂载CentOS的安装镜像到/mnt。 1mount /dev/cdrom /mnt 其实/dev/cdrom是/dev/sr0的一个软链接，/dev/sr0是光驱设备，所以也可以用/dev/sr0进行挂载。 1mount /dev/sr0 /mnt (2).重新挂载。 1[root@xuexi ~]# mount -t ext4 -o remount /dev/sdb1 /data1 (3).重新挂载文件系统为可读写。 1mount -t ext4 -o rw remount /dev/sdb1 /data1 (4).挂载windows的共享目录。win上共享文件的文件系统是cifs类型，要在Linux上挂载，必须得有mount.cifs命令，如果没有则安装cifs-utils包。 假设win上共享目录的unc路径为\\192.168.100.8\\test，共享给的用户名和密码分别为long3:123，要挂在linux上的/mydata目录上。 1shell&gt; mount.cifs -o username=&quot;long3&quot;,password=&quot;123&quot; //192.168.100.8/test /mydata 注意，如果是比较新版本的win10(2017年之后更新的版本)或较新版本的win server，直接mount.cifs会报错： 123[root@xuexi ~]# mount.cifs -o username=&quot;long3&quot;,password=&quot;123&quot; //192.168.100.8/test /mnt mount error(112): Host is downRefer to the mount.cifs(8) manual page (e.g. man mount.cifs) 这是因为2017年微软的一个补丁禁用了SMBv1协议，通过smbclient的报告可知： 1234[root@xuexi ~]# yum -y install samba-client[root@xuexi ~]# smbclient -L //192.168.100.8Enter root&apos;s password: protocol negotiation failed: NT_STATUS_CONNECTION_RESET 因此，在mount的时候指定cifs(SMB)的版本号为2.0即可。 1[root@xuexi ~]# mount.cifs -o username=&quot;long3&quot;,password=&quot;123&quot;,vers=2.0 //192.168.100.8/test /mnt 但是需要注意，在CentOS 4,5,6下的模块cifs.ko版本(较低)只能使用SMBv1协议，因此即使指定版本号也一样无效。只有在CentOS 7上才能使用SMBv2或SMBv3。 (5).基于ssh挂载远程目录。如何基于ssh像NFS一样挂载远程主机上的目录？可以通过sshfs工具，该工具在fuse-sshfs包中，这个包在epel源中提供。 1yum -y install fuse-sshfs 例如，挂载192.168.100.8上的根目录到本地的/mnt上。 1sshfs 192.168.100.8:/ /mnt 卸载时直接umount即可。 (6).挂载目录到另一个目录下。挂载目录时，挂载目录和挂载点的inode是相同的，它们两者的内容也是完全相同的。 1mount --bind /mydata /mnt (7).查看某个目录是否是挂载点，使用mountpoint命令。 1234567891011[root@xuexi ~]# mountpoint /mydata//mydata/ is a mountpoint[root@xuexi ~]# echo $? 0[root@xuexi ~]# mountpoint /mnt/mnt is not a mountpoint[root@xuexi ~]# echo $? 1 挂载的参数信息存放在/proc/mounts(是/proc/self/mounts的软链接)中，在/proc/self/mountstats和/proc/mountinfo里则记录了更详细的挂载信息。 1234567891011[root@xuexi ~]# cat /proc/mountsrootfs / rootfs rw 0 0proc /proc proc rw,relatime 0 0sysfs /sys sysfs rw,relatime 0 0devtmpfs /dev devtmpfs rw,relatime,size=491000k,nr_inodes=122750,mode=755 0 0devpts /dev/pts devpts rw,relatime,gid=5,mode=620,ptmxmode=000 0 0tmpfs /dev/shm tmpfs rw,relatime 0 0/dev/sda2 / ext4 rw,relatime,barrier=1,data=ordered 0 0/proc/bus/usb /proc/bus/usb usbfs rw,relatime 0 0/dev/sda1 /boot ext4 rw,relatime,barrier=1,data=ordered 0 0none /proc/sys/fs/binfmt_misc binfmt_misc rw,relatime 0 0 文件系统是需要驱动支持的，没有驱动的文件系统也无法挂载，Linux中支持的文件系统驱动在/lib/modules/$(uname -r)/kernel/fs下。 123[root@xuexi ~]# ls /lib/modules/$(uname -r)/kernel/fs/autofs4 cachefiles configfs dlm exportfs ext3 fat fuse jbd jffs2 mbcache.ko nfs_common nls ubifs xfsbtrfs cifs cramfs ecryptfs ext2 ext4 fscache gfs2 jbd2 lockd nfs nfsd squashfs udf 直接挂载镜像文件有时候需要挂载CentOS的镜像文件，在虚拟机中经常是将镜像放入虚拟机的CD/DVD虚拟光驱中，然后在Linux上对/dev/cdrom进行挂载。其实/dev/cdrom是/dev/sr0的一个软链接，/dev/sr0是Linux中的光驱，所以上面的过程相当于是将镜像文件通过虚拟软件的虚拟光驱和linux的光驱连接起来，这样只需要挂载Linux中的光驱就可以了。但是，在非虚拟环境中没有虚拟光驱，而且在Linux中的一个镜像文件难道一定要拷贝到主机上通过虚拟光驱进行连接吗？ mount是一个极其强大的挂载工具，它支持挂载很多种文件类型，其中就支持挂载镜像文件，其实它连挂载目录都支持。 12345678910mount -o loop CentOS-6.6-x86_64-bin-DVD2.iso /mnt[root@xuexi ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTloop0 7:0 0 1.2G 0 loop /mntsda 8:0 0 20G 0 disk├─sda1 8:1 0 250M 0 part /boot├─sda2 8:2 0 17.8G 0 part /└─sda3 8:3 0 2G 0 part [SWAP]sr0 11:0 1 1024M 0 rom umount12umount 设备名或挂载目录umount -lf 强制卸载 卸载时，既可以使用设备名也可以使用挂载点卸载。有时候挂载网络系统(如NFS)时，设备名很长，这时候可以使用挂载点来卸载就方便多了。 如果用户正在访问某个目录或文件，使得卸载一直显示Busy，使用fuser -v DIR可以知道谁正在访问该目录或文件。 123[root@xuexi ~]# fuser -v /root USER PID ACCESS COMMAND/root: root 37453 ..c.. bash 使用-k选项kill掉正在使用目录或文件的进程，使用-km选项kill掉文件系统上的所有进程，然后再umount。 1[root@xuexi ~]# fuser -km /mnt/cdrom;umount /mnt/cdrom 开机自动挂载/etc/fstab通过将挂载选项写入到/etc/fstab中，系统会自动挂载该文件中的配置项。但要注意，该文件在开机的前几个过程中就被读取，所以配置错误很可能会导致开机失败。其中最后两列，它们分别表示备份文件系统和开机自检，一般都可以设置为0。 由于能用的备份工具众多，没人会在这里设置备份，所以备份列设置为0。 最后一列是开机自检设置列，开机自检调用的是fsck程序，所有有些ext类文件系统作为”/“时，可能会设置为1，但是fsck是不支持xfs文件系统的，所以对于xfs文件系统而言，该项必须设置为0。其实无需考虑那么多，直接将这两列设置为0就可以了。 修复错误的/etc/fstab万一/etc/fstab配置错误，导致开机无法加载。这时提示输入root密码进入单人维护模式，只不过担任模式下根文件系统是只读的，哪怕是root也无法直接修改/etc/fstab，所以应该将”/“文件系统进行重新挂载。 执行下面的命令，重挂载根分区，并给读写权限，再去修改错误的fstab文件记录，再重启。 1[root@xuexi ~]# mount -n -o remount,rw / 按需自动挂载(autofs)使用autofs实现需要挂载时就挂载，不需要挂载时5分钟后自动卸载。但是在实际环境中基本不会使用按需挂载。 autofs是一个服务程序，需要让其运行在后台，可以用来挂NFS，也可挂本地的文件系统。 默认不装autofs，需要自己装。 1[root@xuexi ~]# yum install -y autofs autofs实现按需挂载的方式是指定监控目录，可在其配置文件/etc/auto.master中指定。 /etc/auto.master里面只有两列：第一列是监控目录；第二列是记录挂载选项的文件，该文件可以随便取名。 12[root@xuexi ~]# cat /etc/auto.master/share /etc/auto.mount # 监控/share目录，使用/etc/auto.nfs记录挂载选项 上述监控的/share目录，其实这是监控的父目录，在此目录下的目录如/share/data目录可以作为挂载点，当访问到/share/data时就被监控到，然后会按照挂载选项将挂载设备挂载到/share/data上。 上述配置中配置的挂载选项文件是/etc/auto.mount，所以建立此文件，写入挂载选项。 1234567891011[root@xuexi ~]# cat /etc/auto.mount#cd -fstype=iso9660,ro,nosuid,nodev :/dev/cdrom# the following entries are samples to pique your imagination#linux -ro,soft,intr ftp.example.org:/pub/linux#boot -fstype=ext2 :/dev/hda1#floppy -fstype=auto :/dev/fd0#floppy -fstype=ext2 :/dev/fd0#e2floppy -fstype=ext2 :/dev/fd0#jaz -fstype=ext2 :/dev/sdc1#removable -fstype=ext2 :/dev/hdd 该文件有3列： 第一列指定的是在/etc/auto.master指定的/share下的目录/share/data，它是真正的被监控路径，也是挂载点。可使用相对路径data表示/share/data。 第二列是mount的选项，前面使用一个”-“表示，该列可有可无。 第三列是待挂载设备，可以是NFS服务端的共享目录，也可以本地设备。 12[root@xuexi ~]# vim /etc/auto.mountdata -rw,bg,soft,rsize=32768,wsize=32768 192.168.100.61:/data 上面的配置表示当访问到/share/data时，自动使用参数(rw,bg,soft,rsize=32768,wsize=32768)挂载远端192.168.100.61的/data目录到/share/data上。 剩下的步骤就是启动autofs服务。 1[root@xuexi data]# /etc/init.d/autofs restart swap分区虽说个人电脑上基本已经无需设置swap分区了，但是在服务器上还是应该准备swap分区，以做到有备无患和防止众多”玄学”问题。 查看swap使用情况1234567891011[root@xuexi ~]# free total used free shared buffers cachedMem: 1906488 349376 1557112 200 16920 200200-/+ buffers/cache: 132256 1774232Swap: 2097148 0 2097148[root@xuexi ~]# free -m # 以MB显示 total used free shared buffers cachedMem: 1861 341 1520 0 16 195-/+ buffers/cache: 129 1732 # 这个是真正的可用内存空间Swap: 2047 0 2047 # 这个是swap空间，发现一点都没被用 使用mount/lsblk等可以查看出哪个分区在充当swap分区。使用swapon -s也可以直接查看出。 123[root@server2 ~]# swapon -sFilename Type Size Used Priority/dev/sda3 partition 2047996 37064 -1 添加swap分区(1).可以新分一个区，在分区时指定其分区的ID号为SWAP类型。 mbr和gpt格式的磁盘上这个ID可能不太一样，不过一般gpt中的格式是在mbr格式的ID后加上两位数的数值，如mbr中swap的类型ID为82，在gpt中则是8200，在mbr中linux filesystem类型的ID为83，在gpt中则为8300，在mbr中lvm的ID为8e，在gpt中为8e00。 (2).格式化为swap分区：mkswap 123[root@xuexi ~]# mkswap /dev/sdb5Setting up swapspace version 1, size = 1951096 KiBno label, UUID=02e5af44-2a16-479d-b689-4e100af6adf5 (3).加入swap分区空间(swapon)： 1234567[root@xuexi ~]# swapon /dev/sdb5 [root@xuexi ~]# free -m total used free shared buffers cachedMem: 1861 343 1517 0 16 196-/+ buffers/cache: 131 1730Swap: 3953 0 3953 (4).取消swap分区空间(swapoff)： 1234567[root@xuexi ~]# swapoff /dev/sdb5[root@xuexi ~]# free -m total used free shared buffers cachedMem: 1861 343 1518 0 16 196-/+ buffers/cache: 130 1731Swap: 0 0 0 (5).开机自动加载swap分区：修改/etc/fstab，加上一行。 1/dev/sda3 swap swap defaults 0 0","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"DHCP服务","slug":"DHCP 服务","date":"2017-04-09T16:00:00.000Z","updated":"2018-06-15T14:41:09.146Z","comments":true,"path":"2017/04/10/DHCP 服务/","link":"","permalink":"http://yoursite.com/2017/04/10/DHCP 服务/","excerpt":"DHCP前身是BOOTP，在Linux的网卡配置中也能看到显示的是BOOTP，DHCP引进一个bootp没有的概念：租约。bootp分配的地址是永久的，而dhcp分配的地址是可以有期限的 。12[root@xuexi vsftpd]# grep -i bootproto /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=dhcp DHCP可以自动分配IP、子网掩码、网关、DNS。DHCP客户端使用的端口68，服务端使用端口67，使用的UDP应用层的协议。","text":"DHCP前身是BOOTP，在Linux的网卡配置中也能看到显示的是BOOTP，DHCP引进一个bootp没有的概念：租约。bootp分配的地址是永久的，而dhcp分配的地址是可以有期限的 。12[root@xuexi vsftpd]# grep -i bootproto /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=dhcp DHCP可以自动分配IP、子网掩码、网关、DNS。DHCP客户端使用的端口68，服务端使用端口67，使用的UDP应用层的协议。DHCP一般不为服务器分配IP，因为他们要使用固定IP，所以DHCP一般只为办公环境的主机分配IP。 DHCP服务器和客户端需要在一个局域网内，在为客户端分配IP的时候需要进行多次广播。但DHCP也可以为其他网段内主机分配IP，只要连接两个网段中间的路由器能转发DHCP配置请求即可，但这要求路由器配置中继功能。 DHCP客户端请求过程（4步请求过程）1）搜索阶段：客户端广播方式发送报文，搜索DHCP服务器。此时网段内所有机器都收到报文，只有DHCP服务器返回消息。2）提供阶段：众多DHCP服务器返回报文信息，并从地址池找一个IP提供给客户端。因为此时客户端还没有IP，所以返回信息也是以广播的方式返回的。3）选择阶段：选择一个DHCP服务器，使用它提供的IP。然后发送广播包，告诉众多DHCP服务器，其已经选好DHCP服务器以及IP地址。此后没有入选的DHCP就可以将原本想分配的IP分配给其他主机. 客户端选择第一个接收到的IP。谁的IP先到客户端的速度是不可控的。但是如果在配置文件里开启了authoritative选项则表示该服务器是权威服务器，其他DHCP服务器将失效，如果多台服务器都配置了这个权威选项，则还是竞争机制；通过MAC地址给客户端配置固定IP也会优先于普通的动态DHCP分配。另外Windows的DHCP服务端回应Windows客户端比Linux更快。4）确认阶段：DHCP服务器收到回应，向客户端发送一个包含IP的数据包，确认租约，并指定租约时长。如果DHCP服务器要跨网段提供服务，一样是四步请求，只不过是每一步中间都多了一个路由器和DHCP服务器之间的单播通信。 1） 客户端广播方式发送报文，搜索DHCP服务器。所有机器包括路由器都收到报文，路由器配置了中继，知道搜索消息后单播给DHCP服务器；2）DHCP服务器单播返回信息给路由器，路由器再广播给客户端；3）客户端选择DHCP服务器提供的IP，并广播信息告诉它我选好了，路由器单播给DHCP服务器；4）DHCP服务器收到信息将确认信息单播给路由器，路由器单播给客户端。 所以DHCP的4步请求： 12Client--&gt; DHCPDISCOVER # 广播：客户端发现DHCP服务器 DHCPOFFER &lt;-- Server # 广播：服务端提供IP给客户端 12client--&gt; DCHPREQUEST # 广播：客户端请求使用提供的IP DCHPACK &lt;-- Server # 单播：服务端进行确认，订立租约等信息 续租的过程：12client--&gt; DHCPREQUEST # 单播：继续请求使用提供的IP DHCPACK &lt;-- Server # 单播：确认续租 HCP服务器不跨网段提供服务时，它自己的IP地址必须要和地址池中全部IP在同一网络中。DHCP服务器跨网段提供服务时，它自己的IP地址必须要和地址池中的一部分IP在同一网络中，另一部分提供给其他网段。因为如果自己的IP完全不在自己的网络中而只提供其他网段的IP，更好的做法是将DHCP服务器设在那个需要DHCP服务的网络中。当计算机从一个子网移到另一个子网，找的DHCP服务器不同，因为旧的租约还存在，会先续租，新的DHCP服务器肯定拒绝它的续租请求，这时将重新开始四步请求。有些机器希望一直使用一个固定的IP，也就是静态IP，除了手动进行配置，DHCP服务器也可以实现这个功能。DHCP服务器可以根据MAC地址来分配这台机器固定IP地址（保留地址），即使重启或重装了系统也不会改变根据MAC地址分配的地址。假如在一个正常联网有DHCP服务器的网段内因为做实验练习的缘故新建立了一台DHCP服务器，但是这台DHCP服务器不能上网，会导致什么后果？使用DHCP分配地址的客户端至少会有续租的请求，如果没有续租成功，或者有新的计算机加入这个网络，那么进行四步请求，有可能会请求到这个不能连网的DHCP服务器上，那么他也就不能上网了。特别是Windows的DHCP服务端回应Windows客户端速度比Linux回应快。安装和配置DHCP服务123456789[root@xuexi ~]# yum -y install dhcp[root@xuexi ~]# rpm -ql dhcp/etc/dhcp/dhcpd.conf # DHCP配置文件/etc/sysconfig/dhcpd/usr/sbin/dhcpd # DHCP服务程序/usr/sbin/dhcrelay # 中继命令程序，用于跨网段提供DHCP服务/var/lib/dhcpd/dhcpd.leases # 存放租借信息（如IP）和租约信息（如租约时长）/usr/share/doc/dhcp-4.1.1/dhcpd.conf.sample # 配置文件的范例文件 123可以将dhcpd.conf.sample复制到/etc/。 [root@xuexi ~]# cp /usr/share/dhcp-4.1.1/dhcpd.conf.sample /etc/dhcpd.conf 以下是dhcpd.conf中部分配置项。123456789101112131415161718192021# 每行分号结束ddns-update-style none; # 动态dns相关，几乎不开启它。也就是不管它。ignore client-updates; # 和上面的相关，也不管它authoritative # 声明为权威服务器next-server marvin.redhat.com; # PXE环境下指定的提供引导程序的文件服务器# DHCP配置文件里必须配置一个地址池，其和DHCP服务器自身IP在同一网段subnet 10.5.5.0 netmask 255.255.255.224 &#123; range 10.5.5.26 10.5.5.30; # 地址池 option domain-name-servers ns1.internal.example.org; # 为客户端指明DNS服务器地址，可以是多个，最多三个 option domain-name &quot;internal.example.org&quot;; # 为客户端指明DNS名字，定义了它会覆盖客户端/etc/resolv.conf里的配置 option routers 10.5.5.1; # 默认路由，其实就是网关 option broadcast-address 10.5.5.31; # 广播地址，不设置时默认会根据A/B/C类地址自动计算 default-lease-time 600; # 默认租约时长 max-lease-time 7200; # 最大租约时长&#125;#下面的是绑定MAC地址设置保留地址，保留地址不能是地址池中的地址host fantasia &#123; # 固定地址的配置，host后面的是标识符，没意义hardware ethernet 08:00:07:26:c0:a5; fixed-address 192.168.100.3; # 根据MAC地址分配的固定IP &#125; 如果不让dhcp修改/etc/resolv.conf里的内容，就在网卡配置文件/etc/sysconfig/network-scripts/ifcfg-ethX里添加一行选项：PEERDNS=no。在客户端如何获取动态分配的地址呢？方法一：service network restart但是每次重启网络很麻烦，可以使用客户端命令dhclient。方法二：直接执行dhclient命令这种方法下会显示4部请求中需要显示的步骤信息，以及最终分配的地址，所以是一个很好的理解dhcp工作的工具。但是这种方法只能使用一次，第二次执行命令会提示该进程已经在执行，因为dhclient是一个进程。可以kill掉该进程再执行dhclient，或者使用dhclient -d选项。方法三：dhclient -d如何重新获取IP地址每次重启网卡默认都获取的同一个ip，有时候想换个ip都很麻烦。在/var/lib/dhclient/目录下有”.leases”文件，将它们清空或者删除这些文件中对应网卡的部分，再重启网络就可以获取新的动态ip。12345678910111213141516[root@xuexi ~]# cat /var/lib/dhclient/dhclient-eth0.leases lease &#123; interface &quot;eth0&quot;; fixed-address 192.168.100.16; option subnet-mask 255.255.255.0; option routers 192.168.100.2; option dhcp-lease-time 1800; option dhcp-message-type 5; option domain-name-servers 192.168.100.2; option dhcp-server-identifier 192.168.100.254; option broadcast-address 192.168.100.255; option domain-name &quot;localdomain&quot;; renew 3 2017/02/15 12:28:27; rebind 3 2017/02/15 12:42:39; expire 3 2017/02/15 12:46:24;&#125; 或者，在/etc/sysconfig/network-scripts/ifcfg-eth0加入”DHCPRELEASE=yes”。当运行ifdown eth0的时候就会发出dhcprelase报文，查看/etc/sysconfig/network-scripts/ifdown-eth脚本中实际上是调用dhclient命令，用下面这个命令应该也可以。1/sbin/dhclient -r eth0","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"DHCP","slug":"DHCP","permalink":"http://yoursite.com/tags/DHCP/"}]},{"title":"Linux系统中su 和 sudo 的用法","slug":"Linux系统中su 和 sudo 的用法","date":"2017-03-31T16:00:00.000Z","updated":"2018-06-22T02:50:25.947Z","comments":true,"path":"2017/04/01/Linux系统中su 和 sudo 的用法/","link":"","permalink":"http://yoursite.com/2017/04/01/Linux系统中su 和 sudo 的用法/","excerpt":"su切换用户或以指定用户运行命令。 使用su可以指定运行命令的身份(user/group/uid/gid)。 12345678910111213141516171819为了向后兼容，su默认不会改变当前目录，且仅设置HOME和SHELL这两个环境变量(若目标用户非root，则还设置USER和LOGNAME环境变量)。推荐使用--login选项(即&quot;-&quot;选项)避免环境变量混乱。 su [options...] [-] [user [args...]]选项说明：-c command：使用-c选项传递要指定的命令到shell上执行。使用-c执行命令会为每个su都分配新的会话环境-, -l, --login：启动shell作为登录的shell，模拟真正的登录环境。它会做下面几件事： 1.清除除了TERM外的所有环境变量 2.初始化HOME,SHELL,USER,LOGNAME,PATH环境变量 3.进入目标用户的家目录 4.设置argv[0]为&quot;-&quot;以便设置shell作为登录的shell 使用--login的su是交互式登录。不使用--login的su是非交互式登录(除不带任何参数的su外-m, -p, --preserve-environment：保留整个环境变量(不会重新设置HOME,SHELL,USER和LOGNAME)， 保留环境的方法是新用户shell上执行原用户的各配置文件，如~/.bashrc。 当设置了--login时，将忽略该选项-s SHELL：运行指定的shell而非默认shell，选择shell的顺序优先级如下： 1.--shell指定的shell 2.如果使用了--preserve-environment，选择SHELL环境变量的shell 3.选项目标用户在passwd文件中指定的shell 4./bin/sh","text":"su切换用户或以指定用户运行命令。 使用su可以指定运行命令的身份(user/group/uid/gid)。 12345678910111213141516171819为了向后兼容，su默认不会改变当前目录，且仅设置HOME和SHELL这两个环境变量(若目标用户非root，则还设置USER和LOGNAME环境变量)。推荐使用--login选项(即&quot;-&quot;选项)避免环境变量混乱。 su [options...] [-] [user [args...]]选项说明：-c command：使用-c选项传递要指定的命令到shell上执行。使用-c执行命令会为每个su都分配新的会话环境-, -l, --login：启动shell作为登录的shell，模拟真正的登录环境。它会做下面几件事： 1.清除除了TERM外的所有环境变量 2.初始化HOME,SHELL,USER,LOGNAME,PATH环境变量 3.进入目标用户的家目录 4.设置argv[0]为&quot;-&quot;以便设置shell作为登录的shell 使用--login的su是交互式登录。不使用--login的su是非交互式登录(除不带任何参数的su外-m, -p, --preserve-environment：保留整个环境变量(不会重新设置HOME,SHELL,USER和LOGNAME)， 保留环境的方法是新用户shell上执行原用户的各配置文件，如~/.bashrc。 当设置了--login时，将忽略该选项-s SHELL：运行指定的shell而非默认shell，选择shell的顺序优先级如下： 1.--shell指定的shell 2.如果使用了--preserve-environment，选择SHELL环境变量的shell 3.选项目标用户在passwd文件中指定的shell 4./bin/sh 注意：(1). 若su没有给定任何参数，将默认以root身份运行交互式的shell(交互式，所以需要输入密码)，即切换到root用户，但只改变HOME和SHELL环境变量。 (2). su - username是交互式登录，要求密码，会重置整个环境变量，它实际上是在模拟真实的登录环境。 (3). su username是非交互登录，不会重置除HOME/SHELL外的环境变量。例如：用户wangwu家目录为/home/wangwu，其shell为/bin/csh。 123shell&gt; head -1 /etc/passwd ; tail -1 /etc/passwdroot:x:0:0:root:/root:/bin/bashwangwu:x:2002:2002::/home/wangwu:/bin/csh 首先su到wangwu上，再执行一个完全不带参数的su。 123456789shell&gt; su - wangwu # 使用su - username后，以登录shell的方式模拟登录，会重新设置各环境变量。su - username是交互式登录shell&gt; env | egrep -i &apos;^home|^shell|^path|^logname|^user&apos;HOME=/home/wangwuSHELL=/bin/cshUSER=wangwuLOGNAME=wangwuPATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbinPWD=/home/wangwu 123456789shell&gt; su # 不带任何参数的su，是交互式登录切换回root，但只会改变HOME和SHELL环境变量 shell&gt; env | egrep -i &apos;^home|^shell|^path|^logname|^user|^pwd&apos;SHELL=/bin/bashUSER=wangwuPATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbinPWD=/home/wangwuHOME=/rootLOGNAME=wangwu 12345678910shell&gt; su - # su - 的方式切换回rootPassword:shell&gt; env | egrep -i &apos;^home|^shell|^path|^logname|^user|^pwd&apos;SHELL=/bin/bashUSER=rootPATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binPWD=/rootHOME=/rootLOGNAME=root 12345678shell&gt; su wangwu # 再直接su username，它只会重置SHELL和HOME两个环境变量，其他环境变量保持不变shell&gt; env | egrep -i &apos;^home|^shell|^path|^logname|^user|^pwd&apos;SHELL=/bin/cshUSER=wangwuPATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binPWD=/rootHOME=/home/wangwuLOGNAME=wangwu 在某些环境下或脚本中，可能需要临时切换身份执行命令，注意这时候的环境变量是否会改变，否则很可能报错提示命令找不到。 sudosudo可以让一个用户以某个身份(如root或其他用户)执行某些命令，它隐含的执行方式是切换到指定用户再执行命令，因为涉及到了用户的切换，所以环境变量是否重置是需要设置的。 sudo支持插件实现安全策略。默认的安全策略插件是sudoers，它是通过/etc/sudoers或LDAP来配置的。 安全策略是控制用户使用sudo命令时具有什么权限，但要注意，安全策略可能需要用户进行身份认证，如密码认证的机制或其他认证机制，如果开启了认证要求，则在指定时间内未完成认证时sudo会退出，默认超时时间为5分钟。 安全策略支持对认证进行缓存，使得在一定时间内该用户无需再次认证就可以执行sudo命令，默认缓存时间为5分钟，sudo -v可以更新认证缓存。 sudo支持日志审核，可以记录下成功或失败的sudo。 /etc/sudoers文件该文件里主要配置sudo命令时指定的用户和对应的权限。 123456789101112131415161718shell&gt; visudo # 以下选取的是部分行## hostname or IP addresses instead. # 主机别名Host_Alias# Host_Alias FILESERVERS = fs1, fs2# Host_Alias MAILSERVERS = smtp, smtp2## User Aliases # 用户别名User_Alias# User_Alias ADMINS = jsmith, mikem## Command Aliases # 命令别名# Cmnd_Alias SERVICES = /sbin/service, /sbin/chkconfig# Cmnd_Alias LOCATE = /usr/bin/updatedb root ALL=(ALL) ALL # sudo权限的配置# %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS## Allows people in group wheel to run all commands# %wheel ALL=(ALL) ALL## Same thing without a password# %wheel ALL=(ALL) NOPASSWD: ALL 在这个文件里，主要有别名(用户别名，主机别名，命令别名)的配置和sudo权限的配置。 安全策略配置格式为： 12用户名 主机名=(可切换到的用户身份) 权限和命令① ② ③ ④ ①用户名：可以用组，只需在组名前加个百分号%表示。②主机名：表示该用户可以在哪些主机上运行sudo，可以用hostname也可以用ip指定。③可切换的用户身份，即指定执行命令的用户，也可以用组。④权限和命令：允许执行和不允许执行的命令(多个命令间用逗号分隔)和特殊权限，命令可以带其选项及参数。命令要写绝对路径。不允许执行的命令需要在命令前加上”!”来表示。可以使用标签，如NOPASSWD标签表示切换或以指定用户执行该标签后的命令时不需要输入密码。一行写不下时可使用”\\”续行。 标签使用方法：NOPASSWD:/usr/sbin/useradd,PASSWD:/usr/sbin/userdel 它表示useradd命令不需要输入密码，而userdel需要输入密码。对于别名，相当于用户对于用户组。权限配置处都可以使用别名，即①②③④处都能使用别名来配置。例如，主机别名里设置多个主机，以后在②位置处直接使用主机别名。 1FILESERVERS = fs1, fs2 以下是某设置示例：123DEFAULT=/bin/*,/sbin/ldconfig,/sbin/ifconfig,/usr/sbin/useradd,/usr/sbin/userdel,/bin/rpm,/usr/bin/yum,/sbin/service,/sbin/chkconfig,sudoedit /etc/rc.local,sudoedit /etc/hosts,sudoedit /etc/ld.so.conf,/bin/mount,sudoedit /etc/exports,/usr/bin/passwd [!-]*,!/usr/bin/passwd root,/bin/su - [!-]*,!/bin/su - root,!/bin/su root, /bin/bash, /usr/sbin/dmidecode, /usr/sbin/lsof, /usr/bin/du, /usr/bin/python, /usr/sbin/xm,sudoedit /etc/profile,sudoedit /etc/bashrc,/usr/bin/make,sudoedit /etc/security/limits.conf,/etc/init.d/*,/usr/bin/rubyABC ALL=(ALL)NOPASSWD:DEFAULT 其中上面的”/usr/bin/passwd [!-]“表示允许修改加参数的密码。”/bin/su - [!-]“表示允许”su -“到某用户下，但必须给参数。 sudo和sudoedit命令当sudo执行指定的command时，它会调用fork函数，并设置命令的执行环境(如某些环境变量)，然后在子进程中执行command，sudo的主进程等待命令执行完毕，然后传递命令的退出状态码给安全策略并退出。 sudoedit等价于sudo -e，它是以sudo的方式执行文件编辑动作。 1234567891011121314151617181920212223sudo [options] [command]选项说明：-b ：(background)该选项告诉sudo在后台执行指定的命令。 注意，如果使用该选项，将无法使用任务计划(job)来控制维护这些后台进程， 需要交互的命令应该考虑是否真的要后台，因为可能会失败-l[l] [command]：当单独使用-l选项时，将列出(list)用户可执行和被禁止的命令。 当配合command时，且该command是被允许执行的命令，将列出命令的全路径及该命令参数。 如果command是不被允许执行的，则sudo直接以状态码-1退出。 可以指定多个字母&quot;l&quot;来显示更详细的格式-n ：使得sudo变成非交互模式，但如果安全策略是要求输入密码的，则sudo将报错-S ：(stdin)该选项使得sudo从标准输入而非终端设备上读取密码，给定的密码必须在尾部加上换行符-s [command] ：(shell)指定要切换到的shell，如果给定command，则在此shell上执行该命令-U user ：(other user)配合-l选项来指定要列出哪个用户的权限信息-u user ：(user)该选项明确指定要以此处指定的用户而非root来运行command。 若使用uid的方式指定用户，则需要使用&quot;#uid&quot;，但很多时候可能需要对&quot;#&quot;使用&quot;\\&quot;转义，即使用&quot;\\#uid&quot;-E ：(environment)该选项告诉sudo在执行命令时保留自己的环境变量，保留环境变量的方式是执行环境配置文件。 但因为跨了用户，所以很可能某些家目录下的环境配置文件会因为无权限而执行失败，此时sudo将报错 -k [command] ：当单独使用-k选项时，sudo将使得用户的认证缓存失效。下次执行sudo命令需要输入密码。 当配合command时，-k选项将忽略用户的缓存，所以sudo将要求用户输入密码，但这次输入密码不会更新认证缓存 但执行-k选项本身，不需要密码-K ：(sure kill)类似于-k选项，但它会完全移除用户的认证缓存，且不会配合command，执行-K本身不需要密码-v ：(validate)该选项使得sudo更新用户认证缓存-- ：暗示sudo命令行参数到此结束 在sudo上可以直接设置环境变量，它会传递为command的环境。设置的方式为var=value，如LD_LIBRARY_PATH=/usr/local/pkg/lib 由于sudo默认的安全策略插件是sudoers，所以当用户执行sudo时，系统会自动去寻找/etc/sudoers文件(该文件里被root配置了用户对应的权限，也即安全策略)，查看sudo要使用的用户是否有对应的权限，如果有则执行，如果没有权限就失败退出sudo。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"su和sudo","slug":"su和sudo","permalink":"http://yoursite.com/tags/su和sudo/"}]},{"title":"实现DNS服务主从复制","slug":"实现DNS服务主从复制","date":"2017-03-21T16:00:00.000Z","updated":"2018-06-15T14:15:04.463Z","comments":true,"path":"2017/03/22/实现DNS服务主从复制/","link":"","permalink":"http://yoursite.com/2017/03/22/实现DNS服务主从复制/","excerpt":"现在我们来实现主从复制，用两台主机做服务器，比如，用192.168.30.7 来做主服务器，用192.168.30.17 来做从服务器。现在我们把两个服务器都搭建起来。 先搭建从服务器， 第一步，首先要装包 1yum install bind 然后来修改主配置文件 12345vim /etc/named.conf 要把 options 中的的这两行都注释掉。 #listen-on port 53 &#123; locklhost; &#125;; #allow-query &#123; localhost;any; &#125;;","text":"现在我们来实现主从复制，用两台主机做服务器，比如，用192.168.30.7 来做主服务器，用192.168.30.17 来做从服务器。现在我们把两个服务器都搭建起来。 先搭建从服务器， 第一步，首先要装包 1yum install bind 然后来修改主配置文件 12345vim /etc/named.conf 要把 options 中的的这两行都注释掉。 #listen-on port 53 &#123; locklhost; &#125;; #allow-query &#123; localhost;any; &#125;; 接下来在配置文件 /etc/named.rfc1912.zones文件中添加区域信息 12345zone &quot;magedu.com&quot; IN &#123; type slave; masters &#123; 192.168.30.7; &#125;; file &quot;slaves/magedu.com.zone.slave&quot;;&#125;; 为什么配置文件中的数据库文件在slaves 这个目录下，因为在系统中自带就有这个目录 /var/named/slaves/ 还有就是数据库文件不用自己创建，它会自动同步主服务器生成。 然后启动服务 systemctl start named 启动后可以查看 /var/named/slaves/ 这个目录下会生成相应的文件，但是这个文件是加密的，不能直接看。 有一个命令可以查看这个文件的基本信息 named-compilezone -f raw -o -zone magedu.com /var/named/slaves/magedu.com.zone.slave 这样从服务器就搭建完成，现在回到主服务器上。 如果在主服务器上添加一个外部服务，然后重启服务，试问从服务器会及时更新吗？ 不会 因为主服务器上的数据库文件中的 NS 没有记录从服务器的信息，所以主服务器不知道有从服务器，所以不会推送更改的内容。 那么要想在主服务器修改内容后并增加序列号的情况下把更改的内容推送给从服务器，就必须在主服务器的数据库文件中的 NS 记录中添加从服务器信息。 如下 ： 123456789$TTL 1D @ IN SOA dns1.magedu.com. admin.magedu.com. (110 1D 1H 3D 1H ) NS dns1.magedu.com. NS dns2.magedu.com. dns1 A 192.168.30.7 dns2 A 192.168.30.17 websrv A 192.168.30.17 websrv A 192.168.30.27 www CNAME websrv 然后重新加载一下 rndc reload然后回到从服务器上 查看下 /var.named/slaves/ 这个目录，就可以发现这个文件的时间刚发生改变，所以说明同步成功。 这是一台主服务器跟一个从服务器同步，理论上一般都是一个主服务器两个从服务器，接下来在搭一个从服务器。刚才是从服务器从主服务器那去同步，现在有个问题，能不能从服务器从从服务器上同步呢。接下来搭建第二个从服务器，以192.168.30.27这台主机来做第二台从服务器 。先装包 yum install bind 然后修改主配置文件 12345vim /etc/named.conf 要把 options 中的的这两行都注释掉。 #listen-on port 53 &#123; locklhost; &#125;; #allow-query &#123; localhost;any; &#125;; 接下来修改配置文件 /etc/named.rfc1912.zones ,在里面添加从服务器的区域信息 12345zone &quot;magedu.com&quot; IN &#123; type slave; masters &#123; 192.168.30.17; &#125;; file &quot;slaves/magedu.com.zone.slave.slave&quot;;&#125;; ######然后启动服务 systemctl restart named 启动后查看下 /var/named/slaves/ 目录下生成文件没，如果生成说明同步成功。 但是建议一般都从主服务器上同步。 现在有个问题了，配置第二个从服务器时是没有经过主服务器的允许，但是却配置成功，这说明什么，说明你的数据库文件很容易被获取。centos 7 还好数据库文件是加密的，但是 6 上就不一样了 ，6 上全是明文。这样就更危险了，更容易被攻击。 还有一种就是不用配从服务器，直接用命令就可以获取某个域的区域信息。如下： dig -t axfr magedu.com @192.168.30.7 显而易见这样就存在太大的安全隐患，因此要想实现安全性，我们就应该禁止这种随意就能获取数据库的，所以就要在主服务器上加安全设置。 在主服务器上的主配置文件中添加内容。 vim /etc/named.conf 还有或许你的服务器上不光有 magedu.com 这一个域，或许还有其他域，这就牵扯到你是想只对某个域做安全控制，还是对全局的域都做控制。 如果是对全局的域都做安全控制，那就在主配置文件中的 options 中添加一行内容，如下： 1allow-transfer &#123; 192.168.30.17;192.168.30.27; &#125;; ##“{}” 中的内容表示只允许这里面的IP能获取数据库，除此之外全部禁止。 配置完后记得重新加载服务 rndc reload 这样其他IP的主机是不能获取了，但是拿从服务器的那两个IP还是可以获取的。还是不够安全。 所以在主服务器上设置完后，还要在从服务器上也做设置。 在从服务器上的主配置文件中添加内容。 vim /etc/named.conf 在配置文件中的 options 中添加一行内容 allow-transfer { none; }; 这样才算安全了，当然这是针对全局设置的。还有一种就是服务器上有两个域，一个 magedu.com , 一个 wange.com ,现在只想对 magedu.com 这个域进行安全控制， wange.com 不管。这怎么实现？ 这回就不往主配置文件中添加内容了，而是在配置文件 /etc/named.rfc1912.zones 中在相应的域中添加控制信息。 比如，现在只对 magedu.com 加以控制。 就在 vim /etc/named.rfc1912.zones 中的 magedu.com 中添加 allow-transfer { 192.168.30.17; }; ，如下： 在 magedu.com 区域中添加 ： 123456zone &quot;magedu.com&quot; IN &#123; type slave; masters &#123; 192.168.30.17; &#125;; file &quot;slaves/magedu.com.zone.slave.slave&quot;; allow-transfer &#123; 192.168.30.17; &#125;;&#125;; 然后重新加载服务 rndc reload 这就表示只有IP 为 192.168.30.17 这台主机能从主服务器上获取数据，其他的不行。这就是主从服务器同步。 注意： 不管主服务器和从服务器一共有几个，一定要记得把所有主机服务器的DNS信息加到主服务器上的数据库中。比如，你这有主从服务器3个，那么就要在主服务器的数据库中添加3个NS记录。 到此就实现了主从服务器的容错性了。那么理论上主服务器宕机了，那么从服务器就应该承担访问责任。那么这是主服务器宕机了才去访问从服务器，那么如果主服务器没有宕机，只是在主服务器上就没有访问的域，那么客户访问这个域，会出现什么结果。一般主服务器会去找根。那么把外网断掉，把缓存清掉，客户再去连接，会出现什么结果。这样就会去找从服务器。 清缓存的命令： rndc flush 现在用命令 dig magedu.com @192.168.30.7 是可以访问的，但是现在把UDP 的53 端口用命令iptables -A INPUT -p udp –dport 53 -j REJECT 给禁掉， 在用命令 dig magedu.com @192.168.30.7 发现不能访问了。 现在把防火墙策略清空，iptables -F 在用命令把TCP的53 端口用命令 iptables -A INPUT -p tcp –dport 53 -j REJECT 给禁掉，在用命令 dig magedu.com @192.168.30.7 发现是可以访问的。 所以总结，我们平时的名字解析IP 走的都是UDP协议。 现在在主服务器上的数据库中添加一些内容并增加版本号，然后重新加载，到从服务器上查看 /etc/named/slaves/ 目录时间发现已经同步。那么现在用命令把端口53的TCP协议禁掉 iptables -A INPUT -p tcp –dport 53 -j REJECT ，然后在对主服务器上的数据库进行修改并重新加载服务，再到从服务器上查看 /etc.named/slaves/ 目录的时间发现没有同步。 然后把防火墙策略清空 iptables -F ,然后把UDP 的53 端口禁掉 iptables -A INPUT -p udp –dport 53 -j REJECT ，然后再次执行以上过程，发现也不能同步。 总结：主服务器跟从服务器同步时，即走TCP 协议，也走 UDP 协议，两个一样都不能少。到此DNS的主从服务就搭建完了。欢迎来怼！！！","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"DNS","slug":"DNS","permalink":"http://yoursite.com/tags/DNS/"}]},{"title":"搭建DNS互联网架构服务器","slug":"搭建DNS互联网架构服务器(一）","date":"2017-03-19T16:00:00.000Z","updated":"2018-06-15T13:12:03.173Z","comments":true,"path":"2017/03/20/搭建DNS互联网架构服务器(一）/","link":"","permalink":"http://yoursite.com/2017/03/20/搭建DNS互联网架构服务器(一）/","excerpt":"互联网结如架构图如下： 拓扑结构清楚之后，现在开始从下往上，一步步构建并测试，直到最终完成！ 至于为什么要从下往上？那是因为这样才能搭建好一台就测试一台，稳扎稳打，容易查清楚错在哪里！ 首先，除了客户端以外的所有DNS服务器都要下载 bind 包，后面操作就不赘述了。 注意！！！所有机器都要关闭 selinux 和 清空防火墙 ！！！","text":"互联网结如架构图如下： 拓扑结构清楚之后，现在开始从下往上，一步步构建并测试，直到最终完成！ 至于为什么要从下往上？那是因为这样才能搭建好一台就测试一台，稳扎稳打，容易查清楚错在哪里！ 首先，除了客户端以外的所有DNS服务器都要下载 bind 包，后面操作就不赘述了。 注意！！！所有机器都要关闭 selinux 和 清空防火墙 ！！！ 1、搭建两台www.bican.com主机： 两台是模拟分流作用，使负载均衡 1》 yum install httpd 下载httpd服务 2》 /var/www/html/index.html 文件中写入不同的内容，例如websrv1 和websrv2 方便等会区分 3》 systemctl start httpd 开启httpd服务 4》测试：在浏览器输入对应IP 如192.168.0.119 ，若出现第二步写入的内容，则httpd服务开启成功！ 2、搭建两台 bican.com DNS服务器，一主一从：###### 搭建主DNS服务器： 1》 编辑主配置文件 /etc/named.conf 把监听端口和允许访问的两行设置注释掉，另加一行 限制抓取资源记录的设置，如下： 2》 编辑区域配置文件 /etc/named.rfc1912.zones ，如下 3》 创建资源记录文件 ： 可复制模板 cp -a /var/named/named.localhost /var/named/bican.com.zone 保留属性！！！ vim /var/named/bican.com.zone 编辑内容如下： 4》 启动服务：systemctl start named，查看服务状态：systemctl status named 无报错即可 5》 测试： dig www.bican.com @192.168.0.116 成功！如下： 搭建从DNS服务器： 1》 更改主配置文件 /etc/named.conf ，注释掉两行，新加一行不允许抓取资源记录，如下： 2》 编辑区域配置文件 /etc/named.rfc1912.zones 启动服务：systemctl start named，查看服务状态：systemctl status named 无报错即可 发现配置文件生成，如下： 这里的配置文件是从主服务器同步过来的，不需要手动创建 测试： dig www.bican.com @192.168.0.111 。成功！ 3、搭建com DNS服务器： 相当于父域，委派给下面两台bican.com服务器 1》 编辑主配置文件 /etc/named.conf： 注释掉两行，把下面两项安全选项关闭，为委派做准备；把尾部zone块删掉，如下： 2》 编辑区域配置文件 /etc/named.rfc1912.zones 3》 创建资源记录 /var/named/com.zone文件， 注意属性！！！编辑如下： 4》 重启服务： systemctl restart named 5》 测试 dig www.bican.com @192.168.0.121 成功！ 4、搭建rootDNS 父域，委派给下面com 1》 编辑配置文件，注释掉两行，把尾部两行安全选项关闭，为委派做准备同上述搭建com服务器操作 2》 编辑区域配置文件 /etc/named.rfc1912.zones 如下： 3》 创建资源记录文件 root.zone 注意属性！！！ 如下： 4》 重启服务 systemctl restart named 5》 测试， dig www.bican.com @192.168.0.126 成功！ 5、小区DNS 1》 编辑主配置文件，注释掉两行，把尾部两行安全选项关闭，为委派做准备 同上述搭建com服务器操作 2》 编辑 真正根域资源记录 /var/named/name.ca 除了a记录两条内容，别的都删掉，使操作环境不受真正根域影响，并且指向自己的根域，如下： 3》 重启服务 systemctl restart named 4》 测试，dig www.bican.com @192.168.0.125 成功！ 6、客户端 在客户端添加 小区DNS解析服务器地址 /etc/resolv.conf 如下： 测试 links www.bican.com 可访问网页！成功！","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"dns","slug":"dns","permalink":"http://yoursite.com/tags/dns/"}]},{"title":"搭建DNS 服务，实现主服务器，邮件服务器，泛域名解析，反向解析等","slug":"搭建DNS 服务，实现主服务器，邮件服务器，泛域名解析，反向解析等","date":"2017-03-14T16:00:00.000Z","updated":"2018-06-15T13:40:25.995Z","comments":true,"path":"2017/03/15/搭建DNS 服务，实现主服务器，邮件服务器，泛域名解析，反向解析等/","link":"","permalink":"http://yoursite.com/2017/03/15/搭建DNS 服务，实现主服务器，邮件服务器，泛域名解析，反向解析等/","excerpt":"实验 ： 搭建DNS 主服务器，现在拿 192.168.30.7 这台主机做主服务器先装包 yum install bind启动服务 systemctl start named然后修改主配置文件中的内容 vim /etc/named.conf 创建以 magedu.com 的区域数据，一般建议区域数据都存放在 /etc/named.rfc1912.zones 文件中 ，添加内容如下： 12345zone &quot;magedu.com&quot; IN &#123; type master; file &quot;magedu.com.zone&quot;;&#125;; ##这是主从类型中的主类型，存放名字和IP 的数据库文件","text":"实验 ： 搭建DNS 主服务器，现在拿 192.168.30.7 这台主机做主服务器先装包 yum install bind启动服务 systemctl start named然后修改主配置文件中的内容 vim /etc/named.conf 创建以 magedu.com 的区域数据，一般建议区域数据都存放在 /etc/named.rfc1912.zones 文件中 ，添加内容如下： 12345zone &quot;magedu.com&quot; IN &#123; type master; file &quot;magedu.com.zone&quot;;&#125;; ##这是主从类型中的主类型，存放名字和IP 的数据库文件 然后 cd 进入 /var/named 目录下创建名字与IP 的数据库文件touch magedu.com.zone 创建完后添加内容vim magedu.com.zone添加内容如下： 1234567$TTL 1D@ IN SOA dns1.magedu.com. admin.magedu.com. (110 1D 1H 3D 1H ) NS dns1dns1 A 192.168.30.7websrv A 192.168.30.17websrv A 192.168.30.27www CNAME websrv 添加完后把属性修改一下，所属组一定要是 named ,权限改成 640 ，所以命令来修改 chgrp named magedu.com.zone chmod 640 magedu.com.zone 修改完后启动服务systemctl restart named如果发现启动不起来，用命令查看下语法，先用 named-checkzone 查看下配置文件语法有没有问题如果没问题在拿命令 named-checkzone “magedu.com.zone” 查看下数据库文件语法有没有问题，如果有问题进行改正在启动服务即可。 然后在 192.168.30.17 和 192.168.30.27 上装上外部服务器并创建外部页面 在两台主机上装包：yum install httpd 为了区分两个主机不同，建立各自的页面在30.17 上执行命令 ： echo 192.168.30.17 websrv &gt; /var/www/html/index.html 在30.27 上执行命令 ： echo 192.168.30.27 websrv &gt; /var/www/html/index.html 这就相当于17 和 27 都是外部服务器，但是对应的是一个网站然后在两台主机上都启动服务并设定开机启动 12systemctl start httpd systemctl enable httpd 现在拿192.168.30.6 这台主机做客户端，当然要做客户端的话，DNS服务的地址就要指向 192.168.30.7 主机上。 然后修改192.168.30.6 的网卡配置文件，在里面添加DNS服务地址 vim /etc/sysconfig/network-scripts/ifcfg-eth1 在里面添加 DNS1=192.168.30.7 然后重启网卡 service network restart 重启完后可以查看下DNS 的文件看添加的DNS地址生效没 cat /etc/resolv.conf 然后就可以在客户端访问网站了links www.magedu.com 显示的页面会随机变化，有事是30.17 的，有时是 30.27 的，这就实现解决了网站压力过大的问题，实现了服务器的冗余性，这样如果网站访问量上升，只需在主服务器后面多配几个从服务器就可以解决这种问题，在页面上都一样，客户不会感到不一样。 所以websrv 这种方式就实现了名字解析和均衡负载的效果。 添加邮件服务记录 也可以在数据库文件 “magedu.com.zone” 中添加邮件服务记录 ， 如下： @ MX A mailsrv1 @ MX A mailsrv2 mailsrv1 A 192.169.30.100 mailsrv2 A 172.201.1 ###### 注意： 添加完后要用命令 rndc reload 来同步一下 如果想查询某个域的邮件服务器可以用命令来查询 dig -t MX “域名” @114.114.114.114 如： dig -t MX sohu.com @114.114.114.114查到邮箱服务器后就可以伪造邮箱发消息了telnet sohumx1.sohu.com 25 就可以连接了 如此之外还可以在数据库文件 ”magedu.com.zone“ 中添加其他记录。就是有时候用户访问网站时，他不输入www ，只输入域名，为了防止这种输入就要添加另一种记录。如： @ A 192.168.30.17 还有一种可能就是用户输入的时候有可能只输入ww 或者多输入，那怎么办？ 可以在数据库文件 “magedu.com.zone” 中添加一条泛域名解析记录，如下： * A 192.168.30.17 重新加载 rndc reload 添加上这条记录，用户多输或少输也能查到相关网站，这就叫泛域名解析。 还有一种就是现在有100台 外部服务器，每个服务器都有对应的IP ，现在要求访问哪个外部服务器就显示哪个服务器的IP ,这怎么实现。 如： 在数据库文件 “magedu.com.zone” 中添加 1$GENERATE 1-100 websrv$ A 192.168.30.$ 然后重新加载务 rndc reload 接下来来看一下 PTR 记录，要实现PTR记录就要实现一个区域，就是反向解析区域。 先在 “ /etc/named.rfc1912.zones” 文件中添加反向解析区域。 1vim /etc/named.rfc1912.zones 1234zone &quot;30.168.192.in-addr.arpa&quot; IN &#123; type master; file &quot;192.168.30.zone&quot; ;&#125;; 然后回到 /var/named 目录下把刚才那个文件创建出来 12345678vim 192.168.30.zone $TTL 1D @ IN SOA dns1.magedu.com. admin.magedu.com. ( 1 1D 1H 1W 3H ) NS dns1.magedu.com. dns1.magedu.com. A 192.168.30.717 PTR websrv.magedu.com.27 PTR appsrv.wange.com. 100 PTR mailsrv.magedu.com. 接下来修改所属组跟权限12chrpg named 192.168.30.zone chmod 640 192.168.30.zone 重新加载 rndc reload 最后用命令 dig -x 192.168.30.17 或者 192.168.30.27 都可以查看出解析出来的名字 注意：这个反向区域要求是要建立的，这个区域要是不建立，将来有些测试工具，他会有错误提示。还有有的邮件服务特别依赖于反向解析区域。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"DNS","slug":"DNS","permalink":"http://yoursite.com/tags/DNS/"}]},{"title":"Linux 文件权限管理","slug":"Linux 文件权限管理","date":"2017-03-11T16:00:00.000Z","updated":"2018-06-20T11:35:33.056Z","comments":true,"path":"2017/03/12/Linux 文件权限管理/","link":"","permalink":"http://yoursite.com/2017/03/12/Linux 文件权限管理/","excerpt":"文件/目录的权限文件的权限每个文件都有其所有者(u:user)、所属组(g:group)和其他人(o:other)对它的操作权限，a:all则同时代表这3者。权限包括读(r:read)、写(w:write)、执行(x:execute)。在不同类型的文件上读、写、执行权限的体现有所不同，所以目录权限和普通文件权限要区分开来。在普通文件上： r：可读，可以使用类似cat等命令查看文件内容；读是文件的最基本权限，没有读权限，普通文件的一切操作行为都被限制。","text":"文件/目录的权限文件的权限每个文件都有其所有者(u:user)、所属组(g:group)和其他人(o:other)对它的操作权限，a:all则同时代表这3者。权限包括读(r:read)、写(w:write)、执行(x:execute)。在不同类型的文件上读、写、执行权限的体现有所不同，所以目录权限和普通文件权限要区分开来。在普通文件上： r：可读，可以使用类似cat等命令查看文件内容；读是文件的最基本权限，没有读权限，普通文件的一切操作行为都被限制。w：可写，可以编辑此文件； x：可执行，表示文件可由特定的解释器解释并运行。可以理解为windows中的可执行程序或批处理脚本，双击就能运行起来的文件。 #####在目录上： r：可以对目录执行ls以列出目录内的所有文件；读是文件的最基本权限，没有读权限，目录的一切操作行为都被限制。 w：可以在此目录创建或删除文件/子目录； x：可进入此目录，可使用ls -l查看文件的详细信息。可以理解为windows中双击就进入目录的动作。 如果目录没有x权限，其他人将无法查看目录内文件属性(只能查看到文件类型和文件名，至于为什么，见后文)，所以一般目录都要有x权限。而如果只有执行却没有读权限，则权限拒绝。一般来说，普通文件的默认权限是644(没有执行权限)，目录的默认权限是755(必须有执行权限，否则进不去)，链接文件的权限是777。当然，默认文件的权限设置方法是可以通过umask值来改变的。 权限的表示方式权限的模式有两种体现：数字体现方式和字符体现方式。 权限的数字表示：”-“代表没有权限,用0表示。 123r-----4 w-----2 x-----1 例如：rwx rw- r–对应的数字权限是764，732代表的权限数值表示为rwx -wx -w-。 chmod修改权限能够修改权限的人只有文件所有者和超级管理员。 1234567chmod [OPTION]... MODE[,MODE]... FILE...chmod [OPTION]... num_mode FILE...chmod [OPTION]... --reference=RFILE FILE...选项说明：--reference=RFILE：引用某文件的权限作为权限值-R：递归修改，只对当前已存在的文件有效 (1). 使用数值方式修改权限1shell&gt; chmod 755 /tmp/a.txt (2). 使用字符方式修改权限由于权限属性附在文件所有者、所属组和其它上，它们三者都有独立的权限位，所有者使用字母”u”表示，所属组使用”g”来表示，其他使用”o”来表示，而字母”a”同时表示它们三者。所以使用字符方式修改权限时，需要指定操作谁的权限。 12chmod [ugoa][+ - =] [权限字符] 文件/目录名&quot;+&quot;是加上权限，&quot;-&quot;是减去权限，&quot;=&quot;是直接设置权限 12[root@xuexi tmp]# chmod u-x,g-x,o-x test # 将ugo都去掉x权限，等价于chmod -x test[root@xuexi tmp]# chmod a+x test # 为ugo都加上x权限，等价于chmod +x test chgrp 更改文件和目录的所属组，要求组已经存在。 注意，对于链接文件而言，修改组的作用对象是链接的源文件，而非链接文件本身。 123456chgrp [OPTION]... GROUP FILE...chgrp [OPTION]... --reference=RFILE FILE..选项说明：-R：递归修改--reference=dest_file file_list：引用某文件的group作为文件列表的组,即将file文件列表的组改为dest_file的组 chown chown可以修改文件所有者和所属组。 注意，对于链接文件而言，默认不会穿过链接修改源文件，而是直接修改链接文件本身，这和chgrp的默认是不一样的。 123456789101112chown [OPTION]... [OWNER][:[GROUP]] FILE...chown [OPTION]... [OWNER][.[GROUP]] FILE...chown [OPTION]... --reference=RFILE FILE...选项说明：--from=CURRENT_OWNER:CURRENT_GROUP：只修改当前所有者或所属组为此处指定的值的文件--reference=RFILE：引用某文件的所有者和所属组的值作为新的所有者和所属组-R：递归修改。注意，当指定-R时，且同时指定下面某一个选项时对链接文件有不同的行为 -H：如果chown的文件参数是一个链接到目录的链接文件，则穿过此链接文件修改其源目录的所有者和所属组 -L：目录中遇到的所有链接文件都穿越过去，修改它们的源文件的所有者和所属组 -P：不进行任何穿越，只修改链接文件本身的所有者和所属组。(这是默认值) 这3项若同时指定多项时，则最后一项生效 chown指定所有者和所属组的方式有两种，使用冒号和点。 12345shell&gt; chown root.root testshell&gt; chown root:root testshell&gt; chown root test # 只修改所有者shell&gt; chown :root test # 自修改组shell&gt; chown .root test 实现权限的本质 涉及文件系统的知识点，若不理解，可以先看看文件系统的内容。此处是以ext4文件系统为例的，在其他文件系统上结果可能会有些不一样(centos 7上使用xfs文件系统时结果可能就不一样)，但本质是一样的。 不同的权限表示对文件具有不同能力，如读写执行(rwx)权限，但是它是怎么实现的呢？描述文件权限的数据放在哪里呢？ 首先，权限的元数据放在inode中，严格地说是放在inode table中，因为每个块组的所有inode组成一个inode table。在inode table中使用一列来存放数字型的权限，比如某文件的权限为644。每次用户要对文件进行操作时系统都会先查看权限，确认该用户是否有对应的权限来执行操作。当然，inode table一般都已经加载到内存中，所以每次查询权限的资源消耗是非常小的。 无论是读、写还是执行权限，所体现出来的能力究其本质都是因为它作用在对应文件的data block上。 读权限(r) 对普通文件具有读权限表示的是具有读取该文件内容的能力，对目录具有读权限表示具有浏览该目录中文件或子目录的能力。其本质都是具有读取其data block的能力。 对于普通文件而言，能够读取文件的data block，而普通文件的data block存储的直接就是数据本身， 所以对普通文件具有读权限表示能够读取文件内容。 对于目录文件而言，能够读取目录的data block，而目录文件的data block存储的内容包括但不限于：目录中文件的inode号(并非直接存储，而是存储指向inode table中该inode号的指针)以及这些文件的文件类型、文件名。所以能够读取目录的data block表示仅能获取到这些信息。 目录的data block内容示例如下： 例如：123shell&gt; mkdir -p /mydata/data/testdir/subdir # 创建testdir测试目录和其子目录subdirshell&gt; touch /mydata/data/testdir/a.log # 再在testdir下创建一个普通文件shell&gt; chmod 754 /mydata/data/testdir # 将testdir设置为对其他人只有读权限 然后切换到普通用户查看testdir目录的内容。123456789101112shell&gt; su - wangwushell&gt; ll -ai /mydata/data/testdir/ls: cannot access /mydata/data/testdir/..: Permission deniedls: cannot access /mydata/data/testdir/a.log: Permission deniedls: cannot access /mydata/data/testdir/subdir: Permission deniedls: cannot access /mydata/data/testdir/.: Permission deniedtotal 0? d????????? ? ? ? ? ? .? d????????? ? ? ? ? ? ..? -????????? ? ? ? ? ? a.log? d????????? ? ? ? ? ? subdir 从结果中看出，testdir下的文件名和文件类型是能够读取的，但是其他属性都不能读取到。而且也读取不到inode号，因为它并没有直接存储inode号，而是存储了指向Inode号的指针，要定位到指针的指向需要执行权限。 执行权限(x) 执行权限表示的是能够执行。如何执行？执行这个词不是很好解释，可以简单的类比Windows中的双击行为。例如对目录双击就能进入到目录，对批处理文件双击就能运行(有专门的解释器解释)，对可执行程序双击就能运行等。 当然，读权限是文件的最基本权限，执行权限能正常运行必须得配有读权限。 对目录有执行权限，表示可以通过目录的data block中指向文件inode号的指针定位到inode table中该文件的inode信息，所以可以显示出这些文件的全部属性信息。 写权限(w) 写权限很简单，就是能够将数据写入分配到的data block。 对目录文件具有写权限，表示能够创建和删除文件。目录的写操作实质是能够在目录的data block中创建或删除关于待操作文件的记录。它要求对目录具有执行权限，因为无论是创建还是删除其内文件，都需要将其data block中inode号和inode table中的inode信息关联或删除。 对普通文件具有写权限，实质是能够改写该文件的data block。还是要说明的是，对文件有写权限不代表能够删除该文件，因为删除文件是要在目录的data block中删除该文件的记录，也就是说删除权限是在目录中定义的。 所以，对目录文件和普通文件而言，读、写、执行权限它们的依赖关系如下图所示。 umask说明 umask值用于设置用户在创建文件时的默认权限。对于root用户(实际上是UID小于200的user)，系统默认的umask值是022；对于普通用户和系统用户，系统默认的umask值是002。 默认它们的设置是写在/etc/profile和/etc/bashrc两个环境配置文件中。 1234shell&gt; grep -C 5 -R &apos;umask 002&apos; /etc | grep &apos;umask 022&apos; /etc/bashrc- umask 022/etc/csh.cshrc- umask 022/etc/profile- umask 022 相关设置项如下：12345if [ $UID -gt 199 ] &amp;&amp; [ &quot;`id -gn`&quot; = &quot;`id -un`&quot; ]; then umask 002else umask 022fi 执行umask命令可以查看当前用户的umask值。12[root@xuexi tmp]# umask0022 12[longshuai@xuexi tmp]$ umask0002 执行umask num可以临时修改umask值为num，但这是临时的，要永久有效，需要写入到环境配置文件中，至于写入到/etc/profile、/etc/bashrc、~/.bashrc还是~/.bash_profile中，看你自己的需求了。不过一般来说，不会去永久修改umask值，只会在特殊条件下临时修改下umask值。 umask是如何决定创建文件的默认权限的呢？ 如果创建的是目录，则使用777-umask值，如root的umask=022，则root创建目录时该目录的默认权限为777-022=755，而普通用户创建目录时，权限为777-002=775. 如果创建的是普通文件，在Linux中，深入贯彻了一点：文件默认不应该有执行权限，否则是危险的。所以在计算时，可能会和想象中的结果不一样。如果umask的三位都为偶数，则直接使用666去减掉umask值，因为6减去一个偶数还是偶数，任何位都不可能会有执行权限。如root创建普通文件时默认权限为666-022=644，而普通用户创建普通文件时默认权限为666-002=664。 如果umask值某一位为奇数，则666减去umask值后再在奇数位上加1。如umask=021时，创建文件时默认权限为666-021=645，在奇数位上加1，则为646。 1234[longshuai@xuexi tmp]$ umask 021[longshuai@xuexi tmp]$ touch b.txt[longshuai@xuexi tmp]$ ls -l b.txt-rw-r--rw- 1 longshuai longshuai 0 Jun 7 12:02 b.txt 总之计算出后默认都是没有执行权限的。 文件的扩展ACL权限 在计算机相关领域，所有的ACL(access control list)都表示访问控制列表。 文件的owner/group/others的权限就是一种ACL，它们是基本的ACL。很多时候，只通过这3个权限位是无法完全合理设置权限问题的，例如如何仅设置某单个用户具有什么权限。这时候需要使用扩展ACL。 扩展ACL是一种特殊权限，它是文件系统上功能，用于解决所有者、所属组和其他这三个权限位无法合理设置单个用户权限的问题。所以，扩展ACL可以针对单一使用者，单一档案或目录里的默认权限进行r,w,x的权限规范。 需要明确的是，扩展ACL是文件系统上的功能，且工作在内核，默认在ext4/xfs上都已开启。在下文中，都直接以ACL来表示代替扩展ACL的称呼。 查看文件系统是否开启ACL功能 对于ext家族的文件系统来说，要查看是否开启acl功能，使用dumpe2fs导出文件系统属性即可。 123shell&gt; dumpe2fs -h /dev/sda2 | grep -i acldumpe2fs 1.41.12 (17-May-2010)Default mount options: user_xattr acl 对于xfs文件系统，则没有直接的命令可以输出它的相关信息，需要使用dmesg来查看。其实无需关注它，因为默认xfs会开启acl功能。 123shell&gt; dmesg | grep -i acl[ 1.465903] systemd[1]: systemd 219 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ -LZ4 -SECCOMP +BLKID +ELFUTILS +KMOD +IDN)[ 2.517705] SGI XFS with ACLs, security attributes, no debug enabled 开启ACL功能后，不代表就使用ACL功能。是否使用该功能，不同文件系统控制方法不一样，对于ext家族来说，通过mount挂载选项来控制，而对于xfs文件系统，mount命令根本不支持acl参数(xfs文件系统如何关闭或启用的方法本人也不知道)。 设置和查看ACL设置使用setfacl命令。 12345678910111213setfacl [options] u:[用户列表]:[rwx] 目录/文件名 # 对用户设置使用usetfacl [options] g:[组列表]:[rwx] 目录/文件名 # 对组设置使用g选项说明：-m：设定ACL权限(modify)-x：删除指定的ACL权限，可以指定用户、组和文件来删除(remove)-M：写了ACL条目的文件，将从此文件中读取ACL条目，需要配合-m，所以-M指定的是modify file-X：写了ACL条目的文件，将从此文件中读取ACL条目，需要配合-x，所以-X指定的是remove file-n：不重置mask-b：删除所有的ACL权限-d：设定默认ACL权限，只对目录有效，设置后子目录(文件)继承默认ACL，只对未来文件 有效-k：删除默认ACL权限-R：递归设定ACL权限，只对目录有效，只对已有文件有效 查看使用getfacl命令 1getfacl filename 案例：假设现有目录/data/videos专门存放视频，其中有一个a.avi的介绍性视频。该目录的权限是750。现在有一个新用户加入，但要求该用户对该目录只有查看的权限，且只能看其中一部视频a.avi，另外还要求该用户在此目录下没有创建和删除文件的权限。 1.准备相关环境。123456shell&gt; mkdir -p /data/videosshell&gt; chmod 750 /data/videosshell&gt; touch /data/videos/&#123;a,b&#125;.avishell&gt; echo &quot;xxx&quot; &gt;/data/videos/a.avishell&gt; echo &quot;xxx&quot; &gt;/data/videos/b.avishell&gt; chown -R root.root /data/videos 2.首先设置用户longshuai对/data/videos目录有读和执行权限。1shell&gt; setfacl -m u:longshuai:rx /data/videos 3.现在longshuai对/data/videos目录下的所有文件都有读权限，因为默认文件的权限为644。要设置longshuai只对a.avi有读权限，先设置所有文件的权限都为不可读。1shell&gt; chmod 640 /data/videos/* 4.然后再单独设置a.avi的读权限。1shell&gt; setfacl -m u:longshuai:r /data/videos/a.avi 到此就设置完成了。查看/data/videos/和/data/videos/a.avi上的ACL信息。 12345678910shell&gt; getfacl /data/videos/getfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos/# owner: root# group: rootuser::rwxuser:longshuai:r-x # 用户longshuai在此文件上的权限是r-xgroup::r-xmask::r-xother::--- 12345678910shell&gt; getfacl /data/videos/a.avigetfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos/a.avi# owner: root# group: rootuser::rw-user:longshuai:r-- # 用户longshuai在此文件上的权限是r--group::r--mask::r--other::--- ACL:mask 设置mask后会将mask权限与已有的acl权限进行与计算，计算后的结果会成为新的ACL权限 。 设定mask的方式为：setfacl -m m:[rwx] 目录/文件名 注意：默认每次设置文件的acl都会重置mask为此次给定的用户的值。既然如此，要如何控制文件上的acl呢？如果一个文件上要设置多个用户的acl，重置mask后就会对已有用户的acl重新计算，而使得acl权限得不到有效的控制。使用setfacl的”-n”选项，它表示此次设置不会重置mask值。 例如：当前的acl权限：12345678910shell&gt; getfacl /data/videos getfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwxgroup::r-xmask::rwxother::--- 设置mask值为rx。123456789101112shell&gt; setfacl -m m:rx /data/videosshell&gt; getfacl /data/videos getfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwx #effective:r-xgroup::r-xmask::r-xother::--- 设置mask后，它提示有效权限是r-x。这是rwx和r-x做与运算之后的结果。 再设置longshuai的acl为rwx，然后查看mask，会发现mask也被重置为rwx。 123456789101112shell&gt; setfacl -m u:longshuai:rwx /data/videosshell&gt; getfacl /data/videosgetfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwxgroup::r-xmask::rwxother::--- 所以，在设置文件的acl时，要使用-n选项来禁止重置mask。 1234567891011121314shell&gt; setfacl -m m:rx /data/videosshell&gt; setfacl -n -m u:longshuai:rwx /data/videosshell&gt; getfacl /data/videosgetfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwx #effective:r-xgroup::r-xmask::r-xother::--- 设置递归和默认ACL权限 递归ACL权限只对目录里已有文件有效，默认权限只对未来目录里的文件有效。 设置递归ACL权限： 1setfacl -m u:username:[rwx] -R 目录名 # -R选项只能放在后面。 设置默认ACL权限：1setfacl -m d:u:username:[rwx] 目录名 删除ACL权限123setfacl -x u:用户名 文件名 # 删除指定用户ACLsetfacl -x g:组名 文件名 # 删除指定组名ACLsetfacl -b 文件名 # 指定文件删除ACL，会删除所有ACL 文件隐藏属性 chattr：change file attributes lsattr：list file attributes 12chattr [+ - =] [ai] 文件或目录名 常用的参数是a(append，追加)和i(immutable，不可更改)，其他参数略。 设置了a参数时，文件中将只能增加内容，不能删除数据，且不能打开文件进行任何编辑，哪怕是追加内容也不可以，所以像sed等需要打开文件的再写入数据的工具也无法操作成功。文件也不能被删除。只有root才能设置。 设置了i参数时，文件将被锁定，不能向其中增删改内容，也不能删除修改文件等各种动作。只有root才能设置。可以将其理解为设置了i后，文件将是永恒不变的了，谁都不能动它。 例如，对/etc/shadow文件设置i属性，任何用户包括root将不能修改密码，而且也不能创建用户。1shell&gt; chattr +i /etc/shadow 此时如果新建一个用户。12shell&gt; useradd newlongsuaishell&gt; useradd: cannot open /etc/shadow # 提示文件不能打开，被锁定了 lsattr查看文件设置的隐藏属性。12shell&gt; lsattr /etc/shadow----i--------e- /etc/shadow # i属性说明被锁定了，e是另一种文件属性，忽略它 删除隐藏属性：123shell&gt; chattr -i /etc/shadowshell&gt; lsattr /etc/shadow-------------e- /etc/shadow 再来一例：1234shell&gt; chattr +a test1.txt # 对test1.txt设置a隐藏属性shell&gt; echo 1234&gt;&gt;test1.txt # 追加内容是允许的行为shell&gt; cat /dev/null &gt;test1.txt # 但是清空文件内容是不允许的-bash: test1.txt: Operation not permitted suid/sgid/sbitsuid suid只针对可执行文件，即二进制文件。它的作用是对某个命令(可执行文件)授予所有者的权限，命令执行完成权限就消失。一般是提权为root权限。 例如/etc/shadow文件所有人都没有权限(root除外)，其他用户连看都不允许。 12shell&gt; ls -l /etc/shadow----------. 1 root root 752 Apr 8 12:42 /etc/shadow 但是他们却能修改自己的密码，说明他们一定有一定的权限。这个权限就是suid控制的。 12shell&gt; ls -l /usr/bin/passwd-rwsr-xr-x. 1 root root 30768 Feb 22 2012 /usr/bin/passwd 其中的”s”权限就是suid，它出现在所有者位置上(是root)，其他用户执行passwd命令时，会暂时拥有所有者位的rwx权限，也就是root的权限，所以能向/etc/shadow写入数据。 suid必须和x配合，如果没有x配合，则该suid是空suid，仍然没有执行命令的权限，所有者都没有了x权限，suid依赖于它所以更不可能有x权限。空的suid权限使用大写的”S”表示。 数字4代表suid，如4755。 sgid针对二进制文件和目录。 针对二进制文件时，权限升级为命令的所属组权限。 针对目录时，目录中所建立的文件或子目录的组将继承默认父目录组，其本质还是提升为目录所属组的权限。此时目录应该要有rx权限，普通用户才能进入目录，如果普通用户有w权限，新建的文件和目录则以父目录组为默认组。 以2代表sgid，如2755，和suid组合如6755。 sbit 只对目录有效。对目录设置sbit，将使得目录里的文件只有所有者能删除，即使其他用户在此目录上有rwx权限，即使是root用户。 以1代表sbit。 补充：suid/sgid/sbit的标志位都作用在x位，当原来的x位有x权限时，这些权限位则为s/s/t，如果没有x权限，则变为S/S/T。例如，/tmp目录的权限有个t位，使得该目录里的文件只有其所有者本身能删除。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"权限管理","slug":"权限管理","permalink":"http://yoursite.com/tags/权限管理/"}]},{"title":"安装管理包：LINUX系统中用户、组管理","slug":"LINUX系统中用户、组管理","date":"2017-03-07T16:00:00.000Z","updated":"2018-06-19T11:52:24.588Z","comments":true,"path":"2017/03/08/LINUX系统中用户、组管理/","link":"","permalink":"http://yoursite.com/2017/03/08/LINUX系统中用户、组管理/","excerpt":"用户和组的基本概念 用户和组是操作系统中一种身份认证资源。 每个用户都有用户名、用户的唯一编号uid(user id)、所属组及其默认的shell，可能还有密码、家目录、附属组、注释信息等。 每个组也有自己的名称、组唯一编号gid(group id)。一般来说，gid和uid是可以不相同的，但绝大多数都会让它们保持一致，大致属于约定俗成类的概念吧。","text":"用户和组的基本概念 用户和组是操作系统中一种身份认证资源。 每个用户都有用户名、用户的唯一编号uid(user id)、所属组及其默认的shell，可能还有密码、家目录、附属组、注释信息等。 每个组也有自己的名称、组唯一编号gid(group id)。一般来说，gid和uid是可以不相同的，但绝大多数都会让它们保持一致，大致属于约定俗成类的概念吧。组分为主组(primary group)和辅助组(secondary group)两种，用户一定会属于某个主组，也可以同时加入多个辅助组。 在Linux中，用户分为3类： (1). 超级管理员 超级管理员是最高权限者，它的uid=0，默认超级管理员用户名为root。因为uid默认具有唯一性，所以超级管理员默认只能有一个(如何添加额外的超级管理员，见useradd命令)，但这一个超级管理员的名称并非一定要是root。但是没人会去改root的名称，在后续非常非常多的程序中，都认为超级管理员名称为root，这里要是一改，牵一发而动全身。 (2). 系统用户 有时候需要一类具有某些特权但又不需要登录操作系统的用户，这类用户称为系统用户。它们的uid范围从201到999(不包括1000)，有些老版本范围是1到499(centos 6)，出于安全考虑，它们一般不用来登录，所以它们的shell一般是/sbin/nologin，而且大多数时候它们是没有家目录的。 (3). 普通用户 普通用户是权限受到限制的用户，默认只能执行/bin、/usr/bin、/usr/local/bin和自身家目录下的命令。它们的uid从500开始。尽管普通用户权限收到限制，但是它对自身家目录下的文件是有所有权限的。 超级管理员和其他类型的用户，它们的命令提示符是不一样的。uid=0的超级管理员，命令提示符是”#”，其他的为”$”。 默认root用户的家目录为/root，其他用户的家目录一般在/home下以用户名命名的目录中，如longshuai这个用户的家目录为/home/longshuai。当然，家目录是可以自定义位置和名称的。 用户和组管理相关的文件用户文件/etc/passwd/etc/passwd文件里记录的是操作系统中用户的信息，这里面记录了几行就表示系统中有几个系统用户。它的格式大致如下：12345678910root:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologinshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltftp:x:14:50:FTP User:/var/ftp:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinmysql:x:27:27:MySQL Server:/var/lib/mysql:/bin/bashnginx:x:498:499:Nginx web server:/var/lib/nginx:/sbin/nologinlongshuai:x:1000:1000::/home/longshuai:/bin/bash 每一行表示一个用户，每一行的格式都是6个冒号共7列属性，其中有很多用户的某些列属性是留空的。 1用户名:x:uid:gid:用户注释信息:家目录:使用的shell类型 12345678910111213第一列：用户名。注意两个个特殊的用户名，root、nobody 第二列：x。在以前老版本的系统上，第二列是存放用户密码的，但是密码和用户信息放在一起不便于管理(密钥要保证其特殊属性)，所以后来将密码单独放在另一个文件/etc/shadow中，这里就都写成x了 第三列：uid 第四列：gid 第五列：用户注释信息。 第六列：用户家目录。注意root用户的家目录为/root 第七列：用户的默认shell，虽然叫shell，但其实可以是任意一个可执行程序或脚本。例如上面的/bin/bash、/sbin/nologin、/sbin/shutdown 用户的默认shell表示的是用户登录(如果允许登录)时的环境或执行的命令。例如shell为/bin/bash时，表示登录时就执行/bin/bash命令进入bash环境；shell为/sbin/nologin表示该用户不能登录，之所以不能登录不是因为指定了这个特殊的程序，而是由/sbin/nologin这个程序的功能实现的，假如修改Linux的源代码，将/sbin/nologin这个程序变成可登录，那么shell为/sbin/nologin时也是可以登录的。 密码文件/etc/shadow /etc/shadow文件中存放的是用户的密码信息。该文件具有特殊属性，除了超级管理员，任何人都不能直接读取和修改该文件，而用户自身之所以能修改密码，则是因为该文件的suid属性，使得修改密码时临时提升为root权限。 该文件的格式大致如下： root:$6$hS4yqJu7WQfGlk0M$Xj/SCS5z4BWSZKN0raNncu6VMuWdUVbDScMYxOgB7mXUj./dXJN0zADAXQUMg0CuWVRyZUu6npPLWoyv8eXPA.::0:99999:7::: ftp::16659:0:99999:7::: nobody::16659:0:99999:7::: longshuai:$6$8LGe6Eh6$vox9.OF3J9nD0KtOYj2hE9DjfU3iRN.v3up4PbKKGWLOy3k1Up50bbo7Xii/Uti05hlqhktAf/dZFy2RrGp5W/:17323:0:99999:7::: 每一行表示一个用户密码的属性，有8个冒号共9列属性。 第一列：用户名。 第二列：加密后的密码。但是这一列是有玄机的，有些特殊的字符表示特殊的意义。①.该列留空，即”::”，表示该用户没有密码。②.该列为”!”，即”:!:”，表示该用户被锁，被锁将无法登陆，但是可能其他的登录方式是不受限制的，如ssh key的方式，su的方式。③.该列为”“，即”::”，也表示该用户被锁，和”!”效果是一样的。④.该列以”!”或”!!”开头，则也表示该用户被锁。⑤.该列为”!!”，即”:!!:”，表示该用户从来没设置过密码。⑥.如果格式为”$id$salt$hashed”，则表示该用户密码正常。其中$id$的id表示密码的加密算法，$1$表示使用MD5算法，$2a$表示使用Blowfish算法，”$2y$”是另一算法长度的Blowfish,”$5$”表示SHA-256算法，而”$6$”表示SHA-512算法，可见上面的结果中都是使用sha-512算法的。$5$和$6$这两种算法的破解难度远高于MD5。$salt$是加密时使用的salt，$hashed才是真正的密码部分。 第三列：从1970年1月1日到上次密码修改经过的时间(天数)。通过计算现在离1970年1月1日的天数减去这个值，结果就是上次修改密码到现在已经经过了多少天，即现在的密码已经使用了多少天。 第四列：密码最少使用期限(天数)。省略或者0表示不设置期限。例如，刚修改完密码又想修改，可以限制多久才能再次修改 第五列：密码最大使用期限(天数)。超过了它不一定密码就失效，可能下一个字段设置了过期后的宽限天数。设置为空时将永不过期，后面设置的提醒和警告将失效。root等一些用户的已经默认设置为了99999，表示永不过期。如果值设置小于最短使用期限，用户将不能修改密码。 第六列：密码过期前多少天就开始提醒用户密码将要过期。空或0将不提醒。 第七列：密码过期后宽限的天数，在宽限时间内用户无法使用原密码登录，必须改密码或者联系管理员。设置为空表示没有强制的宽限时间，可以过期后的任意时间内修改密码。 第八列：帐号过期时间。从1970年1月1日开始计算天数。设置为空帐号将永不过期，不能设置为0。不同于密码过期，密码过期后账户还有效，改密码后还能登录；帐号过期后帐号失效，修改密码重设密码都无法使用该帐号。 第九列：保留字段。 组文件/etc/group和/etc/gshadow 大致知道有这么两个文件即可，至于文件中的内容无需关注。 /etc/group包含了组信息。每行一个组，每一行3个冒号共4列属性。 1root:x:0: longshuai:x:500: xiaofang:x:501:zhangsan,lisi 第一列：组名。第二列：占位符。第三列：gid。第四列：该组下的user列表，这些user成员以该组做为辅助组，多个成员使用逗号隔开。 /etc/gshadow包含了组密码信息 骨架目录/etc/skel 骨架目录中的文件是每次新建用户时，都会复制到新用户家目录里的文件。默认只有3个环境配置文件，可以修改这里面的内容，或者添加几个文件在骨架目录中，以后新建用户时就会自动获取到这些环境和文件。 12345shell&gt; ls –l -A /etc/skeltotal 12-rw-r--r--. 1 root root 18 Oct 16 2014 .bash_logout-rw-r--r--. 1 root root 176 Oct 16 2014 .bash_profile-rw-r--r--. 1 root root 124 Oct 16 2014 .bashrc 删除家目录下这些文件，会导致某些设置出现问题。例如删除”.bashrc”这个文件，会导致提示符变异的问题，如下右图。 要解决这个问题，只需拷贝一个正常的.bashrc文件到其家目录中即可。一般还会修改该文件的所有者和权限。 /etc/login.defs 设置用户帐号限制的文件。该文件里的配置对root用户无效。 如果/etc/shadow文件里有相同的选项，则以/etc/shadow里的设置为准，也就是说/etc/shadow的配置优先级高于/etc/login.defs。 该文件有很多配置项，文件的默认内容只给出了一小部分，若想知道全部的配置项以及配个配置项的详细说明，可以”man 5 login.defs”查看。 123456789101112131415161718192021222324252627282930313233343536373839404142[root@xuexi ~]# less /etc/login.defs#QMAIL_DIR Maildir # QMAIL_DIR是Qmail邮件的目录，所以可以不设置它MAIL_DIR /var/spool/mail # 默认邮件根目录，即信箱#MAIL_FILE .mail # mail文件的格式是.mail# Password aging controls:PASS_MAX_DAYS 99999 # 密码最大有效期(天)PASS_MIN_DAYS 0 # 两次密码修改之间最小时间间隔PASS_MIN_LEN 5 # 密码最短长度PASS_WARN_AGE 7 # 密码过期前给警告信息的时间# 控制useradd创建用户时自动选择的uid范围# Min/max values for automatic uid selection in useraddUID_MIN 1000UID_MAX 60000# System accountsSYS_UID_MIN 201SYS_UID_MAX 999# 控制groupadd创建组时自动选择的gid范围# Min/max values for automatic gid selection in groupaddGID_MIN 1000GID_MAX 60000# System accountsSYS_GID_MIN 201SYS_GID_MAX 999# 设置此项后，在删除用户时，将自动删除用户拥有的at/cron/print等job#USERDEL_CMD /usr/sbin/userdel_local# 控制useradd添加用户时是否默认创建家目录，useradd -m选项会覆盖此处设置CREATE_HOME yes# 设置创建家目录时的umask值，若不指定则默认为022UMASK 077# 设置此项表示当组中没有成员时自动删除该组# 且useradd是否同时创建同用户名的主组。(该文件中并没有此项说明，来自于man useradd中-g选项的说明)USERGROUPS_ENAB yes# 设置用户和组密码的加密算法ENCRYPT_METHOD SHA512 注意，/etc/login.defs中的设置控制的是shadow-utils包中的组件，也就是说，该组件中的工具执行操作时会读取该文件中的配置。该组件中包含下面的程序：12345678910111213141516171819202122/usr/bin/gpasswd ：administer /etc/group and /etc/gshadow/usr/bin/newgrp ：log in to a new group，可用来修改gid，哪怕是正在登陆的会话也可以修改/usr/bin/sg ：execute command as different group ID/usr/sbin/groupadd ：添加组/usr/sbin/groupdel ：删除组/usr/sbin/groupmems ：管理当前用户的主组中的成员，root用户则可以指定要管理的组/usr/sbin/groupmod ：modify a group definition on the system/usr/sbin/grpck ：verify integrity of group files/usr/sbin/grpconv ：无视它/usr/sbin/grpunconv ：无视它/usr/sbin/pwconv ：无视它/usr/sbin/pwunconv ：无视它/usr/sbin/adduser ：是useradd的一个软链接，添加用户/usr/sbin/chpasswd ：update passwords in batch mode/usr/sbin/newusers ：update and create new users in batch/usr/sbin/pwck ：verify integrity of passsword files/usr/sbin/useradd ：添加用户/usr/sbin/userdel ：删除用户/usr/sbin/usermod ：重定义用户信息/usr/sbin/vigr ：edit the group and shadow-group file/usr/sbin/vipw ：edit the password and shadow-password file/usr/bin/lastlog ：输出所有用户或给定用户最近登录信息 /etc/default/useradd 创建用户时的默认配置。useradd -D修改的就是此文件 。 12345678910[root@xuexi ~]# cat /etc/default/useradd # useradd defaults fileGROUP=100 # 在useradd使用-N或/etc/login.defs中USERGROUPS_ENAB=no时表示创建用户时不创建同用户名的主组(primary group)， # 此时新建的用户将默认以此组为主组，网上关于该设置的很多说明都是错的，具体可看man useradd的-g选项或useradd -D的-g选项HOME=/home # 把用户的家目录建在/home中INACTIVE=-1 # 是否启用帐号过期设置(是帐号过期不是密码过期)，-1表示不启用EXPIRE= # 帐号过期时间，不设置表示不启用SHELL=/bin/bash # 新建用户默认的shell类型SKEL=/etc/skel # 指定骨架目录，前文的/etc/skel就在这里CREATE_MAIL_SPOOL=yes # 是否创建用户mail缓冲 man useradd的useradd -D选项介绍部分说明了这些项的意义。 用户和组管理命令useradd和adduseradduser是useradd的一个软链接。123456789101112131415161718192021222324252627282930313233useradd [options] login_name选项说明：-b：指定家目录的basedir，默认为/home目录-d：指定用户家目录，不写时默认为/home/user_name-m：要创建家目录时，若家目录不存在则自动创建，若不指定该项且/etc/login.defs中的CREATE_HOME未启用时将不会创建家目录-M：显式指明不要创建家目录，会覆盖/etc/login.defs中的CREATE_HOME设置 -g：指定用户主组，要求组已存在-G：指定用户的辅助组，多个组以逗号分隔-N：明确指明不要创建和用户名同名的组名-U：明确指明要创建一个和用户名同名的组，并将用户加入到此组中-o：允许创建一个重复UID的用户，只有和-u选项同时使用时才生效-r：创建一个系统用户。useradd命令不会为此选项的系统用户创建家目录，除非明确使用-m选项-s：指定用户登录的shell，默认留空。此时将选择/etc/default/useradd中的SHELL变量设置-u：指定用户uid，默认uid必须唯一，除非使用了-o选项-c：用户的注释信息 -k：指定骨架目录(skeleton)-K：修改/etc/login.defs文件中有关于用户的配置项，不能修改组相关的配置。设置方式为KEY=VALUE，如-K UID_MIN=100-D：修改useradd创建用户时的默认选项，就修改/etc/default/useradd文件-e：帐户过期时间，格式为&quot;YYYY-MM-DD&quot;-f：密码过期后，该账号还能存活多久才被禁用，设置为0表示密码过期立即禁用帐户，设置为-1表示禁用此功能-l：不要将用户的信息写入到lastlog和faillog文件中。默认情况下，用户信息会写入到这两个文件中useradd -D [options]修改/etc/default/useradd文件选项说明：不加任何选项时会列出默认属性-b, --base-dir BASE_DIR-e, --expiredate EXPIRE_DATE-f, --inactive INACTIVE-g, --gid GROUP-s, --shell SHELL 示例：1234567891011121314151617181920[root@xuexi ~]# useradd -D -e &quot;2016-08-20&quot; # 设置用户2016-08-20过期[root@xuexi ~]# useradd -DGROUP=100HOME=/homeINACTIVE=-1EXPIRE=2016-08-20SHELL=/bin/bashSKEL=/etc/skelCREATE_MAIL_SPOOL=yes[root@xuexi ~]# cat /etc/default/useradd# useradd defaults fileGROUP=100HOME=/homeINACTIVE=-1EXPIRE=2016-08-20SHELL=/bin/bashSKEL=/etc/skelCREATE_MAIL_SPOOL=yes useradd创建用户时，默认会自动创建一个和用户名相同的用户组，这是/etc/login.defs中的USERGROUP_ENAB变量控制的。 useradd创建普通用户时，不加任何和家目录相关的选项时，是否创建家目录是由/etc/login.defs中的CREATE_HOME变量控制的。 批量创建用户newusers newusers用于批量创建或修改已有用户信息。在创建用户时，它会读取/etc/login.defs文件中的配置项。 newusers [options] [file] newusers命令从file中或标准输入中读取要创建或修改用户的信息，文件中每行格式都一样，一行代表一个用户。格式如下： 1pw_name:pw_passwd:pw_uid:pw_gid:pw_gecos:pw_dir:pw_shell 各列的意义如下： pw_name：用户名，若不存在则新创建，否则修改已存在用户的信息 pw_passwd：用户密码，该项使用明文密码，在修改或创建用户时会按照指定的算法自动对其进行加密转换 pw_uid：指定uid，留空则自动选择uid。如果该项为已存在的用户名，则使用该用户的uid，但不建议这么做，uid应尽量保证唯一性 pw_gid：用户主组的gid或组名。若给定组不存在，则自动创建组。若留空，则创建同用户名的组，gid将自动选择 pw_gecos：用户注释信息 pw_dir：指定用户家目录，若不存在则自动创建。留空则不创建。：注意，newusers命令不会递归创建父目录，父目录不存在时将会给出信息，但newusers命令仍会继续执行：以完成创建剩下的用户，所以这些错误的用户家目录需要手动去创建。 pw_shell：指定用户的默认shell newusers [options] [file] 选项说明： -c：指定加密方法，可选DES,MD5,NONE,SHA256和SHA512 -r：创建一个系统用户newusers首先尝试创建或修改所有指定的用户，然后将信息写入到user和group的文件中。如果尝试创建或修改用户过程中发生错误，则所有动作都将回滚，但如果在写入过程中发生错误，则写入成功的不会回滚，这将可能导致文件的不一致性。要检查用户、组文件的一致性，可以使用showdow-utils包提供的grpck和pwck命令。 示例：12345678910111213shell&gt; cat /tmp/userfilezhangsan:123456:2000:2000::/home/zhangsan:/bin/bashlisi:123456:::::/bin/bashshell&gt; newusers -c SHA512 /tmp/userfile shell&gt; tail -2 /etc/passwdzhangsan:x:2000:2000::/home/zhangsan:/bin/bashlisi:x:2001:2001:::/bin/bashshell&gt; tail -2 /etc/shadowzhangsan:$6$aI1Mk/krF$xN0TFOIRibrb/mYngJ/sV3M7g4zOxqOh8CWyDlI0uwmr5qNTzsmwauRFvCpfLtvtiJYZ/5bil.XfJMNB.sqDY1:17323:0:99999:7:::lisi:$6$bngXo/V6wWW$.TlQCJtEm9krBX0Oiep/iahS59a/BwVYcSc8F9lAnMGF55K6W5YoUZ2nK6WkMta3p7sihkxHm/AuNrrJ6hqNn1:17323:0:99999:7::: groupadd创建一个新组。1234567groupadd [options] group 选项说明： -f：如果要创建的组已经存在，默认会错误退出，使用该选项则强制创建且以正确状态退出，只不过gid可能会不受控制。-g：指定gid，默认gid必须唯一，除非使用了-o选项。-K：修改/etc/login.defs中关于组相关的配置项。配置方式为KEY=VALUE，例如-K GID_MIN=100 -K GID_MAX=499-o：允许创建一个非唯一gid的组-r：创建系统组 修改密码passwd 修改密码的工具。默认passwd命令不允许为用户创建空密码。 passwd修改密码前会通过pam认证用户，pam配置文件中与此相关的设置项如下： 123456789101112131415passwd password requisite pam_cracklib.so retry=3passwd password required pam_unix.so use_authtok命令的用法如下：passwd options [username]选项说明：-l：锁定指定用户的密码，在/etc/shadow的密码列加上前缀&quot;!&quot;或&quot;!!&quot;。这种锁定不是完全锁定，使用ssh公钥还是能登录。要完全锁定，使用chage -E 0来设置帐户过期。-u：解锁-l锁定的密码，解锁的方式是将/etc/shadow的密码列的前缀&quot;!&quot;或&quot;!!&quot;移除掉。但不能移除只有&quot;!&quot;或&quot;!!&quot;的项。--stdin：从标准输入中读取密码-d：删除用户密码，将/etc/shadow的密码列设置为空-f：指定强制操作-e：强制密码过期，下次登录将强制要求修改密码-n：密码最小使用天数-x：最大密码使用天数-w：过期前几天开始提示用户密码将要过期-i：设置密码过期后多少天，用户才过期。用户过期将被禁用，修改密码也无法登陆。 批量修改密码chpasswd 以批处理模式从标准输入中获取提供的用户和密码来修改用户密码，可以一次修改多个用户密码。也就是说不用交互。适用于一次性创建了多个用户时为他们提供密码。 1234chpasswd [-e -c] &quot;user:passwd&quot;-c：指定加密算法，可选的算法有DES,MD5,NONE,SHA256和SHA512user:passwd为用户密码对，其中默认passwd是明文密码，可以指定多对，每行一个用户密码对。前提是用户是已存在的。-e：passwd默认使用的是明文密码，如果要使用密文，则使用-e选项。参见man chpasswd chpasswd会读取/etc/login.defs中的相关配置，修改成功后会将密码信息写入到密码文件中。 该命令的修改密码的处理方式是先在内存中修改，如果所有用户的密码都能设置成功，然后才写入到磁盘密码文件中。在内存中修改过程中出错，则所有修改都回滚，但若在写入密码文件过程中出错，则成功的不会回滚。 示例：修改单个用户密码。1shell&gt; echo &quot;user1:123456&quot; | chpasswd -c SHA512 修改多个用户密码，则提供的每个用户对都要分行。1shell&gt; echo -e &apos;usertest:123456\\nusertest2:123456&apos; | chpasswd 更方便的是写入到文件中，每行一个用户密码对。12345shell&gt; cat /tmp/passwdfilezhangsan:123456lisi:123456shell&gt; chapasswd -c SHA512 &lt;/tmp/passwdfile chage chage命令主要修改或查看和密码时间相关的内容。具体的看man文档，可能用到的两个选项如下： -l：列出指定用户密码相关信息 -E：指定帐户(不是密码)过期时间，所以是强锁定，如果指定为0，则立即过期，即直接锁定该用户 12345678910111213141516171819[root@server2 ~]# chage -l zhangsanLast password change : Jun 06, 2017Password expires : neverPassword inactive : neverAccount expires : neverMinimum number of days between password change : 0Maximum number of days between password change : 99999Number of days of warning before password expires : 7[root@server2 ~]# chage -E 0 zhangsan[root@server2 ~]# chage -l zhangsan Last password change : Jun 06, 2017Password expires : neverPassword inactive : neverAccount expires : Jan 01, 1970Minimum number of days between password change : 0Maximum number of days between password change : 99999Number of days of warning before password expires : 7 删除用户和组userdel命令用于删除用户。123userdel [options] login_name-r：递归删除家目录，默认不删除家目录。-f：强制删除用户，即使这个用户正处于登录状态。同时也会强制删除家目录。 一般不直接删除家目录，即不用-r，可以vim /etc/passwd，将不需要的用户直接注释掉。 groupdel命令删除组。如果要删除的组是某用户的主组，需要先删除主组中的用户。 usermod 修改帐户属性信息。必须要确保在执行该命令的时候，待修改的用户没有在执行进程。 1234567891011121314151617181920usermod [options] login选项说明：-l：修改用户名，仅仅只是改用户名，其他的一切都不会改动(uid、家目录等)-u：新的uid，新的uid必须唯一，除非同时使用了-o选项-g：修改用户主组，可以是以gid或组名。对于那些以旧组为所属组的文件(除原家目录)，需要重新手动修改其所属组-m：移动家目录内容到新的位置，该选项只在和-d选项一起使用时才生效-d：修改用户的家目录位置，若不存在则自动创建。默认旧的家目录不会删除 如果同时指定了-m选项，则旧的家目录中的内容会移到新家目录 如果当前用户家目录不存在或没有家目录，则也不会创建新的家目录-o：允许用户使用非唯一的UID-s：修改用的shell，留空则选择默认shell-c：修改用户注释信息-a：将用户以追加的方式加入到辅助组中，只能和-G选项一起使用-G：将用户加入指定的辅助组中，若此处未列出某组，而此前该用户又是该组成员，则会删除该组中此成员-L：锁定用户的密码，将在/etc/shadow的密码列加上前缀&quot;!&quot;或&quot;!!&quot;-U：解锁用户的密码，解锁的方式是移除shadow文件密码列的前缀&quot;!&quot;或&quot;!!&quot;-e：帐户过期时间，时间格式为&quot;YYYY-MM-DD&quot;，如果给一个空的参数，则立即禁用该帐户-f：密码过期后多少天，帐户才过期被禁用，0表示密码过期帐户立即禁用，-1表示禁用该功能 同样，还有groupmod修改组信息，用法非常简单，几乎也用不上，不多说了。 vipw和vigr vipw和vigr是编辑用户和组文件的工具，vipw可以修改/etc/passwd和/etc/shadow，vigr可以修改/etc/group和/etc/gshadow，用这两个工具比较安全，在修改的时候会检查文件的一致性。 删除用户出错时，提示用户正在被进程占用。可以使用vi编辑/etc/paswd和/etc/shadow文件将该用户对应的行删除掉。也可以使用vipw和vipw -s来分别编辑/etc/paswd和/etc/shadow文件。它们的作用是一样的。 手动创建用户 手动创建用户的全过程：需要管理员权限。 在/etc/group中添加用户所属组的相关信息。如果用户还有辅助组则在对应组中加入该用户作为成员。在/etc/passwd和/etc/shadow中添加用户相关信息。此时指定的家目录还不存在，密码不存在，所以/etc/shadow的密码位使用”!!”代替。创建家目录，并复制骨架目录中的文件到家目录中。 12shell&gt; mkdir /home/user_nameshell&gt; cp -r /etc/skel /home/user_name。 修改家目录及子目录的所有者和属组。 1shell&gt; chown -R user_name:user_name /home/user_name 修改家目录及子目录的权限。例如设置组和其他用户无任何权限但所有者有。 1shell&gt; chmod -R 700 /home/user_name 到此为止，用户已经创建完成了，只是没有密码，所以只能su，不能登录。 生成密码。使用openssl passwd生成密码。但openssl passwd生成的密码只能是MD5算法的，很容易被破解 1shell&gt; openssl passwd -1 -salt &apos;123456&apos; # 生成使用md5算法的密码，然后将生成的密码复制到/etc/shadow对应用户的密码位。其中-1是指md5，-salt &apos;12345678&apos;是使用8位的字符创建密码的杂项。 直接使用passwd命令创建密码 测试手动创建的用户是否可以正确登录。 以下是全过程。 12345678shell&gt; mkdir /tmp/12;cp /etc/group /etc/passwd /etc/shadow /tmp/12/ # 备份这些文件shell&gt; echo &quot;userX:x:666&quot; &gt;&gt; /etc/groupshell&gt; echo &quot;userX:x:666:666::/home/userX:/bin/bash&quot; &gt;&gt; /etc/passwdshell&gt; echo &apos;userX:!!:17121:0:99999::::&apos; &gt;&gt; /etc/shadowshell&gt; cp -r /etc/skel /home/userXshell&gt; chown -R userX:userX /home/userXshell&gt; chmod -R go= /home/userXshell&gt; passwd --stdin userX &lt;&lt;&lt; &apos;123456&apos; 测试使用userX是否可以登录。 如果是使用openssl passwd创建的密码。那么使用下面的方法将这部分密码替换到/etc/shadow中。 123shell&gt; field=$(tail -1 /etc/shadow | cut -d&quot;:&quot; -f2)shell&gt; password=$(openssl passwd -1 -salt &apos;abcdefg&apos; 123456)shell&gt; sed -i &apos;$s%&apos;$field&apos;%&apos;$password&apos;%&apos; /etc/shadow 其他用户相关命令finger查看用户信息 从CentOS 6版本开始就没有该命令了，要先安装。 12345678910shell&gt; yum -y install fingershell&gt; useradd zhangsanshell&gt; finger zhangsanLogin: zhangsan Name:Directory: /home/zhangsan Shell: /bin/bashNever logged in.No mail.No Plan. id1234id username-u：得到uid-n：得到用户名而不是uid-z：无任何空白字符输出模式，不能在默认的格式下使用。 示例：1234567891011shell&gt; id rootuid=0(root) gid=0(root) groups=0(root)shell&gt; id wangwuuid=500(wangwu) gid=500(wangwu) groups=500(wangwu)shell&gt; id -u wangwu500shell&gt; id -u -z wangwu2002[root@server2 ~]# users 查看当前正在登陆的用户名。 last 查看最近登录的用户列表，其实last查看的是/var/log/wtmp文件。 -n 显示行数：列出最近几次登录的用户 1234567[root@xuexi ~]# last -4root pts/0 192.168.100.1 Wed Mar 30 15:16 still logged in root pts/1 192.168.100.1 Wed Mar 30 14:21 - 14:21 (00:00) root pts/1 192.168.100.1 Wed Mar 30 14:04 - 14:10 (00:06) root pts/0 192.168.100.1 Wed Mar 30 13:12 - 15:16 (02:04) wtmp begins Thu Feb 18 20:59:39 2016 lastb 查看谁尝试登陆过但没有登录成功的。即能够审核和查看谁曾经不断的登录，可能那就是黑客。 -n:只列出最近的n个尝试对象。 who和w 都是查看谁登录过，并干了什么事 w查看的信息比who多。 123456789shell&gt; whoroot tty1 2017-06-07 00:49root pts/0 2017-06-07 02:06 (192.168.100.1)shell&gt; w08:26:38 up 18:48, 2 users, load average: 0.00, 0.01, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot tty1 00:49 7:36m 0.24s 0.24s -bashroot pts/0 192.168.100.1 02:06 6.00s 0.97s 0.02s w 其中w的第一行，分别表示当前时间，已开机时长，当前在线用户，过去1、5、15分钟的平均负载率。这一行和uptime命令获取的信息是完全一致的。 lastlog 可以查看登录的来源IP -u 指定查看用户 1234567891011shell&gt; lastlog|head -n 10Username Port From Latestroot pts/0 192.168.100.1 Wed Mar 30 15:16:25 +0800 2016bin **Never logged in**daemon **Never logged in**adm **Never logged in**lp **Never logged in**sync **Never logged in**shutdown **Never logged in**halt **Never logged in**mail **Never logged in**","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"用户组","slug":"用户组","permalink":"http://yoursite.com/tags/用户组/"}]},{"title":"搭建DNS服务器，实现主DNS服务器，负责解析一个域","slug":"搭建DNS服务器，实现主DNS服务器，负责解析一个域","date":"2017-02-27T16:00:00.000Z","updated":"2018-06-15T13:10:49.817Z","comments":true,"path":"2017/02/28/搭建DNS服务器，实现主DNS服务器，负责解析一个域/","link":"","permalink":"http://yoursite.com/2017/02/28/搭建DNS服务器，实现主DNS服务器，负责解析一个域/","excerpt":"搭建DNS服务器，实现主DNS服务器，负责解析一个域 先装包 yum install bind 然后查看下包的组成结构 rpm -ql bind /etc/named.conf 这是他的配置文件 /var/named 这是存放名字跟IP的数据库 /var/log/named.log 这是存放日志的 /usr/sbin/named 主程序文件 服务名 named.service","text":"搭建DNS服务器，实现主DNS服务器，负责解析一个域 先装包 yum install bind 然后查看下包的组成结构 rpm -ql bind /etc/named.conf 这是他的配置文件 /var/named 这是存放名字跟IP的数据库 /var/log/named.log 这是存放日志的 /usr/sbin/named 主程序文件 服务名 named.service 一般做实验时，先把主配置文件复制一份，避免实验失败造成服务不可用。1cp /etc/named.conf&#123;,.bak&#125; -a ##注意任何配置文件复制时一定要加 -a ，保留他的原有属性。 复制完后启动服务并设定开机自动启动12systemctl start named systemctl enable named 服务起来后对应的端口也相对起来了 ，他应该是两个端口 udp53 tcp53 接下来对配置文件进行修改 vim /etc/named.conf 在里面创建 以 magedu.com 结尾的区域的数据 ，同时在里面定义类型以及区域数据库的路径。但是在这个配置文件中，有一个专门存放域的文件 /etc/named.rfc1912.zones ,所以建议一般把添加的域都存放在这个文件中。不过两个文件都可以存放。 现在来修改 /etc/named.rfc1912.zones 这个文件，这个文件里面存放了大量的区域信息，我们就可以参考里面的格式进行添加。12345zone &quot;magedu.com&quot; IN &#123; type master; file &quot;magedu.com.zone&quot;;&#125;; ##这是主从类型中的主类型，存放名字和IP 的数据库文件 接下来就要创建刚才定义的那个数据库文件，但是刚才也没写这个文件的路径，那么这个文件创建在哪个路径下呢？ 在主配置文件中已经有了严格定义，要求这个文件存放在 /var/named 文件中，这个文件就是专门存放数据库文件的。 所以现在先 cd 进入 /var/named 目录下，然后创建文件 touch magedu.com.zone ,但是这个文件里的内容有严格要求，我们直接写或许会出错。不过这个目录下已经有了很多文件，我们可以仿照其他文件来书写。 现在我们先复制一份目录下原来的文件并改名，在原来的文件内容上进行修改，改成我们需要的就可以。 123456知识点： SOA 中的五个时间段分别是： 1（serial） 版本号 ，每次修改后都要加一，否则从服务器不能匹配。 2(refresh) 从服务器跟主服务器的拉取时间，这个时间也是根据版本号的增加而变化。 3(retry) 表示如果从服务器跟主服务器匹配时出错后的重试时间。 4(expire) 过期时间，表示从服务器从主服务器上抓下来数据后，后续无法再同步，那么从服务器就会在这块定的时间以后过期，无法继续供客户使用。 5(minimum) 缓存器上的缓存时间。 cp named.localhost magedu.com.zone 复制完后进行修改 vim magedu.com.zone12345678910$TTL 1D @ IN SOA master.magedu.com. admin.magedu.com. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS master master A 192.168.30.101 www A 192.168.20.7 12写完后，然后重新加载服务，让配置文件生效。 systemctl reload named 或者 rndc reload 到此服务基本上就搭完了，就可以来测试了。 host www.magedu.com 192.168.30.7测试可能会出现连接不上的问题，首先看下权限对不对，一定要保证所属组是named 。 如果不是，就执行命令给加上。 chgrp named magedu.com.zone 如果还不能连接，就在看下主配置文件vim /etc/named.conf 123要把 options 中的的这两行都注释掉。 #listen-on port 53 &#123; locklhost; &#125;; #allow-query &#123; localhost;any; &#125;; 然后在 rndc reload 重新加载 在用命令 dig www.magedu.com @192.168.30.7 来测，如果能测出来说明成功 但是这还没完，因为刚才在数据库文件中添加 www 是192.168.30.7 ，所以他应该是一个外部服务器，所以现在模拟一个外部服务器，在 30.7 上安装httpd 服务器，然后构建外部服务界面。 1echo welcome to Magedu &gt; /var/www/html/index.html 启动服务 systemctl restart httpd 添加完后拿一台主机的浏览器测试，但这台主机的DNS 要指向搭建的那台DNS服务器。如： 在这台主机的网卡配置文件中添加 DNS1=192.168.30.101 然后重启服务生效添加完后可以查看下 /etc/resolv.conf 文件中DNS记录添加上没 最后打开浏览器 输入 www.magedu.com 连接就可以了","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"DNS","slug":"DNS","permalink":"http://yoursite.com/tags/DNS/"}]},{"title":"DNS 服务从基础到深入","slug":"DNS 服务从基础到深入","date":"2017-02-14T16:00:00.000Z","updated":"2018-06-15T12:22:30.217Z","comments":true,"path":"2017/02/15/DNS 服务从基础到深入/","link":"","permalink":"http://yoursite.com/2017/02/15/DNS 服务从基础到深入/","excerpt":"一 简介 DNS是Domain name system的简称，有些地方也称为Domain name server，这东西是一个很大的话题。如果不是要配置DNS服务，只需要理解DNS的解析流程和DNS有关的基本知识即可。如果要配置DNS服务，则可以看完全文。推荐阅读书籍：《DNS &amp; bind》，第四版有中文版，第五版目前只有英文版。 DNS必懂基础","text":"一 简介 DNS是Domain name system的简称，有些地方也称为Domain name server，这东西是一个很大的话题。如果不是要配置DNS服务，只需要理解DNS的解析流程和DNS有关的基本知识即可。如果要配置DNS服务，则可以看完全文。推荐阅读书籍：《DNS &amp; bind》，第四版有中文版，第五版目前只有英文版。 DNS必懂基础 DNS主要是用于将域名解析为IP地址的协议，有时候也用于将IP地址反向解析成域名，所以DNS可以实现双向解析。DNS可以使用TCP和UDP的53端口，基本使用UDP协议的53端口。 域的分类 域是分层管理的，就像中国的行政级别。最高层的域是根域(root)”.”，就是一个点，它就像国家主席一样。全球只有13个根域服务器，基本上都在美国，中国一台根域服务器都没有。根域的下一层就是第二层次的顶级域（TLD）了，那么它就是各省省长了。顶级域一般两种划分方法：按国家划分和按组织性质划分。 ◇ 按国家划分：.cn(中国)、.tw(台湾)、.hk(香港)。基本都是两个字母的。◇ 按组织性质划分：.org、.net、.com、.edu、.gov、.cc等。◇ 反向域：arpa。这是反向解析的特殊顶级域。 顶级域下来就是普通的域，公司或个人在互联网上注册的域名一般都是这些普通的域，如baidu.com。 主机名、域名、FQDN 以百度(www.baidu.com)和百度贴吧(tieba.baidu.com)来举例。 ◇ 域名不论是www.baidu.com还是tieba.baidu.com，它们的域名都是baidu.com，严格地说是&quot;baidu.com.&quot;。这是百度所购买的com域下的一个子域名。 ◇ 主机名对于www.baidu.com来说，主机名是www，对于tieba.baidu.com来说，主机名是tieba。其实严格来说，www.baidu.com和tieba.baidu.com才是主机名，它们都是baidu.com域下的主机。一个域下可以定义很多主机，只需配置好它的主机名和对应主机的IP地址即可。 ◇ FQDNFQDN是Fully Qualified Domain Name的缩写，称为完全合格域名，是指包含了所有域的主机名，其中包括根域。FQDN可以说是主机名的一种完全表示形式，它从逻辑上准确地表示出主机在什么地方。 例如www.baidu.com的FQDN是&quot;www.baidu.com.&quot;，com后面还有个点，这是根域；tieba.baidu.com的FQDN是&quot;tieba.baidu.com.&quot;。 域的分层授权 域是从上到下授权的，每一层都只负责自己的直辖下层，而不负责下下层。例如根域给顶级域授权，顶级域给普通域授权，但是根域不会给普通域授权。和现实中的行政管理不一样，域的授权和管理绝对不会向下越级，因为它根本不知道下下级的域名是否存在。 DNS解析流程 以访问www.baidu.com为例。 (1).客户端要访问www.baidu.com，首先会查找本机DNS缓存，再查找自己的hosts文件，还没有的话就找DNS服务器（这个DNS服务器就是计算机里设置指向的DNS）。 (2).DNS服务器收到询问请求，首先查看自己是否有www.baidu.com的缓存，如果有就直接返回给客户端，没有就越级上访到根域&quot;.&quot;，并询问根域。 (3).根域看到是找.com域的，把到.com域的路(地址)告诉DNS服务器，让DNS服务器去找.com询问。 (4).DNS服务器去找.com，”.com”一看是自己辖下的baidu.com，就把baidu.com的IP地址给DNS服务器，让它去找baidu.com。 (5).DNS找到baidu.com，baidu.com发现DNS服务器要找的是自己区域里的www主机，就把这个主机IP地址给了DNS服务器。 (6).DNS服务器把得到的www.baidu.com的IP结果告诉客户端，并缓存一份结果在自己机器中(默认会缓存，因为该服务器允许为客户端递归，否则不会缓存非权威数据)。 (7).客户端得到回答的IP地址后缓存下来，并去访问www.baidu.com，然后www.baidu.com就把页面内容发送给客户端，也就是百度页面。 最后要说明的是： 1.本机查找完缓存后如果没有结果，会先查找hosts文件，如果没有找到再把查询发送给DNS服务器，但这仅仅是默认情况，这个默认顺序是可以改变的。在/etc/nsswitch.conf中有一行” hosts: files dns”就是定义先查找hosts文件还是先提交给DNS服务器的，如果修改该行为”hosts: dns files”则先提交给DNS服务器，这种情况下hosts文件几乎就不怎么用的上了。 2.由于缓存是多层次缓存的，所以真正的查询可能并没有那么多步骤，上图的步骤是完全没有所需缓存的查询情况。假如某主机曾经向DNS服务器提交了www.baidu.com的查询，那么在DNS服务器上除了缓存了www.baidu.com的记录，还缓存了&quot;.com&quot;和&quot;baidu.com&quot;的记录，如果再有主机向该DNS服务器提交ftp.baidu.com的查询，那么将跳过&quot;.&quot;和&quot;.com&quot;的查询过程直接向baidu.com发出查询请求。 /etc/resolv.conf文件 这个文件主要用于定义dns指向，即查询主机名时明确指定使用哪个dns服务器。该文件的详细说明见Linux网络管理之：/etc/resolv.conf。 例如此文件中指定了”nameserver 8.8.8.8”，则每当要查询主机名时，都会向8.8.8.8这台dns服务器发起递归查询，这台dns服务器会帮忙查找到最终结果并返回给你。 当然，在后文的实验测试过程中，使用了另一种方式指定要使用的dns服务器：dig命令中使用”@dns_server”。 DNS术语递归查询和迭代查询 例如A主机要查询C域中的一个主机，A所指向的DNS服务器为B，递归和迭代查询的方式是这样的： 递归查询：A –&gt; B –&gt; C –&gt; B –&gt; A 迭代查询：A –&gt; B A –&gt; C –&gt; A 将递归查询和迭代查询的方式放到查询流程中，就如下图所示。(未标出Client指向的DNS服务器) 也就是说，递归的意思是找了谁谁就一定要给出答案。那么允许递归的意思就是帮忙去找位置，如A对B允许递归，那么B询问A时，A就去帮忙找答案，如果A不允许对B递归，那么A就会告诉B的下一层域的地址让B自己去找。 可以想象，如果整个域系统都使用递归查询，那些公共的根域和顶级域会忙到死，因此更好的方案就是把这些压力分散到每个个人定制的DNS服务器。 所以DNS的解析流程才会如下图。并且在客户端到DNS服务器端的这一阶段是递归查询，从DNS服务器之后的是迭代查询。也就是说，顶级域和根域出于性能的考虑，是不允许给其他任何机器递归的。 为什么客户端到DNS服务器阶段是递归查询？因为客户端本身不是DNS服务器，它自己是找不到互联网上的域名地址的，所以只能询问DNS服务器，最后一定由DNS服务器来返回答案，所以DNS服务器需要对这个客户端允许递归。因此，dns解析器(nslookup、host、dig等)所发出的查询都是递归查询。 权威服务器和(非)权威应答 权威服务器（权威者）可以理解为直接上层域的DNS服务器。例如www.baidu.com这台主机的上层域是baidu.com，那么对www来说，它的权威服务器就是baidu.com这个域内负责解析的DNS服务器，而对于baidu.com这个主机来说，它的权威服务器是.com这个域负责解析的DNS服务器。 更具体的说，某域的权威服务器是可以直接查看该域数据(即区域数据文件)的DNS服务器，主、从DNS服务器都是权威服务器。 只有权威服务器给出的应答才是权威应答，否则就是非权威应答。为什么呢？因为一个域中所有的主机都是在DNS服务器中的区域数据文件中记录的，对于主机来说，它们的位置只有直接上层才知道在哪里。 因此如果解析www.baidu.com时要获得权威应答，应该将DNS指向baidu.com这个域内负责解析的DNS服务器。 只有权威服务器直接给出的答案才是永远正确的，通过缓存得到的答案基本都是非权威应答。当然这不是一定的，因为权威服务器给的答案也是缓存中的结果，但是这是权威答案。DNS服务器缓存解析的数据库时间长度是由权威服务器决定的。 DNS缓存 在Client和DNS服务器这些个人订制的DNS解析系统中都会使用缓存来加速解析以减少网络流量和查询压力，就算是解析不到的否定答案也会缓存。 但是要访问的主机IP可能会改变，所有使用缓存得到的答案不一定是对的，因此缓存给的答案是非权威的，只有对方主机的上一级给的答案才是权威答案。缓存给的非权威答案应该设定缓存时间，这个缓存时间的长短由权威者指定。 另外访问某个域下根本不存在的主机，这个域的DNS服务器也会给出答案，但是这是否定答案，否定答案也会缓存，并且有缓存时间。例如某个Client请求51cto.com域下的ftp主机，但是实际上51cto.com下面可能根本没有这个ftp主机，那么51cto.com就会给否定答案，为了防止Client不死心的访问ftp搞破坏，51cto.com这个域负责解析的DNS服务器有必要给Client指定否定答案的缓存时间。 主、从dns服务器 dns服务器也称为name server，每个域都必须有dns服务器负责该域相关数据的解析。但dns服务器要负责整个域的数据解析，压力相对来说是比较大的，且一旦出现问题，整个域都崩溃无法向外提供服务，这是非常严重的事。所以，无论是出于负载均衡还是域数据安全可用的考虑，两台dns服务器已经是最低要求了，多数时候应该配置多台dns服务器。 多台dns服务器之间有主次之分，主dns服务器称为master，从dns服务器称为slave。slave上的域数据都是从master上获取的，这样slave和master就都能向外提供名称解析服务。 资源记录(Resource Record,RR) 对于提供DNS服务的系统(DNS服务器)，域名相关的数据都需要存储在文件(区域数据文件)中。这些数据分为多种类别，每种类别存储在对应的资源记录(resource record,RR)中。也就是说，资源记录既用来区分域数据的类型，也用来存储对应的域数据。 DNS的internet类中有非常多的资源记录类型。常用的是SOA记录、NS记录、A记录(IPV6则为AAAA记录)、PTR记录、CNAME记录、MX记录等。 (1).SOA记录：start of authority，起始授权机构。该记录存储了一系列数据，若不明白SOA记录，请结合下面的NS记录，SOA更多的信息见”子域”部分的内容。格式如下：123456longshuai.com. IN SOA dnsserver.longshuai.com. mail.longshuai.com. ( 1 3h 1h 1w 1h ) 第四列指定了”dnsserver.longshuai.com.”为该域的master DNS服务器。 第五列是该域的管理员邮箱地址，但注意不能使用@格式的邮箱，而是要将@符号替换为点”.”，正如上面的例子”mail.longshuai.com.”，其实际表示的是”mail@longshuai.com“。 第六列使用括号将几个值包围起来。第一个值是区域数据文件的序列编号serial，每次修改此区域数据文件都需要修改该编号值以便让slave dns服务器同步该区域数据文件。第二个值是刷新refresh时间间隔，表示slave dns服务器找master dns服务器更新区域数据文件的时间间隔。第三个值是重试retry时间间隔，表示slave dns服务器找master dns服务器更新区域数据文件时，如果联系不上master，则等待多久再重试联系，该值一般比refresh时间短，否则该值表示的重试就失去了意义。第四个值是过期expire时间值，表示slave dns服务器上的区域数据文件多久过期。第五个值是negative ttl，表示客户端找dns服务器解析时，否定答案的缓存时间长度。这几个值可以分行写，也可以直接写在同一行中使用空格分开，所以，上面的SOA记录可以写成如下格式： 1longshuai.com. IN SOA dnsserver.longshuai.com. mail.longshuai.com. ( 1 3h 1h 1w 1h ) 前三列是声明性的语句，表示”longshuai.com.”这个域内的起始授权机构为第四列的值”dnsserver.longshuai.com.”所表示的主机。第五列和第六列是SOA的附加属性数据。 每个区域数据文件中都有且仅能有一个SOA记录，且一般都定义为区域数据文件中的资源记录。 注意，资源记录的作用之一是存储域相关的对应数据，所以第4、5、6列表示的是该SOA记录所存储的相关值。 (2).NS记录：name server，存储的是该域内的dns服务器相关信息。即NS记录标识了哪台服务器是DNS服务器。格式如下：1longshuai.com. IN NS dnsserver.longshuai.com. 前三列仍然是声明性语句，表示”longshuai.com.”域内的DNS服务器(name server)为第四列值所表示的”dnsserver.longshuai.com.”主机。 如果一个域内有多个dns服务器，则必然有主次之分，即master和slave之分。但在NS记录上并不能体现主次关系。例如： 12longshuai.com. IN NS dnsserver1.longshuai.com.longshuai.com. IN NS dnsserver2.longshuai.com. 表示主机”dnsserver1.longshuai.com.”和主机”dnsserver2.longshuai.com.”都是域”longshuai.com.”内的dns服务器，但没有区分出主次dns服务器。 很多人搞不懂SOA记录，也很容易混淆SOA和NS记录。其实，仅就它们的主要作用而言，NS记录仅仅只是声明该域内哪台主机是dns服务器，用来提供名称解析服务，NS记录不会区分哪台dns服务器是master哪台dns服务器是slave。而SOA记录则用于指定哪个NS记录对应的主机是master dns服务器，也就是从多个dns服务器中挑选一台任命其为该域内的master dns服务器，其他的都是slave，都需要从master上获取域相关数据。由此，SOA的名称”起始授权机构”所表示的意思也就容易理解了。 (3).A记录：address，存储的是域内主机名所对应的ip地址。格式如下：1dnsserver.longshuai.com. IN A 172.16.10.15 客户端之所以能够解析到主机名对应的ip地址，就是因为dns服务器中的有A记录存储了主机名和ip的对应关系。AAAA记录存储的是主机名和ipv6地址的对应关系。 (4).PTR记录：pointer，和A记录相反，存储的是ip地址对应的主机名，该记录只存在于反向解析的区域数据文件中(并非一定)。格式如下：116.10.16.172.in-addr.arpa. IN PTR www.longshuai.com. 表示解析172.16.10.16地址时得到主机名”www.longshuai.com.&quot;的结果。 (5).CNAME记录：canonical name，表示规范名的意思，其所代表的记录常称为别名记录。之所以如此称呼，就是因为为规范名起了一个别名。什么是规范名？可以简单认为是fqdn。格式如下：1www1.longshuai.com. IN CNAM www.longshuai.com. 最后一列就是规范名，而第一列是规范名即最后一列的别名。当查询”www1.longshuai.com.”，dns服务器会找到它的规范名”www.longshuai.com.&quot;，然后再查询规范名的A记录，也就获得了对应的IP地址并返回给客户端。 CNAME记录非常重要，很多时候使用CNAME可以解决很复杂的问题。而且目前常用的CDN技术有一个步骤就是在dns服务器上设置CNAME记录，将客户端对资源的请求引导到与它同网络环境(电信、网通)以及地理位置近的缓存服务器上。关于CDN的简介，见下文CDN和DNS的关系。 (6).MX记录：mail exchanger，邮件交换记录。负责转发或处理该域名内的邮件。和邮件服务器有关，且话题较大，所以不多做叙述，如有深入的必要，请查看《dns &amp; bind》中”Chapter 5. DNS and Electronic Mail”。 关于资源记录，最需要明确的概念就是它不仅仅用来区分和标识区域数据的类型，还用来存储对应的域数据。 安装阶段请关注下一章！","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"DNS","slug":"DNS","permalink":"http://yoursite.com/tags/DNS/"}]},{"title":"SSH端口转发实验","slug":"SSH端口转发实验","date":"2017-02-09T16:00:00.000Z","updated":"2018-06-13T08:59:24.876Z","comments":true,"path":"2017/02/10/SSH端口转发实验/","link":"","permalink":"http://yoursite.com/2017/02/10/SSH端口转发实验/","excerpt":"一、SSH端口转发相关概念二、实验：模拟SSH本地端口转发三、实验：模拟SSH远程端口转发四、实验：模拟SSH动态端口转发一、SSH端口转发相关概念 在上一节我们知道，SSH会自动加密和解密所有SSH客户端和服务器之间的网络数据。 但是，SSH还同时提供了一个非常有用的功能，这就是端口转发。它能够将其他TCP端口的网络数据通过安全的SSH协议 转发，例如：Telnet，SMTP等这些TCP应用都能从中受益，避免了用户名，密码以及隐私信息的明文传输。而与此同时，如果在你的工作环境中防火墙限制了一些网络端口的使用，但是允许SSH的连接，那么端口转发功能也能够将TCP端口转发来使用SSH进行通信。","text":"一、SSH端口转发相关概念二、实验：模拟SSH本地端口转发三、实验：模拟SSH远程端口转发四、实验：模拟SSH动态端口转发一、SSH端口转发相关概念 在上一节我们知道，SSH会自动加密和解密所有SSH客户端和服务器之间的网络数据。 但是，SSH还同时提供了一个非常有用的功能，这就是端口转发。它能够将其他TCP端口的网络数据通过安全的SSH协议 转发，例如：Telnet，SMTP等这些TCP应用都能从中受益，避免了用户名，密码以及隐私信息的明文传输。而与此同时，如果在你的工作环境中防火墙限制了一些网络端口的使用，但是允许SSH的连接，那么端口转发功能也能够将TCP端口转发来使用SSH进行通信。 SSH端口转发提供的功能主要有： 1.加密SSH Client端至SSH Server端之间的数据 2.突破防火墙的限制完成一些之前无法建立的TCP连接 SSH端口转发提供的类型有： 本地转发 远程转发 动态转发 X协议转发 本地转发： 当外网用户想要临时访问公司内部的不安全TCP协议服务器时，由于防火墙限制无法直接访问，但可利用先SSH连接至公司内网的SSH服务器在转发至不安全的TCP协议服务器。由于作为转发的SSH服务器与要访问的不安全TCP协议服务器在同一网络环境内，故这种连接就叫本地转发。 格式：1ssh -L localprot:remotehost:remotehostport sshserver localprot：指定本机端口 remotehost：指定远程不安全协议的服务器地址 remotehostport：远程不安全协议的服务器地址端口 sshserver：SSH服务器地址 options： -f 后台启用 -N 不打开远程shell，处于等待状态 -g 启用网关功能 12345示例：ssh -L 9527:telnetsrv:23 -N sshsrvtelnet 127.0.0.1 9527 当访问本机的9527端口时，被加密后转发到sshsrv的ssh服务，再解密被转发到telnetsrv:23 大致流程：1Data &lt;–&gt; localhost:9527 &lt;–&gt;localhost:xxxxx &lt;–&gt; sshsrv:22 &lt;–&gt;sshsrv:yyyyy &lt;–&gt; telnetsrv:23 远程转发： 与本地端口转发相比，我们将SSH服务器与Client访问端的位置对调，将与不安全TCP协议服务器同一内网的主机作为Client，将外部网络主机作为SSH服务器做为端口转发。由于作为转发的SSH服务器处在外部网络环境中，故这种连接就叫远程转发。 123格式：ssh -R sshserverport:remotehost:remotehostport sshserver sshserverport：指定SSH服务器端口 remotehost：指定远程不安全协议的服务器地址 remotehost:remotehostport：指定远程不安全协议的服务器端口 sshserver：SSH服务器地址 123示例：ssh -R 9527:telnetsrv:23 -N sshsrv 让sshsrv侦听9527端口的访问，如有访问，就加密后通过ssh服务转发请求到本机ssh客户端，再由本机解密后转发到telnetsrv:23 大致流程：1Data &lt;–&gt; sshsrv:9527 &lt;–&gt; sshsrv:22 &lt;–&gt; localhost:xxxxx &lt;–&gt; localhost:yyyyy &lt;–&gt; telnetsrv:23 动态端口转发： 在之前我们已经了解了本地转发，以及远程转发，但它们实现的前提都是要求有一个固定的应用服务端端口 。 但在某些场景下，例如用浏览器浏览网页，是没有固定端口的，这时就需要利用到动态的端口转发。比如说，当用firefox访问Internet时，本机的1080端口作为代理服务器，firefox的访问请求被转发到sshserver上，由sshserver替代访问Internet 1ssh -D 1080 root@sshserver 在本机firefox设置socketproxy:127.0.0.1:1080 1curl –socks5 127.0.0.1:1080 http://www.qq.com X协议转发： 所有图形化应用程序都是X客户程序 能够通过tcp/ip连接远程X服务器 数据没有加密机，但是它通过ssh连接隧道安全进行 1ssh -X user@remotehost gedit remotehost主机上的gedit工具，将会显示在本机的X服务器上 传输的数据将通过ssh连接加密 相关文件： /var/log/secure 存放日志 /etc/ssh/sshd_config SSH服务配置文件 #Port 22 端口生产中一般第一步先改端口号 如Port 9527 定义公钥、私钥存放文件名，位置 H123456789ostKey /etc/ssh/ssh_host_rsa_key#HostKey /etc/ssh/ssh_host_dsa_keyHostKey /etc/ssh/ssh_host_ecdsa_keyHostKey /etc/ssh/ssh_host_ed25519_key日志设置选项，日志存放在/var/log/secure Logging #SyslogFacility AUTH SyslogFacility AUTHPRIV #LogLevel INFO 12345678910111213141516171819#LoginGraceTime 2m 不输入密码最大时间端口#PermitRootLogin yes 生产中一般改成no，普通用户连接su切换#StrictModes yes 检查文件权限#MaxAuthTries 6 密码登录最大验证次数#MaxSessions 10 单个会话能开的最大克隆数 PasswordAuthentication yes 是否允许基于口令登录方式，no表示禁止 #ClientAliveInterval 0 连接后不操作最大时间，单位：秒#ClientAliveCountMax 3 连接环不操作最大时间次数 生产中一般要修改AliveInterval 30 AliveCountMax 3 表示连接后不进行任何操作30S，3次后自动断开连接 #ShowPatchLevel noUseDNS no 是否使用DNS反向解析，关闭可提高连接速度 #MaxStartups10:30:100 最大并发连接数，默认10 限制可登录用户的办法：1234567AllowUsers user1 user2 user3DenyUsersAllowGroupsDenyGroups SSH服务的最佳实践配置： 建议使用非默认端口 禁止使用protocol version 1 限制可登录用户 设定空闲会话超时时长 利用防火墙设置ssh访问策略 仅监听特定的IP地址 基于口令认证时，使用强密码策略1tr -dc A-Za-z0-9_ &lt; /dev/urandom | head -c 30| xargs 使用基于密钥的认证 禁止使用空密码 禁止root用户直接登录 限制ssh的访问频度和并发在线数 经常分析日志 二、实验：模拟SSH本地端口转发 应用场景：当外部客户端想要访问公司内网的Telnet服务器时，由于防火墙限制无法直接访问，可使用SSH本地端口转发实现： 前期准备： 以三台CentOS模拟机作为服务器及主机，主机名网络配置如下： 客户端：192.168.30.133 SSH服务器：192.168.30.158 telnet服务器：192.168.30.160 telnet服务器端操作： 一、安装telnet-server包，系统默认未安装 二、防火墙禁止远程客户端访问： 1iptables -A INPUT -s 192.168.30.133 -j REJECT 为了防止之前防火墙策略干扰，最好先清空下防火墙策略： iptables -K 防火墙 此时作为Clinet的192.168.30.133已经ping不通作为telnet服务器的192.168.30.160 ping不通 三、开启telnet-server服务 CentOS6： service xinted start 开启xinted进程 chkconfig telnet on 开启telnet服务 service xinted restart 重启xinted服务 重启xinetd CentOS7： systemctl start telnet-scoket 客户端操作：1ssh -L 9527:192.168.30.17:23 [-Nf] 192.168.30.6 加-Nf选项将后台执行，关闭时只能通过kill关闭进程 telnet 127.0.0.1 9527 提示输入用户名，密码；默认不让root账户使用SSH端口转发登录 登录成功三、实验：模拟SSH远程端口转发 应用场景：当外部有工程师想要临时访问内部telnet服务器时，作为系统管理员，我们可以将对方主机作为SSH服务器进行端口转发，让其临时可访问公司的telnet服务器。 前期准备：以三台CentOS模拟机作为服务器及主机，主机名及网络配置如下：Internet：192.168.30.133 lanserver：192.168.30.158 telnet服务器：192.168.30.160 lanserver端操作：1ssh -R 9527:192.168.30.17:23 [-Nf] 192.168.30.7 加-Nf选项将后台执行，关闭时只能通过kill关闭进程lanserver命令 Internet端操作：telnet 127.0.0.1 9527telnet成功 四、实验：模拟SSH动态端口转发 应用场景：在某些场景中，用浏览器浏览网页，是没有固定端口的，这时就需要利用到动态的端口转发。下面我们模拟用一台虚拟机模拟google网站，用Internet主机通过代理服务器proxy访问google模拟机 前期准备： 以三台CentOS模拟机作为服务器及主机，主机名及网络配置如下： Internet：192.168.30.133 proxy：192.168.30.158 google：192.168.30.160 google模拟服务器操作： 开启http服务，模拟网页内容： CentOS6： service httpd start CentOS7： systemctl start httpd echo www.google.com &gt; /var/www/html/index.htmlinternet 此时访问192.168.30.160，正常网页内容显示如下: gogole Internet端操作： 此时在Internet端我们是无法访问google服务器的无法打开 使用proxy的1080端口作为动态转发： ssh -D 1080 root@192.168.30.158登录代理 接下来我们可以通过图形界面或者字符界面来尝试访问： 图形界面： 打开firefox浏览器，按以下顺序操作： –12&gt;preferences–&gt;advanced–&gt;network–setting–manual proxy configuration–&gt;SOCKS Host:127.0.0.1 设置火狐 现在再次尝试访问192.168.30.160的google模拟服务器，发现可以正常访问了！访问成功 字符界面： 在字符界面我们可执行下面的命令来进行访问：curl -socks5 127.0.0.1:1080 192.168.30.17 字符界面登录","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"http://yoursite.com/tags/SSH/"}]},{"title":"实现PXE自动安装","slug":"实现PXE自动安装","date":"2017-02-07T16:00:00.000Z","updated":"2018-06-14T14:18:06.373Z","comments":true,"path":"2017/02/08/实现PXE自动安装/","link":"","permalink":"http://yoursite.com/2017/02/08/实现PXE自动安装/","excerpt":"实现PXE自动安装1、基础网络建设与搭建DHCP服务配置静态IP地址并重起网卡12345678910cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=10.0.0.4 NETMASK=255.255.255.0 GATEWAY=10.0.0.2 /etc/init.d/network restartifconfig eth0 2）安装配置DHCP服务123456789yum -y install dhcp vim /etc/dhcp/dhcpd.conf default-lease-time 600; max-lease-time 7200; ddns-update-style none; option domain-name-servers 202.106.0.20; #DNS地址可配置2个用逗号分隔 ignore client-updates;","text":"实现PXE自动安装1、基础网络建设与搭建DHCP服务配置静态IP地址并重起网卡12345678910cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=10.0.0.4 NETMASK=255.255.255.0 GATEWAY=10.0.0.2 /etc/init.d/network restartifconfig eth0 2）安装配置DHCP服务123456789yum -y install dhcp vim /etc/dhcp/dhcpd.conf default-lease-time 600; max-lease-time 7200; ddns-update-style none; option domain-name-servers 202.106.0.20; #DNS地址可配置2个用逗号分隔 ignore client-updates; subnet 10.0.0.0 netmask 255.255.255.0 { range 10.0.0.100 10.0.0.150; #宣告获取地址段 option subnet-mask 255.255.255.0; #子网 option routers 10.0.0.2; #获取网关地址 next-server 10.0.0.4; #重点配置PEX地址 filename “pxelinux.0”; #内核文件名 配置开机自启动chkconfig –add dhcpdchkconfig dhcpd onchkconfig –list dhcpd查看DHCP监听端口好UDP 67netstat -lntup|grep 67 2、搭建TFTP服务1yum -y install tftp-server tftp 12345678910111213141516 vim /etc/xinetd.d/tftp #配置TFTP配置文件： service tftp &#123; socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -s /tftpboot #修改TFTP服务目录 disable = no #修改为no，启动TFTP per_source = 11 cps = 100 2 flags = IPv4 &#125; 123456789101112131415161718192021 配置自启动 chkconfig tftp on chkconfig --list tftp chkconfig --list xinetd 重启动xinetd服务，TFTP是由xinetd服务运行的 /etc/init.d/xinetd restart netstat -lntup|grep 69 ;netstat -a|grep tftp udp 0 0 0.0.0.0:69 0.0.0.0:* 1877/xinetd udp 0 0 *:tftp TFTP端口号为UDP的69 测试下载 mkdir /tftpboot cd /tftpboot/ touch test.txt ls test.txt cd .. tftp 10.0.0.4 -c get test.txt ls #下载成功！ test.txt 3、搭建HTTP服务1234567891011yum -y install httpd #配置自启动 chkconfig --add httpd chkconfig httpd on chkconfig --list httpd #启动http服务 /etc/init.d/httpd start netstat -lntup|grep 80 #使用浏览器测试 http://10.0.0.4 4、组建PXE服务环境 1)安装syslinux包yum -y install syslinux #如不安装syslinux包就没有pxelinux.0文件 find / -type f -name “pxelinux.0”/usr/share/syslinux/pxelinux.0 #将pxelinux.0拷贝到tftp服务目录 cp /usr/share/syslinux/pxelinux.0 /tftpboot/ #在tftp服务目录下创建pxelinux.cfg目录mkdir /tftpboot/pxelinux.cfg -p 2)挂载linux系统盘，拷贝linux内核，初始化镜像文件mkdir -p /media/cdrommount -t iso9660 -o loop /dev/sr0 /media/cdromcd /media/cdrom/images/pxebootcp vmlinuz initrd.img /tftpboot/cd /tftpboot/lsinitrd.img pxelinux.0 pxelinux.cfg vmlinuz #配置启动菜单文件，将系统自带的启动文件拷贝到TFTP目录下改名为 cp /media/cdrom/isolinux/isolinux.cfg /tftpboot/pxelinux.cfg/default修改启动菜单文件 cat default default auto #指定默认启动项prompt 0 #为0时不选择自动按默认安装，为1时可选择选项安装 label auto #配置选项auto kernel vmlinuz #指定内核 append initrd=initrd.img ks=http://10.0.0.4/ks.cfg devfs=nomount ramdisk_size=8192 #指定自动安装文件ks.cfglabel linux text kernel vmlinuz append initrd=initrd.img devfs=nomount ramdisk_size=8192label rescue kernel vmlinuz append initrd=initrd.img rescue #重启动TFTP服务加载配置/etc/init.d/xinetd restart 5、创建kickstart文件 1)安装system-config-kickstartyum -y install system-config-kickstart #注意安装桌面服务才能启动KICKSTART，创建启动文件/usr/bin/system-config-kickstart cat ks.cfg #platform=x86, AMD64, or Intel EM64T #version=DEVEL Firewall configuration关闭防火墙firewall –disabled Install OS instead of upgrade 安装系统install Root password 配置ROOT密码rootpw –iscrypted $1$jIsDXG2F$EGT.VAhEBlZ/ww9GNOTo7.System authorization information 系统授权信息auth –useshadow –passalgo=md5 Use graphical install 图形安装graphicalSystem keyboard 配置键盘keyboard usSystem language 配置系统语言lang en_US SELinux configuration 关闭selinuxselinux –disabled Do not configure the X Window System 不安装图形界面skipxInstallation logging level 安装系统日志记录级别logging –level=info Reboot after installation 安装完重新引导rebootSystem timezone #配置时区timezone Asia/ShanghaiNetwork information 配置网络为自动获取network –bootproto=dhcp –device=eth0 –onboot=onSystem bootloader configuration 系统引导程序配置bootloader –location=mbrClear the Master Boot Record 清除主引导记录zerombrPartition clearing information 分区信息clearpart –allDisk partitioning information 指定分区大小part swap –fstype=”swap” –size=2048part /boot –fstype=”ext4” –size=200part / –fstype=”ext4” –grow –size=1 %packages@base@compat-libraries@debugging@development %end #将应答脚本拷贝到http目录，并赋予权限12cp ks.cfg /var/www/html/ chown apache.apache /var/www/html/ks.cfg 6、启动客户机安装 注意：客户机要和服务器在同一个局域网内如果使用vmware做实验，需要关闭VMware自带的DHCP功能","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"自动化安装","slug":"自动化安装","permalink":"http://yoursite.com/tags/自动化安装/"}]},{"title":"安装管理包：rpm包和yum包","slug":"rpm管理包 和 yum管理包(1)","date":"2017-01-31T16:00:00.000Z","updated":"2018-06-19T08:08:02.964Z","comments":true,"path":"2017/02/01/rpm管理包 和 yum管理包(1)/","link":"","permalink":"http://yoursite.com/2017/02/01/rpm管理包 和 yum管理包(1)/","excerpt":"包基础知识包名称 在rhel/centos/fedora上，包的名称以rpm结尾，分为二进制包和源码包。源码包以”.src.rpm”结尾，它是未编译过的包，可以自行进行编译或者用其制作自己的二进制rpm包，非”.src.rpm”结尾的包都是二进制包，都是已经编译完成的，安装rpm包的过程实际上就是将包中的文件复制到Linux上，有可能还会在复制文件的前后执行一些命令，如创建一个必要的用户，删除非必要文件等。","text":"包基础知识包名称 在rhel/centos/fedora上，包的名称以rpm结尾，分为二进制包和源码包。源码包以”.src.rpm”结尾，它是未编译过的包，可以自行进行编译或者用其制作自己的二进制rpm包，非”.src.rpm”结尾的包都是二进制包，都是已经编译完成的，安装rpm包的过程实际上就是将包中的文件复制到Linux上，有可能还会在复制文件的前后执行一些命令，如创建一个必要的用户，删除非必要文件等。 注意区分源码包和源码的概念，源码一般是打包压缩后的文件(如.tar.gz结尾的文件)。源码包中包含了源码，还包含了一些有助于制作二进制rpm的文件。最有力的说明就是源码编译安装的程序都没有服务启动脚本(/etc/init.d/下对应的启动脚本)，而二进制rpm包安装的就有，因为二进制rpm包都是通过源码包”.src.rpm”定制而来，在源码包中提供了必要的文件(如服务启动脚本)，并在安装rpm的时候复制到指定路径下。 回归正题，一个rpm包的名称分为包全名和包名，包全名如httpd-2.2.15-39.el6.centos.x86_64.rpm，包全名中各部分的意义如下：123456httpd 包名2.2.15 版本号，版本号格式[ 主版本号.[ 次版本号.[ 修正号 ] ] ]39 软件发布次数el6.centos 适合的操作系统平台以及适合的操作系统版本x86_64 适合的硬件平台，硬件平台根据cpu来决定，有i386、i586、i686、x86_64、noarch或者省略，noarch或省略表示不区分硬件平台rpm 软件包后缀扩展名 使用rpm工具管理包时，如果要操作未安装的包，则使用包全名，如安装包，查看未安装包的信息等；如果要操作已安装的rpm包，则只需要给定其包名即可，如查询已装包生成了哪些文件，查看已装包的信息等。 而对于yum工具来说，只需给定其包名即可，若有需要，再指定版本号，如明确指明要安装1.6.10版本的tree工具，yum install tree-1.6.10。 rpm管理包 rpm包被安装后，会在/var/lib/rpm下会建立已装rpm数据库，以后有任何rpm的升级、查询、版本比较等包的操作都是从这个目录下获取信息并完成相应操作的。 12345[root@xuexi ~]# ls /var/lib/rpm/ Basenames __db.003 Group Packages Requirename TriggernameConflictname __db.004 Installtid Providename Requireversion__db.001 Dirnames Name Provideversion Sha1header__db.002 Filedigests Obsoletename Pubkeys Sigmd5 安装包后的文件分布 rpm安装完成后，相关的文件会复制到多个目录下(具体复制的路径是在制作rpm包时指定的)。一般来说，分布形式差不多如下表。 123456789101112/etc放置配置文件的目录/bin、/sbin、/usr/bin或/usr/sbin一些可执行文件/lib、/lib64、/usr/lib(/usr/lib64)一些库文件/usr/include一些头文件/usr/share/doc一些基本的软件使用手册与帮助文件/usr/share/man一些 man page 档案 rpm安装、升级、卸载 rpm工具安装、升级和卸载的功能都很少使用。对于安装来说，它需要人为解决包的依赖关系，这是极其令人恶心的事对于升级来说，基本上都会使用yum工具进行安装和升级，而卸载行为在Linux上很少出现，大不了直接覆盖重装。 12345678910111213rpm -ivhUe --nodeps --test --force --prefix选项说明：-i 表示安装，install的意思-v 显示安装信息，还可以&quot;-vv&quot;、&quot;-vvv&quot;，v提供的越多显示信息越多-h 显示安装进度，以#显示安装的进度-U 升级或升级包-F 只升级已安装的包-e 卸载包，卸载也有依赖性,&quot;--erase&quot;--nodeps 忽略依赖性强制安装或卸载(no dependencies)--test 测试是否能够成功安装指定的rpm包--prefix 新路径 自行指定安装路径而不是使用默认路径，基本上都不支持该功能，功能极其简单的软件估计才支持重定位安装路径--force 强制动作--replacepkgs 替换安装，即重新覆盖安装。 有时误删文件可以不用卸载再装，直接使用–replacepkgs选项再次安装即可。 rpm包另一个缺陷是只能安装本地或给定url路径的rpm包。 注意：不要对内核进行升级；多版本的内核可以并存，因此可以执行安装操作。rpm查询功能 rpm工具的安装功能很少使用，毕竟解决依赖关系是不是件容易的事。但是rpm的查询功能则非常实用。 123456789-q[p] -q查询已安装的包，-qp查询未安装的包。它们都可接下面的参数 -a 查询所有已安装的包，也可以指定通配符名称进行查询 -i 查询指定包的信息（版本、开发商、安装时间等）。从这里面可以查看到软件包属于哪个包组。 -l 查询包的文件列表和目录（包在生产的时候就指定了文件路径，因此可查未装包） -R 查询包的依赖性（Required） -c 查询安装后包生成的配置文件 -d 查询安装后包生成的帮助文档-f 查询系统文件属于哪个已安装的包（接的是文件而不是包）--scripts 查询包相关的脚本文档。脚本文档分四类：安装前运行、安装后运行、卸载前运行、卸载后运行 例如：(1).查询文件/etc/yum.conf是通过哪个包安装的。12[root@xuexi cdrom]# rpm -qf /etc/yum.confyum-3.2.29-60.el6.centos.noarch (2).查询安装httpd时生成了哪些目录和文件，还可以过滤出提供了哪些命令行工具。12rpm -ql httpdrpm -ql httpd | grep &apos;bin/&apos; (3).查询某个未安装包的依赖性如zip-3.0-1.el6.x86_64.rpm的依赖性。123456789101112[root@xuexi cdrom]# rpm -qRp zip-3.0-1.el6.x86_64.rpmlibc.so.6()(64bit) libc.so.6(GLIBC_2.2.5)(64bit) libc.so.6(GLIBC_2.3)(64bit) libc.so.6(GLIBC_2.3.4)(64bit) libc.so.6(GLIBC_2.4)(64bit) libc.so.6(GLIBC_2.7)(64bit) rpmlib(CompressedFileNames) &lt;= 3.0.4-1rpmlib(FileDigests) &lt;= 4.6.0-1rpmlib(PayloadFilesHavePrefix) &lt;= 4.0-1rtld(GNU_HASH) rpmlib(PayloadIsXz) &lt;= 5.2-1 实际上，查看包的依赖性时，使用yum-utils包中的repoquery工具更好，”repoquery -R pkg_name”会更简洁。yum-utils中包含了好几个非常实用的包管理工具，可以大致都了解下。 提取rpm包中文件 安装rpm包会安装rpm中所有文件，如果将某个文件删除了，除了重装rpm，还可以通过从rpm包提取缺失文件的方式来修复。在win上安装个万能压缩工具”好压”，可以直接打开rpm包，然后从中解压需要的文件出来。但是在Linux上，过程还是有点小复杂的，其中涉及了cpio这个古来的归档工具。 方法：使用rpm2cpio命令组合cpio -idv命令的方式来提取。 rpm2cpio是将rpm转换为cpio格式归档文件的命令，有了cpio文件，就可以使用cpio命令对其进行相关的操作。 cpio命令是从归档文件中提取文件或向归档文件中写入文件的工具，一般都从标准输入或输出操作归档文件，所以都使用管道或重定向符号。 1234-i： 运行在copy-in模式，即从归档文件中将文件copy出来，即提取文件（提取）-o： 运行在copy-out模式，将文件copy到归档文件中，即将文件拷贝到归档文件中（写入）-d： 需要目录时自动建立目录-v： 显示信息 提取rpm包文件的一般格式为以下格式：1rpm2cpio package_full_name|cpio -idv dir_name 例如，删除/bin/ls文件，将导致ls命令不可用，使用文件提取的方式去修复。1234567891011121314151617181920[root@xuexi cdrom]# which ls # 查找需要删除的ls文件位置alias ls=&apos;ls --color=auto&apos; /bin/ls[root@xuexi cdrom]# rpm -qf /bin/ls # 查找ls命令属于哪个包coreutils-8.4-37.el6.x86_64[root@xuexi cdrom]# rm -f /bin/ls # 删除ls命令[root@xuexi cdrom]# ls # ls命令已不可用-bash: /bin/ls: No such file or directory[root@xuexi ~]# yumdownloader coreutils # 下载所需的rpm包[root@xuexi ~]# rpm2cpio coreutils-8.4-37.el6.x86_64.rpm | cpio -id ./bin/ls # 提取bin/ls到当前目录下[root@xuexi ~]# dir ~/bin # 使用dir命令查看已经提取成功，dir命令功能等价于lsls[root@xuexi tmp]# cp bin/ls /bin/ # 复制ls命令到/bin下[root@xuexi tmp]# ls # 测试，ls已经可用 yum管理包 yum工具通过仓库的方式简化rpm包的管理。它从仓库中搜索相关的软件包，并自动下载和解决软件包的依赖性，非常方便。 /etc/yum.conf /etc/yum.conf是yum的默认文件，里面配置的也是全局默认项。 1234567891011121314[root@server2 ~]# cat /etc/yum.conf[main]cachedir=/var/cache/yum/$basearch/$releasever # 缓存目录keepcache=0 # 是否保留缓存，设置为1时，安装包时所下载的包将不会被删除debuglevel=2 # 调试信息的级别logfile=/var/log/yum.log # 日志文件位置exactarch=1 # 设置为1将只会安装和系统架构完全匹配的包obsoletes=1 # 是否允许更新旧的包gpgcheck=1 # 是否要进行gpg checkplugins=1 # 是否允许使用yum插件installonly_limit=5bugtracker_url=http://bugs.centos.org/set_project.php?project_id=23&amp;ref=http://bugs.centos.org/bug_report_page.php?category=yumdistroverpkg=centos-release # 指定基准包，yum会根据这个包判断发行版本 配置yum仓库 首先配置yum仓库，配置文件为/etc/yum.conf和/etc/yum.repos.d/中的”.repo”文件，其中/etc/yum.conf配置的是仓库的默认项，一般配置yum源都是在/etc/yum.repos.d/*.repo中配置。注意，该目录中任意repo文件都会被读取。 默认/etc/yum.repos.d/下会有以下几个仓库文件，除了CentOS-Base.repo，其他的都可以删掉，基本没用。 123[root@xuexi yum.repos.d]# ls /etc/yum.repos.d/CentOS-Base.repo CentOS-fasttrack.repo CentOS-Vault.repoCentOS-Debuginfo.repo CentOS-Media.repo repo文件的配置格式如下：12345678910111213141516[root@xuexi yum.repos.d]# vim CentOS-Base.repo[base] # 仓库ID，ID必须保证唯一性name # 仓库名称，可随意命名mirrorlist # 该地址下包含了仓库地址列表，包含一个或多个镜像站点，和baseurl使用一个就可以了#baseurl # 仓库地址。网络上的地址则写网络地址，本地地址则写本地地址，格式为“file://”后接路径，如file:///mnt/cdromgpgcheck=1 # 指定是否需要签名，1表示需要，0表示不需要gpgkey= # 签名文件的路径enable # 该仓库是否生效，enable=1表示生效，enable=0表示不生效cost= # 开销越高，优先级越低【repo配置文件中可用的宏：】$releasever：程序的版本，对Yum而言指的是redhat-relrase版本。只替换为主版本号，如Redhat6.5 则替换为6$arch：系统架构$basharch：系统基本架构，如i686，i586等的基本架构为i386$YUM0-9：在系统定义的环境变量，可以在yum中使用 repo配置示例：配置epel仓库 系统发行商在系统中放置的rpm包一般版本都较老，可能有些包有较大的延后性。而epel是由fedora社区维护的高质量高可靠性的安装源，有很多包是比系统包更新的，且多出很多系统没有的包。总之，用到epel的机会很多很多，所以就拿来当配置示例了。 有两种方式可以使用epel源。方法一：安装epel-release-noarch.rpm1shell&gt; rpm -ivh epel-release-latest-6.noarch.rpm 安装后会在/etc/yum.repo.d/目录下生成两个epel相关的repo文件，其中一个是epel.repo。此文件中epel的源设置在了fedora的镜像站点上，这对国内网来说可能会较慢，可以修改它为下面的内容。 12345678[epel]name=Extra Packages for Enterprise Linux 6 - $basearchbaseurl=http://mirrors.sohu.com/fedora-epel/6Server/$basearch/#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-6&amp;arch=$basearchfailovermethod=priorityenabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 方法二：直接增加epel仓库在/etc/yum.repos.d/下任意一个repo文件中添加上epel的仓库即可。12345[epel]name=epelbaseurl=http://mirrors.sohu.com/fedora-epel/6Server/$basearch/enabled=1gpgcheck=0 然后清除缓存再建立缓存即可。1shell&gt; yum clean all ; yum makecache yum命令不同的版本，yum命令可能功能上有所不同，例如在CentOS 7上的yum有–downloadonly的功能，而在CentOS 6.6上就没有(更新yum包后就有了)。此处介绍几个yum命令。1234567891011121314151617181920212223242526272829303132333435Usage: yum [options] COMMANDList of Commands:help 命令的帮助信息，用法：yum help command，如yum help install则查看install命令的用法说明clean 清除缓存数据，如yum clean allmakecache 生成元数据缓存数据，yum makecachedeplist 列出包的依赖关系erase 卸载包fs 为当前文件系统创建快照，或者列出或删除当前已有快照。快照是非常有用的，升级或打补丁前拍个快照，就能放心地升级或打补丁了fssnapshot 同fs一样groups 操作包组history 查看yum事务信息，yum是独占模式的进程，所以有时候查看事务信息还是有用的info 输出包或包组的信息，例如该包是谁制作的，大概是干什么用的，来源于哪个包组等信息install 包安装命令list 列出包名，一般会结合grep来搜索包，如yum list all | grep -i zabbixprovides 搜索给定的内容是谁提供的，可用来搜索来源于个包，如CentOS 7上mysql被mariadb替代，搜索Mysql提供者时就能找出包mariadbreinstall 重新安装包repolist 列出可用的仓库列表search 给定字符串搜索相关包，并给出相关包较为详细的信息update 更新包 Options: -R [minutes], --randomwait=[minutes]：最多等待时间 -q, --quiet 安静模式 -v, --verbose 详细模式 -y, --assumeyes 对所有问题回答yes --assumeno 对所有问题回答no --enablerepo=[repo] 启用一个或多个仓库，可用通配符通配仓库ID --disablerepo=[repo] 禁用一个或多个仓库，可用通配符通配仓库ID -x [package], --exclude=[package] 通配要排除的包 --nogpgcheck 禁用gpgcheck --color=COLOR 带颜色 --downloadonly 仅下载包，不安装或升级。默认下载在yum的缓存目录中，默认为/var/cache/yum/$basearch/$releasever --downloaddir=DLDIR 指定下载目录 很多时候，yum操作失败的原因是repo的配置错误，或者缓存未更新。 yum操作包组1234567[root@server2 ~]# yum help groupsLoaded plugins: fastestmirror, langpacksgroups [list|info|summary|install|upgrade|remove|mark] [GROUP]Display, or use, the groups informationaliases: group, grouplist, groupinfo, groupinstall, groupupdate, groupremove, grouperase 所以，可以使用别名group, grouplist, groupinfo, groupinstall, groupupdate, groupremove, grouperase替代相应的命令。 如安装包组yum groups install pkg_groupname，也可以yum groupinstall pkg_groupname。 源码编译安装程序源码编译的几个阶段拿到源码的压缩包后，首先就是解压，这就不需说了。解压后，进入解压目录，这是必须动作，之后就是源码编译的一般步骤。并非适用所有程序的编译，但知道过程之后也可以举一反三了。 1.阅读解压目录中的INSTALL/README文件。如果不是对着官方手册或文档，那么在安装前务必读一读INSTALL文件或README文件，只需读其中如何安装的部分即可。 2.解压后的目录里一般还有configure文件（也可能是config文件）。执行”./configure”或带有编译选项的”./configure”，检查系统环境是否符合满足安装要求，并将定义好的安装配置写入和系统环境信息写入Makefile文件中。里面包含了如何编译、启用哪些功能、安装路径等信息。 3.执行make命令进行编译。make命令会根据Makefile文件进行编译。编译工作主要是调用编译器(如gcc)将源码编译为可执行文件，通常需要一些函数库才能产生一个完整的可执行文件。 4.make install将上一步所编译的数据复制到指定的目录下。这就已经完成编译程序的过程了。 configure脚本的通用功能 configure一般都会接受以下几个编译选项： –prefix= ：指定安装的路径–sysconfdir= ：指定配置文件目录–enable-feature ：启用某个特性–disable-fecture ：禁用特性–with-function ：启用某功能–without-function ：禁用某功能 不同的程序，其configure选项不尽相同，应使用”./configure –help”获取具体的信息。 源码编译安装须知 1.上面的每一个步骤都不能出错，否则后一步都不能正常进行。 2.上面的步骤每一步如果出现警告或错误，如果步骤未停止而是继续，则属于可忽略错误或警告，不影响安装。但是进行的步骤停止了出现警告或错误，则根据步骤考虑对策。可以使用“$?”命令查看上一个命令是否正确执行，如果是返回0则是正确，其他的则是错误。 3.卸载时，只需删除安装目录即可。因此，若要便于删除，最好将源码程序安装在/usr/local/对应的目录下。例如apache2安装在/usr/local/apache2下。 4.通过源码编译的软件，需要做一些后续操作，虽非必须，但是都是个性化定制，方便以后的操作。个性化定制大致包括以下几项：(1).将安装路径下的命令路径加入到环境变量。 123shell&gt; echo &quot;export PATH=/usr/local/apache/bin:$PATH&quot; &gt; /etc/profile.d/apache.shshell&gt; chmod +x /etc/profile.d/apache.shshell&gt; source /etc/profile.d/apache.sh (2).按需求定制服务启动脚本，并考虑是否加入开机启动项。 (3).输出头文件和库文件。 头文件库文件很多时候只是为其他程序提供的，所以可能不输出它们的路径也不会影响该程序的运行。 123456# 输出头文件shell&gt; ln -s /usr/local/apache/include /usr/include/apache# 输出库文件shell&gt; echo &quot;/usr/local/apache/lib&quot; &gt;/etc/ld.so.conf.d/apache.confshell&gt; ldconfig (4).导出man路径 1shell&gt; echo &quot;MANPATH /usr/local/apache/man&quot; &gt;&gt; /etc/man.conf","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"rpm","slug":"rpm","permalink":"http://yoursite.com/tags/rpm/"}]},{"title":"如何搭建CA（向CA申请证书）","slug":"搭建CA","date":"2017-01-19T16:00:00.000Z","updated":"2018-06-13T02:36:56.404Z","comments":true,"path":"2017/01/20/搭建CA/","link":"","permalink":"http://yoursite.com/2017/01/20/搭建CA/","excerpt":"系统中搭建CACA的配置文件 vim /etc/pki/tls/openssl.cnf 默认 CA_default （可建多个） [ CA_default ] dir = /etc/pki/CA # Where everything is kept CA的工作目录","text":"系统中搭建CACA的配置文件 vim /etc/pki/tls/openssl.cnf 默认 CA_default （可建多个） [ CA_default ] dir = /etc/pki/CA # Where everything is kept CA的工作目录certs = $dir/certs # Where the issued certs are kept 存放证书的地方 crl_dir = $dir/crl # Where the issued crl are kept 证书吊销列表 database = $dir/index.txt # database index file. 存放证书信息的数据库，需要手工创建new_certs_dir = $dir/newcerts # default place for new certs. 新证书默认放此文件夹 certificate = $dir/cacert.pem # The CA certificate CA的证书文件 serial = $dir/serial # The current serial number 下一个要颁发的证书序列号（16进制数） crlnumber = $dir/crlnumber # the current crl number下一个要吊销证书的序列号 1234567crl = $dir/crl.pem # The current CRL 证书吊销列表&gt; private_key = $dir/private/cakey.pem # The private key 存放私钥&gt; RANDFILE = $dir/private/.rand # private random number file 生成随机数&gt; &gt; x509_extensions = usr_cert # The extentions to add to the cert 不关键 1234567891011policy = policy_match 策略匹配[ policy_match ]countryName = match 国家必须匹配stateOrProvinceName = match 省organizationName = match 公司名organizationalUnitName = optional （可选的） 123commonName = supplied 必须提供不能空 一般为网站名域名emailAddress = optional 邮箱可写可不写 实验：向CA申请证书 进入到CA文件夹 &gt; 1.建立RootCA 生成私钥匙(umask 077; openssl genrsa –out private/cakey.pem 4096) 2）自签名证书 openssl req -new -x509 -key private/cakey.pem -out cacert.pem -deys 3650 -new 建一个新申请 -x509 表示自签名 不加表示是普通证书 -key: 生成请求时用到的私钥文件 -days n：证书的有效期限 -out / PATH/TO/SOMECERTFILE : 证书的保存路径 CN 表示中国 beijing 省，市 查看证书里的内容 openssl x509 -in cacert.pem -noout -text 也可以传到windows里看，改成cer或crt后缀 2.用户或服务器1231）生成私钥(umask 077; openssl genrsa –out test.key –des 2048) 2）生成证书申请文件 openssl req -new -key text.pem -out text.csr .csr 申请证书文件后缀 部门可不一致前面要一致 3）将申请文件发给CA scp app.csr 192.168.30.111:/etc/pki/CA 注意：默认国家，省，公司名称三项必须和CA一致 3 .CA颁发证书touch /index.txt (不创建会提示错误) 123echo 0F(可自己指定) &gt;serialopenssl ca -in app.csr -out certs/app.crt -days 100 4.证书发送客户端scp certs/app.crt 192.168.30.6:/date (传回给申请者) 5.应用软件使证书 一个证书申请，可以申请几个证书 默认不允许 需要改这个文件 vim index.txt.attr 证书管理 查看证书中的信息： 1openssl x509 -in /PATH/FROM/CERT_FILE -noout -text|issuer|subject|serial|dates openssl ca -status 证书编号 查看指定编号的证书状态 吊销证书 在客户端获取要吊销的证书的serial openssl x509 -in / PATH/FROM/CERT_FILE -noout -serial -subject 在CA上，根据客户提交的serial与subject信息，对比检验是否与index.txt文件中的信息一致， 吊销证书：openssl ca -revoke /etc/pki/CA/newcerts/编号 .pem、 R表示已吊销 V 表示在使用 指定第一个吊销证书的编号 , 注意：第一次更新证书吊销列表前，才需要执行 e1cho 01 &gt; /etc/pki/CA/crlnumber 更新证书吊销列表o123456789penssl ca -gencrl -out /etc/pki/CA/crl.pem查看crl文件：openssl crl -in /etc/pki/CA/crl.pem -noout -text其实有脚本可以做这个事rpm -qp –s cripts /misc/cd/Packages/mod_ssl-2.4.6-67.el7.centos.x86_64.rpm","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"CA","slug":"CA","permalink":"http://yoursite.com/tags/CA/"}]},{"title":"自制一个mini 的Linux系统","slug":"自制一个mini 的Linux系统","date":"2017-01-07T16:00:00.000Z","updated":"2018-06-11T11:16:16.247Z","comments":true,"path":"2017/01/08/自制一个mini 的Linux系统/","link":"","permalink":"http://yoursite.com/2017/01/08/自制一个mini 的Linux系统/","excerpt":"步骤概略： （1）划分一块磁盘，用来装系统 （2）给硬盘划分至少两个分区，一个为boot引导分区，一个为/根分区 （3）为分区创建文件系统，并挂载到两个不同目录 （4）在挂载boot的分区创建grub引导目录 （5）复制内核vmlinux与initrd文件到boot目录下，然后根据文件编写grub下的引导配置文件 （6）创建根文件系统 （7）移植bash等命令到根目录下 （8）启动测试","text":"步骤概略： （1）划分一块磁盘，用来装系统 （2）给硬盘划分至少两个分区，一个为boot引导分区，一个为/根分区 （3）为分区创建文件系统，并挂载到两个不同目录 （4）在挂载boot的分区创建grub引导目录 （5）复制内核vmlinux与initrd文件到boot目录下，然后根据文件编写grub下的引导配置文件 （6）创建根文件系统 （7）移植bash等命令到根目录下 （8）启动测试 （一）划分磁盘 制作Linux系统，就需要有硬盘来装载它。所以我们就需要划分一块硬盘来装制作的Linux文件系统。这个硬盘不需要太大，这里我就划分一个20G的硬盘来装载它吧！先用lsblk来看看这个分区 （二）划分分区 既然是一个mini系统，那这里就给它划分两个分区吧！一个boot用来引导内核启动，一个为真正的根分区 创建分区用fdisk这个命令、 （三）创建文件系统 分区创建完成，但是想要它可以装文件就要为它创建文件系统。那就把它创建为ext4的文件系统吧！ 123mkfs -t ext4 /dev/sdb1mkfs -t ext4 /dev/sdb2 完成这两步后，分区已经创建完成。就可以把它们挂载到指定目录下了 （四）创建grub引导目录 Linux的启动需要加载内核，而内核的加载就需要grub里的配置文件来定义 grub-install –root-directory=/mnt/ /dev/sdb（这条命令就是用来生成grub引导文件的，它会根据CentOS6的内核文件来生成grub。然后把生成的文件指定到目标磁盘上） （五）复制内核与initrd到boot目录下 复制完成后就可以来编写grub下的引导配置文件了，它会根据配置文件来逐步引导各个程序的启动。如下图：1、所表示这个系统的默认的启动内核，0就是我们所制作的这个内核。2、表示如果在三秒内未指定为哪个内核，则系统就会启动默认内核。3、表示内核的名字。4、指明启动时的硬盘为哪一块硬盘。5、kernel 指明内核文件放置的相对位置，root 指明根目录的位置，selinux 表示把selinux这个安全策略关闭，init 表示我们要用的shell环境，这里我们用的是bash。 注意：编写时需要注意要把根目录的分区名更改为sda，因为当硬盘去引导系统时系统里只有一块硬盘，它会被自动识别为/dev/sda （六）创建根文件系统 启动分区准备好后就需要准备根分区了。这个分区的作用就是整个系统的真正的分区，整个系统的配置文件、数据都会放置在这个分区内。所以我们就需要在这个分区内创建目录来分别存放各个数据文件。而有些系统所必须的文件目录我们就可以在这里创建完毕。 创建目录的命令如下： cd /mnt/sysroot mkdir -pv {proc,dev,lib,bin,sbin,home,root,etc/rc.d，usr/{lib,bin,sbin},var/{log,run,lock},tmp,mnt,sys} （七）移植命令到根下 系统创建完成后还需要复制一些基本的命令到根下，如bash、ls、cat、cd、hostname、vim等以这些命令来完成某些操作，实现基本的shell环境。所以我们需要编写一个脚本完成这些命令的配置文件的复制以及所依赖的库文件的复制。 下面这个脚本就可以帮我们完成这个任务","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"mini系统","slug":"mini系统","permalink":"http://yoursite.com/tags/mini系统/"}]},{"title":"进程管理与计划任务的知识点","slug":"进程管理和计划任务的知识点()","date":"2016-12-19T16:00:00.000Z","updated":"2018-06-11T08:53:05.101Z","comments":true,"path":"2016/12/20/进程管理和计划任务的知识点()/","link":"","permalink":"http://yoursite.com/2016/12/20/进程管理和计划任务的知识点()/","excerpt":"进程概念：进程与程序的区别： 进程是一个动态的概念，具有生命期，而程序是静态的表现为一个文件，一个程序可对应多个进程","text":"进程概念：进程与程序的区别： 进程是一个动态的概念，具有生命期，而程序是静态的表现为一个文件，一个程序可对应多个进程 内核的功用： 进程管理、文件系统、网络功能、内存管理、驱动程序、安全功能等 Process: 运行中的程序的一个副本，是被载入内存的一个指令集合 进程ID（Process ID，PID）号码被用来标记各个进程 UID、GID、和SELinux语境决定对文件系统的存取和访问权限， 通常从执行进程的用户来继承 存在生命周期 task struct：Linux内核存储进程信息的数据结构格式 task list：多个任务的的task struct组成的链表 进程创建： init：第一个进程 父子关系 进程：都由其父进程创建，CoW（copy on write） fork(), clone() 进程的基本状态和转换：4 创建状态： 进程在创建时需要申请一个空白PCB(process control block进程控 制块)，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完 成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态 就绪状态： 进程已准备好，已分配到所需资源，只要分配到CPU就能够立即运行 执行状态： 进程处于就绪状态被调度后，进程进入执行状态 阻塞状态： 正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时 无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用 终止状态： 进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行 协作时多任务：进程执行完毕，释放CPU 抢占式多任务，时间片用完，必须释放CPU 状态间转换的六种情况： 运行——&gt;就绪：1，主要是进程占用CPU的时间过长，而系统分配给该进程占 用CPU的时间是有限的；2，在采用抢先式优先级调度算法的系统中,当有更高 优先级的进程要运行时，该进程就被迫让出CPU，该进程便由执行状态转变为 就绪状态。 就绪——&gt;运行：运行的进程的时间片用完，调度就转到就绪队列中选择合适 的进程分配CPU 运行——&gt;阻塞：正在执行的进程因发生某等待事件而无法执行，则进程由执 行状态变为阻塞状态，如发生了I/O请求 阻塞——&gt;就绪:进程所等待的事件已经发生，就进入就绪队列 u以下两种状态是不可能发生的： 阻塞——&gt;运行：即使给阻塞进程分配CPU，也无法执行，操作系统在进行调 度时不会从阻塞队列进行挑选，而是从就绪队列中选取 就绪——&gt;阻塞：就绪态根本就没有执行，谈不上进入阻塞态 进程优先级： 进程优先级： 系统优先级：数字越小，优先级越高 0-139（CentOS4,5） 各有140个运行队列和过期队列 0-98，99（CentOS6） 实时优先级: 99-0 值最大优先级最高 nice值：-20到19，对应系统优先级100-139或99 Big O：时间复杂度，用时和规模的关系 O(1)：随时间规模的增大，时间稳定不变 O(logn), O(n)线性, O(n^2)抛物线, O(2^n) 进程相关概念：进程内存： Page Frame: 页框，用存储页面数据，存储Page 4k LRU：Least Recently Used 近期最少使用算法,释放内存 物理地址空间和线性地址空间 MMU：Memory Management Unit负责转换线性和物理地址 (内存管理单元) TLB:Translation Lookaside Buffer 翻译后备缓冲器,用于保存虚拟地址和物理地址 映射关系的缓存 IPC: Inter Process Communication 同一主机: signal:信号 shm: shared memory （共享内存空间） semaphore:信号量，一种计数器 不同主机：socket: IP和端口号 RPC: remote procedure call （远程过程调用） MQ：消息队列，Kafka，ActiveMQ 进程状态： Linux内核：抢占式多任务 进程类型： 守护进程: daemon,在系统引导过程中启动的进程，和终端无关进程 前台进程：跟终端相关，通过终端启动的进程 注意：两者可相互转化 进程状态： 运行态：running 就绪态：ready 睡眠态： 可中断：interruptable（大部分） 不可中断：uninterruptable 停止态：stopped,暂停于内存，但不会被调度，除非手动启动 僵死态：zombie，结束进程，父进程结束前，子进程不关闭 系统管理工具： 进程的分类： CPU-Bound：CPU密集型，非交互 IO-Bound：IO密集型，交互 Linux系统状态的查看及管理工具：1pstree, ps, pidof, pgrep, top, htop, glance, pmap, vmstat, dstat, kill, pkill, job, bg, fg, nohup 12345pstree命令： pstree – display a tree of processesps: process stateps – report a snapshot of the current processes Linux系统各进程的相关信息均保存在/proc/PID目录下的各文件中 查看进程进程PS ps [OPTION]… 支持三种选项： UNIX选项 如-A -e BSD选项 如a GNU选项 如–help 选项：默认显示当前终端中的进程 a 选项包括所有终端中的进程x 选项包括不链接终端的进程 （后台进程）u 选项显示进程所有者的信息f 选项显示进程树,相当于 –forestk|–sort 属性 对属性排序,属性前加- 表示倒序o 属性… 选项显示定制的信息 pid、cmd、%cpu、%memL 显示支持的属性列表一个进程必有一个线程，也可以有多个线程 PS常见选项： -C cmdlist 指定命令，多个命令用，分隔 （查看脚本的话，要求脚本写shebang机制） -L 显示线程 -e: 显示所有进程，相当于-A -f: 显示完整格式程序信息 -F: 显示更完整格式的进程信息 -H: 以进程层级格式显示进程相关信息 -u userlist 指定有效的用户ID或名称 (euser) -U userlist 指定真正的用户ID或名称 （ruser） -g gid或groupname 指定有效的gid或组名称 -G gid或groupname 指定真正的gid或组名称 -p pid 显示指pid的进程 –ppid pid 显示属于pid的子进程 -M 显示SELinux信息，相当于Z PS输出属性： euser(有效用户) ruser（实际用户） Time ：显示的是已启动的时间 VSZ: Virtual memory SiZe，虚拟内存集，线性内存 RSS: ReSident Size, 常驻内存集 （实际内存） STAT：进程状态 R：running S: interruptable sleeping 可打断休眠 D: uninterruptable sleeping 不可打断休眠 T: stopped Z: zombie +: 前台进程 l: 多线程进程 L：内存分页并带锁 N：低优先级进程 &lt;： 高优先级进程 s: session leader，会话（子进程）发起者 PSni: nice值 (值越小，优先级越高) pri: priority 优先级(相当于下图的系统优先级的倒序)（值越大优先级越高） psr: processor CPU编号 rtprio: 实时优先级 （相当于下图realtime优先级） 示例： ps axo pid,cmd,psr,ni,pri,rtprio 常用组合： aux 查看所有进程的详细信息（更全） -ef 查看长格式的所有进程信息 -eFH -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,comm （o必在后） axostat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm（o必在后） 进程优先级： 16 进程优先级调整： 静态优先级：100-139 进程默认启动时的nice值为0，优先级为120 只有根用户才能降低nice值（提高优先性） nice命令：nice [OPTION] [COMMAND [ARG]…] 例如：nice -n -10 sleep 200 renice命令：renice [-n] priority pid… 例如：renice -n -10 2612 查看： ps axo pid,comm,ni 搜索进程： 最灵活：ps 选项 | 其它命令 按预定义的模式：pgrep 相当于 ps |grep pgrep [options] pattern （支持正则表达式） -u uid: effective user，生效者 -U uid: real user，真正发起运行命令者 -t terminal: 与指定终端相关的进程 -l: 显示进程名 -a: 显示完整格式的进程名 -P pid: 显示指定进程的子进程 按确切的程序名称：/sbin/pidof pidof bash //显示某个程序对应的进程ID系统工具 uptime 显示当前时间，系统已启动的时间、当前上线人数，系统平均负载（1、5、10分 钟的平均负载，一般不会超过1） 系统平均负载:指在特定时间间隔内运行队列中的平均进程数 通常每个CPU内核的当前活动进程数不大于3，那么系统的性能良好。如果每 个CPU内核的任务数大于5，那么此主机的性能有严重问题 如果linux主机是1个双核CPU，当Load Average 为6的时候说明机器已经被 充分使用 进程管理工具： top：有许多内置命令：（可动态跟踪进程信息） 排序： P：以占据的CPU百分比,%CPU M：占据内存百分比,%MEM T：累积占据CPU时长,TIME 首部信息显示： uptime信息：l命令 tasks及cpu信息：t命令 cpu分别显示：1 (数字) memory信息：m命令 退出命令：q 修改刷新时间间隔：s 终止指定进程：k 保存文件：W 栏位信息简介 ： us：用户空间 sy：内核空间 ni：调整nice时间 id：空闲 wa：等待IO时间 hi：硬中断 si：软中断（模式切换） st：虚拟机偷走的时间 进程管理工具：top命令也带选项 选项： -d #: 指定刷新时间间隔，默认为3秒 -b: 全部显示所有进程 -n #: 刷新多少次后退出 htop命令： EPEL源 （更高级，有颜色和提示） 选项：-d #: 指定延迟时间； -u UserName: 仅显示指定用户的进程 -s COLUME: 以指定字段进行排序 子命令： s: 跟踪选定进程的系统调用 l: 显示选定进程打开的文件列表 a：将选定的进程绑定至某指定CPU核心（临时绑定） t: 显示进程树 内存空间： 内存空间使用状态： free [OPTION] -b 以字节为单位 -m 以MB为单位 -g 以GB为单位 -h 易读格式 -o 不显示-/+buffers/cache行 -t 显示RAM + swap的总和 -s n 刷新间隔为n秒 -c n 刷新n次后即退出 echo 1 &gt; /proc/sys/vm/drop_caches //清除缓存 内存工具： vmstat命令：虚拟内存信息 vmstat [options] [delay [count]] vmstat 2 5 //2秒执行一次，执行5次 procs: r：可运行（正运行或等待运行）进程的个数，和核心数有关 b：处于不可中断睡眠态的进程个数(被阻塞的队列的长度) memory： swpd: 交换内存的使用总量 free：空闲物理内存总量 buffer：用于buffer的内存总量 cache：用于cache的内存总量 swap: si：从磁盘交换进内存的数据速率(kb/s) so：从内存交换至磁盘的数据速率(kb/s) io： bi：从块设备读入数据到系统的速率(kb/s) bo: 保存数据至块设备的速率 system： in: interrupts 中断速率，包括时钟 cs: context switch 进程切换速率 cpu： us:Time spent running non-kernel code sy: Time spent running kernel code id: Time spent idle. Linux 2.5.41前,包括IO-wait time. wa: Time spent waiting for IO. 2.5.41前，包括in idle. st: Time stolen from a virtual machine. 2.6.11前, unknown. 选项： -s: 显示内存的统计数据 内存工具 iostat:统计CPU和设备 示例：iostat 1 10 pmap命令：进程对应的内存映射 （关注进程占用的真正内存,了解进程是否正常） pmap [options] pid […] （用于检测那个进程模块出错） -x: 显示详细格式的信息 示例：pmap 1 另外一种实现： cat /proc/PID/maps //内存的具体使用情况 系统监控工具;glances命令： EPEL源 （可实现远程监控） glances [-bdehmnrsvyz1] [-B bind] [-c server] [-C conffile] [-p port] [-P password] [–password] [- t refresh] [-f file] [-o output] 常用选项： -b: 以Byte为单位显示网卡数据速率 -d: 关闭磁盘I/O模块 -f /path/to/somefile: 设定输入文件位置 -o {HTML|CSV}：输出格式 -m: 禁用mount模块 -n: 禁用网络模块 -t #: 延迟时间间隔 -1：每个CPU的相关数据单独显示 C/S模式下运行glances命令 服务器模式： glances -s -B IPADDRIPADDR: 指明监听的本机哪个地址 客户端模式： glances -c IPADDRIPADDR：要连入的服务器端地址 dstat命令： 系统资源统计,代替vmstat,iostat （带颜色，更高级） dstat [-afv] [options..] [delay [count]] -c: 显示cpu相关信息 -C #,#,…,total -d: 显示disk相关信息 -D total,sda,sdb,… -g：显示page相关统计数据 -m: 显示memory相关统计数据 -n: 显示network相关统计数据 -p: 显示process相关统计数据 -r: 显示io请求相关的统计数据 -s: 显示swapped相关的统计数据 –top-cpu：显示最占用CPU的进程 –top-io: 显示最占用io的进程 –top-mem: 显示最占用内存的进程 –top-latency: 显示延迟最大的进程 iotop命令iotop命令是一个用来监视磁盘I/O使用状况的top类工具iotop具有与top相似的UI，其 中包括PID、用户、I/O、进程等相关信息，可查看每个进程是如何使用IO iotop输出： 第一行：Read和Write速率总计 第二行：实际的Read和Write速率 第三行：参数如下： 线程ID（按p切换为进程ID）、 优先级、 用户、 磁盘读速率、 磁盘写速率、 swap交换百分比、 IO等待所占的百分比、 线程/进程命令 常用参数： -o, –only只显示正在产生I/O的进程或线程，除了传参，可以在运行过程中按o 生效 -b, –batch非交互模式，一般用来记录日志 -n NUM, –iter=NUM设置监测的次数，默认无限。在非交互模式下很有用 -d SEC, –delay=SEC设置每次监测的间隔，默认1秒，接受非整形数据例如1.1 -p PID, –pid=PID指定监测的进程/线程 -u USER, –user=USER指定监测某个用户产生的I/O -P, –processes仅显示进程，默认iotop显示所有线程 -a, –accumulated显示累积的I/O，而不是带宽 -k, –kilobytes使用kB单位，而不是对人友好的单位。在非交互模式下，脚本 编程有用 -t, –time 加上时间戳，非交互非模式 -q, –quiet 禁止头几行，非交互模式，有三种指定方式 -q 只在第一次监测时显示列名 -qq 永远不显示列名 -qqq 永远不显示I/O汇总 交互按键 left和right方向键：改变排序 r：反向排序 o：切换至选项–only p：切换至–processes选项 a：切换至–accumulated选项 q：退出 i：改变线程的优先级 进程管理工具：Kill 命令向进程发送控制信号，以实现对进程管理,每个信号对应一个数字，信号名称以SIG开头 （可省略），不区分大小写 显示当前系统可用信号： kill –l,trap -l 常用信号：man 7 signal 1) SIGHUP: 无须关闭进程而让其重读配置文件 2) SIGINT: 中止正在运行的进程；相当于Ctrl+c 3) SIGQUIT:相当于ctrl+\\ 9) SIGKILL: 强制杀死正在运行的进程 15) SIGTERM：终止正在运行的进程 18) SIGCONT：继续运行 19) SIGSTOP：后台休眠 指定信号的方法： (1) 信号的数字标识：1, 2, 9 (2) 信号完整名称：SIGHUP (3) 信号的简写名称：HUP 按PID：kill [-SIGNAL] pid … kill –n SIGNAL pid;kill –s SIGNAL pid 按名称：killall [-SIGNAL] 进程名称 //杀死所有同名的进程 按模式：pkill [options] pattern -SIGNAL -u uid: effective user，生效者 -U uid: real user，真正发起运行命令者 -t terminal: 与指定终端相关的进程 -l: 显示进程名（pgrep可用） -a: 显示完整格式的进程名（pgrep可用） -P pid: 显示指定进程的子进程 作业管理： Linux的作业控制 前台作业：通过终端启动，且启动后一直占据终端； 后台作业：可通过终端启动，但启动后即转入后台运行（释放终端） 让作业运行于后台 (1) 运行中的作业： Ctrl+z （将作业放到后台，处于休眠状态） (2) 尚未启动的作业： COMMAND &amp; （在后台运行可执行其他命令） 后台作业虽然被送往后台运行，但其依然与终端相关；退出终端，将关闭后台作业。如果希望 送往后台后，剥离与终端的关系 nohup COMMAND &amp;&gt;/dev/null &amp; （断网仍可继续执行） screen;COMMAND （解决断网不能执行问题） 查看当前终端所有作业：jobs //查看当前终端正在后台运行作业 作业控制： fg [[%]JOB_NUM]：把指定的后台作业调回前台 bg [[%]JOB_NUM]：让送往后台的作业在后台继续运行 kill [%JOB_NUM]： 终止指定的作业 17 并行执行： 同时运行多个进程，提高效率 方法1 vi all.sh f1.sh &amp; f2.sh &amp; f3.sh &amp; （将想要执行的任务放到脚本中） 方法2 (f1.sh &amp;);(f2.sh &amp;);(f3.sh &amp;) 方法3 { f1.sh &amp; f2.sh &amp; f3.sh &amp; } 任务计划：1234567891011121314Linux任务计划、周期性任务执行未来的某时间点执行一次任务 atbatch：系统自行选择空闲时间去执行此处指定的任务周期性运行某任务 cron实现同步时间（永久保存）：ntpdate 20.0.1编辑/etc/chrony.conf (centos7)service 172.20.0.1 iburstsystemctl start chronydsystemctl enabled chronyd centos6中：12345编辑/etc/ntp.confservice 172.20.0.1 iburstchkconfig ntpd onservice ntpd start at任务:(计划任务中如若有标准输出，将以邮件方式发送给对方) at命令：at [option] TIME 常用选项： -V 显示版本信息: -l: 列出指定队列中等待运行的作业；相当于atq -d: 删除指定的作业；相当于atrm -c: 查看具体作业任务 -f /path/from/somefile：从指定的文件中读取任务 -m:当任务被完成之后，将给用户发送邮件，即使没有标准输出 注意：作业执行命令的结果中的标准输出和错误以邮件通知给相关用户 TIME:定义出什么时候进行 at 这项任务的时间 HH:MM [YYYY-mm-dd] noon, midnight, teatime（4pm） tomorrow now+#{minutes,hours,days, OR weeks} at时间格式： HH:MM 02:00 在今日的 HH:MM 进行，若该时刻已过，则明天此时执行任务 HH:MM YYYY-MM-DD 02:00 2016-09-20 规定在某年某月的某一天的特殊时刻进行该项任务 HH:MM[am|pm] [Month] [Date] 04pm March 17 17:20 tomorrow HH:MM[am|pm] + number [minutes|hours|days|weeks] 在某个时间点再加几个时间后才进行该项任务 now + 5 minutes 02pm + 3 days At 任务; 执行方式： 1）交互式 2）输入重定向 3）at –f 文件 依赖与atd服务,需要启动才能实现at任务 at队列存放在/var/spool/at目录中 /etc/at.{allow,deny}控制用户是否能执行at任务 白名单：/etc/at.allow 默认不存在，只有该文件中的用户才能执行at命令 黑名单：/etc/at.deny 默认存在，拒绝该文件中用户执行at命令，而没有在 at.deny 文件中的使用者则可执行 如果两个文件都不存在，只有 root 可以执行 at 命令 注意：如果有白名单，只有白名单里的用户可执行计划任务；没有白名单，有黑名单，只有黑名单外的用户才可以执行任务；如果两个文件都不存在，只有root才可以执行任务 实验：通过脚本实现计划任务：1234567在脚本中： at 18:00 &lt;&lt;end rm –f /data/* halt End 周期性任务计划cron 相关的程序包：cronie: 主程序包，提供crond守护进程及相关辅助工具 cronie-anacron：，用于监控cronie任务执行状况，如 cronie中的任务在过去该运行的时间点未能正常运行，则anacron会随后启动一次 此任务 crontabs：包含CentOS提供系统维护任务 计划任务： 确保crond守护处于运行状态： CentOS 7: systemctl status crond CentOS 6: service crond status 计划周期性执行的任务提交给crond，到指定时间会自动运行 系统cron任务：系统维护作业 /etc/crontab 用户cron任务： crontab命令 日志：/var/log/cron 系统cron任务:/etc/crontab （普通用户不可更改该文件） 注释行以 # 开头 详情参见 man 5 crontab 18 例如： 0 2 1-5 root tar Jcvf /data/etc.tar.gz .etc/ &amp;&gt; /dev/null //实现每月的周1-5的两点对/etc/进行打包并压缩 时间表示法： (1) 特定值 给定时间点有效取值范围内的值(2) 给定时间点上有效取值范围内的所有值 表示 “每…”(3) 离散取值 #,#,#(4) 连续取值 #-#(5) 在指定时间范围上，定义步长 /#: #即为步长 /10 代表每10 分钟|天|小时|月 时间格式： @reboot Run once after reboot @yearly 0 0 1 1 * @annually 0 0 1 1 * @monthly 0 0 1 @weekly 0 0 0 @daily 0 0 * @hourly 0 系统的计划任务: /etc/crontab /etc/cron.d/ 配置文件 /etc/cron.hourly/ 脚本 /etc/cron.daily/ 脚本 /etc/cron.weekly/ 脚本 /etc/cron.monthly/ 脚本 anacron系统： 运行计算机关机时cron不运行的任务，CentOS6以后版本取消anacron服务，由 crond服务管理 对笔记本电脑、台式机、工作站、偶尔要关机的服务器及其它不一直开机的系统 很重要对很有用 配置文件：/etc/anacrontab，负责执行/etc/ cron.daily /etc/cron.weekly /etc/cron.monthly中系统任务。 字段1：如果在这些日子里没有运行这些任务……字段2：在重新引导后等待这么多分钟后运行它字段3：任务识别器，在日志文件中标识字段4：要执行的任务由/etc/cron.hourly/0anacron执行 当执行任务时，更新/var/spool/anacron/cron.daily 文件的时间戳 管理临时文件： CentOS6使用/etc/cron.daily/tmpwatch定时清除临时文件 CentOS7使用systemd-tmpfiles-setup服务实现 配置文件： /etc/tmpfiles.d/*.conf /run/tmpfiles.d/*.conf /usr/lib/tmpfiles/*.conf /usr/lib/tmpfiles.d/tmp.conf d /tmp 1777 root root 10d d /var/tmp 1777 root root 30d 命令： systemd-tmpfiles –clean|remove|create configfile 用户计划任务： crontab命令定义 每个用户都有专用的cron任务文件： /var/spool/cron/USERNAME crontab命令： crontab [-u user] [-l | -r | -e] [-i] -l: 列出所有任务 -e: 编辑任务 -r: 移除所有任务 -i：同-r一同使用，以交互式模式移除指定任务 -u user: 仅root可运行，指定用户管理cron任务 控制用户执行计划任务： /etc/cron.{allow,deny} at和crontab: 一次性作业使用 at 重复性作业使用crontab 没有被重定向的输出会被邮寄给用户 根用户能够修改其它用户的作业 注意：运行结果的标准输出和错误以邮件通知给相关用户 (1) COMMAND &gt; /dev/null (2) COMMAND &amp;&gt; /dev/null 对于cron任务来讲，%有特殊用途；如果在命令中要使用%，则需要转义，将% 放置于单引号中，则可不用转义 usleep 可精确到微秒 实验：循环重启的解救办法（语法错误@reboot root reboot解决方案） centos7 按e键，进入单用户救援 boot menu kernel e linux16行最后 加 rd.break ctrl+x mount -o remount,rw /sysroot vim /sysroot/etc/crontab 删除@reboot root reboot centos6 a 加 空格 1 enter vim /sysroot/etc/crontab 删除@reboot root reboot init 5","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"进程管理、计划任务","slug":"进程管理、计划任务","permalink":"http://yoursite.com/tags/进程管理、计划任务/"}]},{"title":"TCP、IP协议三次握手与四次握手流程解析","slug":"TCP、IP协议三次握手与四次握手流程解析（）","date":"2016-12-07T16:00:00.000Z","updated":"2018-06-10T13:41:41.373Z","comments":true,"path":"2016/12/08/TCP、IP协议三次握手与四次握手流程解析（）/","link":"","permalink":"http://yoursite.com/2016/12/08/TCP、IP协议三次握手与四次握手流程解析（）/","excerpt":"一、TCP报文格式TCP/IP协议的详细信息参看《TCP/IP协议详解》三卷本。下面是TCP报文格式图： 图1","text":"一、TCP报文格式TCP/IP协议的详细信息参看《TCP/IP协议详解》三卷本。下面是TCP报文格式图： 图1 TCP报文格式上图中有几个字段需要重点介绍下：（1）序号：Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。（2）确认序号：Ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，Ack=Seq+1。（3）标志位：共6个，即URG、ACK、PSH、RST、SYN、FIN等，具体含义如下：（A）URG：紧急指针（urgent pointer）有效。（B）ACK：确认序号有效。（C）PSH：接收方应该尽快将这个报文交给应用层 。（D）RST：重置连接。（E）SYN：发起一个新连接。（F）FIN：释放一个连接。 需要注意的是：（A）不要将确认序号Ack与标志位中的ACK搞混了。（B）确认方Ack=发起方Req+1，两端配对。 ##### 二、三次握手所谓三次握手 （Three-Way Handshake）即建立TCP连接，就是指建立一个TCP连接时，需要客户端和服务端总共发送3个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发，整个流程如下图所示： 图2 TCP三次握手（1）第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。（2）第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。（3）第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 SYN攻击：在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。 SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行： #netstat -nap | grep SYN_RECV ### 三、四次挥手三次握手耳熟能详，四次挥手估计就，所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发，整个流程如下图所示： 图3 TCP四次挥手由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭，上图描述的即是如此。 （1）第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。（2）第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。（3）第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。（4）第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。 上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况，具体流程如下图： 图4 同时挥手流程和状态在上图中已经很明了了，在此不再赘述，可以参考前面的四次挥手解析步骤。 四、附注关于三次握手与四次挥手通常都会有典型的面试题，在此提出供有需求的XDJM们参考： 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://yoursite.com/tags/TCP-IP/"}]},{"title":"Linux 的一些基础练习题","slug":"Linux 的一些基础练习题","date":"2016-11-28T16:00:00.000Z","updated":"2018-06-10T13:16:34.982Z","comments":true,"path":"2016/11/29/Linux 的一些基础练习题/","link":"","permalink":"http://yoursite.com/2016/11/29/Linux 的一些基础练习题/","excerpt":"练习题：1，显示当前时间，格式为：2016-06-18 10:20:30 答案：date “+%F,%T” 或者 date “+%F %H:%M:%S” 2，显示前天是星期几？ 答案：date -d “-2 day” +%A 知识点：一 ，date +%s 是把当前时间转化为秒数 二， date -d @”1523604170″ 把秒数转化回来","text":"练习题：1，显示当前时间，格式为：2016-06-18 10:20:30 答案：date “+%F,%T” 或者 date “+%F %H:%M:%S” 2，显示前天是星期几？ 答案：date -d “-2 day” +%A 知识点：一 ，date +%s 是把当前时间转化为秒数 二， date -d @”1523604170″ 把秒数转化回来 3，今天18:30自动关机，并提示用户。 答案：hutdown -h 18:30 “dao dian guan ji，18:30” 如果想取消此操作输入： shutdown -c 4，在本机字符终端登录时，除显示原有信息外，在显示当前登录终端号，主机名和当前时间。 答案：vim /etc/profile.d/kaiji.sh 进去后输入：#**echo your hostname is hostnamewho am i 5，显示/var目录下所有以l开头，以一个小写字母结尾，且中间出现至少一位数字的文件或目录。 答案：ls /var/l[0-9][[:lower:]] 6，显示/etc目录下以任意一位数字开头，且以非数字结尾的文件或目录。 答案：ls /etc/[0-9]*[^0-9] 7，显示/etc/目录下以非字母开头，后面跟了一个字母及其他任意长度任意字符的文件或目录。 答案：ls /etc/[^[:alpha:]][a-zA-Z]* 8，显示/etc/目录下所有以rc开头，并后面是0-6之间的数字，其他为任意字符的文件或目录。 答案：ls /etc/rc[0-6]* 9，显示/etc目录下，所有以.d结尾的文件或目录。 答案：ls /etc/*.d 10，显示/etc目录下，所有.conf结尾，且以m,n,r,p开头的文件或目录。 答案：ls /etc/[m,n,r,p]*.conf 11，只显示/root下的隐藏文件和目录。 只显示/etc下的非隐藏目录 答案：ls -d /root/. ls /etc/[^.]/ -d 12，定义别名命令baketc,每天将/etc/目录下的所有文件，备份到/app独立的子目录下，并要求子目录格式为backupYYYY-mm-dd备份过程可见。 答案：alias baketc=”cp -av /etc /data/backupdate +%F” 13，创建/app/rootdir目录，并复制/root下所有文件到该目录内，要求保留原有权限。 答案：mkdir -p /app/rootdir cp -a /root /app/rootdir/ 14，如何创建/testdir/dir1/x,/testdir/dir/y,/testdir/dir/x/a,/testdir/dir/x/b,/testdir/dir/y/a,/testdir/dir/y/b. 答案：mkdir -p /testdir/dir1/{x,y}/{a,b} 15，如何创建/testdir/dir2/x,/testdir/dir2/y,/testdir/dir2/x/a,/testdir/dir2/x/b. 答案：mkdir -p /testdir/dir2/{x/{a,b},y} 16，如何创建/testdir/dir3,/testdir/dir4,/testdir/dir5,/testdir/dir5/dir6,/testdir/dir5/dir7. 答案：mkdir -p /testdir/{dir3,dir4,dir5/{dir6,dir7}} 17，将/etc/issue文件中的内容转化为大写后保存至/tmp/issue.out文件中。 答案：cat /etc/issue | tr “[a-z]” “[A-Z]” &gt; /tmp/issue.out 18，将当前系统登录用户的信息转换为大写后保存至/tmp/who.out文件中。 答案：who | tr “[a-z]” “[A-Z]” &gt;/tmp/who.out 19，一个linux用户给root发邮件，要求邮件标题为” help”,邮件正文如下：Heello,i am 用户名，The system version is here ,please help me to check it,thanks! 操作系统版本信息 答案：mail -s “help” root &lt;&lt;123 Hello,I am $USERThe system version is here,please help me to check it,thanks!cat /etc/centos-release123 20,将/root/下文件列表，显示成一行，并文件名之间用空格隔开。 答案：ls /root | tr “\\n” ” ” 21，计算1+2+3+..+99+100的总和。 答案：echo {1..100}|tr ” ” “+”|bc 22，删除Windows文本文件中的^M字符 答案：tr -d “\\15” win.txt 23，处理字符串 “xt.,l 1 jr#!$mn 2 c*/fe 3 uz 4” ,只保留其中的数字和空格。 答案：echo “xt.,l 1 jr#hostnamemn 2 c*/fe 3 uz 4” |tr -dc “[:digit:][:space:]” 24,将PATH变量每个目录显示在独立的一行。 答案：echo $PATH |tr “:” “\\n” 25，将指定文件中0-9分别代替成a-j . 答案：先创建文件touch f1 给f1 vim 输入0-9 cat f1 | tr “[0-9]” “[a-j]” 26，将文件/etc/centos-release中每个单词（由字母组成）显示在独立的一行，并无空行。 答案：cat /etc/centos-release |tr -c “[:alpha:]” ” ” |tr -s ” ” “\\n” 27，创建用户gentoo,附加组为bin和root,默认shell为/bin/csh,注释信息为”Gentoo Distribution”. 答案：useradd -G bin,root -s /bin/csh -c “Gentoo Distribution” gentoo 28，创建下面的用户，组和组成员关系名字为webs的组 用户nginx使用webs作为附加组 用户varnish,也使用webs作为附加组用户mysql,不可交互登录系统，且不是webs的成员，nbinx,varnish,mysql密码都是magedu 答案：12345678groupadd webs useradd -G webs nginx useradd -G webs varnish useradd -s /sbin/nologin masql echo magedu |passwd –stdin nginx; echo magedu |passwd –stdin varnish; echo magedu |passwd –stdin mysql; 29，当用户docker对/testdir 目录无执行权限时，意味着无法做哪些操作？ 答案： 不能cd进去，不能查看文件详细属性，也不能去访问目录里的文件内容（即使有读权限）。 30，当用户mongodb对/testdir 目录无读权限时，意味着无法做哪些操作？ 答案：不能对目录下的文件进行访问。 31， 当用户redis 对/testdir 目录无写权限时，该目录下的只读文件file1是否可修改和删除？ 答案：不能，因为对目录没有权限，所以不能。文件能不能删，不由文件决定，而由目录决定。 32，当用户zabbix对/testdir 目录有写和执行权限时，该目录下的只读文件file1是否可修改和删除？ 答案：可以修改和删除 33，复制/etc/fstab 文件到/var/tmp 下，设置文件所有者为tomcat 读写权限，所属组为apps组有读写权限，其他人无权限。 123456答案：（一）cp -a /etc/fstab /var/tmp （二） useradd tomcat （三） groupadd apps （四） chown tomcat /var/tmp （五） chgrp apps /var/tmp （六） chmod 660 /var/tmp 34，误删除了用户git的家目录，请重建并恢复该用户家目录及相应的权限属性。 1234答案： rm -rf /home/git ; mkdir /home/git; cp -a /etc/skel/.[^.]* /home/git; chown -R git:git /home/git; 35,在/testdir/dir 里创建的新文件自动属于webs组，组apps的成员如:tomcat能对这些新文件有读写权限，组dbs的成员如：mysql只能对新文件有读权限，其他用户（不属于webs,apps,dbs）不能访问文件夹。 1234567答案： mkdir -p /testdir/dir chgrp webs /testdir/dir chmod g=s /testdir/dir setfacl -m g:apps:rw /testdir/dir setfacl -m g:dbs:r /testdir/dir chmod o= /testdir/dir 36，备份/testdir/dir 里所有文件的ACL权限到/root/acl.txt中，清除/testdir/dir中所有ACL权限，最后还原ACL权限。 123答案： getfacl -R /testdir/dir &gt; /root/acl.txt setfacl -b /testdir/dir setfacl -R –set-file=acl.txt /testdir/dir 37, 找出ifconfig “网卡名” 命令结果中本机的IPv4地址。 12345答案：（方法一）ifconfig ens33 | grep netmask | tr -s ” ” “:” |cut -d: -f3（方法二）ifconfig ens33 |egrep -o \\&lt;“(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])”\\&gt;（方法三）ifconfig ens33 | sed -n “2p” | sed -r s’@(.*inet)(.*)( netmask.*)@\\2@’ 38，查出分区空间使用率的最大百分比值。 123答案：（方法一）df | grep ^/dev | tr -s ” ” “:” | cut -d: -f5 |cut -d% -f1 | sort -nr | head -n1（方法二） df | grep -o “[0-9]\\&#123;1,3\\&#125;%” |grep -o “[0-9]\\+” |sort -nr |head -n1 39，查出用户UID最大值得用户名，UID及shell类型。 1答案：cat /etc/passwd |sort -nr -t: -k3 |head -n1 |cut -d: -f1,3,7 40，查出/tmp的权限，以数字方式显示 1答案：stat /tmp |head -n4|tail -n1|cut -d/ -f1|cut -d&apos;(‘ -f2 41， 统计当前连接本机的每个远程主机IP的连接数，并从大到小排序。 12答案： 先从桌面获取rz 获取文件，再进行处理。 cat access_log |egrep -o “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;”|sort|uniq -dc|sort -nr 42,显示/proc/meminfo 文件中以大小s开头的行（要求：使用两种方法） 123答案：（方法一）cat /proc/meminfo |egrep -oi ^s.*（方法二）cat /proc/meminfo |egrep ^[Ss].* 43，显示/etc/passwd文件中不以/bin/bash结尾的行。 1答案：cat /etc/passwd |egrep -v /bin/bash$ 44，显示用户rpc默认的shell程序。 123答案：（方法一）cat /etc/passwd |egrep rpc|cut -d: -f1,7（方法二）cat /etc/passwd |egrep rpc|sed -r ‘s/(.*:)([^:]+:?$)/\\2/’ 45，找出/etc/passwd 中的两位或三位数 1答案：cat /etc/passwd | egrep -o “[0-9]&#123;2,3&#125;” 46，显示Centos7的/etc/grub2.cfg文件中，至少以一个空白字符开头的且后面有非空白字符的行。 1答案：cat /etc/grub2.cfg |egrep ^[[:space:]][^[:space:]].*$ 47，找出”netstat -tan” 命令结果中以LISTEN后跟任意多个空白字符结尾的行。 1答案：netstat -tan |egrep .*LISTEN[[:space:]]+ 48, 显示Centos7上所有系统用户的用户名和UID。 1答案：cat /etc/passwd |egrep .*/sbin/nologin$ |cut -d: -f1,3 49，添加用户bash,testbash,basher,sh,nologin(其shell为/sbin/nologin),找出/etc/passwd用户名和shell同名的行。 1答案：cat /etc/passwd | egrep “^(.*)(:.*)\\1$” 50，利用df和grep，去出磁盘各分区利用率，并从大到小排序。 1答案：df |grep ^/dev |tr -s ” ” “:”|cut -d: -f5 |cut -d% -f1 |sort -nr|head -n1 51，显示三个用户root,mage,wang的UID和默认shell. 1答案：cat /etc/passwd |egrep ^”(root|mage|wang)” |cut -d: -f1,3,7 52，找出/etc/rc.d/init.d/functions文件中行首为某单词（包括下划线）后面跟一个小括号的行。 1答案：cat /etc/rc.d/init.d/functions | egrep “^[a-zA-Z_]+.*” 53，使用egrep取出/etc/rc.d/init.d/functions中其基名。 1答案：echo /etc/rc.d/init.d/functions |egrep -o “[^/]*/?$” 54，使用egrep取出上面 路径的目录名。 123答案：（方法一）echo /etc/rc.d/init.d/functions |egrep -o “/.*/”（方法二）echo /etc/rc.d/init.d/functions |egrep -o “(/).*\\1” 55，统计last命令中以root登录的每个主机IP地址登录次数。 1答案： last |egrep root |egrep “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;”|tr -s ” ” “:”|sort -t: -k3|cut -d: -f3|uniq -dc 56，利用扩展正则表达式分别表示0-9,10-99，100-199,200-249,250-255. 1答案： [0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5] 57,显示ifconfig命令结果中所有IPV4地址。 1答案： ifconfig | egrep -o “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;” 58，将此字符串：welcome to magedu linux 中的每个字符去重并排序，重复次数多的放在最前面。 1答案： echo “welcometomagedulinux” |grep -o “.”|sort|uniq -c|sort -nr 59，复制/etc/profile至/tmp/目录，用查找替换命令删除/tmp/profile文件中的行首的空白字符。 12345答案：cp /etc/profile /tmp/ vim /tmp/profile 命令模式下按“:”进入扩展模式输入 %s/^[[:space:]]*//g 60, 复制/etc/rc.d/init.d/functions文件至/tmp目录，用查找替换命令为/tmp/functions的每行开头为空白字符的行的行首添加一个#号。 1234567答案： cp /etc/rc.d/init.d/functions /tmp vim /tmp/functions 命令模式下按“:”进入扩展模式输入 %s/^[[:space:]] */#&amp;/ 或者 %s/[[:space:]]\\+.∗[[:space:]]\\+.∗/#\\1/g 61, 在VIM中设置tab缩进为4个字符。 1234567答案： vim /etc/vimrc 在文件最后添加： set ts=4 set expandtab set autoindent :wq 62，复制/etc/rc.d/init.d/functions文件至/tmp目录，替换/tmp/functions文件中的/etc/sysconfig/init为/var/log. 答案：cp /etc/rc.d/init.d/functions /tmpvim /tmp/functions命令模式下按“:”进入扩展模式输入 %s@\\/etc\\/sysconfig\\/init@\\/var\\/log@ 63, 删除/tmp/functions文件中所有以#开头，且#后面至少有一个空白字符的行的行首的#号。 答案：vim /tmp/functions命令模式下按“:”进入扩展模式输入%s@^#”“+.∗”“+.∗@\\1@ 64, 编写脚本/root/bin/systeminfo.sh,显示当前主机系统信息，包括主机名，IPV4，操作系统版本，内核版本，CPU型号，内存大小，硬盘大小。 答案： vim /root/bin/systeminfo.sh #** echo hostnameecho ifconfig ens33 | egrep -o “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]).){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])>“|head -n1 echo cat /etc/centos-release echo uname -r echo lscpu |grep “^Model name.*” |cut -d: -f2|tr -s “ “ echo cat /proc/meminfo |head -n1 echo lsblk |grep ‘^sda’|tr -s “ “ “%”|cut -d% -f4 :wq 65, 编写脚本/root/bin/backup.sh,可实现每日将/etc/目录备份到/root/etcYYY-mm-dd中。 vim /root/bin/backup.shcp -a /etc /root/etcdate +%F:wq 66,编写脚本/root/bin/disk.sh,显示当前硬盘分区中空间利用率最大的值。 答案： e=df|egrep ^/dev |tr -s “ “ “:”|cut -d: -f5|cut -d% -f1|sort -nr|head -n1 echo $e ：wq 67, 编写脚本/root/bin/links.sh ，显示正连接本主机的每个远程主机的IPV4地址和连接数，并按连接数从大到小排序。 答案： vim /root/bin/linsk.sh a=cat access_log |egrep -o &quot;\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;&quot;|sort|uniq -c|sort -nr echo $a 68, 编写脚本/root/bin/sumid.sh ,计算/etc/passwd 文件中的第10个用户和第20用户的ID之和。 答案：vim /root/bin/sumid.sha=cat /etc/passwd | head -n10 |tail -n1|cut -d: -f3 b=cat /etc/passwd | head -n20 |tail -n1|cut -d: -f3 let c=a+b 或 d=$[ a+b ] echo $d 69, 编写脚本/root/bin/sumspace.sh ,传递两个文件路径作为参数给脚本，计算这两个文件中所有空白行之和。 12345答案： vim /root/bin/sumspace.sh a=cat f1 |egrep ^[[:space:]]*$ |wc -l b=cat f2 |egrep ^[[:space:]]*$ |wc -l let c=a+b 70, 编写脚本/root/bin/sumfile.sh ,统计/etc ,/var,/usr 目录中共有多少个一级子目录和文件。 答案：vim /root/bin/sumfile.sha=ls /etc/ |wc -lb=ls /var/ |wc -l c=ls /usr/ |wc -llet d=a+b+c 71, 编写脚本/root/bin/argsnum.sh ,接受一个文件路径作为参数；如果参数个数小于1，则提示用户 “至少应该给一个参数”，并立即退出；如果参数个数不少于1，则显示第一个参数所指向的文件中的空白行数。 答案：vim /root/bin/argsnum.sh [ $# -lt 1] &amp;&amp; echo “At least one parameter should be given” &amp;&amp; exit[ $# -ge 1] &amp;&amp; echo egrep “^[[:space:]]*$” $1|wc -l 73, 编写脚本/root/bin/hostping.sh ,接受一个主机的IPV4地址做为参数，测试是否可连通。如果能ping通，则提示用户 “该IP地址可以访问” ；如果不可ping通，则提示用户 “该IP地址不可访问”。 答案：vim /root/bin/hostping.sh [[ $1 =~ “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]]]).){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])>” ]] || echo { “IP error”;exit; } ping $1 &amp;&amp; echo “This address can be accessed”|| echo “This address cannot be accessed” 74, 编写脚本/root/bin/checkdisk.sh , 检查磁盘分区空间和inode使用率，如果超过80%，就发广播警告空间将满。 答案：vim /root/bin/checkdisk.sh a=df |egrep ^/dev |tr -s “ “ “:” |cut -d: -f5 |cut -d% -f1|sort -nr|head -n1[[ $a -ge 80 ]] &amp;&amp; echo “zhao huo la ” || echo { “yi qie zheng chang”;exit; } 75, 编写脚本/bin/per.sh ,判断当前用户对指定参数文件，是否不可读并且不可写。 答案：[ -not -r $1 -a -not -w $1 ] &amp;&amp; echo “bu ke du ”[ −r$1−o−w$1−r$1−o−w$1 ] || echo “ke du ” 76，编写脚本/root/bin/excute.sh ,判断参数文件是否为sh后缀的普通文件，如果是，添加所有人可执行权限，否则提示用户非脚本文件。 答案：vim /root/bin/excute.sh[[ $1 =~ .*sh$ ]] &amp;&amp; chmod +x $1 || echo “bu shi jiao ben wen jian “","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"练习题","slug":"练习题","permalink":"http://yoursite.com/tags/练习题/"}]},{"title":"对正则表达式，VIM编辑器命令的基本操作","slug":"对正则表达式，VIM编辑器命令的基本操作（三）","date":"2016-11-22T16:00:00.000Z","updated":"2018-06-10T12:02:01.688Z","comments":true,"path":"2016/11/23/对正则表达式，VIM编辑器命令的基本操作（三）/","link":"","permalink":"http://yoursite.com/2016/11/23/对正则表达式，VIM编辑器命令的基本操作（三）/","excerpt":"正则表达式 正则表达式（REGEXP）是由一类特殊字符和文本字符所编写的模式，其中有些字符（元字符）不表示字符字面的意义，而表示控制或通配的功能。分为两类： 基本正则表达式：BRE 扩展正则表达式： ERE元字符分类：字符匹配，匹配次数，位置锚定，分组。 ###### # 字符匹配： · 表示匹配的单个字符 . 转义，表示（·）的字符本意【】 表示匹配指定范围内的任意单个字符，【】里的·表示本意，不用转义【托字符】 表示匹配指定范围外的任意单个字符【:alnum：】 字母和数字 【:alpha：】 代表任何英文大小写字符【:lower:】 小写字母 【:upper：】 大写字母【:blank：】 空白字符 【:space：】 水平和垂直的空白字符（比blank范围大）【:punct：】 标点符号","text":"正则表达式 正则表达式（REGEXP）是由一类特殊字符和文本字符所编写的模式，其中有些字符（元字符）不表示字符字面的意义，而表示控制或通配的功能。分为两类： 基本正则表达式：BRE 扩展正则表达式： ERE元字符分类：字符匹配，匹配次数，位置锚定，分组。 ###### # 字符匹配： · 表示匹配的单个字符 . 转义，表示（·）的字符本意【】 表示匹配指定范围内的任意单个字符，【】里的·表示本意，不用转义【托字符】 表示匹配指定范围外的任意单个字符【:alnum：】 字母和数字 【:alpha：】 代表任何英文大小写字符【:lower:】 小写字母 【:upper：】 大写字母【:blank：】 空白字符 【:space：】 水平和垂直的空白字符（比blank范围大）【:punct：】 标点符号 匹配次数： 用于在要指定次数的字符后面，是表示前面字符出现的次数。 * 表示匹配前面的字符重复的次数，包括0次·* 任意长度的任意字符\\? 匹配前面的字符0次或1次+ 匹配前面的字符至少1次{n} 匹配前面的字n次，是指定m次{n,m} 匹配前面的字符最少n次，最多m次{,n} 匹配前面的字符最多n次{n,} 匹配前面的字符最多n次 位置锚定： 定位出现的位置。 ^ 行首锚定，用于模式的最左侧$ 行尾锚定，用于模式的最右侧> 词尾锚定，用于单词模式的最右侧\\&lt; 词首锚定，用于单词模式的最左侧\\b 单词的边界 分组： 将一个或多个字符捆绑在一起，当做一个整体进行处理。 二 VIM的基本命令操作VIM 的文本编辑器 +# 打开文件后，让光标处于第#的行首-d 可以比较多个文件-m 只读的方式打开文件，避免误操作-e 进入ex模式（编辑模式）三种主要模式命令模式：默认模式插入模式：编辑模式扩展命令模式：ex模式 可以让命令模式进入插入模式的，按ESC退出的一些操作： 按 i 光标不懂按 I 光标移动到行首按 a 光标往后移动一个字符按 A 光标移动到本行的行尾按 o 在光标下行切换新行按 O 在光标上行切换新行在命令模式下按： 就进入ex模式了 在ex模式下： Wq 存盘退出 q 退出Q! 强行退出，修改的不算W 空格 跟文件 就可以把VIM的内容传送到文件R 空格 跟文件 就可以把文件的内容读入VIM 在命令模式下的一些常用的用法： 字符间的跳动： h 左 l 右 j 下 k 上 前面加上数字# ，配合其他按键进行跳动单词间的跳动： w 跳动到下一个单词的词首e 跳动到下一个单词的词尾b 跳动到前一个单词的词首也可以配合#进行跳动当前页面跳动： H 跳动到当前页面的页首M 跳动到当前页面的中间L 跳动到当前页面的页底 行首行尾的跳动： ^ 跳转至行首的第一个非空白字符0 跳转至行首$ 跳转至行尾 行间移动： G 直接跳动到整个文件的最后一行gg 直接跳动到整个文件的第一行一些快捷键： ctrl +f 向文件尾部翻一页Ctrl+b 向文件首部翻一页Ctrl+d 向文件尾部翻半页Ctrl+u 向文件首部翻半页命令模式的字符编辑： x 删除（剪切）光标处的字符 #x 前面加上数字，表示删除几个字符Xp 交换光标处字符跟后面字符的位置J 删除当前行后的换行符~ 转换大小写 替换命令： r 替换光标所在处的字符R 切换成REPLACE 模式，批量替换字符删除命令： d 删除字符，可以结合光标跳转字符实现范围删除d$ 删除到行尾d^ 删除到非空白字符行首d0 删除到行首，不包括光标处dd 删除光标所在行 （配合数字批量删除）D 从当前光标处一直删除到行尾 复制命令： （复制完可以按P粘贴）y 复制y$ 复制到行尾y0 复制到行首y^ 复制到非空白字符行首yy 复制光标所在行 #yy 配合数字实行多行复制Y 复制整行改变命令： c 修改后切换成插入模式，配合d进行相应操作 100i wang [esc] 粘贴wang 100次 复制wang 100次 扩展命令模式： （ex）模式地址定界： ：# 输入数字几，跳到第几行 #，#：从第几行到第几行，后配合相应命令· 表示当前行$ 表示最后一行% 表示全文件内容S 在扩展模式下完成查找替换操作格式: s/要查找的内容/替换为的内容/修改符修改符： i 忽略大小写g 修改的全局替换（默认情况只替换每行第一次改的）gc 全局替换时每次前询问 命令模式下： （小写）u 撤销 #u 撤销之前多次修改（大写）U 撤销光标落在此行后所有的更改按ctrl -r 重做最后撤销的更改（倒回去） · 重做前一个操作n. 重做前一个操作N次 VIM的寄存器 有26个命名的寄存器 （可以在不同窗口进行）名称以a b c ….z 来表示格式： 寄存器放在数字和命令之间如： “ ayy 表示把当前光标所在行复制到a寄存器“ap 表示把a寄存器的内容粘贴 VIM “F1 F2”一次处理多个文件 刚进去默认在第一个文件：next 下一个: prev 前一个: qall 退出所有: wqall 保存退出所有 VIM 使用多个窗口 VIM -o 上下分屏VIM-O 左右分屏在窗口间来回切换 ctrl+w完成后 wqall 在VIM里加行号 显示 set nu取消 set nonu要想行号永久有效，必须保存配置文件：（用VIM改）全局：/etc/vimrc 个人：~/.vimrc 在VIM里设置文本宽 启用 set textwidth =65禁用 set wrapmargin =15 在VIM里设置光标所在的标识线 启用 set cursorline (cul)禁用 set no cul 更详细用法请查：VIM help","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"基本命令","slug":"基本命令","permalink":"http://yoursite.com/tags/基本命令/"}]}]}