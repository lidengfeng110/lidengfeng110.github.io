{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"","slug":"Nginx 各种实验演示","date":"2018-08-09T07:55:09.765Z","updated":"2018-08-09T07:54:57.733Z","comments":true,"path":"2018/08/09/Nginx 各种实验演示/","link":"","permalink":"http://yoursite.com/2018/08/09/Nginx 各种实验演示/","excerpt":"layout: posttitle: Nginx 各种实验演示date: 2017-8-02tags: Linux nginx 实验：Nginx 实现 SSL 加密要实现 SSL 加密首先在服务器上生成证书，如：创建 CA 第一种方法： cd /etc/pki/CA(umask 077;openssl genrsa -out private/cakey.pem 2048)openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650 然后输入一些地区单位信息等，如： CN beijing beijing magedu opt www.a.com 这样 CA 的自签名证书就创建好了，还要创建两个文件 touch serial index.txtecho 01 &gt; serial 接下来为 nginx 向 CA 申请证书 cd /etc/nginx/mkdir sslcd ssl(umask 077;openssl genrsa -out nginx.key 1024)openssl req -new -key nginx.key -out nginx.csr 然后输入一些地区单位信息等，如： CN beijing beijing magedu opt www.a.com","text":"layout: posttitle: Nginx 各种实验演示date: 2017-8-02tags: Linux nginx 实验：Nginx 实现 SSL 加密要实现 SSL 加密首先在服务器上生成证书，如：创建 CA 第一种方法： cd /etc/pki/CA(umask 077;openssl genrsa -out private/cakey.pem 2048)openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650 然后输入一些地区单位信息等，如： CN beijing beijing magedu opt www.a.com 这样 CA 的自签名证书就创建好了，还要创建两个文件 touch serial index.txtecho 01 &gt; serial 接下来为 nginx 向 CA 申请证书 cd /etc/nginx/mkdir sslcd ssl(umask 077;openssl genrsa -out nginx.key 1024)openssl req -new -key nginx.key -out nginx.csr 然后输入一些地区单位信息等，如： CN beijing beijing magedu opt www.a.com接下来 ca 颁发证书openssl ca -in nginx.csr -out nginx.crt -days 3655这样就生成 nginx 证书 创建 CA 第二种方法：cd /etc/pki/tls/certsmake a.crt接下来会让输入口令，这个口令是给私钥加的口令，这个口令加上后， nginx 服务启动时自动起不来了，输完口令才能起来，为了方便操作，也可以在这先加上，到后面在取消。然后输入一些地区单位信息等，如： CNbeijingbeijingmageduoptwww.a.com这时候就在当前目录下生成两个文件，一个私钥文件，一个自签名证书文件，如： a.key , a.crt如果在前面给私钥加了密，现在就可以给解下密，如：openssl rsa -in a.key -out aa.key 生成的这个 aa.key 跟原来一样就是不加密了接下来就可以把 生成的文件复制到 nginx 的配置文件目录下cp a.crt aa.key /etc/nginx/conf.d/cd /etc/nginx/conf.d/为了好看，可以把 aa.key 文件名在改过来。mv aa.key a.key 然后在当前目录下创建配置文件，vim vhosts.conf 12345678910server &#123; listen 443 ssl; server_name www.a.com; root /data/sitea/; # 这个目录表示 url 的根目录 ssl on; ssl_certificate /etc/nginx/conf.d/a.crt; ssl_certificate_key /etc/nginx/conf.d/a..key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; &#125; 接下来重启服务 nginx就会发现端口 443 已经开启然后就可以在远程服务器上进行测试连接了在远程服务器上 curl -k https:// www.a.com也可以在浏览器上输入 IP 进行访问，如果要在浏览器上输入网址，就还得 DNS 解析才行。在浏览器上输入 https:// www.a.com当然这个证书是没有可信度的，在具体生产中要想实现 https ，那就花钱买正规证书，然后把放在对应的目录下就可以了。这就是 SSL 的实现 实验：在一台 Nginx 服务器上实现搭建多个加密网站在 apache 上要想在一台物理服务器上实现多个 https 的虚拟主机网站是不行的，但是在 nginx 上是可以实现的，因为 nginx 上支持 SNI 技术，所谓的 SNI 技术表示服务器的名称扩展，这个技术就可以让我们在一台物理服务器上实现多个 https 的网站。 那么现在来实现以下在一台服务器上实现多个加密的网站。比如： www.a.com www.b.com首先准备两个证书，过程如上，在这就不细说。两个证书准备好后，然后放到相应的目录下。然后写配置文件，如：cd /etc/nginx/conf.d/vim vhosts.conf 1234567891011121314151617181920server &#123; listen 443 ssl; server_name www.a.com; root /data/sitea/; # 这个目录表示 url 的根目录 ssl on; ssl_certificate /etc/nginx/conf.d/a.crt; ssl_certificate_key /etc/nginx/conf.d/a..key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; &#125;server &#123; listen 443 ssl; server_name www.b.com; root /data/siteb/; # 这个目录表示 url 的根目录 ssl on; ssl_certificate /etc/nginx/conf.d/b.crt; ssl_certificate_key /etc/nginx/conf.d/b.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; &#125; 接下来重启服务 nginx然后就可以测试了，当然要是直接在浏览器上输入 网址，还需要 DNS 解析。当然即使解析了浏览器也会报网站不安全，因为证书是我们自签名的，浏览器比信任，要想浏览器信任，在具体生产中还得花钱购买公认的证书。这就实现了 一个物理服务器上搭建多个 加密网站。 实验： 实现 nginx 服务，fastcgi 模式之间的搭建连接。准备四台服务器来模拟实验，分别用来当做 客户端、nginx 服务器、fastcgi 服务器、mysql 数据库服务器。客户端服务器的地址为 192.168.30.6fastcgi 服务器的地址为 192.168.30.17 首先在192.168.30.7 主机上安装 nginx 服务并启动yum install nginxnginx接下来添加配置文件让能够连接后端的 fastcgi 程序vim /etc/nginx/conf.d/vhosts.conf添加内容 1234567location ~ \\.php$ &#123;fastcgi_pass 192.168.30.17:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/php$fastcgi_script_name; include fastcgi_params; &#125; 添加完后重新加载配置文件nginx -s reload 在192.168.30.17 服务器上安装 php-fpm 包yum install php-fpm修改配置文件 vim /etc/php-fpm.d/www.conf修改 listen = 127.0.0.1:9000 改为 listen = 9000 listen.allowed_clients = 127.0.0.1 改为 listen.allowed_clients = 192.168.30.7 这块的 IP 为前端 nginx 服务器的地址修改完重启服务systemctl start php-fpm创建一个文件夹，将来存放 php 程序的文件mkdir /data/phpcd /data/php/添加一些测试文件 1234vim index.html&lt;?phpinfo();?&gt; 12345678vim tset.php&lt;?php$dsn=&apos;mysql:host=192.168.30.27;dbname=mysql&apos;;$username=&apos;test&apos;;$passwd=&apos;centos&apos;;$dbh=new PDO($dsn,$username,$passwd);var_dump($dbh);?&gt; 接下来就可以拿浏览器访问 nginx 服务器了。这就实现了 fastcgi 的php程序。不过一般在生产中为了节约物理服务器，这两个还是放在一起的，在这只是为了演示原理分开测试的。 如果 nginx 服务器作为中间的一个调度器，后端比如有两个提供外部服务的服务器，那如何调度，首先在后端的外部服务器上设置好各自的服务跟站点页面。然后在 nginx 服务器配置文件的 http 语句块中添加： 1234567upstream www &#123;server 192.168.30.200:80; # 表示后端的外部服务器地址server 192.168.30.17:80; # 表示后端的外部服务器地址&#125; location / &#123;proxy_pass http://www;&#125; 然后在浏览器上进行访问就ok 了，注意访问的是 nginx 服务器的地址。当然，如果后端的外部服务器有一个宕机，前面的 nginx 服务器会立即察觉，并且立即不往那台服务器上调度。不用手动配置什么，一切动作都是自动的。说明 nginx 服务器还有自动健康检查功能。还有如果后端的外部服务器端口发生变化，直接在 nginx 服务器配置文件中进行修改即可，并重启服务。 实验： 实现 nginx 源码编译先在官网上下载源码包到本机 官网： www.nginx.org下载包： nginx-1.12.2.tar.gz下载完解包tar xvf nginx-1.12.2.tar.gz解完包生成一个文件夹nginx-1.12.2解完包对源码进行修改，比如，对外 发布的版本号cd nginx-1.12.2vim src/http/ngx_http_header_filter_module.c在里面进行修改 查找 48 行修改 static u_char ngx_http_server_string[] = “Server: nginx” CRLF; 为： static u_char ngx_http_server_string[] = “Server: Linginx” CRLF; （可以自己随意修改字段） 还有一个就是修改 nginx 版本号vim src/core/nginx.h在里面有版本号，然后进行修改。 安装包组yum groupinstall “development tools”接下来创建一个 nginx 账号，因为一会 work 进程要以 nginx 的身份运行useradd -r nginx然后 cd 到 nginx-1.12.2 目录下进行编译./configure –prefix=/app/nginx \\ –conf-path=/etc/nginx/nginx.conf \\– error-log-path=/var/log/nginx/error.log \\–http-logpath=/var/log/nginx/access.log \\–pid-path=/var/run/nginx.pid \\–lockpath=/var/run/nginx.lock \\–user=nginx \\–group=nginx \\–with-http_ssl_module \\–with-http_v2_module \\–with-http_dav_module \\–withhttp_stub_status_module \\–with-threads \\–with-file-aio 中间可能会提示缺包，提示缺什么包装上就可以了如： yum install pcre-devel yum install openssl-devel make -j 4 &amp;&amp; make install 编译完后在 /app/nginx/sbin/ 目录下有一个 nginx 程序运行这个程序启动服务./nginx可以直接把这个工具加入 PASH 变量中如果想干脆把让客户看到版本号，那就修改主配置文件vim /etc/nginx/conf/nginx.conf在 http 语句块中添加server_tokens off;修改完重新加载配置文件 ./nginx -s reload这样客户端就看不见服务版本了 到此就编译成功了。 实验： 实现 nginx 的反向代理功能现在准备三台主机来模拟实验环境，一个客户端，一个 nginx 服务器， 一个后端提供服务的 httpd 服务器。 实验模拟： 172 网段属于外网， 192 网段的属于内网现在配置环境，客户机上的网卡网段是 172，IP 为 172.20.101.101 nginx 服务器上有两个网卡，一个是 172 网段的，IP 为 172.20.116.116 ， 一个是 192 网段的，IP 为 192.168.30.7 。后端服务器上网卡的网段是 192 网段的，IP 为 192.168.30.17 先在后端提供外部服务的 httpd 服务器上安装 httpd 服务并启动yum install httpdsystemctl start httpd 然后在 nginx 服务器上安装 nginx 服务，并配置反向代理功能在配置文件中添加： 123location / &#123;proxy_pass http://192.168.30.17/;&#125; 然后用 客户机去访问 nginx 服务器的80 端口 ，curl 172.20.116.116就会收到后端提供服务的外部服务器主页面的内容。然后在后端的提供服务的外部服务器上的日志中收到发来的请求，就会发现日志显示的请求 ip 是 nginx 服务器的。但在 nginx 服务器上的日志中会显示真正客户端发来的请求。以上就实现了简单的 nginx 服务的反向代理 如果后端的外部服务器上端口进行修改，修改为 8080，那么就要在 nginx 服务器配置文件中进行修改，如： l123ocation / &#123;proxy_pass http://192.168.30.17：8080/;&#125; 如果只允许访问特定目录时才给转到后端外部服务器上去，怎么配置？ 如： 123location /bbs &#123;proxy_pass http://192.168.30.17/;&#125; 注意： 这里面 IP 后面加斜线，我们表示有 URL ，当访问 /bbs 目录时就会把这个目录置换为 IP 下的根，而不加斜线，就会把 /bbs 目录添加在地址后面充当我的 URL 。 这里面 IP 后面加斜线，反向代理后访问到的是后端服务器默认的主站点页面文件，而不加斜线则访问到的是根下的 /bbs 目录下的文件 实验： 实现 nginx 服务反向代理，并要求客户端访问静态页面就调度到外部1服务器上，访问动态页面就调度到外部2 服务器上，并且动态服务器后还有对应的数据库服务器， 实现动静分离。准备实验环境准备 5 台服务器，分别为 192.168.30.6 192.168.30.7 192.168.30.200 192.168.30.17 192.168.30.27用 192.168.30.6 主机当客户端服务器用 192.168.30.7 主机当 nginx 服务器，还有一个地址 172.20.116.116用 192.168.30.200 主机当外部1 服务器用 192.168.30.17 主机当外部2 服务器用 192.168.30.27 主机当外部2 服务器后的数据库服务器 先配置外部服务器在外部1 服务器 192.168.30.200 上安装 httpd 服务并启动yum install httpd设置静态页面cd /var/www/htmlecho static page &gt; index.htmlsystemctl start httpd 在外部 2服务器 192.168.30.17 上安装 httpd php-fpm php-mysqlyum install httpd php-fpm php-mysqlsystemctl start httpd php-fpm 在数据库服务器 192.168.30.27 安装 mysql 数据库yum install mariadb-server创建数据库账号grant all on . to test@’192.168.30.%’ identfied by ‘centos’;加载数据库flush privileges; 然后回到外部2 服务器 192.168.30.17 上修改配置文件 vim /etc/httpd/conf.d/php.conf在里面添加 123DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/var/www/html/$1 写连接数据库的php 程序配置文件cd /var/www/html/vim tset.php在里面添加 123456789101112&lt;?php$dsn=&apos;mysql:host=192.168.30.27;dbname=mysql&apos;;$username=&apos;test&apos;;$passwd=&apos;centos&apos;;$dbh=new PDO($dsn,$username,$passwd);var_dump($dbh);?&gt;然后再在这个目录下创建一个 php程序文件 vim php.html&lt;?phpphpinfo();?&gt; 重启服务systemctl restart httpd 然后回到 nginx 服务器 192.168.30.7 上配置反向代理在配置文件中添加 vim /etc/nginx/conf.d/vhosts.conf 123456location ~ \\.php$ &#123;proxy_pass http://192.168.30.17;&#125;location / &#123;proxy_pass http://192.168.30.200;&#125; 最后拿客户端访问 nginx 服务器，在浏览器输入 172.20.116.116/test.php ， 如果出现” object(PDO)#1 (0) { } “ 这个字符串，就表示调度到 外部 2 服务器上，输入 172.20.116.116/index.html ,如果出现 “static page” 这个字符串就表示调度到 外部 1服务器上。这就实现了动静分离，访问静态页面调度到一台服务器，访问动态页面调度到另一台服务器。这样就有效的把服务器的负载分配到不同服务器上，提高了服务器性能。 在上面唯一遗憾的就是在后端提供外部服务的服务器日志中显示访问的主机 IP 为 nginx 反向代理服务器的。这样对以后分析哪些地方 的客户访问了哪些页面就不太方便了，为了能够在后端服务器上显示原访问客户端的 IP 地址，就要在 nginx 服务器转发请求报文时在报文头部添加一些指令，把客户端的地址添加到报文头部中，这样在后端的服务器日志中就可以看到客户端的地址了。 但是在后端服务器的日志中他只记录访问用户的地址，并不记录报文头部的地址，所以还要在后端的服务器上修改日志格式才行。 在 nginx 服务器上添加报文头部信息proxy_set_header remoteclientip $remote_addr; 这个信息可以放在 location、server 、http 这三个语句块中都可以。 还要在后端的外部服务器上修改日志格式 ，在服务的配置文件中进行修改。 vim /etc/httpd/conf/httpd.conf 修改下面这条指令： 1LogFormat &quot;%&#123;remoteclientip&#125;i %l %u %&#123;%F %T&#125;t \\&quot;%r\\&quot; %&gt;s %b \\&quot;%&#123;Referer&#125;i\\&quot; \\&quot;%&#123;User-Agent&#125;i\\&quot;&quot; combined 修改完重启服务systemctl restart httpd 如果在生产中，客户端访问后端服务器，中间要经过好几台 nginx 反向服务器，最后面才是 提供外部服 务的外部服务器，那么这样怎么在后端服务器上记录真实客户端的访问地址？ 一般只用在最前面的 nginx 服务器配置文件中添加以下两条 ：proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 中间的 nginx 服务器配置文件中只用添加相应的反向代理地址即可。 注意：如果外部服务器前面有好多反向代理服务器，前面的服务器配置文件中的转发 IP 一定是后面那个转发服务器的地址，不是后面外部服务器的地址，这样一次类推，直到外部服务器前的那一个转发服务器的配置文件中才是 后端外部服务器的地址。 这样只在后端的外部服务日志中记录真实客户端的地址，不记录中间经过的 nginx 服务器的地址。如果在生产中有需求，需要经过的地址都记录，就在所有经过的 nginx 服务器配置文件中添加 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 这条就可以。","categories":[],"tags":[]},{"title":"","slug":"Nginx 详细介绍","date":"2018-08-09T07:53:57.029Z","updated":"2018-08-09T07:53:46.597Z","comments":true,"path":"2018/08/09/Nginx 详细介绍/","link":"","permalink":"http://yoursite.com/2018/08/09/Nginx 详细介绍/","excerpt":"layout: posttitle: Nginx 详细介绍date: 2017-7-28tags: Linux nginx http 协议：80/tcp 全称：超文本传输协议html : 超文本标记语言 nginx是一个高性能的web服务和反向代理服务器 高连接并发的情况下可替代apache;选择epoll作为开发模型即事务处理模型;它包括io事务即io处理模型,内存状态事务模型等等 nginx可做为负载均衡服务器：可以在内部直接支持和php程序对外进行服务，也支持http代理服务对外进行服务； 采用C进行编写，系统资源开销和cpu使用效率比perlbal要好很多 内存消耗少：3万并发连接下开启10个进程才消耗150M内存 内置健康检查功能：后端服务器当机不会影响前端访问 节省带宽：支持Gzip压缩， 稳定性高：用于反向代理，当机的概率微乎其微;master主进程跟workers进程是分开的不会因为worker进程故障而影响主进程 模块化设计：模块可以动态编译，较好的外围拓展，二次开发等 支持热部署：可以不停机重载文件 支持事件驱动、内存映射mmap、sendfile（可直接在内核空间加载头部）","text":"layout: posttitle: Nginx 详细介绍date: 2017-7-28tags: Linux nginx http 协议：80/tcp 全称：超文本传输协议html : 超文本标记语言 nginx是一个高性能的web服务和反向代理服务器 高连接并发的情况下可替代apache;选择epoll作为开发模型即事务处理模型;它包括io事务即io处理模型,内存状态事务模型等等 nginx可做为负载均衡服务器：可以在内部直接支持和php程序对外进行服务，也支持http代理服务对外进行服务； 采用C进行编写，系统资源开销和cpu使用效率比perlbal要好很多 内存消耗少：3万并发连接下开启10个进程才消耗150M内存 内置健康检查功能：后端服务器当机不会影响前端访问 节省带宽：支持Gzip压缩， 稳定性高：用于反向代理，当机的概率微乎其微;master主进程跟workers进程是分开的不会因为worker进程故障而影响主进程 模块化设计：模块可以动态编译，较好的外围拓展，二次开发等 支持热部署：可以不停机重载文件 支持事件驱动、内存映射mmap、sendfile（可直接在内核空间加载头部） I/O模型Nginx介绍Nginx安装Nginx各种模块 性能影响有很多研究都表明，性能对用户的行为有很大的影响：79%的用户表示不太可能再次打开一个缓慢的网站47%的用户期望网页能在2秒钟以内加载40%的用户表示如果加载时间超过三秒钟，就会放弃这个网站页面加载时间延迟一秒可能导致转换损失7%，页面浏览量减少11%8秒定律：用户访问一个网站时，如果等待网页打开的时间超过8秒，会有 超过30%的用户放弃等待 Httpd MPMhttpd MPM： prefork：进程模型，两级结构，主进程master负责生成子进程，每个子进 程负责响应一个请求 worker：线程模型，三级结构，主进程master负责生成子进程，每个子进程 负责生成多个线程，每个线程响应一个请求 event：线程模型，三级结构,主进程master负责生成子进程，每个子进程响 应多个请求 I/O介绍I/O: 网络IO：本质是socket读取 磁盘IO： 每次IO，都要经由两个阶段： 第一步：将数据从磁盘文件先加载至内核内存空间（缓冲区），等待数据准 备完成，时间较长 第二步：将数据从内核缓冲区复制到用户空间的进程的内存中，时间较短 I/O模型同步/异步：关注的是消息通信机制 同步：synchronous，调用者等待被调用者返回消息，才能继续执行 异步：asynchronous，被调用者通过状态、通知或回调机制主动通知调用者 被调用者的运行状态 阻塞/非阻塞：关注调用者在等待结果返回之前所处的状态 阻塞：blocking，指IO操作需要彻底完成后才返回到用户空间，调用结果返回 之前，调用者被挂起 非阻塞：nonblocking，指IO操作被调用后立即返回给用户一个状态值，无需 等到IO操作彻底完成，最终的调用结果返回之前，调用者不会被挂起 I/O模型： 阻塞型、非阻塞型、复用型、信号驱动型、异步 同步阻塞IO模型同步阻塞IO模型是最简单的IO模型，用户线程在内核进行IO操作时被阻塞 用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等 到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作 用户需要等待read将数据读取到buffer后，才继续处理接收的数据。整个IO请 求的过程中，用户线程是被阻塞的，这导致用户在发起IO请求时，不能做任何 事情，对CPU的资源利用率不够 同步非阻塞IO模型用户线程发起IO请求时立即返回。但并未读取到任何数据，用户线程需要不断 地发起IO请求，直到数据到达后，才真正读取到数据，继续执行。即 “轮询” 机制 整个IO请求的过程中，虽然用户线程每次发起IO请求后可以立即返回，但是为 了等到数据，仍需要不断地轮询、重复请求，消耗了大量的CPU的资源是比较浪费CPU的方式，一般很少直接使用这种模型，而是在其他IO模型中使 用非阻塞IO这一特性 I/O多路复用模型 多个连接共用一个等待机制，本模型会阻塞进程，但是进程是阻塞在select或者poll这两 个系统调用上，而不是阻塞在真正的IO操作上 用户首先将需要进行IO操作添加到select中，继续执行做其他的工作（异步），同时等 待select系统调用返回。当数据到达时，IO被激活，select函数返回。用户线程正式发起 read请求，读取数据并继续执行。 从流程上来看，使用select函数进行IO请求和同步阻塞模型没有太大的区别，甚至还多 了添加监视IO，以及调用select函数的额外操作，效率更差。并且阻塞了两次，但是第 一次阻塞在select上时，select可以监控多个IO上是否已有IO操作准备就绪，即可达到在 同一个线程内同时处理多个IO请求的目的。而不像阻塞IO那种，一次只能监控一个IO 虽然上述方式允许单线程内处理多个IO请求，但是每个IO请求的过程还是阻塞的（在 select函数上阻塞），平均时间甚至比同步阻塞IO模型还要长。如果用户线程只是注册 自己需要的IO请求，然后去做自己的事情，等到数据到来时再进行处理，则可以提高 CPU的利用率 IO多路复用是最常使用的IO模型，但是其异步程度还不够“彻底”，因它使用了会阻塞 线程的select系统调用。因此IO多路复用只能称为异步阻塞IO模型，而非真正的异步IO 多路I/O复用 IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，就通知该进程 IO多路复用适用如下场合： 当客户端处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用 当一个客户端同时处理多个套接字时，此情况可能的但很少出现 当一个TCP服务器既要处理监听套接字，又要处理已连接套接字，一般也要用到I/O 复用 当一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用 当一个服务器要处理多个服务或多个协议，一般要使用I/O复用 信号驱动IO模型 信号驱动IO：signal-driven I/O 用户进程可以通过sigaction系统调用注册一个信号处理程序，然后主程序可以 继续向下执行，当有IO操作准备就绪时，由内核通知触发一个SIGIO信号处理程 序执行，然后将用户进程所需要的数据从内核空间拷贝到用户空间 此模型的优势在于等待数据报到达期间进程不被阻塞。用户主程序可以继续执 行，只要等待来自信号处理函数的通知 该模型并不常用 异步IO模型 异步IO与信号驱动IO最主要的区别是信号驱动IO是由内核通知何时可以进行IO 操作，而异步IO则是由内核告诉用户线程IO操作何时完成。信号驱动IO当内核 通知触发信号处理程序时，信号处理程序还需要阻塞在从内核空间缓冲区拷贝 数据到用户空间缓冲区这个阶段，而异步IO直接是在第二个阶段完成后，内核 直接通知用户线程可以进行后续操作了 相比于IO多路复用模型，异步IO并不十分常用，不少高性能并发服务程序使用 IO多路复用模型+多线程任务处理的架构基本可以满足需求。目前操作系统对异 步IO的支持并非特别完善，更多的是采用IO多路复用模型模拟异步IO的方式 （IO事件触发时不直接通知用户线程，而是将数据读写完毕后放到用户指定的 缓冲区中） I/O模型的具体实现 主要实现方式有以下几种： Select：Linux实现对应，I/O复用模型，BSD4.2最早实现 Poll：Linux实现，对应I/O复用模型，System V unix最早实现 Epoll：Linux实现，对应I/O复用模型，具有信号驱动I/O模型的某些特性 Kqueue：FreeBSD实现，对应I/O复用模型，具有信号驱动I/O模型某些特性 /dev/poll：SUN的Solaris实现，对应I/O复用模型，具有信号驱动I/O模型的 某些特性 Iocp Windows实现，对应第5种（异步I/O）模型 select/poll/epoll Select:POSIX所规定，目前几乎在所有的平台上支持，其良好跨平台支持也是 它的一个优点，本质上是通过设置或者检查存放fd标志位的数据结构来进行下 一步处理 缺点 单个进程可监视的fd数量被限制，即能监听端口的数量有限 cat /proc/sys/fs/file-max 对socket是线性扫描，即采用轮询的方法，效率较低 select 采取了内存拷贝方法来实现内核将 FD 消息通知给用户空间，这样一 个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结 构时复制开销大 select/poll/epollpoll 本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询 每个fd对应的设备状态 其没有最大连接数的限制，原因是它是基于链表来存储的 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复 制是不是有意义 poll特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时 会再次报告该fd 边缘触发：只通知一次 select/poll/epollepoll：在Linux 2.6内核中提出的select和poll的增强版本 支持水平触发LT和边缘触发ET，最大的特点在于边缘触发，它只告诉进程哪 些fd刚刚变为就需态，并且只会通知一次 使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核 就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知 优点: 没有最大并发连接的限制：能打开的FD的上限远大于1024(1G的内存能监听 约10万个端口) 效率提升：非轮询的方式，不会随着FD数目的增加而效率下降；只有活跃可 用的FD才会调用callback函数，即epoll最大的优点就在于它只管理“活跃” 的连接，而跟连接总数无关 内存拷贝，利用mmap(Memory Mapping)加速与内核空间的消息传递；即 epoll使用mmap减少复制开销 Nginx介绍Nginx：engine X ，2002年，开源，商业版 NGINX是免费，开源，高性能的HTTP和反向代理服务器，邮件代理服务器，通 用TCP/UDP代理服务器 解决C10K问题（10K Connections） 官网：http://nginx.org 二次开发版： Tengine, OpenResty（章亦春） 特性： 模块化设计，较好的扩展性 高可靠性 支持热部署：不停机更新配置文件，升级版本，更换日志文件 低内存消耗：10000个keep-alive连接模式下的非活动连接，仅需2.5M内存 event-driven,aio,mmap，sendfile基本功能： 静态资源的web服务器 http协议反向代理服务器 pop3/imap4协议反向代理服务器 FastCGI(LNMP),uWSGI(python)等协议 模块化（非DSO），如zip，SSL模块 nginx的程序架构扩展功能：web服务相关的功能： 基于名称和IP的虚拟主机（server） 支持 keep-alive 和管道连接 定制访问日志（支持基于日志缓冲提高其性能） 支持url rewirte 支持路径别名 支持基于IP及用户的访问控制 支持速率限制及并发数限制 重新配置和在线升级而无须中断客户的工作进程 Memcached 的 GET 接口 nginx的程序架构nginx的程序架构： master/worker结构 一个master进程： 负载加载和分析配置文件、管理worker进程、平滑升级 一个或多个worker进程 处理并响应用户请求 缓存相关的进程： cache loader：载入缓存对象 cache manager：管理缓存对象 nginx 的工作模式： 基于非阻塞、事件驱动机制，有一个 master 进程生成多个 werker 线程，每个 worker 线程生成 N 个请求。 nginx模块nginx高度模块化，但其模块早期不支持DSO机制；1.9.11版本支持动态装载和 卸载 模块分类： 核心模块：core module 标准模块： • HTTP 模块： ngx_http_ HTTP Core modules 默认功能 HTTP Optional modules 需编译时指定 • Mail 模块 ngx_mail_ • Stream 模块 ngx_stream_* 第三方模块 nginx的功用静态的web资源服务器 html，图片，js，css，txt等静态资源 结合FastCGI/uWSGI/SCGI等协议反向代理动态资源请求http/https协议的反向代理imap4/pop3协议的反向代理tcp/udp协议的请求转发（反向代理） nginx 的官网 epel 源 [nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/7/x86_64/gpgcheck=0enabled=1 不过这是 1.14 版 的 ，版本比较新，生产中建议不要用太新版本，建议使用稳定版。 nginx的安装 官方： http://nginx.org/packages/centos/7/x86_64/RPMS Fedora-EPEL: https://mirrors.aliyun.com/epel/7/x86_64/ 编译安装： • yum install pcre-devel openssl-devel zlib-devel • useradd -r nginx • ./configure –prefix=/usr/local/nginx –conf-path=/etc/nginx/nginx.conf – error-log-path=/var/log/nginx/error.log –http-logpath=/var/log/nginx/access.log –pid-path=/var/run/nginx.pid –lockpath=/var/run/nginx.lock –user=nginx –group=nginx –with-http_ssl_module –with-http_v2_module –with-http_dav_module –withhttp_stub_status_module –with-threads –with-file-aio • make &amp;&amp; make install 编译安装nginx选项编译安装nginx选项： –prefix=/etc/nginx 安装路径 –sbin-path=/usr/sbin/nginx 指明nginx程序文件安装路径 –conf-path=/etc/nginx/nginx.conf 主配置文件安装位置 -error-log-path=/var/log/nginx/error.log 错误日志文件安装位置 –http-log-path=/var/log/nginx/access.log 访问日志文件安装位置 –pid-path=/var/run/nginx.pid 指明pid文件安装位置 –lock-path=/var/run/nginx.lock 锁文件安装位置 –http-client-body-temp-path=/var/cache/nginx/client_temp 客户端 body部分的临时文件存放路径，服务器允许客户端使用put方法提交大数据 时，临时存放的磁盘路径 编译安装nginx选项 –http-proxy-temp-path=/var/cache/nginx/proxy_temp 作为代理服务器，服务 器响应报文的临时文件存放路径 –http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp 作为fastcgi代理服务 器，服务器响应报文的临时文件存放路径 –http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp 作为uwsgi代理服务器， 服务器响应报文的临时文件存放路径 –http-scgi-temp-path=/var/cache/nginx/scgi_temp 作为scgi反代服务器，服务 器响应报文的临时文件存放路径 –user=nginx 指明以那个身份运行worker进程，主控master进程一般由root运行 –group=nginx –with-http_ssl_module 表示把指定模块编译进来 nginx目录结构和命令ls /usr/local/nginx/ # 源码编译完的路径 html是测试页，sbin是主程序 ls /usr/local/nginx/sbin/ nginx 只有一个程序文件 ls /usr/local/nginx/html/ 50x.html index.html 测试网页 Nginx：默认为启动nginx -h 查看帮助选项 -V 查看版本和配置选项 -t 测试nginx语法错误 -c filename 指定配置文件(default: /etc/nginx/nginx.conf) -s signal 发送信号给master进程，signal：stop, quit, reopen, reload 示例： nginx -s stop 停止nginx nginx -s reload 加载配置文件 -g directives 在命令行中指明全局指令 nginx配置 配置文件的组成部分： 主配置文件：nginx.conf 子配置文件 include conf.d/*.conf fastcgi， uwsgi，scgi等协议相关的配置文件 mime.types：支持的mime类型 主配置文件的配置指令： directive value [value2 …]; 注意： (1) 指令必须以分号结尾 (2) 支持使用配置变量 内建变量：由Nginx模块引入，可直接引用 自定义变量：由用户使用set命令定义 set variable_name value; 引用变量： $variable_name nginx配置文件main 配置段 ： 全局配置段 event: 定义 event 模型工作特性 http {} ：定义http协议相关的配置 配置指令： 要以分好结尾，语法格式：directive valuel [value2…] 支持使用变量： 内置变量：模块会提供内建变量定义 自定义变量：set var_name value 主配置段的指令：用于调试，定位问题正常运行必备的配置优化性能的配置事件相关的配置 主配置文件结构：四部 main block：主配置段，即全局配置段，对http,mail都有效 123456789101112131415161718event &#123; ... &#125; 事件驱动相关的配置 http &#123; ... &#125; http/https 协议相关配置段 mail &#123; ... &#125; mail 协议相关配置段 stream &#123; ... &#125; stream 服务器相关配置段 http协议相关的配置结构 12345678910111213141516171819http &#123; ... ... 各server的公共配置 server &#123; 每个server用于定义一个虚拟主机 ... &#125; server &#123; ... server_name 虚拟主机名 root 主目录 alias 路径别名 location [OPERATOR] URL &#123; 指定URL的特性 ... if CONDITION &#123; ... &#125; &#125; &#125; &#125; nginx配置Main 全局配置段常见的配置指令分类 正常运行必备的配置 优化性能相关的配置用于调试及定位问题相关的配置 事件驱动相关的配置帮助文档 http://nginx.org/en/docs/ nginx配置 正常运行必备的配置： 帮助文档：http://nginx.org/en/docs/ngx_core_module.html 1、user nginx （默认的） 指定以哪个用户的身份或组来运行 worker 进程如组不指定，默认和用户名同名 123如： Syntax: user user [group]; Default: user nobody nobody; Context: main 指定worker进程的运行身份，如组不指定，默认和用户名同名 2、pid /PATH/TO/PID_FILE 默认在 /var/run/nginx/nginx.pid 文件下，里面存着主进程的进程标号（master ） 服务启动时这个文件就自动生成，服务停止这个文件也就不见了。 指定存储nginx主进程PID的文件路径 3、include file | mask 指明包含进来的其它配置文件片断 4、load_module file 模块加载配置文件：/usr/share/nginx/modules/*.conf 指明要装载的动态模块路径: /usr/lib64/nginx/modules nginx配置 性能优化相关的配置： 全局段 1、worker_processes number | auto 所能够打开的worker进程的数量；通常应该少于当前主机的cpu的物理核心数 ，如： 核心数为 8，建议打开 7 个 或 6 个。 在生产中不要把进程数量调的太大，因为进程太多，还会涉及到上下文切换等问题，建议跟 cpu 数量一样即可。 2、worker_cpu_affinity cpumask … 也可以把某一个进程绑定在某一个 cpu 上，这样的好处就是提高缓存的命中率。但有一点要注意，绑定在那一颗 cpu 上并不代表 这颗 cpu 只能运行这一个进程，而是运行其他进程时还是要把这个进程切出去的，只是保证这个进程一定是在这颗 cpu 上运行。 worker_cpu_affinity auto [cpumask] 提高缓存命中率 CPU MASK （cpu 掩码）： 00000001：0号CPU 00000010：1号CPU 10000000：8号CPU 在配置文件中添加绑定 cpu 信息，如： worker_cpu_affinity 0001 0010 ; # 表示绑定在 第一颗和第二颗 cpu 上。 worker_cpu_affinity 0101 1010; 可以用命令查看某个进程跑在哪个 cpu 上 如： ps axo pid,cmd,psr |grep nginx 3、worker_priority number 指定worker进程的nice值，设定worker进程优先级：[-20,19] nice 值越小，对应的优先级越高 4、worker_rlimit_nofile number 指定所有worker进程所能够打开的最大文件句柄数,如65535（总值） 这个在配置文件中没有明确定义，在生产中可以适当调一调。 5、timer_resolution 计时器解析度：降低此值，可减少 gettimeofday()系统调用的次数；在一定程度上可挺高服务器性能。 nginx配置事件驱动相关的配置: 存放在 event 当中的配置 123events &#123; ... &#125; 1、worker_connections #; 指定单个worker进程所能够打开的最大并发连接数数量，如15240 Nginx 的总最大并发数：worker_processes * worker_connections 2、use method 指明并发连接请求的处理方法（使用的时间模型）,建议让Nginx自动选择最优方法 use epoll; 3、accept_mutex on | off 互斥 处理新的连接请求的方法；on指由多个worker轮流处理新请求，使用负载均衡锁，Off指每个新请 求的到达都会通知(唤醒)所有的worker进程，但只有一个进程可获得连接，造成“惊 群”，影响性能 （必须在 enevt 语句块中设定） 尽量设为 ON ，OFF 影响性能。 4、lock_file file; accent_mutex用到的锁文件路径； nginx配置 调试和定位问题： 要想使用调试功能，在编译时一定要添加 –with-debug 这个选项才能使用。 1、daemon on|off （放在 main 语句块中） 是否以守护进程方式运行nignx，默认是守护进程方式 默认为 ON 服务是后台运行的， 改为 OFF ，服务就在前台执行，会把调试过程显示在屏幕上，适合于调示环境，就不用来回加载配置文件了。 2、master_process on|off 是否以master/worker模型运行nginx；默认为on 如果在调试时可以设为 OFF ，就不开启 worker 进程接受请求，只开启一个主进程，如果是一个主进程，一个子进程，这样调试时不容易查看出错误等。 3、error_log file [level] 记录在 /var/log/nginx/error.log 文件下 错误日志文件及其级别；出于调试需要，可设定为debug；但debug仅在编译时 使用了“–with-debug”选项时才有效 方式：file /path/logfile; stderr:发送到标准错误 syslog:server-address[,parameter=values]:发送到syslog memory:size 内存 level:debug|info|notice|warn|error|crit|alter|emerg 总结：常需要进行调整的参数 worker_processes ,worker_connections, worker_cpu_affinity, worker_priority nginx 作为 web 服务器时使用的配置； http协议的相关配置框架： 1234567891011121314http &#123; ... ... server &#123; ... server_name root location [OPERATOR] /uri/ &#123; ... &#125; # 类似于 httpd 中的 &lt;Location&gt;,用于定义 URL 于本地文件系统的映射关系； &#125; server &#123; ... &#125; # 每个 server 类似于 httpd 中的一个 &lt;VirtualHost&gt;;定义虚拟主机的。 &#125; 注意： 与 http 相关的指令仅能够放置于 http、server、location、upstream、if 上下文，但有些指令仅应用于这 5种上下文中的某些种； ngx_http_core_modulengx_http_core_module 将来我们可以在一台服务器上创建多个虚拟机，并在设定各自的配置文件，这样就可以清晰的管理各个虚拟机，如： 都放在 /etc/nginx/conf.d/vhosts/ 目录下 ，然后在这个目录下创建各个虚拟机的子配置文件，但是子文件都要以 .conf 为后缀。 与套接字相关的配置： 1、server { … } 配置一个虚拟主机： 基于端口的虚拟主机： 12345server &#123; listen address[:PORT]|PORT; # 指定端口号 server_name SERVER_NAME; # 起一个虚拟机的名字root /PATH/TO/DOCUMENT_ROOT; # 指定这个虚拟机的主页面在磁盘路径中的那个位置 &#125; 2、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE listen address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] default_server 设定为默认虚拟主机 ssl 限制仅能够通过ssl连接提供服务 backlog=number 超过并发连接数后，新请求进入后援队列的长度 后面跟多大数就表示能承受多少后援请求数量。 rcvbuf=size 接收缓冲区大小 sndbuf=size 发送缓冲区大小 设定 发送 或者 接受 缓冲区的大小 注意： (1) 基于port； listen PORT; 指令监听在不同的端口 (2) 基于ip的虚拟主机 listen IP:PORT; IP 地址不同 (3) 基于hostname server_name fqdn; 指令指向不同的主机名 3、server_name name …; 虚拟主机的主机名称后可跟多个由空白字符分隔的主机 支持*通配任意长度的任意字符 如： server_name .magedu.com www.magedu. 支持~起始的字符做正则表达式模式匹配，性能原因慎用 server_name ~^www\\d+.magedu.com$ 说明： \\d 表示 [0-9] 匹配优先级机制从高到低： (1) 首先是字符串精确匹配 如：www.magedu.com (2) 左侧通配符 如：.magedu.com (3) 右侧通配符 如：www.magedu. (4) 正则表达式 如： ~^.*.magedu.com$ (5) default_server ；默认server 如果这5种都不匹配，那就自上而下匹配第一个 server . ngx_http_core_module4、tcp_nodelay on | off; 在keepalived模式下的连接是否启用TCP_NODELAY选项 当为off时，延迟发送，合并多个请求后再发送 默认On时，不延迟发送 可用于：http, server, location 5、sendfile on | off; 是否启用sendfile功能，在内核中封装报文直接发送 默认Off 6、server_tokens on | off | build | string 是否在响应报文的Server首部显示nginx版本 如果不想客户看到自己的 nginx 版本信息，就可以在主配置文件中的 http 语句块中添加 server_tokens off； 如果只是想服务器上个别网站不想让客户端看到，就可以在各自的子配置文件中添加。 ngx_http_core_module 定义路径相关的配置 7、root设置web资源的路径映射；用于指明请求的URL所对应的文档的目录路径，可 用于http, server, location, if in location 1234server &#123; ... root /data/www/vhost1; &#125; 示例 http://www.magedu.com/images/logo.jpg –&gt; /data/www/vhosts/images/logo.jpg ngx_http_core_module 8、location [ = | ~ | ~* | ^~ ] uri { … } location @name { … } 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路 径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最 佳匹配，而后应用其配置 ,例如:做访问控制等功能； 示例： 123456server &#123;... server_name www.magedu.com; location /images/ &#123; root /data/imgs/; &#125; &#125; http://www.magedu.com/images/logo.jpg --&gt; /data/imgs/images/logo.jpg =：对URI做精确匹配； location = / { ... } http://www.magedu.com/ 匹配 http://www.magedu.com/index.html 不匹配 ^~： 对URI的最左边部分做匹配检查，不区分字符大小写 ，不支持正则表达式 ~： 对URI做正则表达式模式匹配，区分字符大小写 ~*： 对URI做正则表达式模式匹配，不区分字符大小写 不带符号：匹配起始于此uri的所有的uri 匹配优先级从高到低： =, ^~, ～/～* , 不带任何符号的 location ; 示例： root /vhosts/www/htdocs/http://www.magedu.com/index.html –&gt; /vhosts/www/htdocs/index.html 123456server &#123; root /vhosts/www/htdocs/ location /admin/ &#123; root /webapps/app1/data/ &#125; &#125; http://www.magedu.com/admin/index.html –&gt; /webapps/app1/data/admin/index.html ngx_http_core_module9、alias path; 用于 location 配置段中，定义路径别名 。注意： root 表示知名路径为对应的 location “/” URL；alias 表示路径映射，即 location指令后定义的URL是相对于 alias 锁知名的路径而言。 路径别名，文档映射的另一种机制；仅能用于location上下文 示例： http://www.magedu.com/bbs/index.php location /bbs/ { alias /web/forum/; } –&gt; /web/forum/index.html location /bbs/ { root /web/forum/; } –&gt; /web/forum/bbs/index.html 注意：location中使用root指令和alias指令的意义不同 (a) root，给定的路径对应于location中的/uri/左侧的/ (b) alias，给定的路径对应于location中的/uri/右侧的/ 10、index file …; 指定默认网页文件 index index.php index.html自左而右显示注意：ngx_http_index_module模块 11、error_page code … [=[response]] uri; 模块：ngx_http_core_module 定义错误页，以指定的响应状态码进行 响应 可用位置：http, server, location, if in location现在磁盘路径下创建一个文件路径，如：在主配置文件路径下 vim /vhosts/web1/404.html # 在里面添加你希望展示的界面然后在主配置文件中添加： error_page 404 /404.html 为了不让浏览器拦截服务器的页面错误，可以在主配置文件中添加： error_page 404 =200 /404.html 基于 ip 的访问控制allow IP/networkdeny IP/network 12、try_files file … uri; try_files file … =code; 按顺序检查文件是否存在，返回第一个找到的文件或文件夹（结尾加斜线表示 为文件夹），如果所有的文件或文件夹都找不到，会进行一个内部重定向到最 后一个参数。只有最后一个参数可以引起一个内部重定向，之前的参数只设置 内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现内部500错 误 123location /images/ &#123; try_files $uri /images/default.gif; &#125; 123location / &#123; try_files $uri $uri/index.html $uri.html =404; &#125; 定义客户端请求的相关配置 13、keepalive_timeout timeout [header_timeout]; 设定保持连接超时时长，0表示禁止长连接，默认为75s 这个值在生产中建议改小一点，但也要根据实际环境去调 14、keepalive_requests number; 在一次长连接上所允许请求的资源的最大数量默认为100 15、keepalive_disable none | browser … 对哪种浏览器禁用长连接 16、send_timeout time; 向客户端发送响应报文的超时时长，此处是指两次写操作之间的间隔时长， 而非整个响应过程的传输时长 tcp_nodelay ON|off; 是佛普对场链接使用这个选项；建议开启设为 ON 。 17、client_body_buffer_size size; 用于接收每个客户端请求报文的body部分的缓冲区大小；默认为16k；超 出此大小时，其将被暂存到磁盘上的由下面client_body_temp_path指令所定义 的位置 18、client_body_temp_path path [level1 [level2 [level3]]]; 设定存储客户端请求报文的body部分的临时存储路径及子目录结构和数量 目录名为16进制的数字； client_body_temp_path /var/tmp/client_body 1 2 2 1 1级目录占1位16进制，即2^4=16个目录 0-f 2 2级目录占2位16进制，即2^8=256个目录 00-ff 2 3级目录占2位16进制，即2^8=256个目录 00-ff 对客户端进行限制的相关配置 19、limit_rate rate; 限制响应给客户端的传输速率，单位是bytes/second 以字节为单位 默认值0表示无限制 20、limit_except method … { … }，仅用于location 表示限定谁访问我的主机站点的时候，出来哪些方法以外哪些是允许的。 限制客户端使用除了指定的请求方法之外的其它方法 method:GET, HEAD, POST, PUT, DELETE MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, PATCHOPTIONS: 探测哪些网站支持哪些请求方法 1234limit_except GET &#123; allow 192.168.1.0/24; deny all; &#125; 除了GET和HEAD 之外的其它方法仅允许192.168.1.0/24网段主机使用 文件操作优化的配置21、aio on | off | threads[=pool]; 是否启用aio功能 建议启用，默认是不启动的。 22、directio size | off; 当文件大于等于给定大小时，例如directio 4m，同步（直接）写磁盘，而非写缓存 ，如果是 OFF 表示即刻写磁盘。 23、open_file_cache off; open_file_cache max=N [inactive=time]; nginx可以缓存以下三种信息： (1) 文件元数据：文件的描述符、文件大小和最近一次的修改时间 (2) 打开的目录结构 (3) 没有找到的或者没有权限访问的文件的相关信息 max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现管理 inactive=time：缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次 数少于open_file_cache_min_uses指令所指定的次数的缓存项即为非活动项，将被删除 LRU算法：最近最少使用算法，就是缓存达到一定上限，必须删除一些缓存，就按照最近缓存的并且使用较少的予以删除。进而让后续缓存可以继续缓存。 24、open_file_cache_errors on | off; 是否缓存查找时发生错误的文件一类的信息 默认值为off 25、open_file_cache_min_uses number; open_file_cache指令的inactive参数指定的时长内，至少被命中此处指定 的次数方可被归类为活动项 默认值为1 26、open_file_cache_valid time; 缓存项有效性的检查频率 默认值为60s ngx_http_access_module ngx_http_access_module模块 实现基于ip的访问控制功能1、allow address | CIDR | unix: | all;2、deny address | CIDR | unix: | all;http, server, location, limit_except自上而下检查，一旦匹配，将生效，条件严格的置前 示例： 1234567location / &#123; deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all; &#125; ngx_http_auth_basic_module ngx_http_auth_basic_module模块 实现基于用户的访问控制，使用basic机制进行用户认证 1、auth_basic string | off;2、auth_basic_user_file file; 1234location /admin/ &#123; auth_basic &quot;Admin Area&quot;; # 指定描述语 auth_basic_user_file /etc/nginx/.ngxpasswd; # 这指定存放账号密码文件的路径，然后还要在对应的目录下创建相应的文件并写上内容。 &#125; 这的账号的通过 HTTP工具来创建账号 如： htpasswd -cm /etc/nginx/.ngxpasswd httpudser1 htpasswd -m /etc/nginx/.ngxpasswd httpudser2 创建完以后然后在配置文件中写出把账号存放在哪，格式如上。 如果直接在 server 语句块中添加 代码，表示整个网站做验证，但是如果只想某个文件做验证，就可以单独写一个 location 语句块， 如： 12345location /admin/ &#123; alias /data/admin; auth_basic &quot;Admin Area&quot;; auth_basic_user_file /etc/nginx/.ngxpasswd; &#125; 用户口令文件： 1、明文文本：格式name:password:comment 2、加密文本：由htpasswd命令实现 httpd-tools所提供 ngx_http_stub_status_module ngx_http_stub_status_module模块 用于输出nginx的基本状态信息 输出信息示例： Active connections: 291 # 当前所有处于打开的连接数server accepts handled requests 16630948 16630948 31070465 已经接收进来的连接已经处理过的连接 已经处理的请求 （在保持连接的模式下，请求数量可能会多于连接数量） 上面三个数字分别对应accepts,handled,requests三个值 Reading: 6 Writing: 179 Waiting: 106Reading: 正处于接受请求状态的连接数Writing: 请求已经接受完成，正处于处理请求或发送响应的过程中的连接Waiting: 工作于保持连接模式，且处于活动状态的连接数。 ngx_http_stub_status_module Active connections:当前状态，活动状态的连接数 accepts：统计总值，已经接受的客户端请求的总数handled：统计总值，已经处理完成的客户端请求的总数requests：统计总值，客户端发来的总的请求数 Reading：当前状态，正在读取客户端请求报文首部的连接的连接数 Writing：当前状态，正在向客户端发送响应报文过程中的连接数 Waiting：当前状态，正在等待客户端发出请求的空闲连接数 1、stub_status; 示例： location /status {s1234tub_status; allow 172.16.0.0/16; deny all; &#125; ngx_http_log_module ngx_http_log_module模块指定日志格式记录请求1、log_format name string …;string可以使用nginx核心模块及其它模块内嵌的变量 2、access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off;访问日志文件路径，格式及相关的缓冲的配置 buffer=sizeflush=time ngx_http_log_module 示例 log_format compression ‘$remote_addr-$remote_user [$time_local] ‘ ‘“$request” $status $bytes_sent ‘ ‘“$http_referer” “$http_user_agent” “$gzip_ratio”‘; access_log /spool/logs/nginx-access.log compression buffer=32k;注意： 此处可用变量为 nginx 各模块内建变量； ngx_http_log_module 3、open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; 缓存各日志文件相关的元数据信息 max：缓存的最大文件描述符数量 min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项 inactive：非活动时长 valid：验证缓存中各缓存项是否为活动项的时间间隔 ngx_http_gzip_module ngx_http_gzip_module用gzip方法压缩响应数据，节约带宽1、gzip on | off;启用或禁用gzip压缩 2、gzip_comp_level level; 压缩比由低到高：1 到 9默认：1 3、gzip_disable regex …; 匹配到客户端浏览器不执行压缩 4、gzip_min_length length;启用压缩功能的响应报文大小阈值 ngx_http_gzip_module 5、gzip_http_version 1.0 | 1.1;设定启用压缩功能时，协议的最小版本 默认：1.1 6、gzip_buffers number size;支持实现压缩功能时缓冲区数量及每个缓存区的大小 默认：32 4k 或 16 8k 7、gzip_types mime-type …;指明仅对哪些类型的资源执行压缩操作；即压缩过滤器 默认包含有text/html，不用显示指定，否则出错 8、gzip_vary on | off;如果启用压缩，是否在响应报文首部插入“Vary: Accept-Encoding” ngx_http_gzip_module 9、gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any …; nginx充当代理服务器时，对于后端服务器的响应报文，在何种条件下启 用压缩功能 off：不启用压缩 expired，no-cache, no-store，private：对后端服务器的响应报文首部 Cache-Control值任何一个，启用压缩功能 示例： gzip on; gzip_comp_level 6; gzip_min_length 64; gzip_proxied any; gzip_types text/xml text/css application/javascript text/plain; 在生产中压缩是必备的，必须压缩。所以以上选项都和重要。还有 curl 命令默认不压缩，要加 –compressed 才行 ngx_http_ssl_module ngx_http_ssl_module模块：1、ssl on | off; 为指定虚拟机启用HTTPS protocol， 建议用listen指令代替 将来也就用不着了，用 listen 代替了 2、ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件 3、ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件 4、ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2];支持ssl协议版本，默 认为后三个 5、ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; none: 通知客户端支持ssl session cache，但实际不支持 builtin[:size]：使用OpenSSL内建缓存，为每worker进程私有 [shared:name:size]：在各worker之间使用一个共享的缓存 ngx_http_ssl_module 6、ssl_session_timeout time; 客户端连接可以复用ssl session cache中缓存的ssl参数的有效时长，默认5m 示例： 1234567server &#123; listen 443 ssl; server_name www.magedu.com; root /vhosts/ssl/htdocs; ssl on; &#125; ngx_http_rewrite_module ngx_http_rewrite_module模块： The ngx_http_rewrite_module module is used to change request URI using PCRE regular expressions, return redirects, and conditionally select configurations. 将用户请求的URI基于PCRE regex所描述的模式进行检查，而后完成重定 向替换示例： http://www.magedu.com/hn –&gt; http://www.magedu.com/henan http://www.magedu.com–&gt; https://www.magedu.com/ 在生产中，客户访问外部服务时输入的是 http ，要想把 http 重定向到 https ，就要在配置文件中添加内容，如： 123456789101112131415server &#123;listen 80 default_server;listen 443 ssl;server_name www.a.com;root /data/sitea/;ssl_certificate /etc/nginx/conf.d/a.crt;ssl_certificate_key /etc/nginx/conf.d/a.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; location / &#123;if ( $scheme = http ) &#123;rewrite / https://www.a.com/ redirect;&#125;&#125;&#125; 修改完后重启服务 nginx -s reload 就可以访问测试了 可以在远程主机上 curl -iLk www.a.com 也可以在浏览器上访问 不过还需要 DNS 解析 这就实现了 从 http 跳转到 https 上 ngx_http_rewrite_module 1、rewrite regex replacement [flag] 将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为 replacement指定的新的URI 注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个 检查；被某条件规则替换完成后，会重新一轮的替换检查 隐含有循环机制,但不超过10次；如果超过，提示500响应码，[flag]所表示 的标志位用于控制此循环机制 如果replacement是以http://或https://开头，则替换结果会直接以重向返 回给客户端, 即永久重定向301 ngx_http_rewrite_module [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作， 而后对新的URI启动新一轮重写检查；提前重启新一轮循环，不建议在location中 使用 break：重写完成后停止对当前URI在当前location中后续的其它重写操作， 而后直接跳转至重写规则配置块之后的其它配置；结束循环，建议在location中使 用 redirect：临时重定向，重写完成后以临时重定向方式直接返回重写后生成 的新URI给客户端，由客户端重新发起请求；使用相对路径,或者http://或https:// 开头，状态码：302 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给 客户端，由客户端重新发起 请求，状态码：301 ngx_http_rewrite_module 2、return return code [text]; return code URL; return URL; 停止处理，并返回给客户端指定的响应码 3、rewrite_log on | off; 是否开启重写日志, 发送至error_log（notice level） 4、set $variable value; 用户自定义变量 注意：变量定义和调用都要以$开头 ngx_http_rewrite_module 5、if (condition) { … } 条件满足时，执行配置块中的配置指令；server, location condition： （1）变量名；变量值为 空串，或者以 “0”开始，则为false ；其他均为true; （2） 以变量为操作数构成的比较表达式可使用=，！=类似的比较操作符进行测试 （3） 正则表达式模式匹配操作 ~：模式匹配，区分字符大小写 ~：模式匹配，不区分字符大小写 !~：模式不匹配，区分字符大小写 !~：模式不匹配，不区分字符大小写 （4） 文件及目录存在性判断： 测试文件的存在性： -e, !-e 存在（包括文件，目录，软链接） 测试路径为文件的可能性： -f, !-f 文件 测试指定路径为目录的可能性： -d, !-d 目录 检查文件是否有执行权限： -x, !-x 执行 实现地址重写，如： 将 http://www.a.com 跳转为 https://www.a.com ，在一台虚拟主机上实现在 nginx 服务器配置文件中添加 123456789101112131415server &#123; listen 80 default_server; listen 443 ssl; server_name www.a.com; root /data/wwwa/; ssl_certificate /etc/nginx/conf.d/a.crt; ssl_certificate_key /etc/nginx/conf.d/a.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; location / &#123; if ( $scheme = http ) &#123; rewrite / https://www.a.com/ redirect; &#125; &#125;&#125; ngx_http_referer_module ngx_http_referer_module模块： 用来阻止Referer首部无有效值的请求访问，可防止盗链1、valid_referers none|blocked|server_names|string …;定义referer首部的合法可用值，不能匹配的将是非法值none：请求报文首部没有referer首部blocked：请求报文有referer首部，但无有效值server_names：参数，其可以有值作为主机名或主机名模式 arbitrary_string：任意字符串，但可使用作通配符regular expression：被指定的正则表达式模式匹配到的字符串,要使用~开头， 例如： ~..magedu.com ngx_http_referer_module 防止盗链在网站配置文件中添加： 如： valid_referers none blocked server_names .magedu.com .mageedu.com magedu. mageedu. ~.magedu.; 123if ($invalid_referer) &#123; return 403 http://www.magedu.com; &#125; 如： 123456location ~* \\.(jpg|gif|jpeg|png)$ &#123;valid_referer none blocked www.magedu.com;if ($invalid_referer) &#123;rewrite ^/ http://www.magedu.com/403.html;&#125;&#125; ngx_http_proxy_module 反向代理 ngx_http_proxy_module模块： 转发请求至另一台主机 1、proxy_pass URL; Context:location, if in location, limit_except注意：proxy_pass后面路径不带uri时，会将location的uri传递（附加）给后端主机 12345678server &#123; ... server_name HOSTNAME; location /uri/ &#123; proxy_pass http://host[:port]; 最后没有/ &#125; ... &#125; 上面示例：http://HOSTNAME/uri –&gt; http://host/uri 如果上面示例中有 /，即：http://host[:port]/意味着：http://HOSTNAME/uri –&gt; http://host/ 即置换 ngx_http_proxy_module proxy_pass后面的路径是一个uri时，其会将location的uri替换为proxy_pass的 uri 12345678server &#123; ... server_name HOSTNAME; location /uri/ &#123; proxy_pass http://host/new_uri/; &#125; ... &#125; http://HOSTNAME/uri/ –&gt; http://host/new_uri/ ngx_http_proxy_module 如果location定义其uri时使用了正则表达式的模式，则proxy_pass之后必须不 能使用uri; 用户请求时传递的uri将直接附加至后端服务器之后 12345678server &#123; ... server_name HOSTNAME; location ~|~* /uri/ &#123; proxy_pass http://host; 不能加/ &#125; ... &#125; http://HOSTNAME/uri/ –&gt; http://host/uri/ ngx_http_proxy_module 2、proxy_set_header field value; 设定发往后端主机的请求报文的请求首部的值 Context: http, server, location proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 请求报文的标准格式如下： X-Forwarded-For: client1, proxy1, proxy2 3、proxy_cache_path; 定义可用于proxy功能的缓存；Context:http proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; ngx_http_proxy_module 4、proxy_cache zone | off; 默认off 指明调用的缓存，或关闭缓存机制；Context:http, server, location 5、proxy_cache_key string; 缓存中用于“键”的内容 默认值：proxy_cache_key $scheme$proxy_host$request_uri; 6、proxy_cache_valid [code …] time; 定义对特定响应码的响应内容的缓存时长 定义在http{…}中 示例:proxy_cache_valid 200 302 10m;proxy_cache_valid 404 1m; ngx_http_proxy_module 示例：在http配置定义缓存信息 proxy_cache_path /var/cache/nginx/proxy_cache levels=1:1:1 keys_zone=proxycache:20m inactive=120s max_size=1g;说明：proxycache:20m 指内存中缓存的大小，主要用于存放key和metadata （如：使用次数） max_size=1g 指磁盘存入文件内容的缓存空间最大值调用缓存功能，需要定义在相应的配置段，如server{…}； proxy_cache proxycache;proxy_cache_key $request_uri;proxy_cache_valid 200 302 301 1h;proxy_cache_valid any 1m; ngx_http_proxy_module 7、proxy_cache_use_stale; proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off … 在被代理的后端服务器出现哪种情况下，可以真接使用过期的缓存响应客户 端 8、proxy_cache_methods GET | HEAD | POST …; 对哪些客户端请求方法对应的响应进行缓存，GET和HEAD方法总是被缓存 ngx_http_proxy_module 9、proxy_hide_header field; 默认nginx在响应报文不传递后端服务器的首部字段Date, Server, X-Pad, X-Accel-等，用于隐藏后端服务器特定的响应首部 10、proxy_connect_timeout time; 定义与后端服务器建立连接的超时时长，如超时会出现502错误，默认为 60s，一般不建议超出75s 11、proxy_send_timeout time; 将请求发送给后端服务器的超时时长；默认为60s 12、proxy_read_timeout time; 等待后端服务器发送响应报文的超时时长，默认为60s nginx 反向代理缓存放在哪，分为两部分，一部分是放在内存中的，一部分是放在磁盘中的，内存中的缓存放的是用户访问时的 URL 和真正数据存放在磁盘的路径，还有用户的访问次数。真正的数据是放在磁盘中的，而放在磁盘中的文件是以哈希的方式进行存放。 ngx_http_headers_module 自定义添加响应报文头部 ngx_http_headers_module模块 向由代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的 值1、add_header name value [always]; 添加自定义首部 add_header X-Via $server_addr; add_header X-Cache $upstream_cache_status; add_header X-Accel $server_name; 2、add_trailer name value [always]; 添加自定义响应信息的尾部 ngx_http_fastcgi_module ngx_http_fastcgi_module模块 转发请求到FastCGI服务器，不支持php模块方式1、fastcgi_pass address; address为后端的fastcgi server的地址 可用位置：location, if in location 2、fastcgi_index name; fastcgi默认的主页资源 示例：fastcgi_index index.php; 3、fastcgi_param parameter value [if_not_empty]; 设置传递给 FastCGI服务器的参数值，可以是文本，变量或组合 ngx_http_fastcgi_module 示例1：1）在后端服务器先配置fpm server和mariadb-server2）在前端nginx服务上做以下配置： 123456location ~* \\.php$ &#123; … &#125; ngx_http_fastcgi_module 示例2：通过/pm_status和/ping来获取fpm server状态信息 12345location ~* ^/(status|ping)$ &#123; include fastcgi_params; fastcgi_pass 后端fpm服务器IP:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; &#125; ngx_http_fastcgi_module 4、fastcgi_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 定义fastcgi的缓存； path 缓存位置为磁盘上的文件系统 max_size=size 磁盘path路径中用于缓存数据的缓存空间上限 levels=levels：缓存目录的层级数量，以及每一级的目录数量 levels=ONE:TWO:THREE 示例：leves=1:2:2 keys_zone=name:size k/v映射的内存空间的名称及大小 inactive=time 非活动时长 ngx_http_fastcgi_module 5、fastcgi_cache zone | off; 调用指定的缓存空间来缓存数据 可用位置：http, server, location 6、fastcgi_cache_key string; 定义用作缓存项的key的字符串 示例：fastcgi_cache_key $request_rui; 7、fastcgi_cache_methods GET | HEAD | POST …; 为哪些请求方法使用缓存 8、fastcgi_cache_min_uses number; 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方 可被认作活动项 9、fastcgi_keep_conn on | off; 收到后端服务器响应后，fastcgi服务器是否关闭连接，建议启用长连接 10、fastcgi_cache_valid [code …] time; 不同的响应码各自的缓存时长 ngx_http_fastcgi_module 示例： 123456789101112131415http &#123; fastcgi_cache_path /var/cache/nginx/fcgi_cache levels=1:2:1 keys_zone=fcgicache:20m inactive=120s; ... server &#123; location ~* \\.php$ &#123; ... fastcgi_cache fcgicache; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; ... &#125; &#125; 练习定义四个虚拟主机，混合使用三种类型的虚拟主机 仅开放给来自于本地网络中的主机访问实现lnmp，提供多个虚拟主机 http, 提供wordpress https, 提供pma ngx_http_upstream_module ngx_http_upstream_module模块用于将多个服务器定义成服务器组，而由proxy_pass, fastcgi_pass等指令 进行引用 1、upstream name { … }定义后端服务器组，会引入一个新的上下文 默认调度算法是wrr Context: http 12345upstream httpdsrvs &#123; server ... server... ... &#125; ngx_http_upstream_module 2、server address [parameters];在upstream上下文中server成员，以及相关的参数；Context:upstream address的表示格式： unix:/PATH/TO/SOME_SOCK_FILE IP[:PORT] HOSTNAME[:PORT]parameters： weight=number 权重，默认为1 max_conns 连接后端报务器最大并发活动连接数，1.11.5后支持 max_fails=number 失败尝试最大次数；超出此处指定的次数时，server将被标 记为不可用,默认为1 fail_timeout=time 后端服务器标记为不可用状态的连接超时时长，默认10s backup 将服务器标记为“备用”，即所有服务器均不可用时才启用 down 标记为“不可用”，配合ip_hash使用，实现灰度发布 ngx_http_upstream_module 3、ip_hash 源地址hash调度方法 4、least_conn 最少连接调度算法，当server拥有不同的权重时其为wlc， 当所有后端主机连接数相同时，则使用wrr，适用于长连接 5、hash key [consistent] 基于指定的key的hash表来实现对请求的调度， 此处的key可以直接文本、变量或二者组合 作用：将请求分类，同一类请求将发往同一个upstream server，使用 consistent参数，将使用ketama一致性hash算法，适用于后端是Cache服务器 （如varnish）时使用 hash $request_uri consistent; hash $remote_addr; 6、keepalive 连接数N; 为每个worker进程保留的空闲的长连接数量,可节约nginx端口，并减少连 接管理的消耗 ngx_http_upstream_module 7、health_check [parameters]; 健康状态检测机制；只能用于location上下文 常用参数： interval=time检测的频率，默认为5秒fails=number：判定服务器不可用的失败检测次数；默认为1次 passes=number：判定服务器可用的失败检测次数；默认为1次 uri=uri：做健康状态检测测试的目标uri；默认为/match=NAME：健康状态检测的结果评估调用此处指定的match配置块 注意：仅对nginx plus有效 ngx_http_upstream_module 8 match name { … }对backend server做健康状态检测时，定义其结果判断机制；只能用于http上下 文常用的参数： status code[ code …]: 期望的响应状态码 header HEADER[operator value]：期望存在响应首部，也可对期望的响 应首部的值基于比较操作符和值进行比较 body：期望响应报文的主体部分应该有的内容 注意：仅对nginx plus有效 ngx_stream_core_module nginx的其它的二次发行版 ： Tengine：由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大 访问量网站的需求，添加了很多高级功能和特性。Tengine的性能和稳定性已经在 大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目标是打造一个高 效、稳定、安全、易用的Web平台。从2011年12月开始，Tengine成为一个开源 项目，官网 http://tengine.taobao.org/ OpenResty：基于 Nginx 与 Lua 语言的高性能 Web 平台ngx_stream_core_module模块 模拟反代基于tcp或udp的服务连接，即工作于传输层的反代或调度器 ngx_stream_core_module 1、stream { … } 定义stream相关的服务；Context:main 1234567891011stream &#123; upstream mysqlsrvs &#123; server 192.168.22.2:3306; server 192.168.22.3:3306; least_conn; &#125; server &#123; listen 10.1.0.6:3306; proxy_pass mysqlsrvs; &#125; &#125; ngx_stream_core_module 2、listen listen address:port [ssl] [udp] [proxy_protocol] [backlog=number] [bind] [ipv6only=on|off] [reuseport][so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; ngx_stream_proxy_module ngx_stream_proxy_module模块 可实现代理基于TCP，UDP (1.9.13), UNIX-domain sockets的数据流1 proxy_pass address; 指定后端服务器地址2 proxy_timeout timeout; 无数据传输时，保持连接状态的超时时长 默认为10m3 proxy_connect_timeout time; 设置nginx与被代理的服务器尝试建立连接的超时时长 默认为60s 示例 12345678910111213stream &#123; upstream mysqlsrvs &#123; server 192.168.0.10:3306; server 192.168.0.11:3306; hash $remote_addr consistent; &#125; server &#123; listen 172.16.100.100:3306; proxy_pass mysqlsrvs; proxy_timeout 60s; proxy_connect_timeout 10s; &#125; &#125;","categories":[],"tags":[]},{"title":"","slug":"Linux 防火墙各种规则实战应用","date":"2018-08-09T07:50:51.234Z","updated":"2018-08-09T07:50:32.128Z","comments":true,"path":"2018/08/09/Linux 防火墙各种规则实战应用/","link":"","permalink":"http://yoursite.com/2018/08/09/Linux 防火墙各种规则实战应用/","excerpt":"layout: posttitle: Linux 防火墙各种规则实战应用date: 2017-7-03tags: Linux 防火墙 防火墙的概念iptables的基本认识iptables的组成iptables的基本语法iptables之forward的概念iptables之地址转换法则SNAT源地址转换的具体实现DNAT目标地址转换的具体实现firewalld介绍firewalld配置命令rich规则 安全技术入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络 访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主， 提供有针对性的指导措施和安全决策依据。一般采用旁路部署方式入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包 的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析 判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般 采用在线部署方式防火墙（ FireWall ）：隔离功能，工作在网络或主机边缘，对进出网络或主机的 数据包基于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一 组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允 许访问的策略","text":"layout: posttitle: Linux 防火墙各种规则实战应用date: 2017-7-03tags: Linux 防火墙 防火墙的概念iptables的基本认识iptables的组成iptables的基本语法iptables之forward的概念iptables之地址转换法则SNAT源地址转换的具体实现DNAT目标地址转换的具体实现firewalld介绍firewalld配置命令rich规则 安全技术入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络 访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主， 提供有针对性的指导措施和安全决策依据。一般采用旁路部署方式入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包 的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析 判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般 采用在线部署方式防火墙（ FireWall ）：隔离功能，工作在网络或主机边缘，对进出网络或主机的 数据包基于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一 组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允 许访问的策略 防火墙的分类防火墙的分类主机防火墙：服务范围为当前主机网络防火墙：服务范围为防火墙一侧的局域网硬件防火墙：在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件 实现，Checkpoint,NetScreen 软件防火墙：运行于通用硬件平台之上的防火墙的应用软件网络层防火墙：OSI下面第三层 应用层防火墙/代理服务器：代理网关，OSI七层 网络型防火墙网络层防火墙 包过滤防火墙 网络层对数据包进行选择，选择的依据是系统内设置的过滤逻辑，被称为访问控制 列表（ACL），通过检查数据流中每个数据的源地址，目的地址，所用端口号和协议 状态等因素，或他们的组合来确定是否允许该数据包通过 优点：对用户来说透明，处理速度快且易于维护 缺点：无法检查应用层数据，如病毒等 应用层防火墙应用层防火墙/代理服务型防火墙（Proxy Service） 将所有跨越防火墙的网络通信链路分为两段 内外网用户的访问都是通过代理服务器上的“链接”来实现 优点：在应用层对数据进行检查，比较安全 缺点：增加防火墙的负载 现实生产环境中所使用的防火墙一般都是二者结合体 即先检查网络数据，通过之后再送到应用层去检查 iptables的基本认识Netfilter组件 内核空间，集成在linux内核中 扩展各种网络服务的结构化底层框架 内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、FORWARD、 PREROUTING、POSTROUTING)，而这五个hook function向用户开放，用户可以通过一 个命令工具（iptables）向其写入规则 由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则被分组放 在链（chain）上 三种报文流向： 流入本机：PREROUTING –&gt; INPUT–&gt;用户空间进程 流出本机：用户空间进程 –&gt;OUTPUT–&gt; POSTROUTING 转发：PREROUTING –&gt; FORWARD –&gt; POSTROUTING iptables的基本认识防火墙工具iptables 命令行工具，工作在用户空间 用来编写规则，写好的规则被送往netfilter，告诉内核如何去处理信息包firewalld CentOS 7引入了新的前端管理工具管理工具： firewall-cmd 命令行 firewall-config 图形 iptables的组成 iptables由四个表和五个链以及一些规则组成 四个表table：filter、nat、mangle、raw filter表:过滤规则表，根据预定义的规则过滤符合条件的数据包 nat表:network address translation 地址转换规则表 mangle:修改数据标记位规则表 Raw:关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度 优先级由高到低的顺序为:raw–&gt;mangle–&gt;nat–&gt;filter 五个内置链chain INPUT OUTPUT FORWARD PREROUTING POSTROUTING IPTABLES和路由路由功能发生的时间点 报文进入本机后 • 判断目标主机是否为本机 是：INPUT 否：FORWARD 报文离开本机之前 • 判断由哪个接口送往下一跳内核中数据包的传输过程 内核中数据包的传输过程 当一个数据包进入网卡时，数据包首先进入PREROUTING链，内核根据数据包目的 IP判断是否需要转送出去 如果数据包就是进入本机的，数据包就会沿着图向下移动，到达INPUT链。数据包 到达INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些 数据包经过OUTPUT链，然后到达POSTROUTING链输出 如果数据包是要转发出去的，且内核允许转发，数据包就会向右移动，经过 FORWARD链，然后到达POSTROUTING链输出 iptables规则规则rule：根据规则的匹配条件尝试匹配报文，对匹配成功的报文根据规则定义的 处理动作作出处理 匹配条件：默认为与条件，同时满足 基本匹配：IP,端口,TCP的Flags（SYN,ACK等） 扩展匹配：通过复杂高级功能匹配 处理动作：称为target，跳转目标 内建处理动作：ACCEPT(接受),DROP（抛弃）,REJECT（拒绝）,SNAT,DNATMASQUERADE,MARK,LOG… 自定义处理动作：自定义chain，利用分类管理复杂情形规则要添加在链上，才生效；添加在自定义上不会自动生效链chain： 内置链：每个内置链对应于一个钩子函数 自定义链：用于对内置链进行扩展或补充，可实现更灵活的规则组织管理机制； 只有Hook钩子调用自定义链时，才生效 定义防火墙规则应注意： 条件越严的、越苛刻的、范围小的尽量放在前面，相对不太严格的、宽松的放在后面，这个宽松说得是指范围。 在防火墙规则中，如果没有定义任何规则时，系统默认的规则是 ACCEPT 的。 也可以把默认的规则进行修改，如： 把默认规则改为 DROP （注意，改之前一定要把自己本机摘出来，不然自己也不能连接了） iptables -A INPUT -s 192.168.30.1 -j ACCEPT # 表示在规则中添加192.168.30.1 主机访问时允许连接。iptables -P INPUT DROP # 表示把默认规则改为 DROP 也可以把规则里面的任意一条进行修改 ，如：原来在规则中 192.168.30.6 这个主机是拒绝的，编号没第二条，现在要把他改为接受 iptables -R INPUT 2 -s 192.168.30.6 -j ACCEPT 这就表示把192.168.30.6 这台主机改为 接受，允许连接。 iptables -F : 清空所有规则 iptables -vnL –line-numbers : 表示查看规则中的信息，并且前面带有编号 iptables添加要点 iptables规则添加时考量点 要实现哪种功能：判断添加在哪张表上 报文流经的路径：判断添加在哪个链上 报文的流向：判断源和目的 匹配规则：业务需要 链上规则的次序，即为检查的次序，因此隐含一定的法则 同类规则(访问同一应用)，匹配范围小的放上面 不同类规则(访问不同应用)，匹配到报文频率较大的放上面 将那些可由一条规则描述的多个规则合并为一个 设置默认策略 实验环境准备： Centos7: systemctl stop firewalld.service systemctl disable firewalld. service Centos6:service iptables stop; chkconfig iptables off iptables命令man 8 iptables iptables [-t table] {-A|-C|-D} chain rule-specification iptables [-t table] -I chain [rulenum] rule-specification iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options…] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name rule-specification = [matches…] [target] match = -m matchname [per-match-options] target = -j targetname [per-target-options] iptables命令 规则格式：iptables [-t table] SUBCOMMAND chain [-m matchname [per-matchoptions]] -j targetname [per-target-options] -t table： raw, mangle, nat, [filter]默认 SUBCOMMAND： 1、链管理： -N：new, 自定义一条新的规则链 -X：delete，删除自定义的空的规则链 -P：Policy，设置默认策略；对filter表中的链而言，其默认策略有： ACCEPT：接受 DROP：丢弃 -E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除 现在有几个组，分别为 web fileshare mange ， 其中 web 组中定义了 http httpd 两种协议 fileshare 组中定义了 samba ftp 两种协议 ， mange 组中定义了 ssh telnet 两种协议 将来对组进行定义相应的规则、自定义的链，将来看到组名就代表着组中的成员，自定义的链将来必须跟系统自带的链相关联才能起效果 创建一个自定义的链iptables -N WEB也可以把自定义的链给删除了iptables -X WEB接下来给这个自定义的链加规则，怎么加呢，我们希望 http https 属于这个链，希望将来别的主机可以通过 这个种协议来访问本机。iptables -A WEB -p tcp -m multiport –dports 80,443 -j ACCEPT现在这个规则还不能使用，还需要把这个自定义链关联到 系统自带的链上去iptables -A INPUT -j WEB 表示客户端访问本机的 input时 ，会跳转到 web 链上去，如果 web 链上有符合条件的就直接回应，如果没有就继续回到 input 继续往下匹配 修改自定义链这样就可以实现模块化，INPUT 链中只定各自 自定义的链，然后把规则定义在各自自定义链中，将来想修改 INPUT 链中的规则时 就不用直接修改 input 了，把对应的自定义链修改就可以了。比如 ： 现在想增加一条规则，允许客户端访问本机的 8080 端口，就可以直接在 WEB 链中添加规则就可以。 iptables -A WEB -p tcp –dport 8080 -j ACCEPT这样客户端就可以访问本机的8080端口了也可以直接在原来的规则上进行修改ipyables -R WEB 1 -p -m multiport –dports 80,445,8080 -j ACCEPT 删除一个自定义链先把关联在系统自带链中的规则进行删除iptables -D INPUT 1再把自定义链中的规则清空iptables -D WEB 1最后删除自定义链iptables -X WEB 注意： 创建一个成熟的自定义链，需要先创建一个自定义链，再给它定义规则，最后把关联到系统自带的链上。 删除的时应先把系统自带链中的自定义链规则删除，再把自定义链中的规则删除，最后再删除自定义链。 必须按照顺序来，不然会报错。这就是自定义链的内容，一般在生产中，定义的规则比较复杂时，就可以采用这种自定义链来进行管理，就相当于把系统自带链模块化了。 iptables命令2、查看： -L：list, 列出指定鏈上的所有规则，本选项须置后 -n：numberic，以数字格式显示地址和端口号 -v：verbose，详细信息 -vv 更详细-x：exactly，显示计数器结果的精确值,而非单位转换后的易读值 –line-numbers：显示规则的序号常用组合： –vnL –vvnxL –line-numbers -S selected,以iptables-save 命令格式显示链上规则 iptables命令 3、规则管理： -A：append，追加 -I：insert, 插入，要指明插入至的规则编号，默认为第一条 -D：delete，删除 (1) 指明规则序号 (2) 指明规则本身-R：replace，替换指定链上的指定规则编号 -F：flush，清空指定的规则链-Z：zero，置零 iptables的每条规则都有两个计数器 (1) 匹配到的报文的个数 (2) 匹配到的所有报文的大小之和chain：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING iptables命令 匹配条件 基本：通用的，PARAMETERS 扩展：需加载模块，MATCH EXTENTIONS 1、基本匹配条件：无需加载模块，由iptables/netfilter自行提供 [!]-s, –source address[/mask][,…]：源IP地址或范围 [!] -d, –destination address[/mask][,…]：目标IP地址或范围 [!] -p, –protocol protocol：指定协议，可使用数字如0（all） protocol: tcp, udp, icmp, icmpv6, udplite,esp, ah, sctp, mh or “all“ 参看：/etc/protocols [!] -i, –in-interface name：报文流入的接口；只能应用于数据报文流入环节，只应用于 INPUT、FORWARD、PREROUTING链 [!] -o, –out-interface name：报文流出的接口；只能应用于数据报文流出的环节，只应用 于FORWARD、OUTPUT、POSTROUTING链 iptables命令 2 扩展匹配条件：需要加载扩展模块（/usr/lib64/xtables/*.so），方可生效 查看帮助 man iptables-extensions (1)隐式扩展：在使用-p选项指明了特定的协议时，无需再用-m选项指明扩展模块的扩展 机制，不需要手动加载扩展模块 tcp协议的扩展选项 [!] –source-port, –sport port[:port]：匹配报文源端口,可为端口范围 [!] –destination-port,–dport port[:port]：匹配报文目标端口,可为范围 [!] –tcp-flags mask comp mask 需检查的标志位列表，用,分隔 例如 SYN,ACK,FIN,RST comp 在mask列表中必须为1的标志位列表，无指定则必须为0，用,分隔 tcp协议的扩展选项示例： –tcp-flags SYN,ACK,FIN,RST SYN 表示要检查的标志位为 SYN,ACK,FIN,RST四个，其中SYN必须为1，余下的必须为0 –tcp-flags SYN,ACK,FIN,RST SYN,ACK –tcp-flags ALL ALL –tcp_flags ALLNONE [!] –syn：用于匹配第一次握手 相当于：–tcp-flags SYN,ACK,FIN,RST SYN iptables命令udp [!] –source-port, –sport port[:port]：匹配报文的源端口；可以是端口 范围 [!] –destination-port,–dport port[:port]：匹配报文的目标端口；可以 是端口范围icmp [!] –icmp-type {type[/code]|typename} type/code 0/0 echo-reply icmp应答 8/0 echo-request icmp请求 也可以指定协议制定端口来定义规则如： 拒绝 192.168.30.6 这台主机访问本机的 tcp 445 139 这两个端口iptables -A INPUT -s 192.168.30.6 -p tcp –dport 445 -j REJECTiptables -A INPUT -s 192.168.30.6 -p tcp –dport 139 -j REJECT 设定规则拒绝 tcp 协议第一次握手iptables -A INPUT -p tcp –syn -j REJECT 这种设定表示任何主机都不能连接本机，但是已经连接上的用户继续维护，新建连接的主机被拒绝了。 现在有两台主机，192.168.30.7 192.168.30.6 ，现在要求 192.168.30.7 能 ping 通 192.168.30.6 ，但是 192.168.30.6 ping 不同 192.168.30.7 ，操作如下：在 192.168.30.7 主机上输入 ： iptables -A INPUT -p icmp –icmp-type 8 -j REJECT 这样也就实现了上面的效果 (2)显式扩展：必须使用-m选项指明要调用的扩展模块的扩展机制，要手动加载 扩展模块 [-m matchname [per-match-options]] 现在要求其他主机不能访问本机的 80 21 445 这三个端口，操作如下：iptables -A INPUT -p tcp -m multiport –dports 21,80,445 -j REJECT 在生产中，一般配置服务器，都只对外开放特定的端口 80 22 ，剩余其他的都不允许访问。现在模拟一下，先拿一台主机禁止任何主机访问，然后在进行开启 80 22 两个端口加策略时首先把本机先摘出来再进行加策略先把全部禁止访问iptables -A INPUT -s 192.168.30.1 -j REJECTiptables -A OUTPUT -d 192.168.30.1 -j REJECTiptables -A INPUT -j REJECTiptables -A OUTPUT -j REJECT然后再把 80 22 两个端口开放出来iptables -I INPUT -p tcp -m multiport -dports 22,80 -j ACCEPTiptables -I OUTPUT -p tcp -m multiport -sports 22,80 -j ACCEPT 这样就满足了以上要求 现在有要求，要求其他任意主机只允许访问本机的 samba httpd ssh 三种服务，剩余其他都不允许。同样先把所有端口都禁止然后在进行开放特定端口禁止之前先把本机摘出来iptables -A INPUT -s 192.168.30.1 -j REJECTiptables -A OUTPUT -d 192.168.30.1 -j REJECTiptables -A INPUT -j REJECTiptables -A OUTPUT -j REJECT然后在开放特定端口iptables -I INPUT -p tcp -m multiport -dports 22,80,139,445 -j ACCEPTiptables -I INPUT 2 -p udp -m multiport -dports 137,138 -j ACCEPT因为 samba 服务有四个端口，tcp 139 445 udp 137 138 这样就实现以上要求 iptables命令 处理动作： -j targetname [per-target-options] 简单： ACCEPT，DROP扩展： REJECT：–reject-with:icmp-port-unreachable默认 RETURN：返回调用链 REDIRECT：端口重定向 LOG：记录日志，dmesg MARK：做防火墙标记 DNAT：目标地址转换 SNAT：源地址转换 MASQUERADE：地址伪装 … 自定义链： iptables命令显式扩展：必须显式地指明使用的扩展模块进行的扩展使用帮助： CentOS 6: man iptables CentOS 7: man iptables-extensions 1、multiport扩展 以离散方式定义多端口匹配,最多指定15个端口 [!] –source-ports,–sports port[,port|,port:port]… 指定多个源端口 [!] –destination-ports,–dports port[,port|,port:port]… 指定多个目标端口 [!] –ports port[,port|,port:port]…多个源或目标端口 示例： iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.10 -p tcp -m multiport –dports 20:22,80 -j ACCEPT iptables命令2、iprange扩展指明连续的（但一般不是整个网络）ip地址范围 [!] –src-range from[-to] 源IP地址范围 [!] –dst-range from[-to] 目标IP地址范围 示例： iptables -A INPUT -d 172.16.1.100 -p tcp –dport 80 -m iprange –srcrange 172.16.1.5-172.16.1.10 -j DROP iptables命令3、mac扩展 指明源MAC地址适用于：PREROUTING, FORWARD，INPUT chains [!] –mac-source XX:XX:XX:XX:XX:XX 示例： iptables -A INPUT -s 172.16.0.100 -m mac –mac-source 00:50:56:12:34:56 -j ACCEPT iptables -A INPUT -s 172.16.0.100 -j REJECT iptables命令4、string扩展对报文中的应用层数据做字符串模式匹配检测 –algo {bm|kmp}：字符串匹配检测算法 bm：Boyer-Moore kmp：Knuth-Pratt-Morris –from offset 开始偏移–to offset 结束偏移 [!] –string pattern：要检测的字符串模式 [!] –hex-string pattern：要检测字符串模式，16进制格式 示例： iptables -A OUTPUT -s 172.16.100.10 -d 0/0 -p tcp –sport 80 -m string - -algo bm –string “google” -j REJECT 现在客户端可以访问主服务器的 80 端口，主服务器上有两个外部网页，一个是 mage 网页，一个是 google 网页，现在要求客户端访问本机的80 端口时，只能查看到 mage 页面，不能查看 googe 页面。怎么操作？ 在服务器端iptables -A INPUT -s 192.168.30.1 -j REJECTiptables -A INPUT -j REJECTiptables -A INPUT -p tcp –dport 80 -j ACCEPTecho welcome to magedu &gt; /var/www/html/index1.htmlecho welcome to google &gt; /var/www/html/index2.htmliptables -A OUTPUT -m string –algo bm –string “google” -j REJECT这样客户端访问本机的 80 端口时就不能查看到 google 页面，而 magedu 页面还能访问。 5、time扩展根据将报文到达的时间与指定的时间范围进行匹配–datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] 日期 –datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]] –timestart hh:mm[:ss] 时间 –timestop hh:mm[:ss] [!] –monthdays day[,day…] 每个月的几号 [!] –weekdays day[,day…] 星期几 –kerneltz：内核时区，不建议使用，CentOS7系统默认为UTC注意： centos6 不支持kerneltz ，–localtz指定本地时区(默认) 示例： iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.10 -p tcp –dport 80 -m time –timestart 14:30 –timestop 18:30 –weekdays Sat,Sun –kerneltz -j DROP iptables命令6、connlimit扩展 根据每客户端IP做并发连接数数量匹配可防止CC(Challenge Collapsar挑战黑洞)攻击 –connlimit-upto n：连接的数量小于等于n时匹配–connlimit-above n：连接的数量大于n时匹配 通常分别与默认的拒绝或允许策略配合使用 示例： iptables -A INPUT -d 172.16.100.10 -p tcp –dport 22 -m connlimit –connlimit-above 2 -j REJECT iptables命令7、limit扩展 基于收发报文的速率做匹配 令牌桶过滤器 (限流，达到一定程度就要限流) –limit rate[/second|/minute|/hour|/day] （表示按时间限制） –limit-burst number （初始值，表示这设定的值之前不限，超过就开始限）示例： iptables -I INPUT -d 172.16.100.10 -p icmp –icmp-type 8 -m limit –limit 10/minute – limit-burst 5 -j ACCEPT 表示前 五个 不限，超过五个每秒钟只限 十个 iptables -I INPUT 2 -p icmp -j REJECT iptables命令8、state扩展根据”连接追踪机制“去检查连接的状态，较耗资源conntrack机制：追踪本机上的请求和响应之间的关系状态有如下几种： NEW：新发出请求；连接追踪信息库中不存在此连接的相关信息条目，因 此，将其识别为第一次发出的请求 ESTABLISHED：NEW状态之后，连接追踪信息库中为其建立的条目失效之 前期间内所进行的通信状态 RELATED：新发起的但与已有连接相关联的连接，如：ftp协议中的数据连 接与命令连接之间的关系 INVALID：无效的连接，如flag标记不正确 UNTRACKED：未进行追踪的连接，如raw表中关闭追踪 iptables命令 [!] –state state 示例： iptables -A INPUT -d 172.16.1.10 -p tcp -m multiport –dports 22,80 -m state – state NEW,ESTABLISHED -j ACCEPT iptables -A OUTPUT -s 172.16.1.10 -p tcp -m multiport –sports 22,80 -m state – state ESTABLISHED -j ACCEPT 已经追踪到的并记录下来的连接信息库 /proc/net/nf_conntrack 调整连接追踪功能所能够容纳的最大连接数量 /proc/sys/net/nf_conntrack_max 如果修改这个值，如： echo net.nf_conntrack_max=2000000 &gt;&gt; /etc/sysctl.conf 生效一下 ： sysctl -p 这个值也不是越大越好，值越大性能消耗就越多 不同的协议的连接追踪时长 /proc/sys/net/netfilter/注意：CentOS7 需要加载模块： modprobe nf_conntrack iptables命令 iptables的链接跟踪表最大容量为/proc/sys/net/nf_conntrack_max，各种状态的超 时链接会从表中删除；当模板满载时，后续连接可能会超时 解决方法两个： (1) 加大nf_conntrack_max 值 vi /etc/sysctl.conf net.nf_conntrack_max = 393216 net.netfilter.nf_conntrack_max = 393216(2) 降低 nf_conntrack timeout时间 vi /etc/sysctl.conf net.netfilter.nf_conntrack_tcp_timeout_established = 300 net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60 net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120 iptables -t nat -L -n iptables命令 开放被动模式的ftp服务 (1) 装载ftp连接追踪的专用模块： 跟踪模块路径： /lib/modules/kernelversion/kernel/net/netfilter vim /etc/sysconfig/iptables-config 配置文件 IPTABLES_MODULES=“nf_conntrack_ftp” modproble nf_conntrack_ftp (2) 放行请求报文： 命令连接：NEW, ESTABLISHED 数据连接：RELATED, ESTABLISHED iptables –I INPUT -d LocalIP -p tcp -m state –state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -d LocalIP -p tcp –dport 21 -m state –state NEW -j ACCEPT (3) 放行响应报文： iptables -I OUTPUT -s LocalIP -p tcp -m state –state ESTABLISHED -j ACCEPT 开放被动模式的ftp服务示例yum install vsftpdsystemctl start vsftpdmodprobe nf_conntrack_ftpiptables -Fiptables -A INPUT -m state –state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -p tcp –dport 21 -m state –state NEW -j ACCEPTiptables -A OUTPUT -m state –state ESTABLISHED -j ACCEPTiptables -P INPUT DROPiptables -P OUTPUT DROPiptables -vnL iptables命令Target： ACCEPT， DROP， REJECT， RETURN LOG， SNAT， DNAT， REDIRECT， MASQUERADE，.. LOG: 非中断target,本身不拒绝和允许,放在拒绝和允许规则前 并将日志记录在/var/log/messages系统日志中 –log-level level 级别： emerg, alert, crit, error, warning, notice, info or debug –log-prefix prefix 日志前缀，用于区别不同的日志，最多29个字符示例：iptables -I INPUT -s 10.0.1.0/24 -p tcp -m multiport –dports 80,21,22,23 -m state –state NEW -j LOG –log-prefix “new connections: “ 一般在生产中一般不加，除非用于排错等可能添加 iptables命令任何不允许的访问，应该在请求到达时给予拒绝规则在链接上的次序即为其检查时的生效次序基于上述，规则优化 1 安全放行所有入站和出站的状态为ESTABLISHED状态连接 2 谨慎放行入站的新请求 3 有特殊目的限制访问功能，要在放行规则之前加以拒绝 4 同类规则（访问同一应用），匹配范围小的放在前面，用于特殊处理 5 不同类的规则（访问不同应用），匹配范围大的放在前面 6 应该将那些可由一条规则能够描述的多个规则合并为一条 7 设置默认策略，建议白名单（只放行特定连接） 1） iptables -P，不建议 2） 建议在规则的最后定义规则做为默认策略 在生产中，搭建 LAMP 架构，该怎么来添加防火墙策略。如： 有三台服务器，A B C ，A 用来做 apache + php-fpm ， B 用来做 mysql 数据库， C 是管理服务器。然后在不同服务器上添加策略lampclient —&gt; apache+php-fpm A –&gt; mysql B A ：添加前把策略先清空一下iptables -F然后把本服务器回环地址摘出来，因为 apache 连接 php-fpm 程序时，要连接 php-fpm 的9000 端口，而这个连接是在本机连接的，所以如果不加这条规则，外部服务器将无法连接 php 程序。iptables -A INPUT -i lo -j ACCEPT接下来开启本服务器的 80 端口允许所有人能够访问iptables -A INPUT -p tcp –dport 80 -j ACCEPT接下来还要把管理服务器的 22 端口摘出来，保证能够远程连接进行管路iptables -A INPUT -s CIP -p tcp –dport 22 -j ACCEPT添加禁止所有连接本服务器的策略iptables -A INPUT -j REJECT B:先清空所有策略iptables -F允许外部服务器连接本服务器的 3306 端口iptables -A INPUT -s AIP -p tcp –dport 3306 -j ACCEPT开启本服务器的 22 端口，允许管理服务器能够远程管理iptables -A INPUT -s CIP -p tcp –dport 22 -j ACCEPT添加禁止所有连接本服务器的策略iptables -A INPUT -j REJECT iptables命令规则有效期限： 使用iptables命令定义的规则，手动删除之前，其生效期限为kernel存活期限保存规则： 保存规则至指定的文件CentOS 6 service iptables save 将规则覆盖保存至/etc/sysconfig/iptables文件中 CentOS 7 可用下面方法保存规则 iptables-save &gt; /PATH/TO/SOME_RULES_FILE 生产中添加完规则以后一定要保存在文件中，不然重启服务或机器规则会清空的。如： iptables-save &gt; “（这个文件由自己设定，如：/etc/iptables-20180701）”如果把规则清空后还可以还原 如：iptables-restore &lt; /etc/iptables-20180701这样还是手动执行的，如果想机器重启后开机这些规则自动就启用，可以写到启动服务脚本中chmod +x /etc/rc.d/rc.localecho ‘iptables-restore &lt; /etc/iptables-20180701’ &gt;&gt; /etc/rc.d/rc.local或者写进计划任务中vim /etc/crontabiptables-restore &lt; /etc/iptables-20180701不过一般还是建议放在服务脚本中 而 centos 6 上不用这么做，因为 在 6 上就有 iptables 这个服务，我们只需用把规则写进文件中，然后这个服务设为开机启动就可以。 iptables命令CentOS 6： service iptables restart 会自动从/etc/sysconfig/iptables 重新载入规则CentOS 7 重新载入预存规则文件中规则： iptables-restore &lt; /PATH/FROM/SOME_RULES_FILE -n, –noflush：不清除原有规则 -t, –test：仅分析生成规则集，但不提交 开机自动重载规则开机自动重载规则文件中的规则： (1) 用脚本保存各iptables命令；让此脚本开机后自动运行/etc/rc.d/rc.local文件中添加脚本路径 /PATH/TO/SOME_SCRIPT_FILE(2) 用规则文件保存各规则，开机时自动载入此规则文件中的规则 /etc/rc.d/rc.local文件添加 iptables-restore &lt; /PATH/FROM/IPTABLES_RULES_FILE(3)自定义Unit File，进行iptables-restore 网络防火墙iptables/netfilter网络防火墙： (1) 充当网关(2) 使用filter表的FORWARD链 注意的问题： (1) 请求-响应报文均会经由FORWARD链，要注意规则的方向性 (2) 如果要启用conntrack机制，建议将双方向的状态为ESTABLISHED的报 文直接放行 公司中的网络是一台服务器跟外网连接的，然后公司中的其他主机连接外网都有这台主机进行转发，然后在这台主机的网络防火墙中设定公司里在每礼拜 1 3 5 的早上9点钟到下午的6点钟都能上网，并且什么时候都不能登录“youku”这样的网站。先把”youku”的这种网络加进规则中iptables -I FORWORD -m string –algo bm –sting “youku.com” -j REJECT在设定规定时间内不能上网的规则iptables -A FORWORD -m time –timestart 1:00 –timestop 10:00 –weekdays 1,3,5 -j REJECT这样就可以实现以上要求 现在又有要求，要做到只允许公司内容可以连接互联网上的服务器，但是互联网上的服务器不能连接公司内部网络。还是在公司内部往外转发的这台服务器上制定防火墙规则先把所有连接都拒绝iptables -A FORWORD -j REJECT在设定外网连接公司内网时只有已经连接的状态或者是有关联连接的这种状态才允许连进公司内网中iptables -I FORWORD -m state –state ESTABLISHED,RELATED -j ACCEPT在设定新状态连接只能是公司内网连接外网，外网不能连接内网,如： 内网网段是 192.168.30.0/24iptables -I FORWORD 2 -s 192.168.30.0/24 -m state –state NEW -j ACCEPT这样就实现了外网不能访问内网，实现了公司安全。 现在又有新的要求了，公司内部搭建了一个外部服务器，允许外网的任意客户端只能对公司内部的这一台服务器进行访问，怎么添加规则？外部服务器的IP 为 192.168.30.7还是在转发外网的服务器上添加规则，在上面的规则基础上进行添加iptables -I FORWORD 2 -d 192.168.30.7 -p tcp –dport 80 -m state NEW -j ACCEPT这样就实现了外网只能连接内网的 外部服务器，其他的服务器不能访问，但是内网可以随意访问外网。 私有地址端：分别为 A : 10.0.0.0/8 B ： 172.16.0.0/16 - 172.31.0.0/16 合成超网为 ： 172.16.0.0/12 C : 192.168.0.0/24 - 192.168.255.0/24 合成超网 ： 192.168.0.0/16 NATNAT: network address translation PREROUTING，INPUT，OUTPUT，POSTROUTING 请求报文：修改源/目标IP，由定义如何修改 响应报文：修改源/目标IP，根据跟踪机制自动实现SNAT：source NAT POSTROUTING, INPUT 让本地网络中的主机通过某一特定地址访问外部网络，实现地址伪装 请求报文：修改源IPDNAT：destination NAT PREROUTING , OUTPUT 把本地网络中的主机上的某服务开放给外部网络访问(发布服务和端口映射)， 但隐藏真实IP 请求报文：修改目标IPPNAT: port nat，端口和IP都进行修改 SNATnat表的target： SNAT：固定IP –to-source [ipaddr[-ipaddr]][:port[-port]] –randomiptables -t nat -A POSTROU TING -s LocalNET ! -d LocalNet -j SNAT –tosource ExtIP示例： iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j SNAT – to-source 172.18.1.6-172.18.1.9 SNATMASQUERADE：动态IP，如拨号网络 –to-ports port[-port] –randomiptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j MASQUERADE示例： iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j MASQUERADE 实验： 实现 SNAT那三台主机来模拟拓扑，一个为局域网地址： 192.168.30.0/24 ， 一个为外网地址 ： 10.0.0.0/8 还有一个为 NAT 服务器，服务器上有两个网卡，一个内网网卡接口IP 为 192.168.30.17 另一个外网网卡接口IP 为 10.0.0.254现在要求局域网里的主机通过 NAT 服务器能够访问外网中的服务器 接下来首先来配置 NAT 服务器iptables -t nat -A POSTROUTING -s 192.168.30.0/24 -j SNAT –to-source 10.0.0.254这个规则是 NAT 服务器连接外网的地址是固定的，是静态地址或者 NAT 服务器是动态地址，连接外网的地址不是固定的，可以这样添加：iptables -t nat -A POSTROUTING -s 192.168.30.0/24 -j MASQUERADE 实验 ： 实现 DNATiptables -t nat -A PREROUTING -d 10.0.0.254 -p tcp –dport 80 -j DNAT –to-destination 192.168.30.7 表示外网客户端访问 NAT 服务器的80 端口时，就自动转发到内网中端口为 80 的外部服务器192.168.30.7 这台主机，不过也有可能内部端口不是80 ，为8080 也能转发。 DNATDNAT--to-destination [ipaddr[-ipaddr]][:port[-port]] iptables -t nat -A PREROUTING -d ExtIP -p tcp|udp –dport PORT -j DNAT –to-destination InterSeverIP[:PORT]示例： iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp –dport 22 -j DNAT –to-destination 10.0.1.22 iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp –dport 80 -j DNAT –to-destination 10.0.1.22:8080 转发REDIRECT： NAT表 可用于：PREROUTING OUTPUT 自定义链 通过改变目标IP和端口，将接受的包转发至不同端口 –to-ports port[-port] 示例： iptables -t nat -A PREROUTING -d 172.16.100.10 -p tcp –dport 80 -j REDIRECT –to-ports 8080 现在公司有一外部服务器，端口为80，但是为了防止黑客攻击，一般都把端口号进行修改，如： 修改为 8080，但是外界客户访问时访问的是 80 端口，所以就要在防火墙策略中实现端口转发，如下：iptables -t nat -A PREROUTING -d 192.168.30.7 -p tcp –dport 80 -j REDIRECT –to-ports 8080表示客户端访问公司里外部服务器 192.168.30.7 这台服务器的 80 端口时，就给转发到设定的8080端口，是把本机的80 转发为 8080 注意： 这个规则是在外部服务器上添加，不在 NAT 服务器上这就叫做端口转发 firewalld服务firewalld是CentOS 7.0新推出的管理netfilter的工具firewalld是配置和监控防火墙规则的系统守护进程。可以实现 iptables,ip6tables,ebtables的功能firewalld服务由firewalld包提供firewalld支持划分区域zone,每个zone可以设置独立的防火墙规则归入zone顺序： 先根据数据包中源地址，将其纳为某个zone 纳为网络接口所属zone 纳入默认zone，默认为public zone,管理员可以改为其它zone网卡默认属于public zone,lo网络接口属于trusted zone firewalld配置firewall-cmd –get-services 查看预定义服务列表 /usr/lib/firewalld/services/*.xml预定义服务的配置三种配置方法 firewall-config （firewall-config包）图形工具 firewall-cmd （firewalld包）命令行工具 /etc/firewalld 配置文件，一般不建议 firewall-cmd 命令选项–get-zones 列出所有可用区域–get-default-zone 查询默认区域–set-default-zone=设置默认区域–get-active-zones 列出当前正使用的区域–add-source=[–zone=]添加源地址的流量到指定区域，如 果无–zone= 选项，使用默认区域–remove-source= [–zone=] 从指定区域中删除源地址的 流量，如无–zone= 选项，使用默认区域–add-interface=[–zone=] 添加来自于指定接口 的流量到特定区域，如果无–zone= 选项，使用默认区域 firewall-cmd 命令选项–change-interface=[–zone=] 改变指定接口至新的 区域，如果无–zone= 选项，使用默认区域–add-service= [–zone=] 允许服务的流量通过，如果 无–zone= 选项，使用默认区域–add-port=[–zone=] 允许指定端口和协议 的流量，如果无–zone= 选项，使用默认区域 firewall-cmd 命令选项–remove-service= [–zone=] 从区域中删除指定服 务，禁止该服务流量，如果无–zone= 选项，使用默认区域–remove-port=[–zone=] 从区域中删除 指定端口和协议，禁止该端口的流量，如果无–zone= 选项，使用默认区域–reload 删除当前运行时配置，应用加载永久配置–list-services 查看开放的服务 –list-ports 查看开放的端口–list-all [–zone=] 列出指定区域的所有配置信息，包括接口，源 地址，端口，服务等，如果无–zone= 选项，使用默认区域 firewall-cmd 命令示例查看默认zone firewall-cmd –get-default-zone默认zone设为dmz firewall-cmd –set-default-zone=dmz在internal zone中增加源地址192.168.0.0/24的永久规则 firewall-cmd –permanent –zone=internal –addsource=192.168.0.0/24在internal zone中增加协议mysql的永久规则 firewall-cmd –permanent –zone=internal –add-service=mysql加载新规则以生效 firewall-cmd –reload 实验：配置firewalldsystemctl mask iptablessystemctl mask ip6tablessystemctl status firewalldsystemctl enable firewalldsystemctl start firewalldfirewall-cmd –get-default-zonefirewall-cmd –set-default-zone publicfirewall-cmd –permanent –zone=public –list-allfirewall-cmd –permanent –zone=public –add-port 8080/tcpfirewall-cmd —reload 其它规则当基本firewalld语法规则不能满足要求时，可以使用以下更复杂的规则rich-rules 富规则，功能强,表达性语言Direct configuration rules 直接规则，灵活性差帮助：man 5 firewalld.direct 管理rich规则rich规则比基本的firewalld语法实现更强的功能，不仅实现允许/拒绝，还可以 实现日志syslog和auditd，也可以实现端口转发，伪装和限制速率rich语法： rule [source] [destination] service|port|protocol|icmp-block|masquerade|forward-port [log] [audit] [accept|reject|drop]man 5 firewalld.richlanguage 规则规则实施顺序： 该区域的端口转发，伪装规则 该区域的日志规则 该区域的允许规则 该区域的拒绝规则每个匹配的规则生效，所有规则都不匹配，该区域默认规则生效 rich规则示例拒绝从192.168.0.11的所有流量，当address 选项使用source 或 destination 时，必须用family= ipv4 |ipv6.firewall-cmd –permanent –zone=classroom –add-rich-rule=’rule family=ipv4 source address=192.168.0.11/32 reject‘限制每分钟只有两个连接到ftp服务 firewall-cmd –add-rich-rule=‘rule service name=ftp limit value=2/m accept’抛弃esp（ IPsec 体系中的一种主要协议）协议的所有数据包 firewall-cmd –permanent –add-rich-rule=’rule protocol value=esp drop’接受所有192.168.1.0/24子网端口5900-5905范围的TCP流量 firewall-cmd –permanent –zone=vnc –add-rich-rule=’rule family=ipv4 source address=192.168.1.0/24 port port=5900-5905 protocol=tcp accept’ rich日志规则实例接受ssh新连接，记录日志到syslog的notice级别，每分钟最多三条信息 firewall-cmd –permanent –zone=work –add-rich-rule=’rule service name=”ssh” log prefix=”ssh “ level=”notice” limit value=”3/m” accept从2001:db8::/64子网的DNS连接在5分钟内被拒绝，并记录到日志到audit,每 小时最大记录一条信息 firewall-cmd –add-rich-rule=’rule family=ipv6 source address=”2001:db8::/64” service name=”dns” audit limit value=”1/h” reject’ –timeout=300","categories":[],"tags":[]},{"title":"memcache  缓存原理介绍","slug":"memcache  缓存原理介绍","date":"2017-10-14T16:00:00.000Z","updated":"2018-08-09T08:40:19.573Z","comments":true,"path":"2017/10/15/memcache  缓存原理介绍/","link":"","permalink":"http://yoursite.com/2017/10/15/memcache  缓存原理介绍/","excerpt":"memcached 是什么？ memcached 是以 LiveJournal 旗下 Danga Interactive 公司的 Brad Fitzpatric 为首开发的一款软件。现在已成为 mixi、hatena、Facebook、Vox、LiveJournal 等众多服务中提高 Web 应用扩展性的重要因素。许多 Web 应用都将数据保存到 RDBMS 中，应用服务器从中读取数据并在浏览器中显示。但随着数据量的增大、访问的集中，就会出现 RDBMS 的负担加重、数据库响应恶恶化、网站显示延迟等重大影响。这时就该 memcached 大显身手了。memcached 是高性能的分布式内存缓存服务器。一般的使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态 Web 应用的速度、提高可扩展性。","text":"memcached 是什么？ memcached 是以 LiveJournal 旗下 Danga Interactive 公司的 Brad Fitzpatric 为首开发的一款软件。现在已成为 mixi、hatena、Facebook、Vox、LiveJournal 等众多服务中提高 Web 应用扩展性的重要因素。许多 Web 应用都将数据保存到 RDBMS 中，应用服务器从中读取数据并在浏览器中显示。但随着数据量的增大、访问的集中，就会出现 RDBMS 的负担加重、数据库响应恶恶化、网站显示延迟等重大影响。这时就该 memcached 大显身手了。memcached 是高性能的分布式内存缓存服务器。一般的使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态 Web 应用的速度、提高可扩展性。 memcached 的特征 memcached 作为高速运行的分布式缓存服务器，具有以下的特点。 协议简单； 基于 libevent 的事件处理 内置内存存储方式 memcached 不互相通信的分布式 协议简单memcached 的服务器客户端通信并不使用复杂的 XML 等格式，而使用简单的基于文本行的协议。因此，通过 telnet 也能在 memcached 上保存数据，取得数据。 基于 libevent 的事件处理libevent 是个程序库，它将 Linux 的 epoll、BSD 类操作系统的 kqueue 等事件处理功能封装成统一的接口。即使对服务器的连接数增加，也能发挥 O(1)的性能。memcached 使用这个 libevent 库，因此能在 Linux、BSD、Solaris 等操作系统上发挥其高性能 。关于事件处理这里就不再详细介绍，可以参考 Dan Kegel 的 The C10K Problem。 内置内存存储方式为了提高性能，memcached 中保存的数据都存储在 memcached 内置的内存存储空间中。由于数据仅存在于内存中，因此重启 memcached、重启操作系统会导致全部数据消失。另外，内容容量达到指定值之后，就基于 LRU(Least Recently Used)算法自动删除不使用的缓存。memcached 本身是为缓存而设计的服务器，因此并没有过多考虑数据的永久性问题。关于内存存储的详细信息，请参考本文的 第 2 章以后前坂介绍的内容。 memcached 不互相通信的分布式memcached 尽管是“分布式”缓存服务器，但服务器端并没有分布式功能。各个 memcached 不会互相通信以共享信息。那么，怎样进行分布式呢？这完全取决于客户端的实现。本文也将介绍memcached 的分布式。 memcached 现在已经被收入到 base 仓库，直接使用 rpm 安装即可。 memcached 选项： -p 指定端口 -f 指定 chuank 大小的倍数，步径的长度 -u 指明运行时的用户身份 -m 指定缓存空间大小 -c 最大并发连接数 -M 内存耗尽时，不执行LRU清理缓存，而是拒绝存入新的缓存项，直到有多余的空间可用时为止。 -t 启动的用于响应用户请求的线程数 memcached 默认是没有认证功能的，可借用于 SASL进行认证。 使用 memcached 一般要调用客户端工具库 ，工具可有很多种，如果是 C C++ 语言的用libmemcached 这个库 ，如果是 PHP 语言的用 php-pecl-memcache php-pecl-memcached 这两个库，用 python 语言要用 python-memcached 这个库， 所以一般在安装 memcached 时一定也要把 libmemcached 也装上。 要想在 tomcat 中使用 mencached ，必须在 tomcat 中添加 安装（memcached 的资源管理器），这个资源管理器是由 java 语言开发的，使用这个资源管理器要从官网上下载一些安装包，这些包就下载到 tomcat 的 /usr/share/java/tomcat/ 这个目录下. 需用安装包的列表： memcached-session-manager-2.3.0.jar memcached-session-manager-tc7-2.3.0.jar spymemcached-2.12.3.jar asm-6.2.jar kryo-4.0.2.jar kryo-serializers-0.42.jar minlog-1.3.0.jar msm-kryo-serializer-2.3.0.jar objenesis-2.6.jar reflectasm-1.11.7.jar要想找这些包可以在 github 上搜索 要想配置tomcat 支持使用这些资源文件，就要把 tomcat 配置文件中的会话管理器给换掉。 先在 tomcat 服务节点上安装 memcached yum install memcached libmemcached 然后修改 tomcat 配置文件 vim server.xml 在里面的 &lt;Context&gt; 语句块中添加 (&lt;Context&gt; 语句块在 &lt;Host&gt;语句块中) ： &lt;Context path=&quot;/&quot; docBase=&quot;ROOT&quot; reloadable=&quot;&quot;&gt; &lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;n1:li.01.com:11211,n2:li.02.com:11211&quot; failoverNodes=&quot;n2&quot; requestUriIgnorePattern=&quot;.*\\.(ico|png|gif|jpg|css|js)$&quot; transcoderFactoryClass=&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot; /&gt; &lt;/Context&gt; 添加完后重启 tomcat 服务 这样在前端调度就可以进行会话绑定了，这就实现了 session server 会话绑定。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"memcache","slug":"memcache","permalink":"http://yoursite.com/tags/memcache/"}]},{"title":"keepalived 各种高可用实战演练","slug":"keepalived 各种高可用实战演练","date":"2017-09-13T16:00:00.000Z","updated":"2018-08-09T08:32:08.128Z","comments":true,"path":"2017/09/14/keepalived 各种高可用实战演练/","link":"","permalink":"http://yoursite.com/2017/09/14/keepalived 各种高可用实战演练/","excerpt":"实验： 实现单主模型和双主模型的高可用。任何做实验前都要保证时间同步。 timedatectl set-timezone Asia/Shanghai 还有防火墙、SElinux 等都设置完毕。 现在准备两个主机，R1 R2 ，分别在两台主机上安装 keepalived ，各自配置成急群众的两个节点。 第一步，先把这两台主机配置成单主模型的集群，来验证地址是否能流动。 第二步，用两个虚拟路由器工作在双主模型下。 单主模型：两台主机 在第一台主机上修改 keepalived 配置文件","text":"实验： 实现单主模型和双主模型的高可用。任何做实验前都要保证时间同步。 timedatectl set-timezone Asia/Shanghai 还有防火墙、SElinux 等都设置完毕。 现在准备两个主机，R1 R2 ，分别在两台主机上安装 keepalived ，各自配置成急群众的两个节点。 第一步，先把这两台主机配置成单主模型的集群，来验证地址是否能流动。 第二步，用两个虚拟路由器工作在双主模型下。 单主模型：两台主机 在第一台主机上修改 keepalived 配置文件 1234567891011121314vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125; 在第二台主机上修改 keepalived 配置文件 1234567891011121314vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125; 然后在两台主机上各装上一个外部服务器 web1 web2 ，设置好外部主页面。就可以在客户端访问虚拟ip 192.168.1.188 了，刚开始一直是 web1 接受访问，一旦 web1 宕机， web2 就自动接受访问。这就是单主模型的高可用。 双主模型 ： 两台主机 在第一台主机上修改配置文件 12345678910111213141516171819202122232425262728vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125;vrrp_instance VI_2 &#123; state BACKUP interface ens33 virtual_router_id 22 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.199/24 brd 192.168.1.255 dev ens33 &#125;&#125; 在第二台主机上修改配置文件 12345678910111213141516171819202122232425262728vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 11 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125;vrrp_instance VI_2 &#123; state MASTER interface ens33 virtual_router_id 22 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.199/24 brd 192.168.1.255 dev ens33 &#125;&#125; 这就实现了双主模型的配置，然后在两台主机上安装外部服务器 web1 web2 ，设置好外部页面。在客户端访问 虚拟ip 192.168.1.188 显示的是 web1 ，访问虚拟 ip 192.168.1.199 显示的是 web2两台主机上都有对应的两个虚拟ip ，只是优先级不同，两个主机对两个虚拟主机ip 都有一个优先级高的，一旦有一个主机的虚拟ip宕机，这个虚拟ip就会在另外一个优先级相对较低的主机上继续运行，这样就可以保证两个虚拟ip 都能高可用。这就是双主模型的高可用。 实验： 实现 DR 模型ipvs 的高可用准备4台主机进行模拟实验，两台为前端进行高可用的调度器，另外两台为后端提供外部服务器的 relo-server 先在前端两个调度器上安装 keepalived 服务，并修改配置文件 单主模型：两台主机 在第一台主机上修改 keepalived 配置文件 123456789101112131415161718192021222324252627282930vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125; 在第二台主机上修改 keepalived 配置文件 vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125; 然后再在两台主及的keepalived 的配置文件中添加相同的内容 12345678910111213141516171819202122232425262728293031virtual_server 192.168.1.188 80 &#123; delay_loop 2 lb_algo rr lb_kind DR protocol TCP real_server 192.168.1.133 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 2 nb_get_retry 3 delay_before_retry 1 &#125; &#125; real_server 192.168.1.134 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 2 nb_get_retry 3 delay_before_retry 1 &#125; &#125;&#125; 接下来在另外两台主机上配置后端 relo-server 服务器 先修改四个内核参数，为了方便使用，可以写成脚本进行实现，顺便也可以在脚本中把 VIP 直接绑定在两个主机上。 1234567891011121314151617181920212223242526vim neihe.sh #!/bin/bash vip=&quot;192.168.1.188&quot; mask=&quot;255.255.255.255&quot; iface=&quot;lo:0&quot; case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $iface $vip netmask $mask broadcast $vip up rouconfig add -host $vip dev $iface ;; stop) ifconfig $iface down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce ;; esac 脚本写完后在两个主机上都执行一下。 然后在两台主机上安装外部服务器 httpd yum install httpd 设置外部主页面，在生产中正规两个外部服务器的主页面应该是一样的，但在这为了看到实验效果故意设为不一样的。 在 web1 上设置主页面 echo web1 &gt; /var/www/html/index.html 在 web2 上设置主页面 echo web1 &gt; /var/www/html/index.html 并把两个外部服务启动起来 systemctl start httpd 然后把前端调度器上的 keepalived 服务也启动起来 systemctl start keepalived 还有一般启动服务后就会在 iptables 规则中生成相应的规则。为了方便看规则，在前面两个调度器上安装 ipvs 服务 yum install ipvsadm 然后用命令 ipvsadm -Ln 就可以查看生成的规则 还有要在前面两台主机上用命令 iptables -F 清空一下防火墙规则，因为在配置 keepalived 服务时会自动生成一些和规则，这些规则会影响客户端访问外部服务。 最后就可以在客户端主机上进行访问测试了 注意，在客户端访问的地址一定是 VIP 地址 如： curl 192.168.1.188 实验: 实现 keepalived 高可用 nginx准备四台主机来模拟这个实验，两个主机做 nginx 的 keepalived 高可用 ，另外两个做后端提供外部服务的服务器。 先在前面两个主机上安装 nginx keepalived 两个服务 先配置第一个代理服务器上的 keepalived 的配置文件 ，所有格式如下： vim /etc/keepalived/keepalived.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_iptables vrrp_mcast_group4 224.0.123.132&#125;vrrp_script ngxhealth &#123; script &quot;killall -0 nginx &amp;&amp; exit 0 || exit 1&quot; interval 1# auth_pass 12345 weight -5&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125; track_interface &#123; ens33 &#125; track_script &#123; ngxhealth &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;vrrp_instance VI_2 &#123; state BACKUP interface ens33 virtual_router_id 22 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.199/24 brd 192.168.1.255 dev ens33 &#125;&#125; 接下配置 nginx 的配置文件 vim /etc/nginx/conf.d/www.conf 123456789101112upstream websrvs &#123; server 192.168.1.133:80; server 192.168.1.134:80;&#125;server &#123; listen 80 default_server; server_name zuyu.magedu.com; root /usr/share/nginx/html; location / &#123; proxy_pass http://websrvs; &#125;&#125; 并写一个测试脚本vim /etc/keepalived/notify.sh 1234567891011121314151617181920212223242526#!/bin/bash#!/bin/bash # contact=&apos;root@localhost&apos; notify() &#123; local mailsubject=&quot;$(hostname) to be $1, vip floating&quot; local mailbody=&quot;$(date +&apos;%F %T&apos;): vrrp transition, $(hostname) changed to be $1&quot; echo &quot;$mailbody&quot; | mail -s &quot;$mailsubject&quot; $contact &#125; case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo &quot;Usage: $(basename $0) &#123;master|backup|fault&#125;&quot; exit 1 ;; esac 配置完后启动 nginx keepalived 的服务 systemctl start nginx keepalived 这样第一个前端代理服务器的配置就配好了。 接下配置第二个前端的代理服务器 先配置 keepalived 的配置文件，所以格式如下： vim /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_iptables vrrp_mcast_group4 224.0.123.132&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 11 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125; track_script &#123; ngxhealth &#125; vrrp_script &#123; ngxhealth &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;vrrp_instance VI_2 &#123; state MASTER interface ens33 virtual_router_id 22 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.199/24 brd 192.168.1.255 dev ens33 &#125;&#125;vrrp_script ngxhealth &#123; script &quot;killall -0 nginx &amp;&amp; exit 0 || exit 1&quot; interval 1 weight -5&#125; 接下来配置 nginx 服务的配置文件 vim /etc/nginx/conf.d/www.conf 12345678910111213141516171819202122232425upstream websrvs &#123; server 192.168.1.133:80; server 192.168.1.134:80;&#125;server &#123; listen 80 default_server; server_name anmo.magedu.com; root /usr/share/nginx/html; location / &#123; proxy_pass http://websrvs; &#125;&#125;upstream websrvs &#123; server 192.168.1.133:80; server 192.168.1.134:80;&#125;server &#123; listen 80 default_server; server_name anmo.magedu.com; root /usr/share/nginx/html; location / &#123; proxy_pass http://websrvs; &#125;&#125; 并写一个测试脚本vim /etc/keepalived/notify.sh 1234567891011121314151617181920212223242526#!/bin/bash#!/bin/bash # contact=&apos;root@localhost&apos; notify() &#123; local mailsubject=&quot;$(hostname) to be $1, vip floating&quot; local mailbody=&quot;$(date +&apos;%F %T&apos;): vrrp transition, $(hostname) changed to be $1&quot; echo &quot;$mailbody&quot; | mail -s &quot;$mailsubject&quot; $contact &#125; case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo &quot;Usage: $(basename $0) &#123;master|backup|fault&#125;&quot; exit 1 ;; esac 配置完后启动 nginx keepalived 的服务 systemctl start nginx keepalived 这样第二个前端代理服务器的配置也配置好了。 接下来就要配置后端提供外部服务的服务器了。 先在两台主机上安装外部服务 httpd 并设置外部主页面 在web1 服务器上设置页面： echo web1 &gt; /var/www/html/index.html 在web2 服务器上设置页面： echo web2 &gt; /var/www/html/index.html在生产中这两个主机上的页面应该是相同的，在这是为了查看实验效果，故意不一样。在两台主机上都设置好以后，然后都启动服务systemctl start httpd 最后就可以在浏览器测试了，在浏览器上输入 VIP 的地址，在这有两个 VIP 地址，如果输入两个中的某一个 VIP 地址都可以访问到后端服务的外部页面，并且轮询，说明成功。还可以当掉一个 nginx 服务器测试都没有问题的。再生产中无非就是在 DNS 服务器的配置上添加两条 A 记录，把域名解析到这两个 VIP 即可。 这就是高可用的负载均衡前端接入的调度器集群了。测试时可以用命令 tcpdump -i ens33 -nn host 224.0.123.132 到此就实现了 在双主模式下工作的 keepalived 高可用的 nginx调度。OpenAIS RedHat 5 : cman + rgmanager,conga(WebGUI): RHCS(Cluster Suite)(集群套件) RedHat 6 : cman + rgmanager,corosync + pacemaker RedHat 7 : corosync + pacemaker CRM （Cluster Resource Manager）：集群资源管理器LRM(local Resource Manager):本地资源管理器","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"keepalied","slug":"keepalied","permalink":"http://yoursite.com/tags/keepalied/"}]},{"title":"HAproxy 原理介绍","slug":"HAproxy 原理介绍","date":"2017-08-27T16:00:00.000Z","updated":"2018-08-09T08:28:45.910Z","comments":true,"path":"2017/08/28/HAproxy 原理介绍/","link":"","permalink":"http://yoursite.com/2017/08/28/HAproxy 原理介绍/","excerpt":"课前扩展：运维人员的三大核心工作： 发布； 变更； 故障处理； 扩展： 向上，向外。 什么是无状态跟有状态？ 一个客户端向服务器发起多次请求，后一次的请求跟前一次的请求是隔离的，独立的，相互没有关系的，这就叫无状态。 如果后一次的请求必须建立在前一次请求之上，这种就叫做有状态请求。 HAproxy 是一个代理服务器，但他天然是一个能在代理时做负载均衡调度的服务器两个特点： 反代 mode http ： 七层反代 要根据用户的资源请求做分离跳读 ssl/tls 会话卸载器 mode tcp： 伪四层反代 为什么说是伪四层呢，因为它依旧受限于七层的并发连接数。 调度器 支持众多的调度算法 如：轮询，加权轮询等；","text":"课前扩展：运维人员的三大核心工作： 发布； 变更； 故障处理； 扩展： 向上，向外。 什么是无状态跟有状态？ 一个客户端向服务器发起多次请求，后一次的请求跟前一次的请求是隔离的，独立的，相互没有关系的，这就叫无状态。 如果后一次的请求必须建立在前一次请求之上，这种就叫做有状态请求。 HAproxy 是一个代理服务器，但他天然是一个能在代理时做负载均衡调度的服务器两个特点： 反代 mode http ： 七层反代 要根据用户的资源请求做分离跳读 ssl/tls 会话卸载器 mode tcp： 伪四层反代 为什么说是伪四层呢，因为它依旧受限于七层的并发连接数。 调度器 支持众多的调度算法 如：轮询，加权轮询等； HAProxy：HAproxy 也使用事件驱动模型，单进程来相应多请求的模式工作。 但是建议工作在单进程模式下，足以提供交大并发的请求，这样更容易排查和定义故障问题。 http://www.haproxy.org http://www.haproxy.com 文档： http://cbonte.github.io/haproxy-dconv/ HAProxy is a TCP/HTTP reverse proxy which is particularly suited for high availability environments. Indeed, it can: : - route HTTP requests depending on statically assigned cookies # 是一个 HTTP 的路由器，能够把 HTTP 请求路由至最佳节点，还支持做静态 COOKIES 绑定以后做会话连线。 : - spread load among several servers while assuring server persistence # 能否实现调度 : through the use of HTTP cookies # 可以实现对于 HTTP cookies 的高效利用 : - switch to backup servers in the event a main server fails # 在主服务器宕机是可启用备用服务器，通常叫做 抱歉服务器 : - accept connections to special ports dedicated to service monitoring : - stop accepting connections without breaking existing ones : - add, modify, and delete HTTP headers in both directions : - block requests matching particular patterns : - report detailed status to authenticated users from a URI intercepted by the application 版本：1.4, 1.5, 1.6, 1.7 以后不管搭建什么服务，时间一定都要同步，很关键也很重要。 同步时间有一个命令： timedatectl set-timezone Asia/Shanghai 搭建架构时，在所有架构中的服务器上都执行这个命令。 程序环境： 主程序：/usr/sbin/haproxy 主配置文件：/etc/haproxy/haproxy.cfg Unit file：/usr/lib/systemd/system/haproxy.service 配置段： global：全局配置段 进程及安全配置相关的参数 性能调整相关参数 Debug参数 用户列表 peers # 同等端点的兄弟服务器的位置跟通讯方法 proxies：代理配置段 defaults：为frontend, listen, backend提供默认配置； fronted：前端，相当于nginx, server {} backend：后端，相当于nginx, upstream {} listen：同时拥前端和后端 简单的配置示例： frontend web bind *:80 default_backend websrvs backend websrvs balance roundrobin server srv1 192.168.1.132:80 check weight 2 server srv2 192.168.1.134:80 check IaaS, PaaS, SaaS LBaaS, DBaaS, FWaaS, FaaS(Serverless), … OpenShift(PaaS): HAPorxy, Ingress Controller global配置参数： 进程及安全管理：chroot, daemon，user, group, uid, gid log：定义全局的syslog服务器；最多可以定义两个； log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [max level [min level]] log &lt;address&gt; :表示日志发送给哪个 syslog 服务器 [len &lt;length&gt;] ：记录日志的最大长度是多长 &lt;facility&gt; [max level [min level]] : 最大日志级别跟最低日志级别 如何启用日志功能？ 在 hapeoxy 配置文件中复制日志格式到 /etc/syslog.conf 中的对应的语句块中。 如： 复制 haproxy 配置文件中的 local2.* /var/log/haproxy.log 到 /etc/syslog.conf 文件中对应的语句块中，并重启服务 最后客户端的访问日志就会记录在 /var/log/haproxy.log 文件中 nbproc &lt;number&gt;：要启动的haproxy的进程数量； ulimit-n &lt;number&gt;：每个haproxy进程可打开的最大文件数； 性能调整： maxconn &lt;number&gt;：设定每个haproxy进程所能接受的最大并发连接数；Sets the maximum per-process number of concurrent connections to &lt;number&gt;. 总体的并发连接数：nbproc * maxconn maxconnrate &lt;number&gt;：Sets the maximum per-process number of connections per second to &lt;number&gt;. 每个进程每秒种所能创建的最大连接数量； maxsessrate &lt;number&gt;： 每个进程每秒钟能够创建的会话速率 maxsslconn &lt;number&gt;: Sets the maximum per-process number of concurrent SSL connections to &lt;number&gt;. 设定每个haproxy进程所能接受的ssl的最大并发连接数； spread-checks &lt;0..50, in percent&gt; 代理配置段： - defaults &lt;name&gt; - frontend &lt;name&gt; - backend &lt;name&gt; - listen &lt;name&gt; A &quot;frontend&quot; section describes a set of listening sockets accepting client connections. A &quot;backend&quot; section describes a set of servers to which the proxy will connect to forward incoming connections. A &quot;listen&quot; section defines a complete proxy with its frontend and backend parts combined in one section. It is generally useful for TCP-only traffic. All proxy names must be formed from upper and lower case letters, digits, &apos;-&apos; (dash), &apos;_&apos; (underscore) , &apos;.&apos; (dot) and &apos;:&apos; (colon). 区分字符大小写； 配置参数： bind：Define one or several listening addresses and/or ports in a frontend. bind [&lt;address&gt;]:&lt;port_range&gt; [, ...] [param*] listen http_proxy bind :80,:443 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy # 这个参数只能用在 frontend 和 listen 语句块中。 balance：后端服务器组内的服务器调度算法 balance &lt;algorithm&gt; [ &lt;arguments&gt; ] balance url_param &lt;param&gt; [check_post] 算法： roundrobin：Each server is used in turns, according to their weights. server options： weight # 动态算法：支持权重的运行时调整，支持慢启动；每个后端中最多支持4095个server； static-rr： 静态算法：不支持权重的运行时调整及慢启动；后端主机数量无上限； leastconn： 推荐使用在具有较长会话的场景中，例如MySQL、LDAP等； first： 根据服务器在列表中的位置，自上而下进行调度；前面服务器的连接数达到上限，新请求才会分配给下一台服务； source：源地址hash； 将同一个地址发过来的请求一直发往一个后端服务器 除权取余法（静态数组取模法）： 一致性哈希： uri： 对URI的左半部分做hash计算，并由服务器总权重相除以后派发至某挑出的服务器； # 如果在生产中，调度器后面是缓存服务器，uri 就要用一致性哈希的动态算法。 &lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; 左半部分：/&lt;path&gt;;&lt;params&gt; 整个uri：/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; username=jerry url_param：对用户请求的uri的&lt;params&gt;部分中的参数的值作hash计算，并由服务器总权重相除以后派发至某挑出的服务器；通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server； hdr(&lt;name&gt;)：对于每个http请求，此处由&lt;name&gt;指定的http首部将会被取出做hash计算； 并由服务器总权重相除以后派发至某挑出的服务器；没有有效值的会被轮询调度； hdr(Cookie) rdp-cookie rdp-cookie(&lt;name&gt;) hash-type：哈希算法 hash-type &lt;method&gt; &lt;function&gt; &lt;modifier&gt; map-based：除权取余法，哈希数据结构是静态的数组； consistent：一致性哈希，哈希数据结构是一个树； &lt;function&gt; is the hash function to be used : 哈希函数 sdbm djb2 wt6 default_backend &lt;backend&gt; 设定默认的backend，用于frontend中； default-server [param*] 为backend中的各server设定默认选项； server &lt;name&gt; &lt;address&gt;[:[port]] [param*] 定义后端主机的各服务器及其选项； server &lt;name&gt; &lt;address&gt;[:port] [settings ...] default-server [settings ...] &lt;name&gt;：服务器在haproxy上的内部名称；出现在日志及警告信息中； &lt;address&gt;：服务器地址，支持使用主机名； [:[port]]：端口映射；省略时，表示同bind中绑定的端口； [param*]：参数 maxconn &lt;maxconn&gt;：当前server的最大并发连接数； backlog &lt;backlog&gt;：当前server的连接数达到上限后的后援队列长度； backup：设定当前server为备用服务器； check：对当前server做健康状态检测； addr ：检测时使用的IP地址； port ：针对此端口进行检测； inter &lt;delay&gt;：连续两次检测之间的时间间隔，默认为2000ms; rise &lt;count&gt;：连续多少次检测结果为“成功”才标记服务器为可用；默认为2； fall &lt;count&gt;：连续多少次检测结果为“失败”才标记服务器为不可用；默认为3； 注意：option httpchk，&quot;smtpchk&quot;, &quot;mysql-check&quot;, &quot;pgsql-check&quot; and &quot;ssl-hello-chk&quot; 用于定义应用层检测方法； cookie &lt;value&gt;：为当前server指定其cookie值，用于实现基于cookie的会话黏性； disabled：标记为不可用； on-error &lt;mode&gt;：后端服务故障时的行动策略； - fastinter: force fastinter - fail-check: simulate a failed check, also forces fastinter (default) - sudden-death: simulate a pre-fatal failed health check, one more failed check will mark a server down, forces fastinter - mark-down: mark the server immediately down and force fastinter redir &lt;prefix&gt;：将发往此server的所有GET和HEAD类的请求重定向至指定的URL； weight &lt;weight&gt;：权重，默认为1; OK --&gt; PROBLEM OK --&gt; PROBLEM --&gt; PROBLEM --&gt; PROBLEM PROBLEM --&gt; OK 统计接口启用相关的参数： stats enable (加在前端后端都可以) 启用统计页；基于默认的参数启用stats page； - stats uri : /haproxy?stats - stats realm : &quot;HAProxy Statistics&quot; - stats auth : no authentication - stats scope : no restriction stats auth &lt;user&gt;:&lt;passwd&gt; 认证时的账号和密码，可使用多次；（启用账号密码） stats realm &lt;realm&gt; 认证时的realm；（提示语） stats uri &lt;prefix&gt; 自定义stats page uri stats refresh &lt;delay&gt; 设定自动刷新时间间隔； stats admin { if | unless } &lt;cond&gt; 启用stats page中的管理功能 配置示例：（为了信息安全，可以专门给状态信息加端口） listen stats bind :9099 stats enable stats realm HAPorxy\\ Stats\\ Page stats auth admin:admin stats admin if TRUE maxconn &lt;conns&gt;：为指定的frontend定义其最大并发连接数；默认为2000； Fix the maximum number of concurrent connections on a frontend. mode { tcp|http|health } 定义haproxy的工作模式； tcp：基于layer4实现代理；可代理mysql, pgsql, ssh, ssl等协议； http：仅当代理的协议为http时使用； health：工作为健康状态检查的响应模式，当连接请求到达时回应“OK”后即断开连接； 示例： listen ssh bind :22022 balance leastconn mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check cookie &lt;name&gt; [ rewrite | insert | prefix ] [ indirect ] [ nocache ] [ postonly ] [ preserve ] [ httponly ] [ secure ] [ domain &lt;domain&gt; ]* [ maxidle &lt;idle&gt; ] [ maxlife &lt;life&gt; ] &lt;name&gt;：is the name of the cookie which will be monitored, modified or inserted in order to bring persistence. rewirte：重写； insert：插入； prefix：前缀； 基于cookie的session sticky的实现： backend websrvs cookie WEBSRV insert nocache indirect server srv1 172.16.100.6:80 weight 2 check rise 1 fall 2 maxconn 3000 cookie srv1 server srv2 172.16.100.7:80 weight 1 check rise 1 fall 2 maxconn 3000 cookie srv2 option forwardfor [ except &lt;network&gt; ] [ header &lt;name&gt; ] [ if-none ] Enable insertion of the X-Forwarded-For header to requests sent to servers 在由haproxy发往后端主机的请求报文中添加“X-Forwarded-For”首部，其值前端客户端的地址；用于向后端主发送真实的客户端IP； [ except &lt;network&gt; ]：请求报请来自此处指定的网络时不予添加此首部； [ header &lt;name&gt; ]：使用自定义的首部名称，而非“X-Forwarded-For”； errorfile &lt;code&gt; &lt;file&gt; Return a file contents instead of errors generated by HAProxy &lt;code&gt;：is the HTTP status code. Currently, HAProxy is capable of generating codes 200, 400, 403, 408, 500, 502, 503, and 504. &lt;file&gt;：designates a file containing the full HTTP response. 示例： errorfile 400 /etc/haproxy/errorfiles/400badreq.http errorfile 408 /dev/null # workaround Chrome pre-connect bug errorfile 403 /etc/haproxy/errorfiles/403forbid.http errorfile 503 /etc/haproxy/errorfiles/503sorry.http errorloc &lt;code&gt; &lt;url&gt; errorloc302 &lt;code&gt; &lt;url&gt; errorfile 403 http://www.magedu.com/error_pages/403.html reqadd &lt;string&gt; [{if | unless} &lt;cond&gt;] Add a header at the end of the HTTP request rspadd &lt;string&gt; [{if | unless} &lt;cond&gt;] Add a header at the end of the HTTP response # 给客户端法响应报文时给报文头部添加信息 rspadd X-Via:\\ HAPorxy reqdel &lt;search&gt; [{if | unless} &lt;cond&gt;] reqidel &lt;search&gt; [{if | unless} &lt;cond&gt;] (ignore case) Delete all headers matching a regular expression in an HTTP request rspdel &lt;search&gt; [{if | unless} &lt;cond&gt;] rspidel &lt;search&gt; [{if | unless} &lt;cond&gt;] (ignore case) Delete all headers matching a regular expression in an HTTP response rspidel Server.* # 给客户端发送响应报文时可以删除报文头部的信息 日志系统： log： log global log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [&lt;level&gt; [&lt;minlevel&gt;]] no log 注意： 默认发往本机的日志服务器； (1) local2.* /var/log/local2.log (2) $ModLoad imudp $UDPServerRun 514 log-format &lt;string&gt;： 课外实践：参考文档实现combined格式的记录 capture cookie &lt;name&gt; len &lt;length&gt; Capture and log a cookie in the request and in the response. capture request header &lt;name&gt; len &lt;length&gt; Capture and log the last occurrence of the specified request header. capture request header X-Forwarded-For len 15 capture response header &lt;name&gt; len &lt;length&gt; Capture and log the last occurrence of the specified response header. capture response header Content-length len 9 capture response header Location len 15 为指定的MIME类型启用压缩传输功能 compression algo &lt;algorithm&gt; ...：启用http协议的压缩机制，指明压缩算法gzip, deflate； compression type &lt;mime type&gt; ...：指明压缩的MIME类型；常适用于压缩的类型为文本类型； 对后端服务器做http协议的健康状态检测： option httpchk option httpchk &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt; 定义基于http协议的7层健康状态检测机制； http-check expect [!] &lt;match&gt; &lt;pattern&gt; Make HTTP health checks consider response contents or specific status codes. 连接超时时长： timeout client &lt;timeout&gt; # 面向客户端的超时时间 Set the maximum inactivity time on the client side. 默认单位是毫秒; timeout server &lt;timeout&gt; # 面向服务器端的超时时间 Set the maximum inactivity time on the server side. timeout http-keep-alive &lt;timeout&gt; 持久连接的持久时长； timeout http-request &lt;timeout&gt; Set the maximum allowed time to wait for a complete HTTP request timeout connect &lt;timeout&gt; Set the maximum time to wait for a connection attempt to a server to succeed. timeout client-fin &lt;timeout&gt; Set the inactivity timeout on the client side for half-closed connections. timeout server-fin &lt;timeout&gt; Set the inactivity timeout on the server side for half-closed connections. use_backend &lt;backend&gt; [{if | unless} &lt;condition&gt;] Switch to a specific backend if/unless an ACL-based condition is matched. 当符合指定的条件时使用特定的backend； block { if | unless } &lt;condition&gt; # 阻止谁来访问 Block a layer 7 request if/unless a condition is matched acl invalid_src src 172.16.200.2 block if invalid_src errorfile 403 /etc/fstab http-request { allow | deny } [ { if | unless } &lt;condition&gt; ] Access control for Layer 7 requests tcp-request connection {accept|reject} [{if | unless} &lt;condition&gt;] Perform an action on an incoming connection depending on a layer 4 condition 示例： listen ssh bind :22022 balance leastconn acl invalid_src src 172.16.200.2 tcp-request connection reject if invalid_src mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check backup acl： The use of Access Control Lists (ACL) provides a flexible solution to perform content switching and generally to take decisions based on content extracted from the request, the response or any environmental status. acl &lt;aclname&gt; &lt;criterion&gt; [flags] [operator] [&lt;value&gt;] ... &lt;aclname&gt;：ACL names must be formed from upper and lower case letters, digits, &apos;-&apos; (dash), &apos;_&apos; (underscore) , &apos;.&apos; (dot) and &apos;:&apos; (colon).ACL names are case-sensitive. &lt;value&gt;的类型： - boolean - integer or integer range - IP address / network - string (exact, substring, suffix, prefix, subdir, domain) - regular expression （以正则表达式做匹配） - hex block （以 16 进制的代码块做匹配） &lt;flags&gt; -i : ignore case during matching of all subsequent patterns. # 不区分字符大小写 -m : use a specific pattern matching method -n : forbid the DNS resolutions （禁止 DNS 做名字解析） -u : force the unique id of the ACL （要求 ACL必须使用唯一的名称） -- : force end of flags. Useful when a string looks like one of the flags. [operator] 匹配整数值：eq、ge、gt、le、lt 匹配字符串： - exact match (-m str) : the extracted string must exactly match the patterns ; - substring match (-m sub) : the patterns are looked up inside the extracted string, and the ACL matches if any of them is found inside ; - prefix match (-m beg) : the patterns are compared with the beginning of the extracted string, and the ACL matches if any of them matches. - suffix match (-m end) : the patterns are compared with the end of the extracted string, and the ACL matches if any of them matches. - subdir match (-m dir) : the patterns are looked up inside the extracted string, delimited with slashes (&quot;/&quot;), and the ACL matches if any of them matches. - domain match (-m dom) : the patterns are looked up inside the extracted string, delimited with dots (&quot;.&quot;), and the ACL matches if any of them matches. acl作为条件时的逻辑关系： - AND (implicit) - OR (explicit with the &quot;or&quot; keyword or the &quot;||&quot; operator) - Negation with the exclamation mark (&quot;!&quot;) if invalid_src invalid_port # 并且的关系，两个都得满足 if invalid_src || invalid_port # 或者的关系，有一个满足就行 if ! invalid_src invalid_port # 表示不满足第一个，但满足第二个就行 &lt;criterion&gt; ： dst : ip dst_port : integer src : ip src_port : integer acl invalid_src src 172.16.200.2 path : string This extracts the request&apos;s URL path, which starts at the first slash and ends before the question mark (without the host part). /path;&lt;params&gt; path : exact string match path_beg : prefix match # 前缀匹配 path_dir : subdir match # 路径子串匹配 path_dom : domain match # 子域名匹配 path_end : suffix match # 后缀匹配 path_len : length match # 路径的长度匹配 path_reg : regex match # 路径的正则表达式匹配 path_sub : substring match # 子串匹配 path_beg /images/ path_end .jpg .jpeg .png .gif path_reg ^/images.*\\.jpeg$ path_sub image path_dir jpegs path_dom ilinux /images/jpegs/20180312/logo.jpg url : string This extracts the request&apos;s URL as presented in the request. A typical use is with prefetch-capable caches, and with portals which need to aggregate multiple information from databases and keep them in caches. url : exact string match url_beg : prefix match url_dir : subdir match url_dom : domain match url_end : suffix match url_len : length match url_reg : regex match url_sub : substring match req.hdr([&lt;name&gt;[,&lt;occ&gt;]]) : string This extracts the last occurrence of header &lt;name&gt; in an HTTP request. hdr([&lt;name&gt;[,&lt;occ&gt;]]) : exact string match hdr_beg([&lt;name&gt;[,&lt;occ&gt;]]) : prefix match hdr_dir([&lt;name&gt;[,&lt;occ&gt;]]) : subdir match hdr_dom([&lt;name&gt;[,&lt;occ&gt;]]) : domain match hdr_end([&lt;name&gt;[,&lt;occ&gt;]]) : suffix match hdr_len([&lt;name&gt;[,&lt;occ&gt;]]) : length match hdr_reg([&lt;name&gt;[,&lt;occ&gt;]]) : regex match hdr_sub([&lt;name&gt;[,&lt;occ&gt;]]) : substring match 示例： acl bad_curl hdr_sub(User-Agent) -i curl block if bad_curl status : integer Returns an integer containing the HTTP status code in the HTTP response. Pre-defined ACLs ACL name Equivalent to Usage FALSE always_false never match HTTP req_proto_http match if protocol is valid HTTP HTTP_1.0 req_ver 1.0 match HTTP version 1.0 HTTP_1.1 req_ver 1.1 match HTTP version 1.1 HTTP_CONTENT hdr_val(content-length) gt 0 match an existing content-length HTTP_URL_ABS url_reg ^[^/:]*:// match absolute URL with scheme HTTP_URL_SLASH url_beg / match URL beginning with &quot;/&quot; HTTP_URL_STAR url * match URL equal to &quot;*&quot; LOCALHOST src 127.0.0.1/8 match connection from local host METH_CONNECT method CONNECT match HTTP CONNECT method METH_GET method GET HEAD match HTTP GET or HEAD method METH_HEAD method HEAD match HTTP HEAD method METH_OPTIONS method OPTIONS match HTTP OPTIONS method METH_POST method POST match HTTP POST method METH_TRACE method TRACE match HTTP TRACE method RDP_COOKIE req_rdp_cookie_cnt gt 0 match presence of an RDP cookie REQ_CONTENT req_len gt 0 match data in the request buffer TRUE always_true always match WAIT_END wait_end wait for end of content analysis HAProxy：global, proxies（fronted, backend, listen, defaults） balance： roundrobin, static-rr leastconn first source hdr(&lt;name&gt;) uri (hash-type) url_param Nginx调度算法：ip_hash, hash, leastconn, lvs调度算法： rr/wrr/sh/dh, lc/wlc/sed/nq/lblc/lblcr 基于ACL的动静分离示例： frontend web *:80 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js .html .txt .htm use_backend staticsrvs if url_static default_backend appsrvs backend staticsrvs balance roundrobin server stcsrv1 172.16.100.6:80 check backend appsrvs balance roundrobin server app1 172.16.100.7:80 check server app1 172.16.100.7:8080 check listen stats bind :9091 stats enable stats auth admin:admin stats admin if TRUE 配置HAProxy支持https协议： 1 支持ssl会话； bind *:443 ssl crt /PATH/TO/SOME_PEM_FILE crt后的证书文件要求PEM格式，且同时包含证书和与之匹配的所有私钥； cat demo.crt demo.key &gt; demo.pem 2 把80端口的请求重向定443； bind *:80 redirect scheme https if !{ ssl_fc } 另一种配置：对非ssl的任何url的访问统统定向至https主机的主页； redirect location https://172.16.0.67/ if !{ ssl_fc } 3 如何向后端传递用户请求的协议和端口 http_request set-header X-Forwarded-Port %[dst_port] http_request add-header X-Forwared-Proto https if { ssl_fc } 配置时常用的功能： http --&gt; https mode http 压缩、条件式转发、算法、stats page、自定义错误页、访问控制、日志功能 最大并发连接； global, defaults, frontend, listen, server 基于cookie的session粘滞 后端主机的健康状态检测 请求和响应报文首部的操纵 实践（博客）作业： http: (1) 动静分离部署wordpress，动静都要能实现负载均衡，要注意会话的问题； (2) 在haproxy和后端主机之间添加varnish进行缓存； (3) 给出设计拓扑，写成博客； (4) haproxy的设定要求： (a) stats page，要求仅能通过本地访问使用管理接口； (b) 动静分离； (c) 分别考虑不同的服务器组的调度算法； (4) 压缩合适的内容类型；","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"haproxy","slug":"haproxy","permalink":"http://yoursite.com/tags/haproxy/"}]},{"title":"lvs 详细介绍","slug":"lvs 详细介绍","date":"2017-08-18T16:00:00.000Z","updated":"2018-08-09T08:27:15.625Z","comments":true,"path":"2017/08/19/lvs 详细介绍/","link":"","permalink":"http://yoursite.com/2017/08/19/lvs 详细介绍/","excerpt":"Cluster概念 系统扩展方式： Scale UP：向上扩展,增强 Scale Out：向外扩展,增加设备，调度分配问题，Cluster Cluster：集群,为解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster类型： LB：Load Balancing，负载均衡 HA：High Availiablity，高可用，SPOF（single Point Of failure） MTBF:Mean Time Between Failure 平均无故障时间 MTTR:Mean Time To Restoration（ repair）平均恢复前时间 A=MTBF/（MTBF+MTTR） (0,1)：99%, 99.5%, 99.9%, 99.99%, 99.999% HPC：High-performance computing，高性能 www.top500.org 分布式系统： 分布式存储：云盘 分布式计算：hadoop， park","text":"Cluster概念 系统扩展方式： Scale UP：向上扩展,增强 Scale Out：向外扩展,增加设备，调度分配问题，Cluster Cluster：集群,为解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster类型： LB：Load Balancing，负载均衡 HA：High Availiablity，高可用，SPOF（single Point Of failure） MTBF:Mean Time Between Failure 平均无故障时间 MTTR:Mean Time To Restoration（ repair）平均恢复前时间 A=MTBF/（MTBF+MTTR） (0,1)：99%, 99.5%, 99.9%, 99.99%, 99.999% HPC：High-performance computing，高性能 www.top500.org 分布式系统： 分布式存储：云盘 分布式计算：hadoop， park Cluster分类LB Cluster的实现硬件 F5 Big-IP Citrix Netscaler A10 A10软件 lvs：Linux Virtual Server nginx：支持七层调度 haproxy：支持七层调度 ats：apache traffic server，yahoo捐助 perlbal：Perl 编写 pound Cluster分类基于工作的协议层次划分：传输层（通用）：DPORT LVS： nginx：stream haproxy：mode tcp应用层（专用）：针对特定协议，自定义的请求模型分类 proxy server： http：nginx, httpd, haproxy(mode http), … fastcgi：nginx, httpd, … mysql：mysql-proxy, … Cluster相关 会话保持：负载均衡 (1) session sticky：同一用户调度固定服务器 Source IP：LVS sh算法（对某一特定服务而言） Cookie (2) session replication：每台服务器拥有全部session session multicast cluster (3) session server：专门的session服务器 Memcached，Redis HA集群实现方案 keepalived:vrrp协议 ais:应用接口规范 heartbeat cman+rgmanager(RHCS) coresync_pacemaker LVS介绍LVS：Linux Virtual Server，负载调度器，集成内核 章文嵩 阿里 官网：http://www.linuxvirtualserver.org/ VS: Virtual Server，负责调度 RS: Real Server，负责真正提供服务 L4：四层路由器或交换机 工作原理：VS根据请求报文的目标IP和目标协议及端口将其调度转发至某RS，根据调度 算法来挑选RS iptables/netfilter： iptables：用户空间的管理工具 netfilter：内核空间上的框架 流入：PREROUTING –&gt; INPUT 流出：OUTPUT –&gt; POSTROUTING 转发：PREROUTING –&gt; FORWARD –&gt; POSTROUTING DNAT：目标地址转换； PREROUTING LVS概念lvs集群类型中的术语： VS：Virtual Server，Director Server(DS) Dispatcher(调度器)，Load BalancerRS：Real Server(lvs), upstream server(nginx) backend server(haproxy)CIP：Client IPVIP: Virtual serve IP VS外网的IPDIP: Director IP VS内网的IPRIP: Real server IP 访问流程：CIP VIP == DIP RIP lvs集群的类型lvs: ipvsadm/ipvs ipvsadm：用户空间的命令行工具，规则管理器 用于管理集群服务及RealServer ipvs：工作于内核空间netfilter的INPUT钩子上的框架lvs集群的类型： lvs-nat：修改请求报文的目标IP,多目标IP的DNAT lvs-dr：操纵封装新的MAC地址 lvs-tun：在原请求IP报文之外新加一个IP首部 lvs-fullnat：修改请求报文的源和目标IP lvs-nat模式lvs-nat： 本质是多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑 出的RS的RIP和PORT实现转发 （1）RIP和DIP应在同一个IP网络，且应使用私网地址；RS的网关要指向DIP （2）请求报文和响应报文都必须经由Director转发，Director易于成为系统瓶颈 （3）支持端口映射，可修改请求报文的目标PORT （4）VS必须是Linux系统，RS可以是任意OS系统 LVS-DR模式 LVS-DR：Direct Routing，直接路由，LVS默认模式,应用最广泛,通过为请求报文重新 封装一个MAC首部进行转发，源MAC是DIP所在的接口的MAC，目标MAC是某挑选出 的RS的RIP所在接口的MAC地址；源IP/PORT，以及目标IP/PORT均保持不变（1） Director和各RS都配置有VIP（2） 确保前端路由器将目标IP为VIP的请求报文发往Director 在前端网关做静态绑定VIP和Director的MAC地址 在RS上使用arptables工具arptables -A IN -d $VIP -j DROP arptables -A OUT -s $VIP -j mangle –m angle-ip-s $RIP 在RS上修改内核参数以限制arp通告及应答级别/proc/sys/net/ipv4/conf/all/arp_ignore/proc/sys/net/ipv4/conf/all/arp_announce LVS-DR模式（3）RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络； RIP的网关不能指向DIP，以确保响应报文不会经由Director（4）RS和Director要在同一个物理网络（5）请求报文要经由Director，但响应报文不经由Director，而由RS直接发往 Client（6）不支持端口映射（端口不能修败） （7）RS可使用大多数OS系统 lvs-tun模式lvs-tun： 转发方式：不修改请求报文的IP首部（源IP为CIP，目标IP为VIP），而在原IP报文 之外再封装一个IP首部（源IP是DIP，目标IP是RIP），将报文发往挑选出的目标 RS；RS直接响应给客户端（源IP是VIP，目标IP是CIP） (1) DIP, VIP, RIP可以是公网地址，DIP 和 RIP 也可以是私网地址 (2) RS的网关一般不能指向DIP (3) 请求报文要经由Director，但响应不能经由Director (4) 不支持端口映射 (5) RS的OS须支持隧道功能 lvs-fullnat模式lvs-fullnat：通过同时修改请求报文的源IP地址和目标IP地址进行转发 CIP –&gt; DIP VIP –&gt; RIP (1) VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此， RIP的网关一般不会指向DIP (2) RS收到的请求报文源地址是DIP，因此，只需响应给DIP；但Director还 要将其发往Client (3) 请求和响应报文都经由Director (4) 支持端口映射注意：此类型kernel默认不支持 lvs-nat与lvs-fullnat：请求和响应报文都经由Director lvs-nat：RIP的网关要指向DIP lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信 lvs-dr与lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发lvs-tun：通过在原IP报文外封装新IP头实现转发，支持远距离通信 ipvs scheduleripvs scheduler：根据其调度时是否考虑各RS当前的负载状态 两种：静态方法和动态方法静态方法：仅根据算法本身进行调度 1、RR：roundrobin，轮询 2、WRR：Weighted RR，加权轮询3、SH：Source Hashing，实现session sticky，源IP地址hash；将来自于同一 个IP地址的请求始终发往第一次挑中的RS，从而实现会话绑定 4、DH：Destination Hashing；目标地址哈希，将发往同一个目标地址的请求 始终转发至第一次挑中的RS，典型使用场景是正向代理缓存场景中的负载均衡， 如：宽带运营商 ipvs scheduler动态方法：主要根据每RS当前的负载状态及调度算法进行调度Overhead=value 较小的RS将被调度 1、LC：least connections 适用于长连接应用 Overhead=activeconns256+inactiveconns 2、WLC：Weighted LC，默认调度方法 Overhead=(activeconns256+inactiveconns)/weight 3、SED：Shortest Expection Delay,初始连接高权重优先 Overhead=(activeconns+1)*256/weight 4、NQ：Never Queue，第一轮均匀分配，后续SED5、LBLC：Locality-Based LC，动态的DH算法，使用场景：根据负载状态实现 正向代理6、LBLCR：LBLC with Replication，带复制功能的LBLC 解决LBLC负载不均衡问题，从负载重的复制到负载轻的RS ipvsipvsadm/ipvs：ipvs： grep -i -C 10 “ipvs” /boot/config-VERSION-RELEASE.x86_64 支持的协议：TCP， UDP， AH， ESP， AH_ESP, SCTPipvs集群： 管理集群服务 管理服务上的RS ipvsadm包构成ipvsadm：程序包：ipvsadm Unit File: ipvsadm.service 主程序：/usr/sbin/ipvsadm 规则保存工具：/usr/sbin/ipvsadm-save 规则重载工具：/usr/sbin/ipvsadm-restore 配置文件：/etc/sysconfig/ipvsadm-config ipvsadm命令ipvsadm命令： 核心功能： 集群服务管理：增、删、改 集群服务的RS管理：增、删、改 查看 ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [–pe persistence_engine] [-b sched-flags] ipvsadm -D -t|u|f service-address 删除 ipvsadm –C 清空 ipvsadm –R 重载 ipvsadm -S [-n] 保存 ipvsadm -a|e -t|u|f service-address -r server-address [options] ipvsadm -d -t|u|f service-address -r server-address ipvsadm -L|l [options] ipvsadm -Z [-t|u|f service-address] ipvsadm命令管理集群服务：增、改、删增、改： ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]]删除： ipvsadm -D -t|u|f service-addressservice-address： -t|u|f： -t: TCP协议的端口，VIP:TCP_PORT -u: UDP协议的端口，VIP:UDP_PORT -f：firewall MARK，标记，一个数字[-s scheduler]：指定集群的调度算法，默认为wlc ipvsadm命令管理集群上的RS：增、改、删增、改：ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight]删：ipvsadm -d -t|u|f service-address -r server-addressserver-address： rip[:port] 如省略port，不作端口映射选项： lvs类型： -g: gateway, dr类型，默认 -i: ipip, tun类型 -m: masquerade, nat类型 -w weight：权重 ipvsadm命令清空定义的所有内容：ipvsadm –C清空计数器：ipvsadm -Z [-t|u|f service-address]查看：ipvsadm -L|l [options] –numeric, -n：以数字形式输出地址和端口号 –exact：扩展信息，精确值 –connection，-c：当前IPVS连接输出 –stats：统计信息 –rate ：输出速率信息ipvs规则： /proc/net/ip_vsipvs连接：/proc/net/ip_vs_conn 保存及重载规则保存：建议保存至/etc/sysconfig/ipvsadm ipvsadm-save -n &gt; /PATH/TO/IPVSADM_FILE ipvsadm -Sn &gt; /PATH/TO/IPVSADM_FILE systemctl stop ipvsadm.service重载： ipvsadm-restore &lt; /PATH/FROM/IPVSADM_FILE ipvsadm -R &lt; /PATH/FROM/IPVSADM_FILE systemctl restart ipvsadm.service LVS负载均衡集群设计时要注意的问题 (1) 是否需要会话保持(2) 是否需要共享存储 共享存储：NAS， SAN， DS（分布式存储） 数据同步：lvs-nat： 设计要点： (1) RIP与DIP在同一IP网络, RIP的网关要指向DIP (2) 支持端口映射 (3) Director要打开核心转发功能 作业NAT模型实现http负载均衡集群NAT模型实现https负载均衡集群注意：RS: 都要提供同一个私钥和同一个证书 LVS-DR DR模型中各主机上均需要配置VIP，解决地址冲突的方式有三种： (1) 在前端网关做静态绑定 (2) 在各RS使用arptables (3) 在各RS修改内核参数，来限制arp响应和通告的级别 限制响应级别：arp_ignore0：默认值，表示可使用本地任意接口上配置的任 意地址进行响应1: 仅在请求的目标IP配置在本地主机的接收到请求报文的接口上时，才给予响应 限制通告级别：arp_announce0：默认值，把本机所有接口的所有信息向每个接口的网络进行通告 1：尽量避免将接口信息向非直接连接网络进行通告 2：必须避免将接口信息向非本网络进行通告 RS的配置脚本 12345678910111213141516171819202122232425#!/bin/bash vip=10.0.0.100 mask=&apos;255.255.255.255‘ dev=lo:1 case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $dev $vip netmask $mask #broadcast $vip up #route add -host $vip dev $dev ;; stop) ifconfig $dev down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ;; *) echo &quot;Usage: $(basename $0) start|stop&quot; exit 1 ;; esac VS的配置脚本 12345678910111213141516171819202122232425#!/bin/bash vip=&apos;10.0.0.100&apos; iface=&apos;eth0:1&apos; mask=&apos;255.255.255.255&apos; port=&apos;80&apos; rs1=&apos;192.168.0.101&apos; rs2=&apos;192.168.0.102&apos; scheduler=&apos;wrr&apos; type=&apos;-g&apos; case $1 in start) ifconfig $iface $vip netmask $mask #broadcast $vip up iptables -F ipvsadm -A -t $&#123;vip&#125;:$&#123;port&#125; -s $scheduler ipvsadm -a -t $&#123;vip&#125;:$&#123;port&#125; -r $&#123;rs1&#125; $type -w 1 ipvsadm -a -t $&#123;vip&#125;:$&#123;port&#125; -r $&#123;rs2&#125; $type -w 1 ;; stop) ipvsadm -C ifconfig $iface down ;; *) echo &quot;Usage $(basename $0) start|stop“ exit 1 esac 作业实现NAT模式网络拓扑要求：VIP与DIP/RIP不在同一网络DR模型实现http负载均衡集群DR模型实现https负载均衡集群 注意：RS: 都要提供同一个私钥和同一个证书DR模型实现mysql负载均衡集群 FireWall MarkFWM：FireWall MarkMARK target 可用于给特定的报文打标记 –set-mark value 其中：value 可为0xffff格式，表示十六进制数字借助于防火墙标记来分类报文，而后基于标记定义集群服务；可将多个不同的 应用使用同一个集群服务进行调度实现方法： 在Director主机打标记： iptables -t mangle -A PREROUTING -d $vip -p $proto –m multiport –dports $port1,$port2,… -j MARK –set-mark NUMBER 在Director主机基于标记定义集群服务： ipvsadm -A -f NUMBER [options] 持久连接session 绑定：对共享同一组RS的多个集群服务，需要统一进行绑定，lvs sh算法无法实现 持久连接（ lvs persistence ）模板：实现无论使用任何调度算法，在一段时间内（默认 360s ），能够实现将来自同一个地址的请求始终发往同一个RS ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] 持久连接实现方式： 每端口持久（PPC）：每个端口对应定义为一个集群服务，每集群服务单独调度 每防火墙标记持久（PFWMC）：基于防火墙标记定义集群服务；可实现将多个端口上的应 用统一调度，即所谓的port Affinity 每客户端持久（PCC）：基于0端口（表示所有服务）定义集群服务，即将客户端对所有应 用的请求都调度至后端主机，必须定义为持久模式 LVS高可用性 1 Director不可用，整个系统将不可用；SPoF Single Point of Failure 解决方案：高可用 keepalived heartbeat/corosync 2 某RS不可用时，Director依然会调度请求至此RS 解决方案： 由Director对各RS健康状态进行检查，失败时禁用，成功时启用 keepalived heartbeat/coro sync ldirectord 检测方式： (a) 网络层检测，icmp (b) 传输层检测，端口探测 (c) 应用层检测，请求某关键资源 RS全不用时：backup server, sorry server ldirectordldirectord：监控和控制LVS守护进程，可管理LVS规则包名：ldirectord-3.9.6-0rc1.1.1.x86_64.rpm文件： /etc/ha.d/ldirectord.cf 主配置文件 /usr/share/doc/ldirectord-3.9.6/ldirectord.cf 配置模版 /usr/lib/systemd/system/ldirectord.service 服务 /usr/sbin/ldirectord 主程序 /var/log/ldirectord.log 日志 /var/run/ldirectord.ldirectord.pid pid 文件 Ldirectord配置文件示例 checktimeout=3checkinterval=1 autoreload=yes logfile=“/var/log/ldirectord.log“ #日志文件 quiescent=no #down时yes权重为0，no为删除 virtual=5 #指定VS的FWM或IP：port real=172.16.0.7:80 gate 2 real=172.16.0.8:80 gate 1 fallback=127.0.0.1:80 gate #sorry server service=http scheduler=wrr checktype=negotiate checkport=80 request=”index.html” receive=“Test Ldirectord” 在生产中，假如，LVS 服务器后端有很多外部服务器，如果按照 rr 算法，轮询的方式进行调度，也就是说每个服务器都会被调度到，但是其中一台服务器宕机，不能提供外部服务， LVS 服务器还会把请求调度到这台服务器上，这是就会报错，所以 LVS 调度器没有健康检查的功能，宕机了还会调度，这就不好了，所以就有 ldirectord 这个工具来完成这个任务，这个工具是用来监控和控制 LVS 进程，可以把出故障的服务器在 LVS 规则中删除掉，进而解决用户访问出错的问题。所以要在 lvs 调度器上安装这个工具。 要用这个工具，必须安装相应的包，但是这个包在 base源 和 epel 源中都没有，只能自己在网上找相应的 epel 源进行安装。还有就是如果安装这个包，就不用在手动添加 ipvs 规则，都直接在这个包的配置文件中进行修改即可。 下载包 ldirectord-3.9.6-0rc1.1.1 下载完后 /etc/ha.d 是他的主配置文件,但是这个文件是空的 /usr/share/doc/ldirectord-3.9.6/ldirectord.cf 这个也是配置文件，但是这个里面全是一些案例。 我们可以把 ldirectord.cf 这个文件拷贝 到主配置文件中 /etc/ha.d 然后进行修改就可以了。 cp /usr/share/doc/ldirectord-3.9.6/ldirectord.cf /etc/ha.d/ 然后进行修改 vim /etc/ha.d/ldirectord.cf 这样基本上就修改完毕了，接下来重启服务，第一次设置还要重启服务，以后就不用了。systemctl restart ldirectord.service这个配置文件重启服务后，就会在 LVS 服务器上自动生成相应的规则，所以在前面说不用手动配规则。 还有就是，假如后端有两个外部服务器，有一个宕机了，这时 LVS 调度器就不会把客户的访问调度到宕机的服务器上了，如果都宕机，也会显示系统维修或 抱歉 的一些信息。 但是不跑上面的脚本加调度规则了，还有一个就是 VIP 地址就得手动添加了，也可以先跑一边脚本， 这样 VIP 地址就加上了，然后把规则清空，在重启下 ldirectord.service 这个服务也是可以的。 注意： 安装这个服务，一定是在 LVS 调度器上安装，还有要在这台服务器上安装 外部服务 httpd ，以便提供 维护信息等。 如果要把 http 和 https 当成一个集群服务的话，就要定义防火墙标签，但是定义标签后 ldirectord 这个包的配置文件就得修改 标签如： iptables -t mangle -A PREROUTING -d 10.0.0.100 -p tcp -m multiport –dports 443,80 -j MARK –set-mark 10 修改 ldirectord 配置文件 vim /etc/ha.d/ldirectord.cf 注意上面的配置文件还得添加 fallback=127.0.0.1:80 gate这条记录，不然 维护信息不能显示。 修改完要重启服务systemctl restart ldirectord.service","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"lvs","slug":"lvs","permalink":"http://yoursite.com/tags/lvs/"}]},{"title":"LAMP 架构的各种演示","slug":"LAMP 架构的各种演示","date":"2017-06-10T16:00:00.000Z","updated":"2018-08-09T07:56:59.155Z","comments":true,"path":"2017/06/11/LAMP 架构的各种演示/","link":"","permalink":"http://yoursite.com/2017/06/11/LAMP 架构的各种演示/","excerpt":"实验： LAMP 实现phpMyadmin先装包yum -y install httpd mariadb-server php php-mysqlsystemctl start httpdsystemctl start mariadb然后从官网上下载对应版本的phpMyadmin下载：https://www.phpmyadmin.net/downloads/然后进行解包，注意解包时一定要解在 /var/www/html 目录下cd /var/www/html unzip phpMyAdmin-4.0.10.20-all-languages.zip解完包后给改个名mv phpMyAdmin-4.0.10.20-all-languages pma找到类似于配置文件的一个文件给他改名cp config.sample.inc.php config.inc.php还需要安装一个工具包yum -y install php-mbstring安装完重启服务systemctl reload httpd这样就可以打开浏览器进行访问了，但是显示的界面让输入账号密码。注意这儿的账号密码是相对于 mysql 的账号密码所以还要在数据库中设置账号密码，我们可以跑一下安全脚本来生成账号密码。mysql_secure_installation然后就可以在浏览器上输入账号密码就入了，这样就可以在图形界面来管理数据库了。","text":"实验： LAMP 实现phpMyadmin先装包yum -y install httpd mariadb-server php php-mysqlsystemctl start httpdsystemctl start mariadb然后从官网上下载对应版本的phpMyadmin下载：https://www.phpmyadmin.net/downloads/然后进行解包，注意解包时一定要解在 /var/www/html 目录下cd /var/www/html unzip phpMyAdmin-4.0.10.20-all-languages.zip解完包后给改个名mv phpMyAdmin-4.0.10.20-all-languages pma找到类似于配置文件的一个文件给他改名cp config.sample.inc.php config.inc.php还需要安装一个工具包yum -y install php-mbstring安装完重启服务systemctl reload httpd这样就可以打开浏览器进行访问了，但是显示的界面让输入账号密码。注意这儿的账号密码是相对于 mysql 的账号密码所以还要在数据库中设置账号密码，我们可以跑一下安全脚本来生成账号密码。mysql_secure_installation然后就可以在浏览器上输入账号密码就入了，这样就可以在图形界面来管理数据库了。 实验：实现LAMP 搭建个人博客wordpress （基于上面实验的状态）先从官网上下载相应的包 https://cn.wordpress.org/下载包 wordpress-4.9.4-zh_CN.tar.gz然后进行解压缩，但是解压缩要指定一各路径，在生产中如果整个网站都用来搭建博客，那就解压缩到 /var/www/html 目录下，我们现在在一台主机上，所以放在一个子目录下。 tar xf wordpress-4.9.4-zh_CN.tar.gz -C /var/www/html/解压后会在/var/www/html/ 目录下生成一个文件夹wordpresscd wordpress还是找到配置文件然后进行改名cp wp-config-sample.php wp-config.php 然后对这个文件进行修改，把自己设置的数据库信息填上去 然后就可以在浏览器上访问这个目录了 http://192.168.1.136/wordpress就会看到输入账号密码界面，在上面填写相关信息 成功后就会在刚才创建的那个数据库 wpdb 中生成一些表，创建时是空的。然后就可以点击上面的登录进行登录了。这样就可以在上面进行操作了，写文章等。到此就实现了个人博客搭建 CentOS7源码编译Php-xcache加速访问官网：http://xcache.lighttpd.net/wiki/ReleaseArchive下载包 xcache-3.2.0.tar.gz先解压 tar xvf xcache-3.2.0.tar.gz解压完会生成 xcache-3.2.0 这个文件夹安装开发包组yum groupinstall “development tools” 按平时编译安装现在一般就跑一下编译脚本 configure ，但是 cd xcache-3.2.0 这个目录发现没有这个脚本，所以先装一个包yum -y install php-devel装完后然后跑一下 phpize 这个程序来生成编译环境跑完这个程序会发现在xcache-3.2.0 目录下生成了 configure 这个脚本接下来就可以运行了 注意编译前一定要在 xcache-3.2.0 这个目录下./configure –enable-xcache –with-php-config=/usr/bin/php-config make &amp;&amp; make install编译完后就会在 /usr/lib64/php/modules/ 目录下生成 xcache.so 这个模块然后我们需用来加载下这个模块让系统知道cp xcache-3.2.0/xcache.ini /etc/php.d/最后重启服务就可以使用了 systemctl restart httpd 实验： 实现 fastcgi 模式的LAMP （基于一台主机）先装包yum install httpd php-fpm php-mysql mariadb-server装完后查看下 php-fpm 包的结构 /etc/php-fpm.conf 这是主配置文件 /etc/php-fpm.d/www.conf 这是与Apache 相关的配置文件 /usr/sbin/php-fpm 这是主程序启动 php-fpm 服务systemctl start php-fpm因为客户端向 apache 访问 php 程序时， apache 要知道 php程序放在哪，所以要在 httpd 的配置文件中添加相关内容。 1234vim /etc/httpd/conf.d/fcgi.conf 在里面添加 DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/var/www/html/$1 启动服务 systemctl start httpd mariadb到此 LAMP 架构配置就搭建好了 接下来就可以测试一下现在 /var/www/html/ 目录下创建一个文件 index.php .编辑此文件 vim index.php在里面添加 1234567&gt;?php$dsn=&apos;mysql:host=localhost;dbname=mysql&apos;;$username=&apos;root&apos;;$passwd=&apos;&apos;;$dbh=new PDO($dsn,$username,$passwd);var_dump($dbh);?&gt; 接下来就可以打开浏览器进行访问了。 现在我们可以把各个服务分别放在不同主机上，准备三台主机，分别为 192.168.30.7 192.168.30.17 192.168.30.27 。 安装前在各台主机上把 SElinux 和 iptables 都关掉。 192.168.30.7 用来当做apache 服务器 192.168。30.17 用来当做 php-fpm 服务器 192.168.30.27 用来当做 mysql 服务器在 192.168.30.17 主机上安装 yum install php-fpm php-mysql在 192.168.30.27 主机上安装 yum install mariadb-server在 192.168.30.7 主机上安装 yum install httpd 接下来先来配置后端数据库，来到 192.168.30.27 主机上连接数据库，先创建一个账号 grant all on . to test@’192.168.30.17’ identified by ‘centos’;flush privileges; 重新加载数据库 接下来来到 192.168.30.17 这台主机上修改 php-fpm 的配置文件 vim /etc/php-fpm.d/www.conf在里面进行修改 把 listen = 127.0.0.1:9000 修改为 listen = 9000 把 listen.allowed_clients = 127.0.0.1 这行注释掉然后启动服务 systemctl start php-fpm创建文件夹 mkdir /data/www 在这个目录下在创建一个文件 vim index.html在里面添加内容 1234567891011121314&lt;?phptry &#123; $user=&apos;test&apos;; $pass=&apos;centos&apos;; $dbh = new PDO(&apos;mysql:host=192.168.30.27;dbname=mysql&apos;, $user, $pass); foreach($dbh-&gt;query(&apos;SELECT user,host from user&apos;) as $row) &#123; print_r($row); &#125; $dbh = null;&#125; catch (PDOException $e) &#123; print &quot;Error!: &quot; . $e-&gt;getMessage() . &quot;&lt;br/&gt;&quot;; die();&#125;?&gt; 来到 192.168.30.7 这台主机上修改 httpd 的配置文件 vim /etc/httpd/conf.d/fcgi.conf在里面添加 123DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://192.168.30.17:9000/data/www/$1 重启服务systemctl restart httpd 到此各个主机上的服务就配置好了，接下来就可以进行测试访问了打开浏览器 输入 192.168.30.7 （注意：这块是访问外部服务器的地址），如果访问结果显示出数据库内容说明搭建成功。 现在在这个架构上搭建一个应用 ， Discuz 论坛来到 192.168.30.17 主机上，把从官网下载的相应包传送到这台主机上。 Discuz_x3.2_SC_UTF8.zip这是个压缩包，所以先解压缩unzip Discuz_x3.2_SC_UTF8.zip解完后会生成很多文件夹 ，我们用 upload 这个文件夹cd upload/如果想整个网站做这个论坛就把所有文件都复制过去cp -r * /data/www/现在还要给 apache 用户添加这个目录的权限，将来 apache 会在这个目录下生成一些配置文件setfacl -R -m u:apache:rwx /data/www接下来就可以在浏览器上进行访问了 192.168.30.7/install/index.php就会显示一些信息 点击我同意 然后进行填写信息即可。 但是会发现搭建是搭建成功了，只有文字，没有图片。因为 php 程序是支持动态页面的，对静态页面兼容性不好，一般在生产中默认也是把这两个服务放在一台主机上的，现在就把 httpd 和 php-fpm 放在一台主机上就不会出现这样的情况。 现在再192.168.30.17 这台主机上安装 httpd 服务yum install httpd 修改配置文件 vim /etc/httpd/conf.d/fcgi.conf 在里面添加 123DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/data/www/$1 并且在主配置文件中把网站默认路径修改为我们创建的这个目录 vim /etc/httpd/conf/httpd.conf 在里面进行修改 DocumentRoot “/data/www/“ 并且要进行授权 重启服务systemctl restart httpd然后在拿浏览器进行访问 ，这回访问的就是 192.168.30.17就会看到正常页面了。到此就实现了LAMP 搭建应用。 现在又有新的要求了，要求实现虚拟主机，在同一台主机上搭建 wordpress 和 Discuz 。现在已经实现了一个Discuz ，那怎么实现另一个呢，将来要实现的结果是在浏览器上访问 www.bbs.com 是 Discuz ，访问 www.blog.com 是 wordpress。 还是在 192.168.30.17 这台主机上 首先查看目录 cd /data目录下现在只有一个 www/ 目录，这个目录是存放论坛的数据现在再创建一个文件夹来存放博客 mkdir www2/接下来把 wordpress 包传送到这台主机上wordpress-4.9.4-zh_CN.tar.gz进行解压缩tar xvf wordpress-4.9.4-zh_CN.tar.gz解压完后把解压的数据全部复制到 /data/www2/目录下cp -r wordpress/* /data/www2/复制完后 cd 到 /data/www2/ 目录下把配置文件进行改名并修改内容cp wp-config-sample.php wp-config.php 修改这个配置文件时先要创建一个数据库，因为这个配置文件中要连接数据库和用户账号密码等。 所以回到 192.168.30.27 主机上 连接到数据库创建一个数据库 create database wpdb;然后又回到 192.168.30.17 主机上cd /data/www2/ 目录下 修改配置文件 vim wp-config.php在里面修改 到这 wordpress 就做完了接下来准备虚拟主机的配置 cd 到 /etc/httpd/conf.d/ 目录下vim vhosts.conf在里面添加内容 123456789101112131415161718192021&lt;virtualhost *:80servername www.bbs.comdocumentroot /data/wwwDirectoryIndex index.phpProxyPassMatch off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/data/www/$1&lt;directory /data/wwwrequire all granted&lt;/directory&lt;/virtualhost&lt;virtualhost *:80&gt;servername www.blog.comdocumentroot /data/www2DirectoryIndex index.phpProxyPassMatch off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/data/www2/$1&lt;directory /data/www2&gt;require all granted&lt;/directory&gt;&lt;/virtualhost&gt; 重启服务systemctl restart httpd 接下来就可以找个主机当客户端进行访问测试了。现在用 192.168.30.6 这台主机进行测试访问。测试前先在这台主机的 hosts 文件中添加 域名 vim /etc/hosts 在里面添加 192.168.30.17 www.bbs.com www.blog.com然后打开图形界面浏览器 分别访问两个地址 filefox www.bbs.com filefox www.blog.com 实验：实现 CentOS7 fpm方式源码编译安装LAMP现在准备一台主机，192.168.30.17 ， 192.168.30.17 主机上安装 apache ,php-fpm，mariadb,编译前我们要先规划一下思路，先编译谁再编译谁，顺序一定要搞清。现在我们先编译 apache ，再编译 mariadb ， 最后编译 php-fpm ，把架构搭建好以后，最后那博客搭建就OK 。 接下来我们进行编译 首先准备各种源码包，版本环境apr-1.6.3.tar.gzapr-util-1.6.1.tar.gzhttpd-2.4.33.tar.bz2mariadb-10.2.15-linux-x86_64.tar.gzphp-7.1.18.tar.bz2wordpress-4.9.4-zh_CN.tar.gz 这些包在相应的官网上都可以下载到接下来创建一个文件夹把这些包 都放进去mkdir srcsmv .gz .bz2 srcs/ 1, 接下来先编译安装 httpd ，因为 httpd 依赖于 apr ，所以也要安装上。先解包cd /root/srcs/tar xvf apr-1.6.3.tar.gztar xvf apr-util-1.6.1.tar.gztar xvf httpd-2.4.33.tar.bz2解包完后生成三个文件夹 apr-1.6.3 apr-util-1.6.1 httpd-2.4.33把三个软件都放在一块进行编译，都放在 httpd 的 srclib/ 文件夹下并改名。 mv apr-1.6.3 httpd-2.4.33/srclib/apr mv apr-util-1.6.1 httpd-2.4.33/srclib/apr-util/然后 cd 切入 httpd-2.4.33 这个目录下进行编译编译前先把一些依赖性的包先装上。yum groupinstall “development tools”yum install openssl-devel pcre-devel expat-devel ./configure –prefix=/app/httpd24 \\ –sysconfdir=/etc/httpd24 \\–enableso \\–enable-ssl \\–enable-cgi \\ –enable-rewrite \\ –with-zlib \\ –with-pcre \\–with-includedapr \\–enable-modules=most \\–enable-mpms-shared=all \\–with-mpm=prefork如果编译完发现少编译了一些选项等，可以用命令 make clean 清理了重新编译。make -j 4 &amp;&amp; make install编译完后 cd /app/httpd24/ 目录下 添加 PATH 变量echo PATH=/app/httpd24/bin:$PATH &gt; /etc/profile.d/lamp.sh生效一下 . /etc/profile.d/lamp.sh可以查看下他的各种文件的路径主页面放在 /app/httpd24/htdocs 文件下配置文件放在 /app/httpd24/conf/httpd.conf 文件中然后用启动工具 apachectl 启动服务这样外部服务就基本上配置完了 2, 接下来安装数据库 mariadb （在生产中是编译安装的，因为源码编译数据库有点慢，这次就拿二进制编译代替了） 先解包 cd /root/srcs/ tar xvf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/local/ 解包完后 cd 到 /usr/local/ 目录下创建软连接 ， 并且软连接的名字必须叫 mysqlln -s mariadb-10.2.15-linux-x86_64.tar.gz mysql创建 mysql 账号uaeradd -r -s /sbin/nologin mysql修改 mysql/ 目录所有者所属组chown -R mysql.mysql mysql/接下来创建一个存放用户数据的目录并修改属性mkdir /data/mysql -pvchown mysql.mysql /data/mysql/然后添加 PATH 变量 vim /etc/profile.d/lamp.sh在原来的基础上修改为： PATH=/app/httpd24/bin:/usr/local/mysql/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin/:/usr/bin:/root/bin修改完后生效一下 . /etc/profile.d/lamp.sh接下来跑一个脚本cd /usr/local/mysql. /scripts/mysql_install_db –datadir=/data/mysql –user=mysql接下来拷贝 服务脚本和配置文件cp support-files/my-huge.cnf /etc/my.cnfcp support-files/mysql.server /etc/init.d/mysqld修改配置文件 vim /etc/my.cnf在里面添加 datadir= /data/mysql log_bin接下来就准备启动了chkconfig –add mysqldservice mysqld start接下里连接到数据库中创建一个数据库和一个账号将来给 wordpress 用的。create database wpdb;grant all on wpdb.* to wpuser@’192.168.30.%’ identified by ‘centos’;重新加载数据库 flush privileges;到此数据库就配置完毕了。 3, 接下来编译 安装 fastcgi 模式的 php 先解包cd /root/srcstar xvf php-7.1.18.tar.bz2解完包后会生成一个文件夹 php-7.1.18然后 cd 到 php-7.1.18 目录下进行编译编译前先把一些依赖的包先装上yum install libxm12-devel bzipz-devel libmcrypt-devel ./configure –prefix=/app/php \\–enable-mysqlnd \\–with-mysqli=mysqlnd \\ –with-openssl \\ –with-pdo-mysql=mysqlnd \\ –enable-mbstring \\ –with-freetype-dir \\–with-jpeg-dir \\ –with-png-dir \\–with-zlib \\–with-libxml-dir=/usr \\ –enable-xml \\ –enable-sockets \\–enable-fpm \\–with-config-file-path=/etc \\ –with-config-file-scan-dir=/etc/php.d \\ –enable-maintainer-zts \\–disable-fileinfomake -j 4 &amp;&amp; make installcd /root/srcs/php-7.1.18编译完后添加PATH 变量 vim /etc/profile.d/lamp.sh在原来的基础上修改为： PATH=/app/php/bin:/app/php/sbin:/app/httpd24/bin:/usr/local/mysql/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin/:/usr/bin:/root/bin修改完后生效一下 . /etc/profile.d/lamp.sh接下来准备php 的配置文件cp php.ini-production /etc/php.ini还要准备一个服务脚本cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm并且给这个文件加权限chmod +x /etc/init.d/php-fpm还要添加到服务chkconfig –add php-fpmchkconfig php-fpm on接下来还要准备一个配置文件cd /app/php/etc/cp php-fpm.conf.default php-fpm.confcd php-fpm.dcp www.conf.default www.conf接下来启动服务service php-fpm start到此 php 就准备好了 4, 接下来准备一下 worepress先解包，但是解包要接到外部服务的访问页面路径下cd /app/httpd24/htdocs/tar xvf /root/srcs/wordpress-4.9.4-zh_CN.tar.gz .接完后就生成一个文件夹 wordpress如果将来搭建的这个网站只用来做博客用就可以把 wordpress 这个文件夹下的数据全部移动到当前目录下mv wordpress/* .然后把配置文件的名字修改一下,并修改配置文件cp wp-config-sample.php wp-config.phpvim wp-config.php这样 wordpress 就准备好了 5, 接下来还要对 httpd 的配置文件 进行修改 vim /app/httpd24/conf/httpd.conf在里面进行修改 取消下面两行的注释 1234567891011LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 修改下面行，添加 index.php ，如下: &lt;IFModule dir_module&gt; DirectoryIndex index.php index.html &lt;/IFModule&gt; 还要添加下面四行 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 修改完后需要把 apache 服务停了在重新启动apachectl stopapachectl 到此所有配置就完成了，就可以拿浏览器进行连接了，如： 192.168.30.17如果成功，就会显示出安装博客的页面，然后就可以设置账号密码进行安装了。注意： 这个账号密码是将来管理博客后台的账号密码。 CentOS6编译安装PHP-FPM模式的LAMP编译httpd和二进制安装mariadb安装相关包 bzip2-devel libxml2-devel libmcrypt-devel(epel源)编译安装phpcd php-5.6.30/./configure –prefix=/app/php5 –with-mysql=/usr/local/mysql –withopenssl –with-mysqli=/usr/local/mysql/bin/mysql_config –enablembstring –with-freetype-dir –with-jpeg-dir –with-png-dir –with-zlib –with-libxml-dir=/usr –enable-xml –enable-sockets –enable-fpm – with-mcrypt –with-config-file-path=/etc/php5 –with-config-filescan-dir=/etc/php5.d –with-bz2make -j 4 &amp;&amp; make install CentOS6编译安装PHP-FPM模式的LAMP实现php的配置文件和服务脚本mkdir /etc/php5 /etc/php5.d/cd php-5.6.30/cp php.ini-production /etc/php5/php.ini cp sapi/fpm/init.d.php-fpm /etc/rc.d/init.d/php-fpmchmod +x /etc/rc.d/init.d/php-fpmchkconfig –add php-fpmchkconfig –list php-fpm CentOS6编译安装PHP-FPM模式的LAMP编辑php配置文件cd /app/php5/etccp php-fpm.conf.default php-fpm.confvim /app/php5/etc/php-fpm.conf pm.max_children = 50 pm.start_servers = 5 pm.min_spare_servers = 2pm.max_spare_servers = 5 和pm.start_servers一致 pid = /app/php5/var/run/php-fpm.pid service php-fpm restart 实验：CentOS6编译安装PHP-FPM模式的LAMP修改httpd24的配置文件vim /app/apache24/conf/httpd.conf 说明：启用httpd的相关模块 在Apache httpd 2.4以后已经专门有一个模块针对FastCGI的实现，此模块为 mod_proxy_fcgi.so，它其实是作为mod_proxy.so模块的扩充，因此，这两个 模块都要加载去掉下面两行注释 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 添加如下二行 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps定位至DirectoryIndex index.html修改为：DirectoryIndex index.php index.html 加下面两行 ProxyRequests Off 关闭正向代理 ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 service httpd24 restart 测试vim /app/httpd24/htdocs/index.php如下：&lt;?php$link = mysql_connect(‘127.0.0.1’,’root’,’magedu’);if ($link)echo “Success…”;else echo “Failure…”; mysql_close();phpinfo();?&gt;","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"LAMP","slug":"LAMP","permalink":"http://yoursite.com/tags/LAMP/"}]},{"title":"MYSQL 数据库的日志介绍","slug":"MYSQL 数据库的日志介绍","date":"2017-05-21T16:00:00.000Z","updated":"2018-06-18T10:33:47.787Z","comments":true,"path":"2017/05/22/MYSQL 数据库的日志介绍/","link":"","permalink":"http://yoursite.com/2017/05/22/MYSQL 数据库的日志介绍/","excerpt":"不管是哪个数据库产品，一定会有日志文件。在MariaDB/MySQL中，主要有5种日志文件： 1.错误日志(error log)：记录mysql服务的启停时正确和错误的信息，还记录启动、停止、运行过程中的错误信息。 2.查询日志(general log)：记录建立的客户端连接和执行的语句。 3.二进制日志(bin log)：记录所有更改数据的语句，可用于数据复制。 4.慢查询日志(slow log)：记录所有执行时间超过long_query_time的所有查询或不使用索引的查询。 5.中继日志(relay log)：主从复制时使用的日志。","text":"不管是哪个数据库产品，一定会有日志文件。在MariaDB/MySQL中，主要有5种日志文件： 1.错误日志(error log)：记录mysql服务的启停时正确和错误的信息，还记录启动、停止、运行过程中的错误信息。 2.查询日志(general log)：记录建立的客户端连接和执行的语句。 3.二进制日志(bin log)：记录所有更改数据的语句，可用于数据复制。 4.慢查询日志(slow log)：记录所有执行时间超过long_query_time的所有查询或不使用索引的查询。 5.中继日志(relay log)：主从复制时使用的日志。 日志刷新操作 以下操作会刷新日志文件，刷新日志文件时会关闭旧的日志文件并重新打开日志文件。对于有些日志类型，如二进制日志，刷新日志会滚动日志文件，而不仅仅是关闭并重新打开。 123mysql&gt; FLUSH LOGS;shell&gt; mysqladmin flush-logsshell&gt; mysqladmin refresh 错误日志 错误日志是最重要的日志之一，它记录了MariaDB/MySQL服务启动和停止正确和错误的信息，还记录了mysqld实例运行过程中发生的错误事件信息。 可以使用” –log-erroe=[file_name] “来指定mysqld记录的错误日志文件，如果没有指定file_name，则默认的错误日志文件为datadir目录下的 hostname.err ，hostname表示当前的主机名。 也可以在MariaDB/MySQL配置文件中的mysqld配置部分，使用log-error指定错误日志的路径。 如果不知道错误日志的位置，可以查看变量log_error来查看。123456mysql&gt; show variables like &apos;log_error&apos;;+---------------+----------------------------------------+| Variable_name | Value |+---------------+----------------------------------------+| log_error | /var/lib/mysql/node1.longshuai.com.err |+---------------+----------------------------------------+ 在MySQL 5.5.7之前，刷新日志操作(如flush logs)会备份旧的错误日志(以_old结尾)，并创建一个新的错误日志文件并打开，在MySQL 5.5.7之后，执行刷新日志的操作时，错误日志会关闭并重新打开，如果错误日志不存在，则会先创建。 在MariaDB/MySQL正在运行状态下删除错误日志后，不会自动创建错误日志，只有在刷新日志的时候才会创建一个新的错误日志文件。 以下是MySQL 5.6.35启动的日志信息。 123456789101112131415161718192021222017-03-29 01:15:14 2362 [Note] Plugin &apos;FEDERATED&apos; is disabled.2017-03-29 01:15:14 2362 [Note] InnoDB: Using atomics to ref count buffer pool pages2017-03-29 01:15:14 2362 [Note] InnoDB: The InnoDB memory heap is disabled2017-03-29 01:15:14 2362 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins2017-03-29 01:15:14 2362 [Note] InnoDB: Memory barrier is not used2017-03-29 01:15:14 2362 [Note] InnoDB: Compressed tables use zlib 1.2.32017-03-29 01:15:14 2362 [Note] InnoDB: Using Linux native AIO2017-03-29 01:15:14 2362 [Note] InnoDB: Using CPU crc32 instructions2017-03-29 01:15:14 2362 [Note] InnoDB: Initializing buffer pool, size = 128.0M2017-03-29 01:15:14 2362 [Note] InnoDB: Completed initialization of buffer pool2017-03-29 01:15:14 2362 [Note] InnoDB: Highest supported file format is Barracuda.2017-03-29 01:15:14 2362 [Note] InnoDB: 128 rollback segment(s) are active.2017-03-29 01:15:14 2362 [Note] InnoDB: Waiting for purge to start2017-03-29 01:15:14 2362 [Note] InnoDB: 5.6.35 started; log sequence number 39116102017-03-29 01:15:14 2362 [Note] Server hostname (bind-address): &apos;*&apos;; port: 33062017-03-29 01:15:14 2362 [Note] IPv6 is available.2017-03-29 01:15:14 2362 [Note] - &apos;::&apos; resolves to &apos;::&apos;;2017-03-29 01:15:14 2362 [Note] Server socket created on IP: &apos;::&apos;.2017-03-29 01:15:14 2362 [Warning] &apos;proxies_priv&apos; entry &apos;@ root@xuexi.longshuai.com&apos; ignored in --skip-name-resolve mode.2017-03-29 01:15:14 2362 [Note] Event Scheduler: Loaded 0 events2017-03-29 01:15:14 2362 [Note] /usr/local/mysql/bin/mysqld: ready for connections.Version: &apos;5.6.35&apos; socket: &apos;/mydata/data/mysql.sock&apos; port: 3306 MySQL Community Server (GPL) 一般查询日志 查询日志分为一般查询日志和慢查询日志，它们是通过查询是否超出变量 long_query_time 指定时间的值来判定的。在超时时间内完成的查询是一般查询，可以将其记录到一般查询日志中，但是建议关闭这种日志（默认是关闭的），超出时间的查询是慢查询，可以将其记录到慢查询日志中。 使用” –general_log={0|1} “来决定是否启用一般查询日志，使用” –general_log_file=file_name “来指定查询日志的路径。不给定路径时默认的文件名以 hostname.log 命名。 和查询日志有关的变量有： 12341 long_query_time = 10 # 指定慢查询超时时长，超出此时长的属于慢查询，会记录到慢查询日志中 2 log_output=&#123;TABLE|FILE|NONE&#125; # 定义一般查询日志和慢查询日志的输出格式，不指定时默认为file TABLE表示记录日志到表中，FILE表示记录日志到文件中，NONE表示不记录日志。只要这里指定为NONE，即使开启了一般查询日志和慢查询日志，也都不会有任何记 录。 和一般查询日志相关的变量有：123451 general_log=off # 是否启用一般查询日志，为全局变量，必须在global上修改。 2 sql_log_off=off # 在session级别控制是否启用一般查询日志，默认为off，即启用 3 general_log_file=/mydata/data/hostname.log # 默认是库文件路径下主机名加上.log 在MySQL 5.6以前的版本还有一个”log”变量也是决定是否开启一般查询日志的。在5.6版本开始已经废弃了该选项。 默认没有开启一般查询日志，也不建议开启一般查询日志。此处打开该类型的日志，看看是如何记录一般查询日志的。 首先开启一般查询日志。 12345mysql&gt; set @@global.general_log=1;[root@xuexi data]# ll *.log-rw-rw---- 1 mysql mysql 5423 Mar 20 16:29 mysqld.log-rw-rw---- 1 mysql mysql 262 Mar 29 09:31 xuexi.log 执行几个语句。12345mysql&gt; select host,user from mysql.user;mysql&gt; show variables like &quot;%error%&quot;;mysql&gt; insert into ttt values(233);mysql&gt; create table tt(id int);mysql&gt; set @a:=3; 查看一般查询日志的内容。123456789[root@xuexi data]# cat xuexi.log /usr/local/mysql/bin/mysqld, Version: 5.6.35-log (MySQL Community Server (GPL)). started with:Tcp port: 3306 Unix socket: /mydata/data/mysql.sockTime Id Command Argument180421 20:04:41 13 Query select user,host from mysql.user180421 20:06:06 13 Query show variables like &quot;%error%&quot;180421 20:07:28 13 Query insert into ttt values(233)180421 20:11:47 13 Query create table tt(id int)180421 20:12:29 13 Query set @a:=3 由此可知，一般查询日志查询的不止是select语句，几乎所有的语句都会记录。慢查询日志 查询超出变量 long_query_time 指定时间值的为慢查询。但是查询获取锁(包括锁等待)的时间不计入查询时间内。 mysql记录慢查询日志是在查询执行完毕且已经完全释放锁之后才记录的，因此慢查询日志记录的顺序和执行的SQL查询语句顺序可能会不一致(例如语句1先执行，查询速度慢，语句2后执行，但查询速度快，则语句2先记录)。 注意，MySQL 5.1之后就支持微秒级的慢查询超时时长，对于DBA来说，一个查询运行0.5秒和运行0.05秒是非常不同的，前者可能索引使用错误或者走了表扫描，后者可能索引使用正确。 另外，指定的慢查询超时时长表示的是超出这个时间的才算是慢查询，等于这个时间的不会记录。 和慢查询有关的变量：12345678910111 long_query_time=10 # 指定慢查询超时时长(默认10秒)，超出此时长的属于慢查询 2 log_output=&#123;TABLE|FILE|NONE&#125; # 定义一般查询日志和慢查询日志的输出格式，默认为file 3 log_slow_queries=&#123;yes|no&#125; # 是否启用慢查询日志，默认不启用 4 slow_query_log=&#123;1|ON|0|OFF&#125; # 也是是否启用慢查询日志，此变量和log_slow_queries修改一个另一个同时变化 5 slow_query_log_file=/mydata/data/hostname-slow.log #默认路径为库文件目录下主机名加上-slow.log 6 log_queries_not_using_indexes=OFF # 查询没有使用索引的时候是否也记入慢查询日志 现在启用慢查询日志。 1mysql&gt; set @@global.slow_query_log=on; 因为默认超时时长为10秒，所以进行一个10秒的查询。 1mysql&gt; select sleep(10); 查看慢查询日志文件。这里看到虽然sleep了10秒，但是最后查询时间超出了847微秒，因此这里也记录了该查询。 12345678910[root@xuexi data]# cat xuexi-slow.log /usr/local/mysql/bin/mysqld, Version: 5.6.35-log (MySQL Community Server (GPL)). started with:Tcp port: 3306 Unix socket: /mydata/data/mysql.sockTime Id Command Argument# Time: 170329 9:55:58# User@Host: root[root] @ localhost [] Id: 1# Query_time: 10.000847 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use test;SET timestamp=1490752558;select sleep(10); 随着时间的推移，慢查询日志文件中的记录可能会变得非常多，这对于分析查询来说是非常困难的。好在提供了一个专门归类慢查询日志的工具mysqldumpslow。 1234567891011[root@xuexi data]# mysqldumpslow --help -d debug -v verbose：显示详细信息 -t NUM just show the top n queries：仅显示前n条查询 -a don&apos;t abstract all numbers to N and strings to &apos;S&apos;：归类时不要使用N替换数字，S替换字符串 -g PATTERN grep: only consider stmts that include this string：通过grep来筛选select语句。 该工具归类的时候，默认会将同文本但变量值不同的查询语句视为同一类，并使用N代替其中的数值变量，使用S代替其中的字符串变量。可以使用-a来禁用这种替换。如： 123456789[root@xuexi data]# mysqldumpslow xuexi-slow.log Reading mysql slow query log from xuexi-slow.logCount: 1 Time=10.00s (10s) Lock=0.00s (0s) Rows=1.0 (1), root[root]@localhost select sleep(N)[root@xuexi data]# mysqldumpslow -a xuexi-slow.log Reading mysql slow query log from xuexi-slow.logCount: 1 Time=10.00s (10s) Lock=0.00s (0s) Rows=1.0 (1), root[root]@localhost select sleep(10) 显然，这里归类后的结果只是精确到0.01秒的，如果想要显示及其精确的秒数，则使用-d选项启用调试功能。 12345678910111213141516171819202122232425262728293031[root@xuexi data]# mysqldumpslow -d xuexi-slow.log Reading mysql slow query log from xuexi-slow.log[[/usr/local/mysql/bin/mysqld, Version: 5.6.35-log (MySQL Community Server (GPL)). started with:Tcp port: 3306 Unix socket: /mydata/data/mysql.sockTime Id Command Argument# Time: 170329 9:55:58# User@Host: root[root] @ localhost [] Id: 1# Query_time: 10.000847 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use test;SET timestamp=1490752558;select sleep(10);]]&lt;&lt;&gt;&gt;&lt;&lt;# Time: 170329 9:55:58# User@Host: root[root] @ localhost [] Id: 1# Query_time: 10.000847 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use test;SET timestamp=1490752558;select sleep(10);&gt;&gt; at /usr/local/mysql/bin/mysqldumpslow line 97, &lt;&gt; chunk 1.[[# Time: 170329 9:55:58# User@Host: root[root] @ localhost [] Id: 1# Query_time: 10.000847 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0use test;SET timestamp=1490752558;select sleep(10);]]&#123;&#123; select sleep(N)&#125;&#125;Count: 1 Time=10.00s (10s) Lock=0.00s (0s) Rows=1.0 (1), root[root]@localhost select sleep(N) 慢查询在SQL语句调优的时候非常有用，应该将它启用起来。二进制日志二进制日志文件 二进制日志包含了引起或可能引起数据库改变(如delete语句但没有匹配行)的事件信息，但绝不会包括select和show这样的查询语句。语句以”事件”的形式保存，所以包含了时间、事件开始和结束位置等信息。 二进制日志是以事件形式记录的，不是事务日志(但可能是基于事务来记录二进制日志)，不代表它只记录innodb日志，myisam表也一样有二进制日志。 二进制日志只在事务提交的时候一次性写入(基于事务的innodb二进制日志)。 MariaDB/MySQL默认没有启动二进制日志，要启用二进制日志使用 –log-bin=[on|off|file_name] 选项指定，如果没有给定file_name，则默认为datadir下的主机名加”-bin”，并在后面跟上一串数字表示日志序列号，如果给定的日志文件中包含了后缀(logname.suffix)将忽略后缀部分。 或者在配置文件中的[mysqld]部分设置log-bin也可以。注意：对于mysql 5.7，直接启动binlog可能会导致mysql服务启动失败，这时需要在配置文件中的mysqld为mysql实例分配server_id。 123[mysqld] # server_id=1234 log-bin=[on|filename] mysqld还创建一个二进制日志索引文件，当二进制日志文件滚动的时候会向该文件中写入对应的信息。所以该文件包含所有使用的二进制日志文件的文件名。默认情况下该文件与二进制日志文件的文件名相同，扩展名为’.index’。要指定该文件的文件名使用 –log-bin-index[=file_name] 选项。当mysqld在运行时不应手动编辑该文件，免得mysqld变得混乱。 当重启mysql服务或刷新日志或者达到日志最大值时，将滚动二进制日志文件，滚动日志时只修改日志文件名的数字序列部分。 二进制日志文件的最大值通过变量 max_binlog_size 设置(默认值为1G)。但由于二进制日志可能是基于事务来记录的(如innodb表类型)，而事务是绝对不可能也不应该跨文件记录的，如果正好二进制日志文件达到了最大值但事务还没有提交则不会滚动日志，而是继续增大日志，所以 max_binlog_size 指定的值和实际的二进制日志大小不一定相等。 因为二进制日志文件增长迅速，但官方说明因此而损耗的性能小于1%，且二进制目的是为了恢复定点数据库和主从复制，所以出于安全和功能考虑，极不建议将二进制日志和datadir放在同一磁盘上。 查看二进制日志 MySQL中查看二进制日志的方法主要有几种。 1.使用mysqlbinlog工具。 2.使用show显示对应的信息。 12345SHOW &#123;BINARY | MASTER&#125; LOGS # 查看使用了哪些日志文件 SHOW BINLOG EVENTS [IN &apos;log_name&apos;] [FROM pos] # 查看日志中进行了哪些操作 SHOW MASTER STATUS # 显式主服务器中的二进制日志信息 mysqlbinlog 二进制日志可以使用mysqlbinlog命令查看。 12mysqlbinlog [option] log-file1 log-file2... 以下是常用的几个选项： 123456789101112131415-d,--database=name：只查看指定数据库的日志操作 -o,--offset=#：忽略掉日志中的前n个操作命令 -r,--result-file=name：将输出的日志信息输出到指定的文件中，使用重定向也一样可以。 -s,--short-form：显示简单格式的日志，只记录一些普通的语句，会省略掉一些额外的信息如位置信息和时间信息以及基于行的日志。可以用来调试，生产环境千万不可使用 --set-charset=char_name：在输出日志信息到文件中时，在文件第一行加上set names char_name --start-datetime,--stop-datetime：指定输出开始时间和结束时间内的所有日志信息 --start-position=#,--stop-position=#：指定输出开始位置和结束位置内的所有日志信息 -v,-vv：显示更详细信息，基于row的日志默认不会显示出来，此时使用-v或-vv可以查看 在进行测试之前，先对日志进行一次刷新，以方便解释二进制日志的信息。 1shell&gt; mysqladmin -uroot -p refresh 假设现在的日志文件是mysql-bin.000001，里面暂时只有一些初始信息，没有记录任何操作过的记录。 下面是每个二进制日志文件的初始信息。可以看到记录了时间和位置信息(at 4)。 12345678910111213141516171819[root@xuexi data]# mysqlbinlog mysql-bin.000001 /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#170329 2:18:10 server id 1 end_log_pos 120 CRC32 0x40f62523 Start: binlog v 4, server v 5.6.35-log created 170329 2:18:10 at startup# Warning: this binlog is either in use or was not closed properly.ROLLBACK/*!*/;BINLOG &apos;4qjaWA8BAAAAdAAAAHgAAAABAAQANS42LjM1LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADiqNpYEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAASMl9kA=&apos;/*!*/;DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 现在在数据库中执行下面的操作：1234use test;create table student(studentid int not null primary key,name varchar(30) not null,gender enum(&apos;female&apos;,&apos;mail&apos;));alter table student change gender gender enum(&apos;female&apos;,&apos;male&apos;);insert into student values(1,&apos;malongshuai&apos;,&apos;male&apos;),(2,&apos;gaoxiaofang&apos;,&apos;female&apos;); 再查看二进制日志信息。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@xuexi data]# mysqlbinlog mysql-bin.000001 /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#170329 2:18:10 server id 1 end_log_pos 120 CRC32 0x40f62523 Start: binlog v 4, server v 5.6.35-log created 170329 2:18:10 at startup# Warning: this binlog is either in use or was not closed properly.ROLLBACK/*!*/;BINLOG &apos;4qjaWA8BAAAAdAAAAHgAAAABAAQANS42LjM1LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADiqNpYEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAASMl9kA=&apos;/*!*/;# at 120#170329 5:20:00 server id 1 end_log_pos 305 CRC32 0xbac43912 Query thread_id=1 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1490736000/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;create table student(studentid int not null primary key,name varchar(30) not null,gender enum(&apos;female&apos;,&apos;mail&apos;))/*!*/;# at 305#170329 5:21:21 server id 1 end_log_pos 441 CRC32 0xde67f702 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736081/*!*/;alter table student change gender gender enum(&apos;female&apos;,&apos;male&apos;)/*!*/;# at 441#170329 5:21:33 server id 1 end_log_pos 520 CRC32 0x05a9c5a1 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;BEGIN/*!*/;# at 520#170329 5:21:33 server id 1 end_log_pos 671 CRC32 0xad9e7dc8 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;insert into student values(1,&apos;malongshuai&apos;,&apos;male&apos;),(2,&apos;gaoxiaofang&apos;,&apos;female&apos;)/*!*/;# at 671#170329 5:21:33 server id 1 end_log_pos 702 CRC32 0xb69b0f7d Xid = 32COMMIT/*!*/;DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 将上述信息整理为下图：其中timestamp记录的是从1970-01-01到现在的总秒数时间戳，可以使用 date -d ‘@1490736093’ 转换。 位置0-120记录的是二进制日志的一些固定信息。 位置120-305记录的是use和create table语句，语句的记录时间为5:20:00。但注意，这里的use不是执行的use语句，而是MySQL发现要操作的数据库为test，而自动进行的操作并记录下来。人为的use语句是不会记录的。 位置305-441记录的是alter table语句，语句的记录时间为5:20:21。 位置441-702记录的是insert操作，因为该操作是DML语句，因此记录了事务的开始BEGIN和提交COMMIT。begin的起止位置为441-520；insert into语句的起止位置为520-671，记录的时间和自动开启事务的begin时间是一样的；commit的起止位置为671-702。 使用-r命令将日志文件导入到指定文件中，使用重定向也可以实现同样的结果。并使用-s查看简化的日志文件。 12[root@xuexi data]# mysqlbinlog mysql-bin.000001 -r /tmp/binlog.000001[root@xuexi data]# mysqlbinlog mysql-bin.000001 -s&gt;/tmp/binlog.sample 比较这两个文件，看看简化的日志文件简化了哪些东西。 从上图中可以看出，使用-s后，少了基于行的日志信息，也少了记录的位置和时间信息。 使用-o可以忽略前N个条目，例如上面的操作涉及了6个操作。忽略掉前3个后的日志显示如下：可以看到直接从位置441开始显示了。 1234567891011121314151617181920212223242526272829[root@xuexi data]# mysqlbinlog mysql-bin.000001 -o 3...前面固定部分省略...&apos;/*!*/;# at 441#170329 5:21:33 server id 1 end_log_pos 520 CRC32 0x05a9c5a1 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 520#170329 5:21:33 server id 1 end_log_pos 671 CRC32 0xad9e7dc8 Query thread_id=1 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1490736093/*!*/;insert into student values(1,&apos;malongshuai&apos;,&apos;male&apos;),(2,&apos;gaoxiaofang&apos;,&apos;female&apos;)/*!*/;# at 671#170329 5:21:33 server id 1 end_log_pos 702 CRC32 0xb69b0f7d Xid = 32COMMIT/*!*/;DELIMITER ;...后面固定部分省略... 使用-d可以只显示指定数据库相关的操作。例如先切换到其他数据库进行一番操作，然后再使用-d查看日志。 1234567891011121314151617181920212223242526272829303132mysql&gt; use mysql;mysql&gt; create table mytest(id int);[root@xuexi data]# mysqlbinlog mysql-bin.000001 -d mysql...前固定部分省略...&apos;/*!*/;# at 120# at 305# at 441#170329 5:21:33 server id 1 end_log_pos 520 CRC32 0x05a9c5a1 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 520# at 671#170329 5:21:33 server id 1 end_log_pos 702 CRC32 0xb69b0f7d Xid = 32COMMIT/*!*/;# at 702#170329 6:27:12 server id 1 end_log_pos 805 CRC32 0x491529ff Query thread_id=1 exec_time=0 error_code=0use `mysql`/*!*/;SET TIMESTAMP=1490740032/*!*/;create table mytest(id int)/*!*/;DELIMITER ;...后面固定部分省略... 可以看到，除了指定的mysql数据库的信息输出了，还非常简化的输出了其他数据库的信息。 mysqlbinlog最有用的两个选项就是指定时间和位置来输出日志。 指定时间时，将输出指定时间范围内的日志。指定的时间可以不和日志中记录的日志相同。 123456789101112131415161718192021222324[root@xuexi data]# mysqlbinlog mysql-bin.000001 --start-datetime=&apos;2017-03-28 00:00:01&apos; --stop-datetime=&apos;2017-03-29 05:21:23&apos;...前面固定部分省略...&apos;/*!*/;# at 120#170329 5:20:00 server id 1 end_log_pos 305 CRC32 0xbac43912 Query thread_id=1 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1490736000/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;create table student(studentid int not null primary key,name varchar(30) not null,gender enum(&apos;female&apos;,&apos;mail&apos;))/*!*/;# at 305#170329 5:21:21 server id 1 end_log_pos 441 CRC32 0xde67f702 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736081/*!*/;alter table student change gender gender enum(&apos;female&apos;,&apos;male&apos;)/*!*/;DELIMITER ;...后面固定部分省略... 同理指定位置也一样，但是指定位置时有个要求是如果指定起始位置，则必须指定日志文件中明确的起始位置。例如，日志文件中有位置120、305、441，可以指定起始和结束位置为120、500，但是不可以指定起止位置为150、500，因为日志文件中不存在150这个位置。 123456789101112131415161718192021222324252627282930[root@xuexi data]# mysqlbinlog mysql-bin.000001 --start-position=150 --stop-position=441...前面固定部分省略...&apos;/*!*/;ERROR: Error in Log_event::read_log_event(): &apos;read error&apos;, data_len: 4202496, event_type: 0...后面固定部分省略... [root@xuexi data]# mysqlbinlog mysql-bin.000001 --start-position=305 --stop-position=500...前面固定部分省略... &apos;/*!*/;# at 305#170329 5:21:21 server id 1 end_log_pos 441 CRC32 0xde67f702 Query thread_id=1 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1490736081/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;alter table student change gender gender enum(&apos;female&apos;,&apos;male&apos;)/*!*/;# at 441#170329 5:21:33 server id 1 end_log_pos 520 CRC32 0x05a9c5a1 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490736093/*!*/;BEGIN/*!*/;DELIMITER ;...后面固定部分省略... show binary logs 该语句用于查看当前使用了哪些二进制日志文件。 可以通过查看二进制的index文件来查看当前正在使用哪些二进制日志。 12345[root@xuexi data]# cat mysql-bin.index ./mysql-bin.000003./mysql-bin.000004./mysql-bin.000005./mysql-bin.000006 也可以在mysql环境中使用 show {binary | master} logs 来查看。binary和master是同义词。 123456789mysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000003 | 167 || mysql-bin.000004 | 785 || mysql-bin.000005 | 1153 || mysql-bin.000006 | 602 |+------------------+----------- show binlog events 该语句用于查看日志中进行了哪些操作。 1mysql&gt; show binlog events in &apos;mysql-bin.000005&apos;; 可以指定起始位置。同样，起始位置必须指定正确，不能指定不存在的位置。123456789mysql&gt; show binlog events in &apos;mysql-bin.000005&apos; from 961;+------------------+------+------------+-----------+-------------+--------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+------------------+------+------------+-----------+-------------+--------------------------------+| mysql-bin.000005 | 961 | Table_map | 1 | 1019 | table_id: 98 (test.student) || mysql-bin.000005 | 1019 | Write_rows | 1 | 1075 | table_id: 98 flags: STMT_END_F || mysql-bin.000005 | 1075 | Xid | 1 | 1106 | COMMIT /* xid=129 */ || mysql-bin.000005 | 1106 | Rotate | 1 | 1153 | mysql-bin.000006;pos=4 |+------------------+------+------------+-----------+-------------+--------------------------------+ show master status 该语句用于显示主服务器中的二进制日志信息。如果是主从结构，它只会显示主从结构中主服务器的二进制日志信息。 123456mysql&gt; show master status; +------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000006 | 602 | | | |+------------------+----------+--------------+------------------+-------------------+ 可以查看到当前正在使用的日志及下一事件记录的开始位置，还能查看到哪些数据库需要记录二进制日志，哪些数据库不记录二进制日志。 删除二进制日志删除二进制日志有几种方法。不管哪种方法，都会将删除后的信息同步到二进制index文件中。reset master将会删除所有日志，并让日志文件重新从000001开始。1mysql&gt; reset master; PURGE { BINARY | MASTER } LOGS { TO ‘log_name’ | BEFORE datetime_expr } purge master logs to “binlog_name.00000X” 将会清空00000X之前的所有日志文件。例如删除000006之前的日志文件。 12mysql&gt; purge master logs to &quot;mysql-bin.000006&quot;;mysql&gt; purge binary logs to &quot;mysql-bin.000006&quot;; master和binary是同义词 purge master logs before ‘yyyy-mm-dd hh:mi:ss’ 将会删除指定日期之前的所有日志。但是若指定的时间处在正在使用中的日志文件中，将无法进行purge。 12345678mysql&gt; purge master logs before &apos;2017-03-29 07:36:40&apos;;mysql&gt; show warnings;+---------+------+---------------------------------------------------------------------------+| Level | Code | Message |+---------+------+---------------------------------------------------------------------------+| Warning | 1868 | file ./mysql-bin.000003 was not purged because it is the active log file. |+---------+------+---------------------------------------------------------------------------+ 使用–expire_logs_days=N选项指定过了多少天日志自动过期清空。二进制日志的记录格式 在MySQL 5.1之前，MySQL只有一种基于语句statement形式的日志记录格式。即将所有的相关操作记录为SQL语句形式。但是这样的记录方式对某些特殊信息无法同步记录，例如uuid，now()等这样动态变化的值。 从MySQL 5.1开始，MySQL支持statement、row、mixed三种形式的记录方式。row形式是基于行来记录，也就是将相关行的每一列的值都在日志中保存下来，这样的结果会导致日志文件变得非常大，但是保证了动态值的确定性。还有一种mixed形式，表示如何记录日志由MySQL自己来决定。 日志的记录格式由变量 binlog_format 来指定。其值有：row,statement,mixed。innodb引擎的创始人之一在博客上推荐使用row格式。 下面将记录格式改为row。1234mysql&gt; alter table student add birthday datetime default now();mysql&gt; flush logs;mysql&gt; set binlog_format=&apos;row&apos;;mysql&gt; insert into student values(7,&apos;xiaowoniu&apos;,&apos;female&apos;,now()); 查看产生的日志。1234567891011121314151617181920212223242526272829303132[root@xuexi data]# mysqlbinlog mysql-bin.000005...前面固定部分省略...&apos;/*!*/;# at 120#170329 8:06:24 server id 1 end_log_pos 200 CRC32 0x0ac02649 Query thread_id=1 exec_time=0 error_code=0SET TIMESTAMP=1490745984/*!*/;SET @@session.pseudo_thread_id=1/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.time_zone=&apos;SYSTEM&apos;/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 200#170329 8:06:24 server id 1 end_log_pos 258 CRC32 0xb8cdfd09 Table_map: `test`.`student` mapped to number 94# at 258#170329 8:06:24 server id 1 end_log_pos 314 CRC32 0x8ce6f72c Write_rows: table id 94 flags: STMT_END_FBINLOG &apos;gPraWBMBAAAAOgAAAAIBAAAAAF4AAAAAAAEABHRlc3QAB3N0dWRlbnQABAMP/hIFHgD3AQAMCf3NuA==gPraWB4BAAAAOAAAADoBAAAAAF4AAAAAAAEAAgAE//AHAAAACXhpYW93b25pdQGZnDqBmCz35ow=&apos;/*!*/;# at 314#170329 8:06:24 server id 1 end_log_pos 345 CRC32 0x7a48c057 Xid = 114COMMIT/*!*/;DELIMITER ;...后面固定部分省略... 发现是一堆看不懂的东西，使用-vv可将这些显示出来。可以看出，结果中记录的非常详细，这也是为什么基于row记录日志会导致日志文件极速变大。 123456789101112131415[root@xuexi data]# mysqlbinlog mysql-bin.000005 -vv...前面省略...BINLOG &apos;gPraWBMBAAAAOgAAAAIBAAAAAF4AAAAAAAEABHRlc3QAB3N0dWRlbnQABAMP/hIFHgD3AQAMCf3NuA==gPraWB4BAAAAOAAAADoBAAAAAF4AAAAAAAEAAgAE//AHAAAACXhpYW93b25pdQGZnDqBmCz35ow=&apos;/*!*/;### INSERT INTO `test`.`student`### SET### @1=7 /* INT meta=0 nullable=0 is_null=0 */### @2=&apos;xiaowoniu&apos; /* VARSTRING(30) meta=30 nullable=0 is_null=0 */### @3=1 /* ENUM(1 byte) meta=63233 nullable=1 is_null=0 */### @4=&apos;2017-03-29 08:06:24&apos; /* DATETIME(0) meta=0 nullable=1 is_null=0 */# at 314...后面省略... 还有一种mixed模式。这种模式下默认会采用statement的方式记录，只有以下几种情况会采用row的形式来记录日志。 1.表的存储引擎为NDB，这时对表的DML操作都会以row的格式记录。 2.使用了uuid()、user()、current_user()、found_rows()、row_count()等不确定函数。但测试发现对now()函数仍会以statement格式记录，而sysdate()函数会以row格式记录。 3.使用了insert delay语句。 4.使用了临时表。 二进制日志相关的变量注意：在配置binlog相关变量的时候，相关变量名总是搞混，因为有的是binlog，有的是log_bin，当他们分开的时候，log在前，当它们一起的时候，bin在前。在配置文件中也同样如此。 log_bin = {on | off | base_name} #指定是否启用记录二进制日志或者指定一个日志路径(路径不能加.否则.后的被忽略) sql_log_bin ={ on | off } #指定是否启用记录二进制日志，只有在log_bin开启的时候才有效 expire_logs_days = #指定自动删除二进制日志的时间，即日志过期时间 binlog_do_db = #明确指定要记录日志的数据库 binlog_ignore_db = #指定不记录二进制日志的数据库 log_bin_index = #指定mysql-bin.index文件的路径 binlog_format = { mixed | row | statement } #指定二进制日志基于什么模式记录 binlog_rows_query_log_events = { 1|0 } # MySQL5.6.2添加了该变量，当binlog format为row时，默认不会记录row对应的SQL语句，设置为1或其他true布尔值时会记录，但需要使用mysqlbinlog -v查看，这些语句是被注释的，恢复时不会被执行。 max_binlog_size = #指定二进制日志文件最大值，超出指定值将自动滚动。但由于事务不会跨文件，所以并不一定总是精确。 binlog_cache_size = 32768 #基于事务类型的日志会先记录在缓冲区，当达到该缓冲大小时这些日志会写入磁盘 max_binlog_cache_size = #指定二进制日志缓存最大大小，硬限制。默认4G，够大了，建议不要改 binlog_cache_use：使用缓存写二进制日志的次数(这是一个实时变化的统计值) binlog_cache_disk_use:使用临时文件写二进制日志的次数，当日志超过了binlog_cache_size的时候会使用临时文件写日志，如果该变量值不为0，则考虑增大binlog_cache_size的值 binlog_stmt_cache_size = 32768 #一般等同于且决定binlog_cache_size大小，所以修改缓存大小时只需修改这个而不用修改binlog_cache_size binlog_stmt_cache_use：使用缓存写二进制日志的次数 binlog_stmt_cache_disk_use: 使用临时文件写二进制日志的次数，当日志超过了binlog_cache_size的时候会使用临时文件写日志，如果该变量值不为0，则考虑增大binlog_cache_size的值 sync_binlog = { 0 | n } #这个参数直接影响mysql的性能和完整性sync_binlog=0:不同步，日志何时刷到磁盘由FileSystem决定，这个性能最好。sync_binlog=n:每写n次二进制日志事件(不是事务)，MySQL将执行一次磁盘同步指令fdatasync()将缓存日志刷新到磁盘日志文件中。Mysql中默认的设置是sync_binlog=0，即不同步，这时性能最好，但风险最大。一旦系统奔溃，缓存中的日志都会丢失。 在innodb的主从复制结构中，如果启用了二进制日志(几乎都会启用)，要保证事务的一致性和持久性的时候，必须将sync_binlog的值设置为1，因为每次事务提交都会写入二进制日志，设置为1就保证了每次事务提交时二进制日志都会写入到磁盘中，从而立即被从服务器复制过去。二进制日志定点还原数据库 只需指定二进制日志的起始位置（可指定终止位置）并将其保存到sql文件中，由mysql命令来载入恢复即可。当然直接通过管道送给mysql命令也可。 至于是基于位置来恢复还是基于时间点来恢复，这两种行为都可以。选择时间点来恢复比较直观些，并且跨日志文件恢复时更方便。 1mysqlbinlog --stop-datetime=&quot;2014-7-2 15:27:48&quot; /tmp/mysql-bin.000008 | mysql -u user -p password 恢复多个二进制日志文件时： 1mysqlbinlog mysql-bin.[*] | mysql -uroot -p password 或者将它们导入到一个文件中后恢复。 123mysqlbinlog mysql-bin.000001 &gt; /tmp/a.sqlmysqlbinlog mysql-bin.000002 &gt;&gt;/tmp/a.sqlmysql -u root -p password -e &quot;source /tmp/a.sql&quot;","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"MYSQL","slug":"MYSQL","permalink":"http://yoursite.com/tags/MYSQL/"}]},{"title":"MYSQL MariaDB 的事务和事务隔离级别","slug":"MYSQL MariaDB 的事务和事务隔离级别","date":"2017-05-14T16:00:00.000Z","updated":"2018-06-18T09:44:33.026Z","comments":true,"path":"2017/05/15/MYSQL MariaDB 的事务和事务隔离级别/","link":"","permalink":"http://yoursite.com/2017/05/15/MYSQL MariaDB 的事务和事务隔离级别/","excerpt":"事务特性事务具有ACID特性：原子性(A,atomicity)、一致性(C,consistency)、隔离性(I,isolation)、持久性(D,durabulity)。原子性：事务内的所有操作要么都执行，要么都不执行。一致性：事务开始和结束前后，数据都满足数据一致性约束，而不是经过事务控制之后数据变得不满足条件或业务规则。隔离性：事务之间不能互影响，它们必须完全的各行其道，互不可见。","text":"事务特性事务具有ACID特性：原子性(A,atomicity)、一致性(C,consistency)、隔离性(I,isolation)、持久性(D,durabulity)。原子性：事务内的所有操作要么都执行，要么都不执行。一致性：事务开始和结束前后，数据都满足数据一致性约束，而不是经过事务控制之后数据变得不满足条件或业务规则。隔离性：事务之间不能互影响，它们必须完全的各行其道，互不可见。 持久性：事务完成后，该事务内涉及的数据必须持久性的写入磁盘保证其持久性。当然，这是从事务的角度来考虑的的持久性，从操作系统故障或硬件故障来说，这是不一定的。事务分类 扁平事务带保存点的扁平事务链事务嵌套事务分布式事务 扁平事务 即最常见的事务。由begin开始，commit或rollback结束，中间的所有操作要么都回滚要么都提交。扁平事务在生产环境中占绝大多数使用情况。因此每一种数据库产品都支持扁平事务。 扁平事务的缺点在于无法回滚或提交一部分，只能全部回滚或全部提交，所以就有了”带有保存点”的扁平事务。 带有保存点的扁平事务通过在事务内部的某个位置使用savepoint，将来可以在事务中回滚到此位置。 MariaDB/MySQL中设置保存点的命令为: 1savepoint [savepoint_name] 回滚到指定保存点的命令为： 1rollback to savepoint_name 删除一个保存点的命令为： 1release savepoint savepoint_name 实际上，扁平事务也是有保存点的，只不过它只有一个隐式的保存点，且自动建立在事务开始的位置，因此扁平事务只能回滚到事务开始处。 链式事务 链式事务是保存点扁平事务的变种。它在一个事务提交的时候自动隐式的将上下文传给下一个事务，也就是说一个事务的提交和下一个事务的开始是原子性的，下一个事务可以看到上一个事务的处理结果。通俗地说，就是事务的提交和事务的开始是链接式下去的。 这样的事务类型，在提交事务的时候，会释放要提交事务内所有的锁和要提交事务内所有的保存点。因此链式事务只能回滚到当前所在事务的保存点，而不能回滚到已提交的事务中的保存点。 嵌套事务 嵌套事务由一个顶层事务控制所有的子事务。子事务的提交完成后不会真的提交，而是等到顶层事务提交才真正的提交。 关于嵌套事务的机制，主要有以下3个结论： 回滚内部事务的同时会回滚到外部事务的起始点。 事务提交时从内向外依次提交。 回滚外部事务的同时会回滚所有事务，包括已提交的内部事务。因为只提交内部事务时没有真的提交。 不管怎么样，最好少用嵌套事务。且MariaDB/MySQL不原生态支持嵌套事务(SQL Server支持)。分布式事务将多个服务器上的事务(节点)组合形成一个遵循事务特性(acid)的分布式事务。 例如在工行atm机转账到建行用户。工行atm机所在数据库是一个事务节点A，建行数据库是一个事务节点B，仅靠工行atm机是无法完成转账工作的，因为它控制不了建行的事务。所以它们组成一个分布式事务： 1.atm机发出转账口令。2.atm机从工行用户减少N元。3.在建行用户增加N元。4.在atm机上返回转账成功或失败。 上面涉及了两个事务节点，这些事务节点之间的事务必须同时具有acid属性，要么所有的事务都成功，要么所有的事务都失败，不能只成功atm机的事务，而建行的事务失败。 MariaDB/MySQL的分布式事务使用两段式提交协议(2-phase commit,2PC)。最重要的是，MySQL 5.7.7之前，MySQL对分布式事务的支持一直都不完善(第一阶段提交后不会写binlog，导致宕机丢失日志)，这个问题持续时间长达数十年，直到MySQL 5.7.7，才完美支持分布式事务。相关内容可参考网上一篇文章：https://www.linuxidc.com/Linux/2016-02/128053.htm。遗憾的是，MariaDB至今(MariaDB 10.3.6)都没有解决这个问题。 事务控制语句 begin 和 start transaction表示显式开启一个事务。它们之间并没有什么区别，但是在存储过程中，begin会被识别成begin…end的语句块，所以存储过程只能使用start transaction来显式开启一个事务。 commit 和 commit work用于提交一个事务。 rollbac 和 rollback work用于回滚一个事务。 savepoint identifier表示在事务中创建一个保存点。一个事务中允许存在多个保存点。 release savepoint identifier表示删除一个保存点。当要删除的保存点不存在的时候会抛出异常。 rollback to savepoint表示回滚到指定的保存点，回滚到保存点后，该保存点之后的所有操纵都被回滚。注意，rollback to不会结束事务，只是回到某一个保存点的状态。 set transaction用来设置事务的隔离级别。可设置的隔离级别有read uncommitted/read committed/repeatable read/serializable。 commit与commit work以及rollback与rollback work作用是一样的。但是他们的作用却和变量 completion_type的值有关。 ######例如将completion_type设置为1，进行测试。 12345678910111213mysql&gt; set completion_type=1;mysql&gt; begin;mysql&gt; insert into ttt values(1000);mysql&gt; commit work;mysql&gt; insert into ttt values(2000);mysql&gt; rollback;mysql&gt; select * from ttt where id&gt;=1000;+------+| id |+------+| 1000 |+------+1 row in set (0.00 sec) begin开始事务后，插入了值为1000的记录，commit work了一次，然后再插入了值为2000的记录后rollback，查询结果结果中只显示了1000，而没有2000，因为commit work提交后自动又开启了一个事务，使用rollback会回滚该事务。 将completion_type设置为2，进行测试。1234mysql&gt; set completion_type=2;mysql&gt; begin;mysql&gt; insert into ttt select 1000;mysql&gt; commit; 提交后，再查询或者进行其他操作，结果提示已经和MariaDB/MySQL服务器断开连接了。123mysql&gt; select * from ttt;ERROR 2006 (HY000): MySQL server has gone awayNo connection. Trying to reconnect... 显式事务的次数统计通过全局状态变量com_commit和com_rollback可以查看当前已经显式提交和显式回滚事务的次数。还可以看到回滚到保存点的次数。12345678910111213mysql&gt; show global status like &quot;%com_commit%&quot;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_commit | 14 |+---------------+-------+mysql&gt; show global status like &quot;%com_rollback%&quot;;+---------------------------+-------+| Variable_name | Value |+---------------------------+-------+| Com_rollback | 24 || Com_rollback_to_savepoint | 0 |+---------------------------+-------+ 一致性非锁定读(快照查询) 在innodb存储引擎中，存在一种数据查询方式：快照查询。因为查询的是快照数据，所以查询时不申请共享锁。 当进行一致性非锁定读查询的时候，查询操作不会去等待记录上的独占锁释放，而是直接去读取快照数据。快照数据是通过undo段来实现的，因此它基本不会产生开销。显然，通过这种方式，可以极大的提高读并发性。 快照数据其实是行版本数据，一个行记录可能会存在多个行版本，并发时这种读取行版本的方式称为多版本并发控制(MVCC)。在隔离级别为read committed和repeatable read时，采取的查询方式就是一致性非锁定读方式。但是，不同的隔离级别下，读取行版本的方式是不一样的。在后面介绍对应的隔离级别时会作出说明。 下面是在innodb默认的隔离级别是repeatable read下的实验，该隔离级别下，事务总是在开启的时候获取最新的行版本，并一直持有该版本直到事务结束。更多的”一致性非锁定读”见后文说明read committed和repeatable read部分。 当前示例表ttt的记录如下：1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 在会话1执行：12mysql&gt; begin;mysql&gt; update ttt set id=100 where id=1 在会话2中执行：12345678mysql&gt; begin;mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 查询的结果和预期的一样，来自开启事务前最新提交的行版本数据。 回到会话1提交事务： 1mysql&gt; commit; 再回到会话2中查询： 1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 再次去会话1更新该记录： 123mysql&gt; begin;mysql&gt; update ttt set id=1000 where id=100;mysql&gt; commit; 再回到会话2执行查询： 1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 这就是repeatable read隔离级别下的一致性非锁定读的特性。 当然，MySQL也支持一致性锁定读的方式。 一致性锁定读 在隔离级别为read committed和repeatable read时，采取的查询方式就是一致性非锁定读方式。但是在某些情况下，需要人为的对读操作进行加锁。MySQL中对这种方式的支持是通过在select语句后加上lock in share mode或者for update。 select … from … where … lock in share mode; select …from … where … for update; 使用lock in share mode会对select语句要查询的记录加上一个共享锁(S)，使用for update语句会对select语句要查询的记录加上独占锁(X)。 另外，对于一致性非锁定读操作，即使要查询的记录已经被for update加上了独占锁，也一样可以读取，就和纯粹的update加的锁一样，只不过此时读取的是快照数据而已。 事务隔离级别 SQL标准定义了4中隔离级别：read uncommitted、read committed、repeatable read、serializable。 MariaDB/MySQL也支持这4种隔离级别。但是要注意的是，MySQL中实现的隔离级别和SQL Server实现的隔离级别在同级别上有些差别。在后面有必要说明地方会给出它们的差异之处。 MariaDB/MySQL中默认的隔离级别是repeatable read，SQL Server和oracle的默认隔离级别都是read committed。 事务特性(ACID)中的隔离性(I,isolation)就是隔离级别，它通过锁来实现。也就是说，设置不同的隔离级别，其本质只是控制不同的锁行为。例如操作是否申请锁，什么时候申请锁，申请的锁是立刻释放还是持久持有直到事务结束才释放等。 设置和查看事务隔离级别 隔离级别是基于会话设置的，当然也可以基于全局进行设置，设置为全局时，不会影响当前会话的级别。设置的方法是： 123set [global | session] transaction isolation level &#123;type&#125;type: read uncommitted | read committed | repeatable read | serializable 或者直接修改变量值也可以： 12set @@global.tx_isolation = &apos;read-uncommitted&apos; | &apos;read-committed&apos; | &apos;repeatable-read&apos; | &apos;serializable&apos;set @@session.tx_isolation = &apos;read-uncommitted&apos; | &apos;read-committed&apos; | &apos;repeatable-read&apos; | &apos;serializable&apos; 查看当前会话的隔离级别方法如下： 12345678910111213mysql&gt; select @@tx_isolation;mysql&gt; select @@global.tx_isolation;mysql&gt; select @@tx_isolation;select @@global.tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------++-----------------------+| @@global.tx_isolation |+-----------------------+| REPEATABLE-READ |+-----------------------+ 注意，事务隔离级别的设置只需在需要的一端设置，不用在两边会话都设置。例如想要让会话2的查询加锁，则只需在会话2上设置serializable，在会话1设置的serializable对会话2是没有影响的，这和SQL Server中一样。但是，MariaDB/MySQL除了serializable隔离级别，其他的隔离级别都默认会读取旧的行版本，所以查询永远不会造成阻塞。而SQL Server中只有基于快照的两种隔离级别才会读取行版本，所以在4种标准的隔离级别下，如果查询加的S锁被阻塞，查询会进入锁等待。 在MariaDB/MySQL中不会出现更新丢失的问题，因为独占锁一直持有直到事务结束。当1个会话开启事务A修改某记录，另一个会话也开启事务B修改该记录，该修改被阻塞，当事务A提交后，事务B中的更新立刻执行成功，但是执行成功后查询却发现数据并没有随着事务B的想法而改变，因为这时候事务B更新的那条记录已经不是原来的记录了。但是事务A回滚的话，事务B是可以正常更新的，但这没有丢失更新。 read uncommitted 该级别称为未提交读，即允许读取未提交的数据。 在该隔离级别下，读数据的时候不会申请读锁，所以也不会出现查询被阻塞的情况。 在会话1执行： 12345create table ttt(id int);insert into ttt select 1;insert into ttt select 2;begin;update ttt set id=10 where id=1; 如果会话1的隔离级别不是默认的，那么在执行update的过程中，可能会遇到以下错误： 1ERROR 1665 (HY000): Cannot execute statement: impossible to write to binary log since BINLOG_FORMAT = STATEMENT and at least one table uses a storage engine limited to row-based logging. InnoDB is limited to row-logging when transaction isolation level is READ COMMITTED or READ UNCOMMITTED. 这是read committed和read uncommitted两个隔离级别只允许row格式的二进制日志记录格式。而当前的二进制日志格式记录方式为statement时就会报错。要解决这个问题，只要将格式设置为row或者mixed即可。 1set @@session.binlog_format=row; 在会话2执行： 12345678set transaction isolation level read uncommitted;select * from ttt;+------+| id |+------+| 10 || 2 |+------+ 发现查询的结果是update后的数据，但是这个数据是会话1未提交的数据。这是脏读的问题，即读取了未提交的脏数据。 如果此时会话1进行了回滚操作，那么会话2上查询的结果又变成了id=1。 在会话1上执行： 1rollback; 在会话2上查询： 1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 这是读不一致问题。即同一个会话中对同一条记录的读取结果不一致。 read uncommitted一般不会在生产环境中使用，因为问题太多，会导致脏读、丢失的更新、幻影读、读不一致的问题。但由于不申请读锁，从理论上来说，它的并发性是最佳的。所以在某些特殊情况下还是会考虑使用该级别。 要解决脏读、读不一致问题，只需在查询记录的时候加上共享锁即可。这样在其他事务更新数据的时候就无法查询到更新前的记录。这就是read commmitted隔离级别。 read committed 对于熟悉SQL Server的人来说，在说明这个隔离级别之前，必须先给个提醒：MariaDB/MySQL中的提交读和SQL Server中的提交读完全不一样，MariaDB/MySQL中该级别基本类似于SQL Server中基于快照的提交读。 在SQL Server中，提交读的查询会申请共享锁，并且在查询结束的一刻立即释放共享锁，如果要查询的记录正好被独占锁锁住，则会进入锁等待，而没有被独占锁锁住的记录则可以正常查询。SQL Server中基于快照的提交读实现的是语句级的事务一致性，每执行一次操作事务序列号加1，并且每次查询的结果都是最新提交的行版本快照。 也就是说，MariaDB/MySQL中read committed级别总是会读取最新提交的行版本。这在MySQL的innodb中算是一个术语:”一致性非锁定读”，即只读取快照数据，不加共享锁。这在前文已经说明过。 MariaDB/MySQL中的read committed隔离级别下，除非是要检查外键约束或者唯一性约束需要用到gap lock算法，其他时候都不会用到。也就是说在此隔离级别下，一般来说只会对行进行锁定，不会锁定范围，所以会导致幻影读问题。 这里要演示的就是在该级别下，会不断的读取最新提交的行版本数据。 当前示例表ttt的记录如下：1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 在会话1中执行： 1begin;update ttt set id=100 where id=1; 在会话2中执行： 123set @@session.tx_isolation=&apos;read-committed&apos;;begin;select * from ttt; 会话2中查询得到的结果为id=1，因为查询的是最新提交的快照数据，而最新提交的快照数据就是id=1。 123456+------+| id |+------+| 1 || 2 |+------+ 现在将会话1中的事务提交。 在会话1中执行： 1commit; 在会话2中查询记录： 1234567select * from ttt;+------+| id |+------+| 100 || 2 |+------+ 结果为id=100，因为这个值是最新提交的。 再次在会话1中修改该值并提交事务。 在会话1中执行： 1begin;update ttt set id=1000 where id=100;commit; 在会话2中执行： 1234567select * from ttt;+------+| id |+------+| 1000 || 2 |+------+ 发现结果变成了1000，因为1000是最新提交的数据。 read committed隔离级别的行版本读取特性，在和repeatable read隔离级别比较后就很容易理解。 repeatable read 同样是和上面一样的废话，对于熟悉SQL Server的人来说，在说明这个隔离级别之前，必须先给个提醒：MariaDB/MySQL中的重复读和SQL Server中的重复读完全不一样，MariaDB/MySQL中该级别基本类似于SQL Server中快照隔离级别。 在SQL Server中，重复读的查询会申请共享锁，并且在查询结束的一刻不释放共享锁，而是持有到事务结束。所以会造成比较严重的读写并发问题。SQL Server中快照隔离级别实现的是事务级的事务一致性，每次事务开启的时候获取最新的已提交行版本，只要事务不结束，读取的记录将一直是该行版本中的数据，不管其他事务是否已经提交过对应的数据了。但是SQL Server中的快照隔离会有更新冲突：当检测到两边都想要更新同一记录时，会检测出更新冲突，这样会提前结束事务(进行的是回滚操作)而不用再显式地commit或者rollback。 也就是说，MariaDB/MySQL中repeatable read级别总是会在事务开启的时候读取最新提交的行版本，并将该行版本一直持有到事务结束。但是MySQL中的repeatable read级别下不会像SQL Server一样出现更新冲突的问题。 前文说过read committed隔离级别下，读取数据时总是会去获取最新已提交的行版本。这是这两个隔离级别在”一致性非锁定读”上的区别。 另外，MariaDB/MySQL中的repeatable read的加锁方式是next-key lock算法，它会进行范围锁定。这就避免了幻影读的问题(官方手册上说无法避免)。在标准SQL中定义的隔离级别中，需要达到serializable级别才能避免幻影读问题，也就是说MariaDB/MySQL中的repeatable read隔离级别已经达到了其他数据库产品(如SQL Server)的serializable级别，而且SQL Server中的serializable加范围锁时，在有索引的时候式锁范围比较不可控(你不知道范围锁锁住哪些具体的范围)，而在MySQL中是可以判断锁定范围的(见innodb锁算法)。 这里要演示的就是在该级别下，读取的行版本数据是不随提交而改变的。 当前示例表ttt的记录如下：1234567mysql&gt; select * from ttt;+------+| id |+------+| 1 || 2 | +------+ 在会话1执行： 1begin;update ttt set id=100 where id=1 在会话2中执行： 12345678set @@session.tx_isolation=&apos;repeatable-read&apos;;begin;select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 查询的结果和预期的一样，来自开启事务前最新提交的行版本数据 回到会话1提交事务： 1commit; 再回到会话2中查询： 1234567select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 再次去会话1更新该记录： 1begin;update ttt set id=1000 where id=100;commit; 再回到会话2执行查询： 1234567select * from ttt;+------+| id |+------+| 1 || 2 |+------+ 发现结果根本就不会改变，因为会话2开启事务时获取的行版本的id=1，所以之后读取的一直都是id=1所在的行版本。 serializable 在SQL Server中，serializable隔离级别会将查询申请的共享锁持有到事务结束，且申请的锁是范围锁，范围锁的情况根据表有无索引而不同：无索引时锁定整个表，有索引时锁定某些范围，至于锁定哪些具体的范围我发现是不可控的(至少我无法推测和计算)。这样就避免了幻影读的问题。 这种问题在MariaDB/MySQL中的repeatable read级别就已经实现了，MariaDB/MySQL中的next-key锁算法在加范围锁时也分有无索引：无索引时加锁整个表(实际上不是表而是无穷大区间的行记录)，有索引时加锁部分可控的范围。 MariaDB/MySQL中的serializable其实类似于repeatable read，只不过所有的select语句会自动在后面加上lock in share mode。也就是说会对所有的读进行加锁，而不是读取行版本的快照数据，也就不再支持”一致性非锁定读”。这样就实现了串行化的事务隔离：每一个事务必须等待前一个事务(哪怕是只有查询的事务)结束后才能进行哪怕只是查询的操作。 这个隔离级别对并发性来说，显然是有点太严格了。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"MYSQL","slug":"MYSQL","permalink":"http://yoursite.com/tags/MYSQL/"}]},{"title":"MASQL MariaDB 用户权限管理","slug":"MASQL MariaDB 用户权限管理","date":"2017-05-07T16:00:00.000Z","updated":"2018-06-18T06:20:32.651Z","comments":true,"path":"2017/05/08/MASQL MariaDB 用户权限管理/","link":"","permalink":"http://yoursite.com/2017/05/08/MASQL MariaDB 用户权限管理/","excerpt":"MariaDB/MySQL中的user由用户名和主机名构成，如”root@localhost”，同用户名但不同主机名对MySQL/MariaDB来讲是不同的，也就是说”root@localhost”和”root@127.0.0.1“是不同的用户，尽管它们都是本机的root。权限验证 在MariaDB/MySQL服务器启动后会载入权限表到内存中，当用户要连接服务器，会读取权限表来验证和分配权限，即在内存中进行权限的读取和写入。","text":"MariaDB/MySQL中的user由用户名和主机名构成，如”root@localhost”，同用户名但不同主机名对MySQL/MariaDB来讲是不同的，也就是说”root@localhost”和”root@127.0.0.1“是不同的用户，尽管它们都是本机的root。权限验证 在MariaDB/MySQL服务器启动后会载入权限表到内存中，当用户要连接服务器，会读取权限表来验证和分配权限，即在内存中进行权限的读取和写入。 MariaDB/MySQL中的权限系统经过两步验证： 1.合法性验证：验证user是否合法，合法者允许连接服务器，否则拒绝连接。2.权限验证和分配：对通过合法性验证的用户分配对数据库中各对象的操作权限。 权限表 MariaDB/MySQL中的权限表都存放在mysql数据库中。MySQL5.6以前，权限相关的表有user表、db表、host表、tables_priv表、columns_priv表、procs_priv表(存储过程和函数相关的权限)。从MySQL5.6开始，host表已经没有了。MariaDB中虽然有host表，但却不用。 这几个表用的最多的是user表。user表主要分为几个部分：用户列、权限列、安全列、资源控制列以及杂项列，最需要关注的是用户列和权限列。其中权限列又分为普通权限(上表中红色字体)和管理权限列，如select类的为普通权限，super权限为管理权限。且可以看到，db表中的权限全都是普通权限，user表中除了db表中具有的普通权限还有show_db_pirv和create_tablespace_priv，除此之外还有几个管理员权限。也就是说，db中没有的权限是无法授予到指定数据库的。例如不能授予super权限给test数据库。 另外，usage权限在上表中没有列出，因为该权限是所有用户都有的权限，它只用来表示能否登录数据库，它的一个特殊功能是grant仅指定该权限的时候不会影响现有权限，也就是说可以拿grant来修改密码而不影响现有权限。 需要说明的是，从user表到db表再到tables_priv表最后是columns_priv表，它们的权限是逐层细化的。user表中的普通权限是针对所有数据库的，例如在user表中的select_priv为Y，则对所有数据库都有select权限；db表是针对特定数据库中所有表的，如果只有test数据库中有select权限，那么db表中就有一条记录test数据库的select权限为Y，这样对test数据库中的所有表都有select权限，而此时user表中的select权限就为N(因为为Y的时候是所有数据库都有权限)；同理tables_priv表也一样，是针对特定表中所有列的权限；columns_priv则是针对特定列的权限。 所以对于已经通过身份合法性验证的用户的权限读取和分配的机制如下： 1.读取uesr表，看看user表是否有对应为Y的权限列，有则分配。 2.读取db表，看看db表中是否有哪个数据库分配了对应的权限。 3.读取tables_priv表，看看哪些表中有对应的权限。 4.读取columns_priv表，看看对哪些具体的列有什么权限。 例如，为某一用户授予test数据库的select权限。可以看到user表中的select_priv为N，而db表中的select为Y。123GRANT SELECT ON test.* TO &apos;long&apos;@&apos;192.168.100.1&apos; IDENTIFIED BY &apos;123456&apos;;SELECT host,user,select_priv FROM mysql.user;SELECT * FROM mysql.db; 图解认证和权限分配的两个阶段 权限生效时机 在服务器启动时读取权限表到内存中，从此时开始权限表生效。 之后使用grant、revoke、set password 等命令也会隐含的刷新权限表到内存中。 另外，使用显式的命令flush privileges或mysqladmin flush-privileges或mysqladmin reolad也会将上述几张权限表重新刷到内存中以供后续的身份验证和权限验证、分配。 用户管理用户管理分为几个方面，创建用户、对用户授权、修改和删除用户。创建用户创建账号有几种方法。 1.使用grant直接对账号授权，账号不存在则会创建； 2.向mysql.user表中插入记录； 3.使用create user命令。 后两种方法创建的用户初始时没有任何权限(只有usage登录数据库的权限)，并且修改权限后要使用 FLUSH PRIVILEGES 语句或执行 mysqladmin flush-privileges 或 mysqladmin reload 命令刷新权限表到内存中，而第一种方法简便的多，创建用户后会自动刷新权限表。 grant和revoke语法：1234567891011121314151617181920212223242526GRANT priv_type [(column_list)] [, priv_type [(column_list)]] ... ON [object_type] priv_level TO user [IDENTIFIED [BY [PASSWORD] &apos;password&apos;][WITH with_option [with_option]object_type: TABLE | FUNCTION | PROCEDUREpriv_level: * | *.* | db_name.* | db_name.tbl_name | tbl_name | db_name.routine_namewith_option: GRANT OPTION | MAX_QUERIES_PER_HOUR count | MAX_UPDATES_PER_HOUR count | MAX_CONNECTIONS_PER_HOUR count | MAX_USER_CONNECTIONS count | MAX_STATEMENT_TIME time grant可以在库、表、函数、存储过程、特定列上授权，且一次性可以为多个用户授予多个对象的权限。其中 with grant option 表示拥有该权限后的用户可以给别的用户授予自身所拥有的权限。 revoke表示收回权限，注意revoke无法收回usage权限。 其中user的表示方法是 ‘用户名‘@’主机名’ ，主机名部分可以是主机名，可以是IP地址，可以是localhost，可以是通配符组成的主机名(空的host值也表示所有host，等价于‘user_name‘@’%’)。如下示例： 对于网段地址，可以指定掩码来表示，如192.168.100.1/255.255.255.0，不能使用cidr格式的掩码记录方式，也不能指定非8、16、24、32位的掩码，如192.168.100.1/255.255.255.240是不允许的。 如果在user表中的用户有交叉部分，如root既可以从localhost登录，也可以从127.0.0.1登录，还可以从本机IP192.168.100.61登录，还可以从网段地址192.168.100.%登录，那么到底会从哪个登录？ 在读取权限表user到内存中的时候，首先会根据host列的具体性进行排序，然后再根据user列进行具体性排序(即理解为order by host,user)，然后从上到下扫描，首次扫描到符合的记录就使用该记录登录。具体性的意思是越具体的user优先级越高，通配符范围越宽的user优先级越低。例如root@localhost的具体性比root@’%’的具体性高，后者又比‘%‘@’%’的具体性高。create user和alter user 在MySQL 5.6.7之前，不要使用这两个命令创建用户和修改用户，因为它们会在mysql.user表的password列设置空串。到mysql5.6.7解决了这个问题。MariaDB可随意使用。 语法：C123456789101112131415REATE [OR REPLACE] USER [IF NOT EXISTS] user_specification [,user_specification] ... [WITH resource_option [resource_option] ...]user_specification: username [authentication_option]authentication_option: IDENTIFIED BY &apos;authentication_string&apos; resource_option: MAX_QUERIES_PER_HOUR count | MAX_UPDATE_PER_HOUR count | MAX_CONNECTIONS_PER_HOUR count | MAX_USER_CONNECTIONS count 例如：1create user &apos;longshuai&apos;@&apos;127.0.0.1&apos; identified by &apos;123456&apos;; alter user和create user语法基本一致，但在MySQL中有让密码过期的功能，而在MariaDB中不支持该功能。 123ALTER USER user_specification [, user_specification] ...user_specification: user PASSWORD EXPIRE 例如，让刚才创建的用户过期。1alter user &apos;longshuai&apos;@&apos;127.0.0.1&apos; password expire; 记录创建用户的时间 MariaDB/MySQL中user的元数据信息都存放在mysql.user表中，但是在这个表中的信息分类很少，常用的就只有用户类列和权限类列，没有用户的创建时间。 可以通过新增一列来记录用户的创建时间。 1alter table mysql.user add column create_time timestamp default current_timestamp; 这样以后新建用户都会记录创建时间。但是显然，对于已有的用户是没有记录时间的，它们的值都为’0000-00-00 00:00:00’。 12345678910111213MariaDB [mysql]&gt; select host,user,create_time from mysql.user;+---------------------+-----------+---------------------+| host | user | create_time |+---------------------+-----------+---------------------+| localhost | root | 2018-04-21 05:58:19 || 127.0.0.1 | root | 2018-04-21 05:58:19 || ::1 | root | 2018-04-21 05:58:19 || localhost | | 2018-04-21 05:58:19 || 192.168.100.% | root | 2018-04-21 05:58:19 || 192.168.100.1 | long | 2018-04-21 05:58:19 || 127.0.0.1 | longshuai | 2018-04-21 05:58:19 || 192.168.100.1 | longshuai | 0000-00-00 00:00:00 |+---------------------+-----------+---------------------+ 查看用户权限 可以使用show grants语句查看某个user的权限信息。 例如：123456MariaDB [mysql]&gt; show grants for &apos;root&apos;@&apos;localhost&apos;;Grants for root@localhost -----------------------------------------------------------------------------------------------------------------GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY PASSWORD &apos;*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9&apos; WITH GRANT OPTION GRANT PROXY ON &apos;&apos;@&apos;&apos; TO &apos;root&apos;@&apos;localhost&apos; WITH GRANT OPTION 123456MariaDB [mysql]&gt;SHOW GRANTS FOR &apos;long&apos;@&apos;192.168.100.1&apos;;Grants for long@192.168.100.1 -----------------------------------------------------------------------------------------------------------GRANT USAGE ON *.* TO &apos;long&apos;@&apos;192.168.100.1&apos; IDENTIFIED BY PASSWORD &apos;*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9&apos; GRANT SELECT ON `test`.* TO &apos;long&apos;@&apos;192.168.100.1&apos; revoke命令的严格性 revoke命令回收权限时必须要明确指定回收的数据库对象以及用户名，其中usage权限无法回收。特别要说明的是revoke all，当你以为它会回收所有权限的时候，它可能一点权限都没有回收。也就是说revoke命令的书写非常严格。 用户 ‘long‘@’192.168.100.1’ 在 . 上具有usage权限，在test.*上具有select权限。 12345MariaDB [mysql]&gt; SHOW GRANTS FOR &apos;long&apos;@&apos;192.168.100.1&apos;;Grants for long@192.168.100.1 -----------------------------------------------------------------------------------------------------------GRANT USAGE ON *.* TO &apos;long&apos;@&apos;192.168.100.1&apos; IDENTIFIED BY PASSWORD &apos;*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9&apos; GRANT SELECT ON `test`.* TO &apos;long&apos;@&apos;192.168.100.1&apos; 对该用户在 . 上进行revoke all，再次查看权限，发现权限根本一点变化都没有。因为usage权限无法回收，而select权限是在test.上而非.*上。 1REVOKE ALL ON *.* FROM &apos;long&apos;@&apos;192.168.100.1&apos;; 要回收test.上的select权限，必须在revoke中指定test.，而不能是 . 。以下两个语句都能回收。 12revoke select on test.* from &apos;long&apos;@&apos;192.168.100.1&apos;;revoke all on test.* from &apos;long&apos;@&apos;192.168.100.1&apos;; 删除用户 直接使用drop user命令或者从mysql.user表中删除对应记录。 1drop user user_name1,username2... 注意，删除表中用户记录的时候不会从现有用户中回收对该表的权限，当下次再创建同名表的时候，会自动为用户授予该表的权限造成权限外流。 因此，建议使用drop user语句来删除用户。 设置密码和恢复root密码设置密码12(1)grant all on *.* to &apos;root&apos;@&apos;localhost&apos; identified by &apos;123456&apos; with grant option; (2)grant usage on *.* to &apos;root&apos;@&apos;localhost&apos; identified by &apos;123456&apos; with grant option; 使用usage权限表示在不影响现有权限的情况下使用grant来修改密码。1(3)set password [for &apos;root&apos;@&apos;localhost&apos;] =password(&apos;123456&apos;); password函数中必须加引号，不写user时是为当前用户修改。123(4)alter user root@localhost identified by &apos;123456&apos;; (5)mysqladmin -uroot -h localhost -p&apos;old_password&apos; password &apos;new_password&apos;; (6)update mysql.user set password=password(&apos;123456&apos;) where user=&apos;root&apos; and host=&apos;localhost&apos;; 其中grant和set password语句可以直接刷新权限表，其他语句需要使用 flush privileges 或其他刷新语句。 恢复root密码 可以在启动mysql服务时使用mysqld_safe服务程序并指定”–skip-grant-tables”选项表示跳过授权表，这样登陆mysql服务器将不需要任何权限，包括密码认证也不需要，但是同样受限的是不能操作任何权限相关的内容，比如修改权限，刷新授权表等。这通常是mysql管理员密码忘记的时候使用的选项。由于跳过授权表使得mysql服务器极不安全，任何用户都能直接登录服务器，所以通常和”–skip-networking”选项一起使用来禁止来自网络的服务器连接请求，这样只能使用localhost或者127.0.0.1作为host来登录。 另外，使用mysqld_safe启动无授权表的服务前要停止已有的MySQL实例。由于跳过授权表无法操作权限相关内容，所以修改mysql.user表中的管理员账号的密码字段是唯一修改方法。修改密码后记得重启MySQL服务。 步骤如下：1234567891011121314151617[root@xuexi mysql]# service mysqld stop[root@xuexi mysql]# mysqld_safe --skip-grant-tables --skip-networking &amp;[root@xuexi mysql]# mysqlmysql&gt; update mysql.user set password=password(&quot;123456&quot;) where user=&apos;root&apos; and host=&apos;localhost&apos;;mysql&gt; flush privileges;mysql&gt; select user,host,password from mysql.user where user=&apos;root&apos; and host=&apos;localhost&apos;;+------+-----------+-------------------------------------------+| user | host | password |+------+-----------+-------------------------------------------+| root | localhost | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |+------+-----------+-------------------------------------------+1 row in setmysql&gt; \\q[root@xuexi mysql]# service mysqld stop[root@xuexi mysql]# service mysqld start[root@xuexi mysql]# mysql -uroot -p123456mysql&gt; \\q 如果要找回多实例的密码，则在mysqld_safe命令中使用 –defaults-file 指定对应的配置文件即可。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"MYSQL","slug":"MYSQL","permalink":"http://yoursite.com/tags/MYSQL/"}]},{"title":"ext 文件系统机制原理","slug":"ext 文件系统机制原理","date":"2017-04-19T16:00:00.000Z","updated":"2018-06-25T11:32:23.414Z","comments":true,"path":"2017/04/20/ext 文件系统机制原理/","link":"","permalink":"http://yoursite.com/2017/04/20/ext 文件系统机制原理/","excerpt":"将磁盘进行分区，分区是将磁盘按柱面进行物理上的划分。划分好分区后还要进行格式化，然后再挂载才能使用(不考虑其他方法)。格式化分区的过程其实就是创建文件系统。 文件系统的类型有很多种，如CentOS 5和CentOS 6上默认使用的ext2/ext3/ext4，CentOS 7上默认使用的xfs，windows上的NTFS，光盘类的文件系统ISO9660，MAC上的混合文件系统HFS，网络文件系统NFS，Oracle研发的btrfs，还有老式的FAT/FAT32等。 本文将非常全面且详细地对ext家族的文件系统进行介绍。有ext2/ext3/ext4，ext3是有日志的ext2改进版，ext4对相比ext3做了非常多的改进。虽然xfs/btrfs等文件系统有所不同，但它们只是在实现方式上不太同，再加上属于自己的特性而已。","text":"将磁盘进行分区，分区是将磁盘按柱面进行物理上的划分。划分好分区后还要进行格式化，然后再挂载才能使用(不考虑其他方法)。格式化分区的过程其实就是创建文件系统。 文件系统的类型有很多种，如CentOS 5和CentOS 6上默认使用的ext2/ext3/ext4，CentOS 7上默认使用的xfs，windows上的NTFS，光盘类的文件系统ISO9660，MAC上的混合文件系统HFS，网络文件系统NFS，Oracle研发的btrfs，还有老式的FAT/FAT32等。 本文将非常全面且详细地对ext家族的文件系统进行介绍。有ext2/ext3/ext4，ext3是有日志的ext2改进版，ext4对相比ext3做了非常多的改进。虽然xfs/btrfs等文件系统有所不同，但它们只是在实现方式上不太同，再加上属于自己的特性而已。 文件系统的组成部分block的出现硬盘的读写IO一次是一个扇区512字节，如果要读写大量文件，以扇区为单位肯定很慢很消耗性能，所以Linux中通过文件系统控制使用”块”为读写单元。现在的文件系统上，块的大小一般为1024bytes(1K)或2048bytes(2K)或4096bytes(4K)。比如需要读一个或多个块时，文件系统的IO管理器通知磁盘控制器要读取哪些块的数据，硬盘控制器将这些块按扇区读取出来，再通过硬盘控制器将这些扇区数据重组返回给计算机。 block的出现使得在文件系统层面上读写性能大大提高，也大量减少了碎片。但是它的副作用是可能造成空间浪费。由于文件系统以block为读写单元，即使存储的文件只有1K大小也将占用一个block，剩余的空间完全是浪费的。在某些业务需求下可能大量存储小文件，这会浪费大量的空间。 尽管有缺点，但是其优点足够明显，在当下硬盘容量廉价且追求性能的时代，使用block是一定的。 inode的出现如果存储的1个文件占用了大量的block读取时会如何？假如block大小为1KB，仅仅存储一个10M的文件就需要10240个block，而且这些blocks很可能在位置上是不连续在一起的(不相邻)，读取该文件时难道要从前向后扫描整个文件系统的块，然后找出属于该文件的块吗？显然是不应该这么做的，因为太慢太傻瓜式了。再考虑一下，读取一个只占用1个block的文件，难道只读取一个block就结束了吗？并不是，仍然是扫描整个文件系统的所有block，因为它不知道什么时候扫描到，扫描到了它也不知道这个文件是不是已经完整而不需要再扫描其他的block。 另外，每个文件都有属性(如权限、大小、时间戳等)，这些属性类的元数据存储在哪里呢？难道也和文件的数据部分存储在块中吗？如果一个文件占用多个block那是不是每个属于该文件的block都要存储一份文件元数据？但是如果不在每个block中存储元数据文件系统又怎么知道某一个block是不是属于该文件呢？但是显然，每个数据block中都存储一份元数据太浪费空间。 文件系统设计者当然知道这样的存储方式很不理想，所以需要优化存储方式。如何优化？对于这种类似的问题的解决方法是使用索引，通过扫描索引找到对应的数据，而且索引可以存储部分数据。 在文件系统上索引技术具体化为索引节点(index node)，在索引节点上存储的部分数据即为文件的属性元数据及其他少量信息。一般来说索引占用的空间相比其索引的文件数据而言占用的空间就小得多，扫描它比扫描整个数据要快得多，否则索引就没有存在的意义。这样一来就解决了前面所有的问题。 在文件系统上的术语中，索引节点称为inode。在inode中存储了inode号、文件类型、权限、文件所有者、大小、时间戳等元数据信息，最重要的是还存储了指向属于该文件block的指针，这样读取inode就可以找到属于该文件的block，进而读取这些block并获得该文件的数据。由于后面还会介绍一种指针，为了方便称呼和区分，暂且将这个inode记录中指向文件data block的指针称之为block指针，。 一般inode大小为128字节或256字节，相比那些MB或GB计算的文件数据而言小得多的多，但也要知道可能一个文件大小小于inode大小，例如只占用1个字节的文件。 bmap出现在向硬盘存储数据时，文件系统需要知道哪些块是空闲的，哪些块是已经占用了的。最笨的方法当然是从前向后扫描，遇到空闲块就存储一部分，继续扫描直到存储完所有数据。 优化的方法当然也可以考虑使用索引，但是仅仅1G的文件系统就有1KB的block共1024*1024=1048576个，这仅仅只是1G，如果是100G、500G甚至更大呢，仅仅使用索引索引的数量和空间占用也将极大，这时就出现更高一级的优化方法：使用块位图(bitmap简称bmap)。 位图只使用0和1标识对应block是空闲还是被占用，0和1在位图中的位置和block的位置一一对应，第一位标识第一个块，第二个位标识第二个块，依次下去直到标记完所有的block。 考虑下为什么块位图更优化。在位图中1个字节8个位，可以标识8个block。对于一个block大小为1KB、容量为1G的文件系统而言，block数量有10241024个，所以在位图中使用10241024个位共1024*1024/8=131072字节=128K，即1G的文件只需要128个block做位图就能完成一一对应。通过扫描这100多个block就能知道哪些block是空闲的，速度提高了非常多。 但是要注意，bmap的优化针对的是写优化，因为只有写才需要找到空闲block并分配空闲block。对于读而言，只要通过inode找到了block的位置，cpu就能迅速计算出block在物理磁盘上的地址，cpu的计算速度是极快的，计算block地址的时间几乎可以忽略，那么读速度基本认为是受硬盘本身性能的影响而与文件系统无关。大多数稍大一点的文件可能都会存储在不连续的block上，而且使用了一段时间的文件系统可能会有不少碎片，这时硬盘的随机读取性能直接决定读数据的速度，这也是机械硬盘速度相比固态硬盘慢的多的多的原因之一，而且固态硬盘的随机读和连续读取速度几乎是一致的，对它来说，文件系统碎片的多少并不会影响读取速度。 虽然bmap已经极大的优化了扫描，但是仍有其瓶颈：如果文件系统是100G呢？100G的文件系统要使用128*100=12800个1KB大小的block，这就占用了12.5M的空间了。试想完全扫描12800个很可能不连续的block这也是需要占用一些时间的，虽然快但是扛不住每次存储文件都要扫描带来的巨大开销。 所以需要再次优化，如何优化？简而言之就是将文件系统划分开形成块组，至于块组的介绍放在后文。 inode表的出现回顾下inode相关信息：inode存储了inode号、文件属性元数据、指向文件占用的block的指针；每一个inode占用128字节或256字节。 现在又出现问题了，一个文件系统中可以说有无数多个文件，每一个文件都对应一个inode，难道每一个仅128字节的inode都要单独占用一个block进行存储吗？这太浪费空间了。 所以更优的方法是将多个inode合并存储在block中，对于128字节的inode，一个block存储8个inode，对于256字节的inode，一个block存储4个inode。这就使得每个存储inode的块都不浪费。 在ext文件系统上，将这些物理上存储inode的block组合起来，在逻辑上形成一张inode表(inode table)来记录所有的inode。 举个例子，每一个家庭都要向派出所登记户口信息，通过户口本可以知道家庭住址，而每个镇或街道的派出所将本镇或本街道的所有户口整合在一起，要查找某一户地址时，在派出所就能快速查找到。inode table就是这里的派出所。它的内容如下图所示。 实际上，在文件系统创建完成后所有的inode号都已经分配好并记录到inode table中了，只不过被使用的inode号所在的行还有文件属性的元数据信息和block位置信息，而未被使用的inode号只有一个inode号而已而没有其他信息而已。 再细细一思考，就能发现一个大的文件系统仍将占用大量的块来存储inode，想要找到其中的一个inode记录也需要不小的开销，尽管它们已经形成了一张逻辑上的表，但扛不住表太大记录太多。那么如何快速找到inode，这同样是需要优化的，优化的方法是将文件系统的block进行分组划分，每个组中都存有本组inode table范围、bmap等。 imap的出现前面说bmap是块位图，用于标识文件系统中哪些block是空闲哪些block是占用的。 对于inode也一样，在存储文件(Linux中一切皆文件)时需要为其分配一个inode号。但是在格式化创建文件系统后所有的inode号都是被事先设定好存放在inode table中的，因此产生了问题：要为文件分配哪一个inode号呢？又如何知道某一个inode号是否已经被分配了呢？ 既然是”是否被占用”的问题，使用位图是最佳方案，像bmap记录block的占用情况一样。标识inode号是否被分配的位图称为inodemap简称为imap。这时要为一个文件分配inode号只需扫描imap即可知道哪一个inode号是空闲的。 imap存在着和bmap和inode table一样需要解决的问题：如果文件系统比较大，imap本身就会很大，每次存储文件都要进行扫描，会导致效率不够高。同样，优化的方式是将文件系统占用的block划分成块组，每个块组有自己的imap范围。 块组的出现前面一直提到的优化方法是将文件系统占用的block划分成块组(block group)，解决bmap、inode table和imap太大的问题。 在物理层面上的划分是将磁盘按柱面划分为多个分区，即多个文件系统；在逻辑层面上的划分是将文件系统划分成块组。每个文件系统包含多个块组，每个块组包含多个元数据区和数据区：元数据区就是存储bmap、inode table、imap等的数据；数据区就是存储文件数据的区域。注意块组是逻辑层面的概念，所以并不会真的在磁盘上按柱面、按扇区、按磁道等概念进行划分。 块组的划分块组在文件系统创建完成后就已经划分完成了，也就是说元数据区bmap、inode table和imap等信息占用的block以及数据区占用的block都已经划分好了。那么文件系统如何知道一个块组元数据区包含多少个block，数据区又包含多少block呢？ 它只需确定一个数据——每个block的大小，再根据bmap至多只能占用一个完整的block的标准就能计算出块组如何划分。如果文件系统非常小，所有的bmap总共都不能占用完一个block，那么也只能空闲bmap的block了。 每个block的大小在创建文件系统时可以人为指定，不指定也有默认值。 假如现在block的大小是1KB，一个bmap完整占用一个block能标识1024*8= 8192个block(当然这8192个block是数据区和元数据区共8192个，因为元数据区分配的block也需要通过bmap来标识)。每个block是1K，每个块组是8192K即8M，创建1G的文件系统需要划分1024/8=128个块组，如果是1.1G的文件系统呢？128+12.8=128+13=141个块组。 每个组的block数目是划分好了，但是每个组设定多少个inode号呢？inode table占用多少block呢？这需要由系统决定了，因为描述”每多少个数据区的block就为其分配一个inode号”的指标默认是我们不知道的，当然创建文件系统时也可以人为指定这个指标或者百分比例。见后文”inode深入”。 使用dumpe2fs可以将ext类的文件系统信息全部显示出来，当然bmap是每个块组固定一个block的不用显示，imap比bmap更小所以也只占用1个block不用显示。 下图是一个文件系统的部分信息，在这些信息的后面还有每个块组的信息，其实这里面的很多信息都可以通过几个比较基本的元数据推导出来。 从这张表中能计算出文件系统的大小，该文件系统共4667136个blocks，每个block大小为4K，所以文件系统大小为4667136*4/1024/1024=17.8GB。 也能计算出分了多少个块组，因为每一个块组的block数量为32768，所以块组的数量为4667136/32768=142.4即143个块组。由于块组从0开始编号，所以最后一个块组编号为Group 142。如下图所示是最后一个块组的信息。 文件系统的完整结构将上文描述的bmap、inode table、imap、数据区的blocks和块组的概念组合起来就形成了一个文件系统，当然这还不是完整的文件系统。完整的文件系统如下图。 首先，该图中多了Boot Block、Super Block、GDT、Reserver GDT这几个概念。下面会分别介绍它们。 然后，图中指明了块组中每个部分占用的block数量，除了superblock、bmap、imap能确定占用1个block，其他的部分都不能确定占用几个block。 最后，图中指明了Superblock、GDT和Reserved GDT是同时出现且不一定存在于每一个块组中的，也指明了bmap、imap、inode table和data blocks是每个块组都有的。 引导块即上图中的Boot Block部分，也称为boot sector。它位于分区上的第一个块，占用1024字节，并非所有分区都有这个boot sector，只有装了操作系统的主分区和装了操作系统的逻辑分区才有。里面存放的也是boot loader，这段boot loader称为VBR(主分区装操作系统时)或EBR(扩展分区装操作系统时)，这里的Boot loader和mbr上的boot loader是存在交错关系的。开机启动的时候，首先加载mbr中的bootloader，然后定位到操作系统所在分区的boot serctor上加载此处的boot loader。如果是多系统，加载mbr中的bootloader后会列出操作系统菜单，菜单上的各操作系统指向它们所在分区的boot sector上。它们之间的关系如下图所示。 但是，这种方式的操作系统菜单早已经弃之不用了，而是使用grub来管理启动菜单。尽管如此，在安装操作系统时，仍然有一步是选择boot loader安装位置的步骤。 超级块(superblock)既然一个文件系统会分多个块组，那么文件系统怎么知道分了多少个块组呢？每个块组又有多少block多少inode号等等信息呢？还有，文件系统本身的属性信息如各种时间戳、block总数量和空闲数量、inode总数量和空闲数量、当前文件系统是否正常、什么时候需要自检等等，它们又存储在哪里呢？ 毫无疑问，这些信息必须要存储在block中。存储这些信息占用1024字节，所以也要一个block，这个block称为超级块(superblock)，它的block号可能为0也可能为1。如果block大小为1K，则引导块正好占用一个block，这个block号为0，所以superblock的号为1；如果block大小大于1K，则引导块和超级块同置在一个block中，这个block号为0。总之superblock的起止位置是第二个1024(1024-2047)字节。 使用df命令读取的就是每个文件系统的superblock，所以它的统计速度非常快。相反，用du命令查看一个较大目录的已用空间就非常慢，因为不可避免地要遍历整个目录的所有文件。 12345[root@xuexi ~]# df -hTFilesystem Type Size Used Avail Use% Mounted on/dev/sda3 ext4 18G 1.7G 15G 11% /tmpfs tmpfs 491M 0 491M 0% /dev/shm/dev/sda1 ext4 190M 32M 149M 18% /boot superblock对于文件系统而言是至关重要的，超级块丢失或损坏必将导致文件系统的损坏。所以旧式的文件系统将超级块备份到每一个块组中，但是这又有所空间浪费，所以ext2文件系统只在块组0、1和3、5、7幂次方的块组中保存超级块的信息，如Group9、Group25等。尽管保存了这么多的superblock，但是文件系统只使用第一个块组即Group0中超级块信息来获取文件系统属性，只有当Group0上的superblock损坏或丢失才会找下一个备份超级块复制到Group0中来恢复文件系统。 下图是一个ext4文件系统的superblock的信息，ext家族的文件系统都能使用dumpe2fs -h获取。 块组描述符表(GDT)既然文件系统划分了块组，那么每个块组的信息和属性元数据又保存在哪里呢？ ext文件系统每一个块组信息使用32字节描述，这32个字节称为块组描述符，所有块组的块组描述符组成块组描述符表GDT(group descriptor table)。 虽然每个块组都需要块组描述符来记录块组的信息和属性元数据，但是不是每个块组中都存放了块组描述符。ext文件系统的存储方式是：将它们组成一个GDT，并将该GDT存放于某些块组中，存放GDT的块组和存放superblock和备份superblock的块相同，也就是说它们是同时出现在某一个块组中的。读取时也总是读取Group0中的块组描述符表信息。 假如block大小为4KB的文件系统划分了143个块组，每个块组描述符32字节，那么GDT就需要143*32=4576字节即两个block来存放。这两个GDT block中记录了所有块组的块组信息，且存放GDT的块组中的GDT都是完全相同的。 下图是一个块组描述符的信息(通过dumpe2fs获取)。 保留GDT(Reserved GDT)保留GDT用于以后扩容文件系统使用，防止扩容后块组太多，使得块组描述符超出当前存储GDT的blocks。保留GDT和GDT总是同时出现，当然也就和superblock同时出现了。 例如前面143个块组使用了2个block来存放GDT，但是此时第二个block还空余很多空间，当扩容到一定程度时2个block已经无法再记录块组描述符了，这时就需要分配一个或多个Reserverd GDT的block来存放超出的块组描述符。 由于新增加了GDT block，所以应该让每一个保存GDT的块组都同时增加这一个GDT block，所以将保留GDT和GDT存放在同一个块组中可以直接将保留GDT变换为GDT而无需使用低效的复制手段备份到每个存放GDT的块组。 同理，新增加了GDT需要修改每个块组中superblock中的文件系统属性，所以将superblock和Reserverd GDT/GDT放在一起又能提升效率。 Data Block 如上图，除了Data Blocks其他的部分都解释过了。data block是直接存储数据的block，但事实上并非如此简单。 数据所占用的block由文件对应inode记录中的block指针找到，不同的文件类型，数据block中存储的内容是不一样的。以下是Linux中不同类型文件的存储方式。 对于常规文件，文件的数据正常存储在数据块中。 对于目录，该目录下的所有文件和一级子目录的目录名存储在数据块中。 文件名不是存储在其自身的inode中，而是存储在其所在目录的data block中。 对于符号链接，如果目标路径名较短则直接保存在inode中以便更快地查找，如果目标路径名较长则分配一个数据块来保存。 设备文件、FIFO和socket等特殊文件没有数据块，设备文件的主设备号和次设备号保存在inode中。 常规文件的存储就不解释了，下面分别解释特殊文件的存储方式。 目录文件的data block对于目录文件，其inode记录中存储的是目录的inode号、目录的属性元数据和目录文件的block指针，这里面没有存储目录自身文件名的信息。 而其data block的存储方式则如下图所示。 由图可知，在目录文件的数据块中存储了其下的文件名、目录名、目录本身的相对名称”.”和上级目录的相对名称”..”，还存储了指向inode table中这些文件名对应的inode号的指针(并非直接存储inode号码)、目录项长度rec_len、文件名长度name_len和文件类型file_type。注意到除了文件本身的inode记录了文件类型，其所在的目录的数据块也记录了文件类型。由于rec_len只能是4的倍数，所以需要使用”\\0”来填充name_len不够凑满4倍数的部分。至于rec_len具体是什么，只需知道它是一种偏移即可。 目录的data block中并没有直接存储目录中文件的inode号，它存储的是指向inode table中对应文件inode号的指针，暂且称之为inode指针(至此，已经知道了两种指针：一种是inode table中每个inode记录指向其对应data block的block指针，一个此处的inode指针)。一个很有说服力的例子，在目录只有读而没有执行权限的时候，使用”ls -l”是无法获取到其内文件inode号的，这就表明没有直接存储inode号。实际上，因为在创建文件系统的时候，inode号就已经全部划分好并在每个块组的inode table中存放好，inode table在块组中是有具体位置的，如果使用dumpe2fs查看文件系统，会发现每个块组的inode table占用的block数量是完全相同的，如下图是某分区上其中两个块组的信息，它们都占用249个block。 除了inode指针，目录的data block中还使用数字格式记录了文件类型，数字格式和文件类型的对应关系如下图。 注意到目录的data block中前两行存储的是目录本身的相对名称”.”和上级目录的相对名称”..”，它们实际上是目录本身的硬链接和上级目录的硬链接。硬链接的本质后面说明。 由此也就容易理解目录权限的特殊之处了。目录文件的读权限(r)和写权限(w)，都是针对目录文件的数据块本身。由于目录文件内只有文件名、文件类型和inode指针，所以如果只有读权限，只能获取文件名和文件类型信息，无法获取其他信息，尽管目录的data block中也记录着文件的inode指针，但定位指针是需要x权限的，因为其它信息都储存在文件自身对应的inode中，而要读取文件inode信息需要有目录文件的执行权限通过inode指针定位到文件对应的inode记录上。以下是没有目录x权限时的查询状态，可以看到除了文件名和文件类型，其余的全是”?”。 123456[lisi4@xuexi tmp]$ ll -i dls: cannot access d/hehe: Permission deniedls: cannot access d/haha: Permission deniedtotal 0? d????????? ? ? ? ? ? haha? -????????? ? ? ? ? ? hehe 注意，xfs文件系统和ext文件系统不一样，它连文件类型都无法获取。 符号链接存储方式符号链接即为软链接，类似于Windows操作系统中的快捷方式，它的作用是指向原文件或目录。 软链接之所以也被称为特殊文件的原因是：它一般情况下不占用data block，仅仅通过它对应的inode记录就能将其信息描述完成；符号链接的大小是其指向目标路径占用的字符个数，例如某个符号链接的指向方式为”rmt –&gt; ../sbin/rmt”，则其文件大小为11字节；只有当符号链接指向的目标的路径名较长(60个字节)时文件系统才会划分一个data block给它；它的权限如何也不重要，因它只是一个指向原文件的”工具”，最终决定是否能读写执行的权限由原文件决定，所以很可能ls -l查看到的符号链接权限为777。 注意，软链接的block指针存储的是目标文件名。也就是说，链接文件的一切都依赖于其目标文件名。这就解释了为什么/mnt的软链接/tmp/mnt在/mnt挂载文件系统后，通过软链接就能进入/mnt所挂载的文件系统。究其原因，还是因为其目标文件名”/mnt”并没有改变。 例如以下筛选出了/etc/下的符号链接，注意观察它们的权限和它们占用的空间大小。 1234567891011121314151617[root@xuexi ~]# ll /etc/ | grep &apos;^l&apos;lrwxrwxrwx. 1 root root 56 Feb 18 2016 favicon.png -&gt; /usr/share/icons/hicolor/16x16/apps/system-logo-icon.pnglrwxrwxrwx. 1 root root 22 Feb 18 2016 grub.conf -&gt; ../boot/grub/grub.conflrwxrwxrwx. 1 root root 11 Feb 18 2016 init.d -&gt; rc.d/init.dlrwxrwxrwx. 1 root root 7 Feb 18 2016 rc -&gt; rc.d/rclrwxrwxrwx. 1 root root 10 Feb 18 2016 rc0.d -&gt; rc.d/rc0.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc1.d -&gt; rc.d/rc1.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc2.d -&gt; rc.d/rc2.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc3.d -&gt; rc.d/rc3.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc4.d -&gt; rc.d/rc4.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc5.d -&gt; rc.d/rc5.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc6.d -&gt; rc.d/rc6.dlrwxrwxrwx. 1 root root 13 Feb 18 2016 rc.local -&gt; rc.d/rc.locallrwxrwxrwx. 1 root root 15 Feb 18 2016 rc.sysinit -&gt; rc.d/rc.sysinitlrwxrwxrwx. 1 root root 14 Feb 18 2016 redhat-release -&gt; centos-releaselrwxrwxrwx. 1 root root 11 Apr 10 2016 rmt -&gt; ../sbin/rmtlrwxrwxrwx. 1 root root 14 Feb 18 2016 system-release -&gt; centos-release 设备文件、FIFO、套接字文件关于这3种文件类型的文件只需要通过inode就能完全保存它们的信息，它们不占用任何数据块，所以它们是特殊文件。 设备文件的主设备号和次设备号也保存在inode中。以下是/dev/下的部分设备信息。注意到它们的第5列和第6列信息，它们分别是主设备号和次设备号，主设备号标识每一种设备的类型，次设备号标识同种设备类型的不同编号；也注意到这些信息中没有大小的信息，因为设备文件不占用数据块所以没有大小的概念。 1234567891011[root@xuexi ~]# ll /dev | tailcrw-rw---- 1 vcsa tty 7, 129 Oct 7 21:26 vcsa1crw-rw---- 1 vcsa tty 7, 130 Oct 7 21:27 vcsa2crw-rw---- 1 vcsa tty 7, 131 Oct 7 21:27 vcsa3crw-rw---- 1 vcsa tty 7, 132 Oct 7 21:27 vcsa4crw-rw---- 1 vcsa tty 7, 133 Oct 7 21:27 vcsa5crw-rw---- 1 vcsa tty 7, 134 Oct 7 21:27 vcsa6crw-rw---- 1 root root 10, 63 Oct 7 21:26 vga_arbitercrw------- 1 root root 10, 57 Oct 7 21:26 vmcicrw-rw-rw- 1 root root 10, 56 Oct 7 21:27 vsockcrw-rw-rw- 1 root root 1, 5 Oct 7 21:26 zero inode基础知识每个文件都有一个inode，在将inode关联到文件后系统将通过inode号来识别文件，而不是文件名。并且访问文件时将先找到inode，通过inode中记录的block位置找到该文件。 硬链接虽然每个文件都有一个inode，但是存在一种可能：多个文件的inode相同，也就即inode号、元数据、block位置都相同，这是一种什么样的情况呢？能够想象这些inode相同的文件使用的都是同一条inode记录，所以代表的都是同一个文件，这些文件所在目录的data block中的inode指针目的地都是一样的，只不过各指针对应的文件名互不相同而已。这种inode相同的文件在Linux中被称为”硬链接”。 硬链接文件的inode都相同，每个文件都有一个”硬链接数”的属性，使用ls -l的第二列就是被硬链接数，它表示的就是该文件有几个硬链接。 1234567[root@xuexi ~]# ls -ltotal 48drwxr-xr-x 5 root root 4096 Oct 15 18:07 700-rw-------. 1 root root 1082 Feb 18 2016 anaconda-ks.cfg-rw-r--r-- 1 root root 399 Apr 29 2016 Identity.pub-rw-r--r--. 1 root root 21783 Feb 18 2016 install.log-rw-r--r--. 1 root root 6240 Feb 18 2016 install.log.syslog 例如下图描述的是dir1目录中的文件name1及其硬链接dir2/name2，右边分别是它们的inode和datablock。这里也看出了硬链接文件之间唯一不同的就是其所在目录中的记录不同。注意下图中有一列Link Count就是标记硬链接数的属性。 每创建一个文件的硬链接，实质上是多一个指向该inode记录的inode指针，并且硬链接数加1。 删除文件的实质是删除该文件所在目录data block中的对应的inode指针，所以也是减少硬链接次数，由于block指针是存储在inode中的，所以不是真的删除数据，如果仍有其他指针指向该inode，那么该文件的block指针仍然是可用的。当硬链接次数为1时再删除文件就是真的删除文件了，此时inode记录中block指针也将被删除。 不能跨分区创建硬链接，因为不同文件系统的inode号可能会相同，如果允许创建硬链接，复制到另一个分区时inode可能会和此分区已使用的inode号冲突。 硬链接只能对文件创建，无法对目录创建硬链接。之所以无法对目录创建硬链接，是因为文件系统已经把每个目录的硬链接创建好了，它们就是相对路径中的”.”和”..”，分别标识当前目录的硬链接和上级目录的硬链接。每一个目录中都会包含这两个硬链接，它包含了两个信息：(1)一个没有子目录的目录文件的硬链接数是2，其一是目录本身，即该目录datablock中的”.”，其二是其父目录datablock中该目录的记录，这两者都指向同一个inode号；(2)一个包含子目录的目录文件，其硬链接数是2+子目录数，因为每个子目录都关联一个父目录的硬链接”..”。很多人在计算目录的硬链接数时认为由于包含了”.”和”..”，所以空目录的硬链接数是2，这是错误的，因为”..”不是本目录的硬链接。另外，还有一个特殊的目录应该纳入考虑，即”/“目录，它自身是一个文件系统的入口，是自引用(下文中会解释自引用)的，所以”/“目录下的”.”和”..”的inode号相同，它自身不占用硬链接，因为其datablock中只记录inode号相同的”.”和”..”，不再像其他目录一样还记录一个名为”/“的目录，所以”/“的硬链接数也是2+子目录数，但这个2是”.”和”..”的结果。 12[root@xuexi ~]# ln /tmp /mydataln: `/tmp&apos;: hard link not allowed for directory 为什么文件系统自己创建好了目录的硬链接就不允许人为创建呢？从”.”和”..”的用法上考虑，如果当前目录为/usr，我们可以使用”./local”来表示/usr/local，但是如果我们人为创建了/usr目录的硬链接/tmp/husr，难道我们也要使用”/tmp/husr/local”来表示/usr/local吗？这其实已经是软链接的作用了。若要将其认为是硬链接的功能，这必将导致硬链接维护的混乱。 不过，通过mount工具的”–bind”选项，可以将一个目录挂载到另一个目录下，实现伪”硬链接”，它们的内容和inode号是完全相同的。 硬链接的创建方法： ln file_target link_name 。 软链接软链接就是字符链接，链接文件默认指的就是字符链接文件(注意不是字符设备)，使用”l”表示其类型。 软链接在功能上等价与Windows系统中的快捷方式，它指向原文件，原文件损坏或消失，软链接文件就损坏。可以认为软链接inode记录中的指针内容是目标路径的字符串。 创建方式： ln –s source_file softlink_name ，记住是source_file&lt;–link_name的指向关系(反箭头)，以前我老搞错位置。 查看软链接的值： readlink softlink_name 在设置软链接的时候，source_file虽然不要求是绝对路径，但建议给绝对路径。是否还记得软链接文件的大小？它是根据软链接所指向路径的字符数计算的，例如某个符号链接的指向方式为”rmt –&gt; ../sbin/rmt”，它的文件大小为11字节，也就是说只要建立了软链接后，软链接的指向路径是不会改变的，仍然是”../sbin/rmt”。如果此时移动软链接文件本身，它的指向是不会改变的，仍然是11个字符的”../sbin/rmt”，但此时该软链接父目录下可能根本就不存在/sbin/rmt，也就是说此时该软链接是一个被破坏的软链接。 inode深入inode大小和划分inode大小为128字节的倍数，最小为128字节。它有默认值大小，它的默认值由/etc/mke2fs.conf文件中指定。不同的文件系统默认值可能不同。 12345678910111213141516[root@xuexi ~]# cat /etc/mke2fs.conf[defaults] base_features = sparse_super,filetype,resize_inode,dir_index,ext_attr enable_periodic_fsck = 1 blocksize = 4096 inode_size = 256 inode_ratio = 16384[fs_types] ext3 = &#123; features = has_journal &#125; ext4 = &#123; features = has_journal,extent,huge_file,flex_bg,uninit_bg,dir_nlink,extra_isize inode_size = 256 &#125; 同样观察到这个文件中还记录了blocksize的默认值和inode分配比率inode_ratio。inode_ratio=16384表示每16384个字节即16KB就分配一个inode号，由于默认blocksize=4KB，所以每4个block就分配一个inode号。当然分配的这些inode号只是预分配，并不真的代表会全部使用，毕竟每个文件才会分配一个inode号。但是分配的inode自身会占用block，而且其自身大小256字节还不算小，所以inode号的浪费代表着空间的浪费。 既然知道了inode分配比率，就能计算出每个块组分配多少个inode号，也就能计算出inode table占用多少个block。 如果文件系统中大量存储电影等大文件，inode号就浪费很多，inode占用的空间也浪费很多。但是没办法，文件系统又不知道你这个文件系统是用来存什么样的数据，多大的数据，多少数据。 当然inodesize、inode分配比例、blocksize都可以在创建文件系统的时候人为指定。 ext文件系统预留的inode号Ext预留了一些inode做特殊特性使用，如下：某些可能并非总是准确，具体的inode号对应什么文件可以使用”find / -inum NUM”查看。 123456789101112Ext4的特殊inodeInode号 用途0 不存在0号inode1 虚拟文件系统，如/proc和/sys2 根目录3 ACL索引4 ACL数据5 Boot loader6 未删除的目录7 预留的块组描述符inode8 日志inode11 第一个非预留的inode，通常是lost+found目录 所以在ext4文件系统的dumpe2fs信息中，能观察到fisrt inode号可能为11也可能为12。 并且注意到”/“的inode号为2，这个特性在文件访问时会用上。 需要注意的是，每个文件系统都会分配自己的inode号，不同文件系统之间是可能会出现使用相同inode号文件的。例如： 123456[root@xuexi ~]# find / -ignore_readdir_race -inum 2 -ls 2 4 dr-xr-xr-x 22 root root 4096 Jun 9 09:56 / 2 2 dr-xr-xr-x 5 root root 1024 Feb 25 11:53 /boot 2 0 c--------- 1 root root Jun 7 02:13 /dev/pts/ptmx 2 0 -rw-r--r-- 1 root root 0 Jun 6 18:13 /proc/sys/fs/binfmt_misc/status 2 0 drwxr-xr-x 3 root root 0 Jun 6 18:13 /sys/fs 从结果中可见，除了根的Inode号为2，还有几个文件的inode号也是 2，它们都属于独立的文件系统，有些是虚拟文件系统，如/proc和/sys。 ext2/3的inode直接、间接寻址前文说过，inode中保存了blocks指针，但是一条inode记录中能保存的指针数量是有限的，否则就会超出inode大小(128字节或256字节)。 在ext2和ext3文件系统中，一个inode中最多只能有15个指针，每个指针使用i_block[n]表示。 前12个指针i_block[0]到i_block[11]是直接寻址指针，每个指针指向一个数据区的block。如下图所示。 第13个指针i_block[12]是一级间接寻址指针，它指向一个仍然存储了指针的block即i_block[12] –&gt; Pointerblock –&gt; datablock。 第14个指针i_block[13]是二级间接寻址指针，它指向一个仍然存储了指针的block，但是这个block中的指针还继续指向其他存储指针的block，即i_block[13] –&gt; Pointerblock1 –&gt; PointerBlock2 –&gt; datablock。 第15个指针i_block[14]是三级间接寻址指针，它指向一个任然存储了指针的block，这个指针block下还有两次指针指向。即i_block[13] –&gt; Pointerblock1 –&gt; PointerBlock2 –&gt; PointerBlock3 –&gt; datablock。 其中由于每个指针大小为4字节，所以每个指针block能存放的指针数量为BlockSize/4byte。例如blocksize为4KB，那么一个Block可以存放4096/4=1024个指针。 如下图。 为什么要分间接和直接指针呢？如果一个inode中15个指针全是直接指针，假如每个block的大小为1KB，那么15个指针只能指向15个block即15KB的大小，由于每个文件对应一个inode号，所以就限制了每个文件最大为15*1=15KB，这显然是不合理的。 如果存储大于15KB的文件而又不太大的时候，就占用一级间接指针i_block[12]，这时可以存放指针数量为1024/4+12=268，所以能存放268KB的文件。 如果存储大于268K 的文件而又不太大的时候，就继续占用二级指针i_block[13]，这时可以存放指针数量为[1024/4]^2+1024/4+12=65804，所以能存放65804KB=64M左右的文件。 如果存放的文件大于64M，那么就继续使用三级间接指针i_block[14]，存放的指针数量为[1024/4]^3+[1024/4]^2+[1024/4]+12=16843020个指针，所以能存放16843020KB=16GB左右的文件。 如果blocksize=4KB呢？那么最大能存放的文件大小为([4096/4]^3+[4096/4]^2+[4096/4]+12)*4/1024/1024/1024=4T左右。当然这样计算出来的不一定就是最大能存放的文件大小，它还受到另一个条件的限制。这里的计算只是表明一个大文件是如何寻址和分配的。 其实看到这里的计算数值，就知道ext2和ext3对超大文件的存取效率是低下的，它要核对太多的指针，特别是4KB大小的blocksize时。而ext4针对这一点就进行了优化，ext4使用extent的管理方式取代ext2和ext3的块映射，大大提高了效率也降低了碎片。 单文件系统中文件操作的原理在Linux上执行删除、复制、重命名、移动等操作时，它们是怎么进行的呢？还有访问文件时是如何找到它的呢？其实只要理解了前文中介绍的几个术语以及它们的作用就很容易知道文件操作的原理了。 注：在这一小节所解释的都是在单个文件系统下的行为，在多个文件系统中如何请看下一个小节：多文件系统关联。 读取文件当执行”cat /var/log/messages”命令在系统内部进行了什么样的步骤呢？该命令能被成功执行涉及了cat命令的寻找、权限判断以及messages文件的寻找和权限判断等等复杂的过程。这里只解释和本节内容相关的如何寻找到被cat的/var/log/messages文件。 找到根文件系统的块组描述符表所在的blocks，读取GDT(已在内存中)找到inode table的block号。 因为GDT总是和superblock在同一个块组，而superblock总是在分区的第1024-2047个字节，所以很容易就知道第一个GDT所在的块组以及GDT在这个块组中占用了哪些block。其实GDT早已经在内存中了，在系统开机的时候会挂在根文件系统，挂载的时候就已经将所有的GDT放进内存中。 在inode table的block中定位到根”/“的inode，找出”/“指向的data block。 前文说过，ext文件系统预留了一些inode号，其中”/“的inode号为2，所以可以根据inode号直接定位根目录文件的data block。 在”/“的datablock中记录了var目录名和指向var目录文件inode的指针，并找到该inode记录，inode记录中存储了指向var的block指针，所以也就找到了var目录文件的data block。 通过var目录的inode指针，可以寻找到var目录的inode记录，但是指针定位的过程中，还需要知道该inode记录所在的块组以及所在的inode table，所以需要读取GDT，同样，GDT已经缓存到了内存中。 在var的data block中记录了log目录名和其inode指针，通过该指针定位到该inode所在的块组及所在的inode table，并根据该inode记录找到log的data block。 在log目录文件的data block中记录了messages文件名和对应的inode指针，通过该指针定位到该inode所在的块组及所在的inode table，并根据该inode记录找到messages的data block。 最后读取messages对应的datablock。将上述步骤中GDT部分的步骤简化后比较容易理解。如下:找到GDT–&gt;找到”/“的inode–&gt;找到/的数据块读取var的inode–&gt;找到var的数据块读取log的inode–&gt;找到log的数据块读取messages的inode–&gt;找到messages的数据块并读取它们。 删除、重命名和移动文件注意这里是不跨越文件系统的操作行为。 删除文件分为普通文件和目录文件，知道了这两种类型的文件的删除原理，就知道了其他类型特殊文件的删除方法。 对于删除普通文件：(1)找到文件的inode和data block(根据前一个小节中的方法寻找)；(2)将inode table中该inode记录中的data block指针删除；(3)在imap中将该文件的inode号标记为未使用；(4)在其所在目录的data block中将该文件名所在的记录行删除，删除了记录就丢失了指向inode的指针；(5)将bmap中data block对应的block号标记为未使用。 对于删除目录文件：找到目录和目录下所有文件、子目录、子文件的inode和data block；在imap中将这些inode号标记为未使用；将bmap中将这些文件占用的 block号标记为未使用；在该目录的父目录的data block中将该目录名所在的记录行删除。需要注意的是，删除父目录data block中的记录是最后一步，如果该步骤提前，将报目录非空的错误，因为在该目录中还有文件占用。 关于上面的(2)-(5)：当(2)中删除data block指针后，将无法再找到这个文件的数据；当(3)标记inode号未使用，表示该inode号可以被后续的文件重用；当(4)删除目录data block中关于该文件的记录，真正的删除文件，外界再也定位也无法看到这个文件了；当(5)标记data block为未使用后，表示开始释放空间，这些data block可以被其他文件重用。 注意，在第(5)步之前，由于data block还未被标记为未使用，在superblock中仍然认为这些data block是正在使用中的。这表示尽管文件已经被删除了，但空间却还没有释放，df也会将其统计到已用空间中(df是读取superblock中的数据块数量，并计算转换为空间大小)。 什么时候会发生这种情况呢？当一个进程正在引用文件时将该文件删除，就会出现文件已删除但空间未释放的情况。这时步骤已经进行到(4)，外界无法再找到该文件，但由于进程在加载该文件时已经获取到了该文件所有的data block指针，该进程可以获取到该文件的所有数据，但却暂时不会释放该文件空间。直到该进程结束，文件系统才将未执行的步骤(5)继续完成。这也是为什么有时候du的统计结果比df小的原因，关于du和df统计结果的差别，详细内容见：详细分析du和df的统计结果为什么不一样。 重命名文件分为同目录内重命名和非同目录内重命名。非同目录内重命名实际上是移动文件的过程，见下文。 同目录内重命名文件的动作仅仅只是修改所在目录data block中该文件记录的文件名部分，不是删除再重建的过程。 如果重命名时有文件名冲突(该目录内已经存在该文件名)，则提示是否覆盖。覆盖的过程是覆盖目录data block中冲突文件的记录。例如/tmp/下有a.txt和a.log，若将a.txt重命名为a.log，则提示覆盖，若选择覆盖，则/tmp的data block中关于a.log的记录被覆盖，此时它的指针是指向a.txt的inode。 移动文件同文件系统下移动文件实际上是修改目标文件所在目录的data block，向其中添加一行指向inode table中待移动文件的inode指针，如果目标路径下有同名文件，则会提示是否覆盖，实际上是覆盖目录data block中冲突文件的记录，由于同名文件的inode记录指针被覆盖，所以无法再找到该文件的data block，也就是说该文件被标记为删除(如果多个硬链接数，则另当别论)。 所以在同文件系统内移动文件相当快，仅仅在所在目录data block中添加或覆盖了一条记录而已。也因此，移动文件时，文件的inode号是不会改变的。 对于不同文件系统内的移动，相当于先复制再删除的动作。见后文。 关于文件移动，在Linux环境下有一个非常经典网上却又没任何解释的问题：/tmp/a/a能覆盖为/tmp/a吗？答案是不能，但windows能。为什么不能？见mv的一个经典问题(mv的本质)。 存储和复制文件对于文件存储 (1).读取GDT，找到各个(或部分)块组imap中未使用的inode号，并为待存储文件分配inode号； (2).在inode table中完善该inode号所在行的记录； (3).在目录的data block中添加一条该文件的相关记录； (4).将数据填充到data block中。注意，填充到data block中的时候会调用block分配器：一次分配4KB大小的block数量，当填充完4KB的data block后会继续调用block分配器分配4KB的block，然后循环直到填充完所有数据。也就是说，如果存储一个100M的文件需要调用block分配器100*1024/4=25600次。 另一方面，在block分配器分配block时，block分配器并不知道真正有多少block要分配，只是每次需要分配时就分配，在每存储一个data block前，就去bmap中标记一次该block已使用，它无法实现一次标记多个bmap位。这一点在ext4中进行了优化。 (5)填充完之后，去inode table中更新该文件inode记录中指向data block的寻址指针。 对于复制，完全就是另一种方式的存储文件。步骤和存储文件的步骤一样。 多文件系统关联在单个文件系统中的文件操作和多文件系统中的操作有所不同。本文将对此做出非常详细的说明。 根文件系统的特殊性这里要明确的是，任何一个文件系统要在Linux上能正常使用，必须挂载在某个已经挂载好的文件系统中的某个目录下，例如/dev/cdrom挂载在/mnt上，/mnt目录本身是在”/“文件系统下的。而且任意文件系统的一级挂载点必须是在根文件系统的某个目录下，因为只有”/“是自引用的。这里要说明挂载点的级别和自引用的概念。 假如/dev/sdb1挂载在/mydata上，/dev/cdrom挂载在/mydata/cdrom上，那么/mydata就是一级挂载点，此时/mydata已经是文件系统/dev/sdb1的入口了，而/dev/cdrom所挂载的目录/mydata/cdrom是文件系统/dev/sdb1中的某个目录，那么/mydata/cdrom就是二级挂载点。一级挂载点必须在根文件系统下，所以可简述为：文件系统2挂载在文件系统1中的某个目录下，而文件系统1又挂载在根文件系统中的某个目录下。 再解释自引用。首先要说的是，自引用的只能是文件系统，而文件系统表现形式是一个目录，所以自引用是指该目录的data block中，”.”和”..”的记录中的inode指针都指向inode table中同一个inode记录，所以它们inode号是相同的，即互为硬链接。而根文件系统是唯一可以自引用的文件系统。 1234[root@xuexi /]# ll -ai /total 102 2 dr-xr-xr-x. 22 root root 4096 Jun 6 18:13 . 2 dr-xr-xr-x. 22 root root 4096 Jun 6 18:13 .. 由此也能解释cd /.和cd /..的结果都还是在根下，这是自引用最直接的表现形式。 1234[root@xuexi tmp]# cd /.[root@xuexi /]#[root@xuexi tmp]# cd /..[root@xuexi /]# 注意，根目录下的”.”和”..”都是”/“目录的硬链接，且其datablock中不记录名为”/“的条目，因此除去根目录下子目录数后的硬链接数为2。 1234[root@server2 tmp]# a=$(ls -ld / | awk &apos;&#123;print $2&#125;&apos;)[root@server2 tmp]# b=$(ls -l / | grep &quot;^d&quot; |wc -l)[root@server2 tmp]# echo $((a - b))2 挂载文件系统的细节挂载文件系统到某个目录下，例如”mount /dev/cdrom /mnt”，挂载成功后/mnt目录中的文件全都暂时不可见了，且挂载后权限和所有者(如果指定允许普通用户挂载)等的都改变了，知道为什么吗？ 下面就以通过”mount /dev/cdrom /mnt”为例，详细说明挂载过程中涉及的细节。 在将文件系统/dev/cdrom(此处暂且认为它是文件系统)挂载到挂载点/mnt之前，挂载点/mnt是根文件系统中的一个目录，”/“的data block中记录了/mnt的一些信息，其中包括inode指针inode_n，而在inode table中，/mnt对应的inode记录中又存储了block指针block_n，此时这两个指针还是普通的指针。 当文件系统/dev/cdrom挂载到/mnt上后，/mnt此时就已经成为另一个文件系统的入口了，因此它需要连接两边文件系统的inode和data block。但是如何连接呢？如下图。 在根文件系统的inode table中，为/mnt重新分配一个inode记录m，该记录的block指针block_m指向文件系统/dev/cdrom中的data block。既然为/mnt分配了新的inode记录m，那么在”/“目录的data block中，也需要修改其inode指针为inode_m以指向m记录。同时，原来inode table中的inode记录n就被标记为暂时不可用。 block_m指向的是文件系统/dev/cdrom的data block，所以严格说起来，除了/mnt的元数据信息即inode记录m还在根文件系统上，/mnt的data block已经是在/dev/cdrom中的了。这就是挂载新文件系统后实现的跨文件系统，它将挂载点的元数据信息和数据信息分别存储在不同的文件系统上。 挂载完成后，将在/proc/self/{mounts,mountstats,mountinfo}这三个文件中写入挂载记录和相关的挂载信息，并会将/proc/self/mounts中的信息同步到/etc/mtab文件中，当然，如果挂载时加了-n参数，将不会同步到/etc/mtab。 而卸载文件系统，其实质是移除临时新建的inode记录(当然，在移除前会检查是否正在使用)及其指针，并将指针指回原来的inode记录，这样inode记录中的block指针也就同时生效而找回对应的data block了。由于卸载只是移除inode记录，所以使用挂载点和文件系统都可以实现卸载，因为它们是联系在一起的。 下面是分析或结论。 (1).挂载点挂载时的inode记录是新分配的。 挂载前挂载点/mnt的inode号1234[root@server2 tmp]# ll -id /mnt100663447 drwxr-xr-x. 2 root root 6 Aug 12 2015 /mnt[root@server2 tmp]# mount /dev/cdrom /mnt 挂载后挂载点的inode号12[root@server2 tmp]# ll -id /mnt 1856 dr-xr-xr-x 8 root root 2048 Dec 10 2015 mnt 由此可以验证，inode号确实是重新分配的。 (2).挂载后，挂载点的内容将暂时不可见、不可用，卸载后文件又再次可见、可用。 123# 在挂载前，向挂载点中创建几个文件[root@server2 tmp]# touch /mnt/a.txt[root@server2 tmp]# mkdir /mnt/abcdir 12345678910111213141516171819202122232425# 挂载[root@server2 tmp]# mount /dev/cdrom /mnt# 挂载后，挂载点中将找不到刚创建的文件[root@server2 tmp]# ll /mnttotal 636-r--r--r-- 1 root root 14 Dec 10 2015 CentOS_BuildTagdr-xr-xr-x 3 root root 2048 Dec 10 2015 EFI-r--r--r-- 1 root root 215 Dec 10 2015 EULA-r--r--r-- 1 root root 18009 Dec 10 2015 GPLdr-xr-xr-x 3 root root 2048 Dec 10 2015 imagesdr-xr-xr-x 2 root root 2048 Dec 10 2015 isolinuxdr-xr-xr-x 2 root root 2048 Dec 10 2015 LiveOSdr-xr-xr-x 2 root root 612352 Dec 10 2015 Packagesdr-xr-xr-x 2 root root 4096 Dec 10 2015 repodata-r--r--r-- 1 root root 1690 Dec 10 2015 RPM-GPG-KEY-CentOS-7-r--r--r-- 1 root root 1690 Dec 10 2015 RPM-GPG-KEY-CentOS-Testing-7-r--r--r-- 1 root root 2883 Dec 10 2015 TRANS.TBL# 卸载后，挂载点/mnt中的文件将再次可见[root@server2 tmp]# umount /mnt[root@server2 tmp]# ll /mnttotal 0drwxr-xr-x 2 root root 6 Jun 9 08:18 abcdir-rw-r--r-- 1 root root 0 Jun 9 08:18 a.txt 之所以会这样，是因为挂载文件系统后，挂载点原来的inode记录暂时被标记为不可用，关键是没有指向该inode记录的inode指针了。在卸载文件系统后，又重新启用挂载点原来的inode记录，”/“目录下的mnt的inode指针又重新指向该inode记录。 (3).挂载后，挂载点的元数据和data block是分别存放在不同文件系统上的。 (4).挂载点即使在挂载后，也还是属于源文件系统的文件。 多文件系统操作关联假如下图中的圆代表一块硬盘，其中划分了3个区即3个文件系统。其中根是根文件系统，/mnt是另一个文件系统A的入口，A文件系统挂载在/mnt上，/mnt/cdrom也是一个文件系统B的入口，B文件系统挂载在/mnt/cdrom上。每个文件系统都维护了一些inode table，这里假设图中的inode table是每个文件系统所有块组中的inode table的集合表。 如何读取/var/log/messages呢？这是和”/“在同一个文件系统的文件读取，在前面单文件系统中已经详细说明了。 但如何读取A文件系统中的/mnt/a.log呢？首先，从根文件系统找到/mnt的inode记录，这是单文件系统内的查找；然后根据此inode记录的block指针，定位到/mnt的data block中，这些block是A文件系统的data block；然后从/mnt的data block中读取a.log记录，并根据a.log的inode指针定位到A文件系统的inode table中对应a.log的inode记录；最后从此inode记录的block指针找到a.log的data block。至此，就能读取到/mnt/a.log文件的内容。 下图能更完整的描述上述过程。 那么又如何读取/mnt/cdrom中的/mnt/cdrom/a.rpm呢？这里cdrom代表的文件系统B挂载点位于/mnt下，所以又多了一个步骤。先找到”/“，再找到根中的mnt，进入到mnt文件系统中，找到cdrom的data block，再进入到cdrom找到a.rpm。也就是说，mnt目录文件存放位置是根，cdrom目录文件存放位置是mnt，最后a.rpm存放的位置才是cdrom。 继续完善上图。如下。 ext3文件系统的日志功能相比ext2文件系统，ext3多了一个日志功能。 在ext2文件系统中，只有两个区：数据区和元数据区。如果正在向data block中填充数据时突然断电，那么下一次启动时就会检查文件系统中数据和状态的一致性，这段检查和修复可能会消耗大量时间，甚至检查后无法修复。之所以会这样是因为文件系统在突然断电后，它不知道上次正在存储的文件的block从哪里开始、哪里结束，所以它会扫描整个文件系统进行排除(也许是这样检查的吧)。 而在创建ext3文件系统时会划分三个区：数据区、日志区和元数据区。每次存储数据时，先在日志区中进行ext2中元数据区的活动，直到文件存储完成后标记上commit才将日志区中的数据转存到元数据区。当存储文件时突然断电，下一次检查修复文件系统时，只需要检查日志区的记录，将bmap对应的data block标记为未使用，并把inode号标记未使用，这样就不需要扫描整个文件系统而耗费大量时间。 虽说ext3相比ext2多了一个日志区转写元数据区的动作而导致ext3相比ext2性能要差一点，特别是写众多小文件时。但是由于ext3其他方面的优化使得ext3和ext2性能几乎没有差距。 ext4文件系统回顾前面关于ext2和ext3文件系统的存储格式，它使用block为存储单元，每个block使用bmap中的位来标记是否空闲，尽管使用划分块组的方法优化提高了效率，但是一个块组内部仍然使用bmap来标记该块组内的block。对于一个巨大的文件，扫描整个bmap都将是一件浩大的工程。另外在inode寻址方面，ext2/3使用直接和间接的寻址方式，对于三级间接指针，可能要遍历的指针数量是非常非常巨大的。 ext4文件系统的最大特点是在ext3的基础上使用区(extent，或称为段)的概念来管理。一个extent尽可能的包含物理上连续的一堆block。inode寻址方面也一样使用区段树的方式进行了改进。默认情况下，EXT4不再使用EXT3的block mapping分配方式 ，而改为Extent方式分配。 (1). 关于EXT4的结构特征 EXT4在总体结构上与EXT3相似，大的分配方向都是基于相同大小的块组，每个块组内分配固定数量的inode、可能的superblock(或备份)及GDT。 EXT4的inode 结构做了重大改变，为增加新的信息，大小由EXT3的128字节增加到默认的256字节，同时inode寻址索引不再使用EXT3的”12个直接寻址块+1个一级间接寻址块+1个二级间接寻址块+1个三级间接寻址块”的索引模式，而改为4个Extent片断流，每个片断流设定片断的起始block号及连续的block数量(有可能直接指向数据区，也有可能指向索引块区)。 片段流即下图中索引节点(inde node block)部分的绿色区域，每个15字节，共60字节。 (2). EXT4删除数据的结构更改。 EXT4删除数据后，会依次释放文件系统bitmap空间位、更新目录结构、释放inode空间位。 (3). ext4使用多block分配方式。 在存储数据时，ext3中的block分配器一次只能分配4KB大小的Block数量，而且每存储一个block前就标记一次bmap。假如存储1G的文件，blocksize是4KB，那么每存储完一个Block就将调用一次block分配器，即调用的次数为10241024/4KB=262144次，标记bmap的次数也为10241024/4=262144次。 而在ext4中根据区段来分配，可以实现调用一次block分配器就分配一堆连续的block，并在存储这一堆block前一次性标记对应的bmap。这对于大文件来说极大的提升了存储效率。 ext类的文件系统的缺点最大的缺点是它在创建文件系统的时候就划分好一切需要划分的东西，以后用到的时候可以直接进行分配，也就是说它不支持动态划分和动态分配。对于较小的分区来说速度还好，但是对于一个超大的磁盘，速度是极慢极慢的。例如将一个几十T的磁盘阵列格式化为ext4文件系统，可能你会因此而失去一切耐心。 除了格式化速度超慢以外，ext4文件系统还是非常可取的。当然，不同公司开发的文件系统都各有特色，最主要的还是根据需求选择合适的文件系统类型。 虚拟文件系统VFS每一个分区格式化后都可以建立一个文件系统，Linux上可以识别很多种文件系统，那么它是如何识别的呢？另外，在我们操作分区中的文件时，并没有指定过它是哪个文件系统的，各种不同的文件系统如何被我们用户以无差别的方式操作呢？这就是虚拟文件系统的作用。 虚拟文件系统为用户操作各种文件系统提供了通用接口，使得用户执行程序时不需要考虑文件是在哪种类型的文件系统上，应该使用什么样的系统调用来操作该文件。有了虚拟文件系统，只要将所有需要执行的程序调用VFS的系统调用就可以了，剩下的动作由VFS来帮忙完成。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"Linux分区信息与管理文件系统","slug":"Linux分区信息与管理文件系统","date":"2017-04-14T16:00:00.000Z","updated":"2018-06-22T11:29:44.139Z","comments":true,"path":"2017/04/15/Linux分区信息与管理文件系统/","link":"","permalink":"http://yoursite.com/2017/04/15/Linux分区信息与管理文件系统/","excerpt":"分区分区是为了在逻辑上将某些柱面隔开形成边界。它是以柱面为单位来划分的，首先划分外圈柱面，然后不断向内划分。 由于读写越外圈磁道中的数据比越内圈更快，所以第一个分区在读写性能上比后面的分区更好。在Windows操作系统上，C盘的速度是最快的，越后面的区越慢就是这个原因。 在磁盘数据量非常大的情况下，划分分区的好处是扫描块位图等更快速：不用再扫描整块磁盘的块位图，只需扫描对应分区的块位图。","text":"分区分区是为了在逻辑上将某些柱面隔开形成边界。它是以柱面为单位来划分的，首先划分外圈柱面，然后不断向内划分。 由于读写越外圈磁道中的数据比越内圈更快，所以第一个分区在读写性能上比后面的分区更好。在Windows操作系统上，C盘的速度是最快的，越后面的区越慢就是这个原因。 在磁盘数据量非常大的情况下，划分分区的好处是扫描块位图等更快速：不用再扫描整块磁盘的块位图，只需扫描对应分区的块位图。 分区方法(MBR和GPT)MBR格式的磁盘中，会维护磁盘第一个扇区——MBR扇区，在该扇区中第446字节之后的64字节是分区表，每个分区占用16字节，所以限制了一块磁盘最多只能有4个主分区(Primary,P)，如果多于4个区，只能将主分区少于4个，通过建立扩展分区(Extend,E)，然后在扩展分区建立逻辑分区(Logical,L)的方式来突破4个分区的限制。 在Linux中，MBR格式的磁盘主分区号从1-4，扩展分区号从2-4，逻辑分区号从5-15，也就是最大限制是15个分区。 例如，一块盘想分成6个分区，可以： 1231P+5L：sda1+sda5+sda6+sda7+sda8+sda92P+4L：sda1+sda2+sda5+sda6+sda7+sda83P+3L：sda1+sda2+sda3+sda5+sda6+sda7 而GPT格式突破了MBR的限制，它不再限制只能存储4个分区表条目，而是使用了类似MBR扩展分区表条目的格式，它允许有128个主分区，这也使得它可以对超过2TB的磁盘进行分区。 MBR和GPT分区表信息在MBR格式分区表中，MBR扇区占用512个字节，前446个字节是主引导记录，即boot loader。中间64字节记录着分区表信息，每个主分区信息占用16字节，因此最多只能有4个主分区，最后2个字节是有效标识位。如果使用扩展分区，则扩展分区对应的16字节记录的是指向扩展分区中扩展分区表的指针。 在MBR磁盘上，分区和启动信息是保存在一起的，如果这部分数据被覆盖或破坏，只能重建MBR。而GPT在整个磁盘上保存多个这部分信息的副本，因此它更为健壮，并可以恢复被破坏的这部分信息。GPT还为这些信息保存了循环冗余校验码(CRC)以保证其完整和正确，如果数据被破坏，GPT会发现这些破坏，并从磁盘上的其他地方进行恢复。 下面是GPT格式的分区表信息，大致约占17个字节。EFI部分可以分为4个区域：EFI信息区(GPT头)、分区表、GPT分区区域和备份区域。 EFI信息区(GPT头)：起始于磁盘的LBA1，通常也只占用这个单一扇区。其作用是定义分区表的位置和大小。GPT头还包含头和分区表的校验和，这样就可以及时发现错误。 分区表：分区表区域包含分区表项。这个区域由GPT头定义，一般占用磁盘LBA2～LBA33扇区，每扇区可存储4个主分区的分区信息，所以共能分128个主分区。分区表中的每个分区项由起始地址、结束地址、类型值、名字、属性标志、GUID值组成。分区表建立后，128位的GUID对系统来说是唯一的。 GPT分区：最大的区域，由分配给分区的扇区组成。这个区域的起始和结束地址由GPT头定义。 备份区：备份区域位于磁盘的尾部，包含GPT头和分区表的备份。它占用GPT结束扇区和EFI结束扇区之间的33个扇区。其中最后一个扇区用来备份1号扇区的EFI信息，其余的32个扇区用来备份LBA2～LBA33扇区的分区表。 添加磁盘正常情况下，添加磁盘后需要重启系统才能被内核识别，在/dev/下才有对应的设备号，使用fdisk -l才会显示出来。但是有时候不方便重启，所以下面介绍一种磁盘热插拔方式。更多热插和热拔方法见我的另一篇文章：Linux上磁盘热插拔。 12[root@node1 ~]# ls /sys/class/scsi_host/ # 查看主机scsi总线号host0 host1 host2 重新扫描scsi总线以热插拔方式添加新设备。 1234[root@node1 ~]# echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host0/scan[root@node1 ~]# echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host1/scan[root@node1 ~]# echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host2/scan[root@node1 ~]# fdisk -l # 再查看就有了 如果scsi_host目录系很多hostN目录，则使用循环来完成。 123456[root@xuexi scsi_host]# ls /sys/class/scsi_host/host0 host11 host14 host17 host2 host22 host25 host28 host30 host4 host7host1 host12 host15 host18 host20 host23 host26 host29 host31 host5 host8host10 host13 host16 host19 host21 host24 host27 host3 host32 host6 host9[root@xuexi scsi_host]# for i in /sys/class/scsi_host/host*/scan;do echo &quot;- - -&quot; &gt;$i;done 使用fdisk分区工具fdisk工具用来分MBR磁盘上的区。要分GPT磁盘上的区，可以使用gdisk。parted工具对这两种格式的磁盘分区都支持。 如果一个存储设备已经分过区，那么它可能是mbr格式的，也可能是gpt格式的，如果已经是mbr格式的，则只能继续使用fdisk进行分区，如果已经是gpt格式的，则只能使用gdisk进行分区。当然，无论什么格式的都可以使用parted进行分区，只不过也只能划分和已存在分区格式一样的分区，因为无论何种格式的分区，它的分区表和分区标识是已经固定的。 使用fdisk分区，它只能实现MBR格式的分区。 12345678910111213141516171819[root@xuexi ~]# fdisk /dev/sdb # sdb后没加数字Command (m for help): m # 输入m查看可用命令帮助Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition # 删除分区，如果删除扩展分区同时会删除里面的逻辑分区 l list known partition types # 列出分区类型 m print this menu # 显示帮助信息 n add a new partition # 创建新分区 o create a new empty DOS partition table p print the partition table # 输出分区信息 q quit without saving changes # 不保存退出 s create a new empty Sun disklabel t change a partition&apos;s system id # 修改分区类型 u change display/entry units v verify the partition table w write table to disk and exit # 保存分区信息并退出 x extra functionality (experts only) 新建第一个主分区： 1234567891011121314151617181920Command (m for help): n # 添加分区Command action e extended # 添加扩展分区 p primary partition (1-4) # 添加主分区p # 输入p来创建第一个主分区Partition number (1-4): 1 # 输入分区号，从1开始First cylinder (1-1305, default 1): # 输入柱面号，不输人默认是1Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-1305, default 1305): +2G # 给第一个主分区/dev/sdb1分2G，也可以使用柱面号来指定大小。Command (m for help): p # 第一个分区结束，p查看下已分区信息 Disk /dev/sdb: 10.7 GB, 10737418240 bytes255 heads, 63 sectors/track, 1305 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x2d8d64eb Device Boot Start End Blocks Id System/dev/sdb1 1 262 2104483+ 83 Linux 新建扩展分区： 123456789101112131415161718192021Command (m for help): n # 再建一个分区Command action e extended p primary partition (1-4)e # 创建扩展分区Partition number (1-4): 2 # 扩展分区号为2First cylinder (263-1305, default 263):Using default value 263Last cylinder, +cylinders or +size&#123;K,M,G&#125; (263-1305, default 1305): # 剩余空间全部给扩展分区Using default value 1305Command (m for help): p Disk /dev/sdb: 10.7 GB, 10737418240 bytes255 heads, 63 sectors/track, 1305 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x2d8d64eb Device Boot Start End Blocks Id System/dev/sdb1 1 262 2104483+ 83 Linux/dev/sdb2 263 1305 8377897+ 5 Extended 新建扩展分区： 123456789101112131415161718192021Command (m for help): n # 新建逻辑分区Command action l logical (5 or over) # 这里不再是扩展分区标识e，只有l。 # 如果已有3个主分区，这里连l都没有 p primary partition (1-4)l # 新建逻辑分区First cylinder (263-1305, default 263): # 这里也不能选逻辑分区号了Using default value 263Last cylinder, +cylinders or +size&#123;K,M,G&#125; (263-1305, default 1305): +3GCommand (m for help): pDisk /dev/sdb: 10.7 GB, 10737418240 bytes255 heads, 63 sectors/track, 1305 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x2d8d64eb Device Boot Start End Blocks Id System/dev/sdb1 1 262 2104483+ 83 Linux/dev/sdb2 263 1305 8377897+ 5 Extended/dev/sdb5 263 655 3156741 83 Linux 分区结束，保存。如果不保存，则按q。 12345Command (m for help): w The partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 分区的过程，实质上是划分柱面以及修改分区表。 上面的fdisk操作全部是在内存中执行的，必须保存生效。保存后，内核还未识别该分区，可以查看/proc/partition目录下存在的文件，这些文件是能被内核识别的分区。运行partprobe或partx命令重新读取分区表让内核识别新的分区，内核识别后才可以格式化。而且分区结束时按w保存分区表有时候会失败，提示重启，这时候运行partprobe命令可以代替重启就生效。 12345[root@xuexi ~]# partprobe # 执行partprobe，下面一堆信息，不理它Warning: WARNING: the kernel failed to re-read the partition table on /dev/sda (Device or resource busy). As a result, it may not reflect all of your changes until after reboot.Warning: Unable to open /dev/sr0 read-write (Read-only file system). /dev/sr0 has been opened read-only.Warning: Unable to open /dev/sr0 read-write (Read-only file system). /dev/sr0 has been opened read-only.Error: Invalid partition table - recursive partition on /dev/sr0. 也可指定在/dev/sdb上重加载分区表，省的无法读取正忙的/dev/sda磁盘，给出上面一堆信息。 1[root@xuexi ~]# partprobe /dev/sdb 分区之后再使用fdisk -l查看新的分区状态。 将上面分区所需要使用的命令总结如下，以后便于使用脚本分区。 s fdisk /dev/sdb # 选择要分区的设备n # 创建分区p/e/l # 选择分区类型 如果主分区数有3个，且已经划分了扩展分区，再继续分区时将只能划分逻辑分区，这种情况下l选项会直接跳过进入下一个阶段。 s N # 指定分区号\\n # 指定起始柱面号，使用默认值就直接回车即换行+N # 指定分区大小为Nw # 分区结束保存退出partprobe /dev/sdb &amp;&gt;/dev/null # 重读分区表fdisk -l | grep “^/dev/sdb” &amp;&gt;/dev/null # 检查分区状态 使用gdisk分区工具gdisk用来划分gpt分区，需要单独安装这个工具包。 1shell&gt; yum -y install gdisk 分区的时候直接带上设备即可。以下是对新硬盘划分gpt分区的过程。 12345678910111213141516171819202122232425262728[root@xuexi ~]# gdisk /dev/sdbGPT fdisk (gdisk) version 0.8.10Partition table scan: MBR: not present BSD: not present APM: not present GPT: not presentCreating new GPT entries.Command (? for help): ?b back up GPT data to a filec change a partition&apos;s named delete a partition # 删除分区i show detailed information on a partition # 列出分区详细信息l list known partition types # 列出所以已知的分区类型n add a new partition # 添加新分区o create a new empty GUID partition table (GPT) # 创建一个新的空的guid分区表p print the partition table # 输出分区表信息q quit without saving changes # 退出gdisk工具r recovery and transformation options (experts only) s sort partitions t change a partition&apos;s type code # 修改分区类型v verify diskw write table to disk and exit # 将分区信息写入到磁盘x extra functionality (experts only) ? print this menu 添加一个新分区。 1234567891011121314151617181920212223242526272829Command (? for help): n Partition number (1-128, default 1):First sector (34-41943006, default = 2048) or &#123;+-&#125;size&#123;KMGTP&#125;:Last sector (2048-41943006, default = 41943006) or &#123;+-&#125;size&#123;KMGTP&#125;: +10GCurrent type is &apos;Linux filesystem&apos;Hex code or GUID (L to show codes, Enter = 8300):Changed type of partition to &apos;Linux filesystem&apos; Command (? for help): pDisk /dev/sdb: 41943040 sectors, 20.0 GiBLogical sector size: 512 bytesDisk identifier (GUID): F8AE925F-515F-4807-92ED-4109D0827191Partition table holds up to 128 entriesFirst usable sector is 34, last usable sector is 41943006Partitions will be aligned on 2048-sector boundariesTotal free space is 20971453 sectors (10.0 GiB) Number Start (sector) End (sector) Size Code Name 1 2048 20973567 10.0 GiB 8300 Linux filesystemCommand (? for help): i # 查看分区详细信息Using 1Partition GUID code: 0FC63DAF-8483-4772-8E79-3D69D8477DE4 (Linux filesystem)Partition unique GUID: B2452103-4F32-4B60-AEF7-4BA42B7BF089First sector: 2048 (at 1024.0 KiB)Last sector: 20973567 (at 10.0 GiB)Partition size: 20971520 sectors (10.0 GiB)Attribute flags: 0000000000000000Partition name: &apos;Linux filesystem ‘保存分区表到磁盘。 12345678Command (? for help): w Final checks complete. About to write GPT data. THIS WILL OVERWRITE EXISTINGPARTITIONS!!Do you want to proceed? (Y/N): YOK; writing new GUID partition table (GPT) to /dev/sdb.The operation has completed successfully. 执行partprobe重新读取分区表信息。 1[root@server2 ~]# partprobe /dev/sdb gdisk还有几个expert only的命令，其实没什么专家不专家可用的，咱们需要知道的是命令何时能用，它们的作用是什么？ 在gdisk交互过程命令行下，按下x表示进入扩展功能模式，该模式下的功能大部分都和gpt分区表相关，在不是非常了解gpt分区表结构的时候不建议做修改动作，但是查看信息类是没问题的。以下是扩展功能模式下的命令。 123456789101112131415161718192021222324Command (? for help): xExpert command (? for help): ?a set attributesc change partition GUIDd display the sector alignment valuee relocate backup data structures to the end of the diskg change disk GUIDh recompute CHS values in protective/hybrid MBRi show detailed information on a partitionl set the sector alignment valuem return to main menun create a new protective MBRo print protective MBR datap print the partition tableq quit without saving changesr recovery and transformation options (experts only)s resize partition table # 修改分区表大小，注意不是分区大小t transpose two partition table entriesu Replicate partition table on new device # 将分区表导出v verify diskw write table to disk and exitz zap (destroy) GPT data structures and exit # 损毁gpt上的数据? print this menu 使用parted分区工具parted支持mbr格式和gpt格式的磁盘分区。它的强大在于可以一步到位而不需要不断的交互式输入(也可以交互式)。 parted分区工具是实时的，所以每一步操作都是直接写入磁盘而不是写进内存，它不像fdisk/gdisk还需要w命令将内存中的结果保存到磁盘中。 1234567891011121314151617181920212223242526[root@xuexi ~]# parted /dev/sdcGNU Parted 2.1Using /dev/sdcWelcome to GNU Parted! Type &apos;help&apos; to view a list of commands. (parted) help align-check TYPE N check partition N for TYPE(min|opt) alignment check NUMBER do a simple check on the file system(centos 7上已删除该功能) cp [FROM-DEVICE] FROM-NUMBER TO-NUMBER copy file system to another partition(centos 7上已删除该功能) help [COMMAND] print general help, or help on COMMAND mklabel,mktable LABEL-TYPE create a new disklabel (partition table) mkfs NUMBER FS-TYPE make a FS-TYPE file system on partition NUMBER (centos 7上已删除改该功能) mkpart PART-TYPE [FS-TYPE] START END make a partition mkpartfs PART-TYPE FS-TYPE START END make a partition with a file system(centos 7上已删除该功能) move NUMBER START END move partition NUMBER(centos 7上已删除该功能) name NUMBER NAME name partition NUMBER as NAME print [devices|free|list,all|NUMBER] display the partition table,available devices,free space, all found partitions,or a particular partition quit exit program rescue START END rescue a lost partition near START and END resize NUMBER START END resize partition NUMBER and its file system(修改分区大小(centos 7上已删除该功能)) rm NUMBER delete partition NUMBER (删除分区) select DEVICE choose the device to edit (重选磁盘进入parted状态) set NUMBER FLAG STATE change the FLAG on partition NUMBER(设置分区状态，如将其off或on) toggle [NUMBER [FLAG]] toggle the state of FLAG on partition NUMBER(修改文件系统类型，如swap、lvm) unit UNIT set the default unit to UNIT(修改默认单位，kB/MB/GB等) version display the version number and copyright information of GNU Parted 常用的命令是mklabel/rm/print/mkpart/help/quit，至于parted中一些看上去很好的功能如mkfs/mkpartfs/resize等可能会损毁当前数据而不够安全，所以只要使用它的5个常用命令即可。 parted分区的前提是磁盘已经有分区表(partition table)或磁盘标签(disk label)，否则将显示”unrecognised disk label”，这是和fdisk/gdisk不同的地方，所以需要先使用mklabel创建标签或分区表，最常见的标签(分区表)为”msdos”和”gpt”，其中msdos分区就是MBR格式的分区表，也就是会有主分区、扩展分区和逻辑分区的概念和限制。 下面使用parted对/dev/sdc创建msdos的新分区。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869[root@xuexi ~]# parted /dev/sdcGNU Parted 2.1Using /dev/sdbWelcome to GNU Parted! Type &apos;help&apos; to view a list of commands.(parted) mklabel # 创建磁盘分区标签(分区表类型) New disk label type? msdos # 选择msdos即MBR类型 # 上面的两步也可以直接一步进行：(parted) mklabel msdos (parted) mkpart # 开始进行分区 Partition type? primary/extended? p # 创建主分区File system type? [ext2]? ext4 # 创建ext4文件系统 # (注意，这里虽然指明了文件系统，但没有任何意义，后面还是需要手动格式化并选择文件系统类型)Start? 1 # 分区开始位置，默认是M为单位，表示从1M开始，也可直接指定1G这种方式End? 1024 # 分区结束位置，1024-1=1023M(parted) p # print，查看分区信息Model: VMware, VMware Virtual S (scsi)Disk /dev/sdc: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdosNumber Start End Size Type File system Flags 1 1049kB 1024MB 1023MB primary# 可以一步完成一个命令中的多个动作(parted) mkpart p ext4 1026M 4096M # 可以一步完成，也可以一步完成到任何位置，然后继续交互下一步 # 可能会提示分区未对齐&quot;Warning: The resulting partition is not properly aligned for best performance.&quot;，忽略它(parted) mkpart e 4098 -1 # 创建扩展分区，注意创建扩展分区时不指定文件系统类型；-1表示剩余的全部分配给该分区(parted) p Model: VMware, VMware Virtual S (scsi)Disk /dev/sdc: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdos Number Start End Size Type File system Flags 1 1049kB 1024MB 1023MB primary 2 1026MB 4096MB 3070MB primary 3 4098MB 21.5GB 17.4GB extended lba(parted) mkpart l ext4 4099 8194 # 创建逻辑分区，指定ext4(parted) mkpart l ext4 8195 -1 # 继续创建逻辑分区(parted) pModel: VMware, VMware Virtual S (scsi)Disk /dev/sdc: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdosNumber Start End Size Type File system Flags 1 1049kB 1024MB 1023MB primary 2 1026MB 4096MB 3070MB primary 3 4098MB 21.5GB 17.4GB extended lba 5 4099MB 8194MB 4095MB logical 6 8195MB 21.5GB 13.3GB logical(parted) rm 5 # 删除5号分区(parted) pModel: VMware, VMware Virtual S (scsi)Disk /dev/sdc: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdosNumber Start End Size Type File system Flags 1 1049kB 1024MB 1023MB primary 2 1026MB 4096MB 3070MB primary 3 4098MB 21.5GB 17.4GB extended lba 5 8195MB 21.5GB 13.3GB logical(parted) quit # 退出parted工具Information: You may need to update /etc/fstab. # 提示你要更新/etc/fstab中的配置，说明该工具是可以在线分区的 mkfs和mkpartfs等命令不完善，下面的警告信息已经给出了提示。 123456789101112(parted) mkfs 1 WARNING: you are attempting to use parted to operate on (mkfs) a file system.parted&apos;s file system manipulation code is not as robust as what you&apos;ll find indedicated, file-system-specific packages like e2fsprogs. We recommendyou use parted only to manipulate partition tables, whenever possible.Support for performing most operations on most types of file systemswill be removed in an upcoming release.Warning: The existing file system will be destroyed and all data on the partition will be lost. Do you want tocontinue?parted: invalid token: 1Yes/No? n 使用parted工具进行的分区无需运行partprobe重新读取分区表，内核会即时识别已经分区的分区信息。如下所示。 123456[root@xuexi tmp]# cat /proc/partitions | grep &quot;sdc&quot; 8 32 20971520 sdc 8 33 999424 sdc1 8 34 2998272 sdc2 8 35 1 sdc3 8 37 12967936 sdc5 一定要注意，虽然parted工具中指定了文件系统，但是并没有意义，它仍需要手动进行格式化并指定分区类型。实际上，在parted中文件系统是可以不用指定的，即使是非交互模式下也可以省略。 fdisk/gdisk以及parted非交互式操作分区使用非交互分区时，最重要的是待分的区的起始点不能是已使用的。可以使用lsblk或fdisk -l或parted DEV print来判断将要从哪个地方开始分区。其实parted在非交互分区是最佳的工具，不仅是因为其书写方式简洁，而且待分区的起点如不合理它会自动提示是否要自动调整。 parted实现非交互parted命令只能一次非交互一个命令中的所有动作。如下所示： 123456parted /dev/sdb mklabel msdos # 设置硬盘flagparted /dev/sdb mkpart primary ext4 1 1000 # Mbr格式分区，分别是partition type/fstype/start/endparted /dev/sdb mkpart 1 ext4 1M 10240M # gpt格式分区，分别是name/fstype/start/endparted /dev/sdb mkpart 1 10G 15G # 省略fstype的交互式分区parted /dev/sdb rm 1 # 删除分区parted /dev/sdb p # 输出信息 如果不确定分区的起点大小，可以加上-s选项使用script模式，该模式下parted将回答一切默认值，如yes、no。 12345shell&gt; parted -s /dev/sdb mkpart 3 14G 16GWarning: You requested a partition from 14.0GB to 16.0GB. The closest location we can manage is 15.0GB to 16.0GB.Is this still acceptable to you?Information: You may need to update /etc/fstab. fdisk实现非交互fdisk实现非交互的原理是从标准输入中读取，每读取一行传递一次操作。 所以可以有两种方式：使用echo和管道传递；将操作写入到文件中，从文件中读取。 例如：下面的命令创建了两个分区。使用默认值时传递空行即可。 1echo -e &quot;n\\np\\n1\\n\\n+5G\\nn\\np\\n2\\n\\n+1G\\nw\\n&quot; | fdisk /dev/sdb 如果要传递的操作很多，则可以将它们写入到一个文件中，从文件中读取。 12echo -e &quot;n\\np\\n1\\n\\n+5G\\nn\\np\\n2\\n\\n+1G\\nw\\n&quot; &gt;/tmp/a.txtfdisk /dev/sdb &lt;/tmp/a.txt gdisk实现非交互原理同fdisk。例如： 1echo -e &quot;n\\n1\\n\\n+3G\\n\\nw\\nY\\n&quot; | gdisk /dev/sdb 上面传递的各参数意义为：新建分区，分区number为1，使用默认开始扇区位置，分区大小+3G，使用默认分区类型，保存，确认。 格式化分区分区结束后就需要格式化创建文件系统了，格式化分区的过程就是创建文件系统的过程。可以使用mkfs(make filesystem)工具进行格式化，也可以使用该工具家族的其他工具如mkfs.ext4/mkfs.xfs等专门针对文件系统的工具。 要查看支持的文件系统类型，只需简单的输入mkfs然后按两下tab键，就可以列出各文件系统对应的格式化命令，这些就是支持的文件系统类型。 CentOS 6上支持的： 12[root@xuexi ~]# mkfsmkfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.ext4dev mkfs.msdos mkfs.vfat CentOS 7上支持的： 12[root@server2 ~]# mkfsmkfs mkfs.btrfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.fat mkfs.minix mkfs.msdos mkfs.vfat mkfs.xfs 5.4.1 mkfs工具 mkfs [-t fstype] 分区该工具非常简单，它只需指定一个可选的”-t”选项指定要创建的文件系统类型，如果省略则默认创建ext2文件系统。该工具指定的”-t”选项其实是在调用对应文件系统专属的格式化工具。 mke2fs工具mkfs.ext2/mkfs.ext3/mkfs.ext4或mkfs -t extX其实都是在调用mke2fs工具。 该工具创建文件系统时，会从/etc/mke2fs.conf配置中读取默认的配置项。 1234567891011121314151617181920212223242526272829303132mke2fs [ -c ] [ -b block-size ] [ -f fragment-size ] [ -g blocks-per-group ] [ -G number-of-groups ] [ -i bytes-per-inode ] [ -I inode-size ] [ -j ] [ -N number-of-inodes ] [ -m reserved-blocks-percentage ] [ -q ] [ -r fs-revision-level ] [ -v ] [ -L volume-label ] [ -S ] [ -t fs-type ] device [ blocks-count ]选项说明：-t fs-type ：指定要创建的文件系统类型(ext2,ext3 ext4)，若不指定，则从/etc/mke2fs.conf中获取默认的文件系统类型。-b block-size ：指定每个block的大小，有效值有1024、2048和4096，单位是字节。-I inode-size ：指定inode大小，单位为字节。必须为2的幂次方，且大于等于128字节。值越大，说明inode的集合体inode table占用越多的空 间，这不仅会挤占文件系统中的可用空间，还会降低性能，因为要扫描inode table需要消耗更多时间，但是在linux kernel 2.6.10 之后，由于使用inode存储了很多扩展的额外属性，所以128字节已经不够用了，因此ext4默认的inode size已经变为256，尽管 inode大小增大了，但因为使用inode存储扩展属性带来的性能提升远高于inode size变大导致的负面影响，所以仍建议使用256字 节的inode。-i bytes-per-inode ：指定每多少个字节就为其分配一个inode号。值越大，说明一个文件系统中分配的inode号越少，更适用于存储大量大文件，值越 小，inode号越多，更适用于存储大量小文件。该值不能小于一个block的大小，因为这样会造成inode多余。 注意，创建文件系统后该值就不能再改变了。-c ：创建文件系统前先检查设备是否有bad blocks。-f fragment-size ：指定fragments的大小，单位字节。-g blocks-per-group：指定每个块组中的block数量。不建议修改此项。-G number-of-groups：该选项用于ext4文件系统(严格地说是启用了flex_bg特性)，指定虚拟块组(即一个extent)中包含的块组个数，必须为2的幂次方。 对于ext4文件系统来说，使用extent的功能能极大提升其性能。-j ：创建带有日志功能的文件系统，即ext3。如果要指定关于日志方面的设置，在-j的基础上再使用-J指定，不过一般默认即可，具体可 指定的选项看man文档。 -L new-volume-label：指定卷标名称，名称不得超出16字节。-m reserved-blocks-percentage：指定文件系统保留block数量的比例，保留一部分block，可以降低物理碎片。默认比例为5%。-N number-of-inodes ：强制指定该文件系统应该分配多少个inode号，它会覆盖通过计算得出inode数量的结果(根据block大小、数量和每多少字节分配 一个inode得出Inode数量)，但是不建议这么做。-q ：安静模式，可用于脚本中-S ：重建superblock和group descriptions。在所有的superblock和备份的superblock都损坏时有用。它会重新初始化superblock和 group descriptions，但不会改变inode table、bmap和imap(若真的改变，该分区数据就全丢了，还不如重新格式化)。在重建 superblock后，应该执行e2fsck来保证文件系统的一致性。但要注意，应该完全正确地指定block的大小，其改选项并不能完全保 证数据不丢失。-v ：输出详细执行过程 所以，有可能用到的选项也就”-t”指定文件系统类型，”-b”指定block大小，”-I”指定inode大小，”-i”指定分配inode的比例。 例如： 1234567891011121314151617181920212223shell&gt; mke2fs -t ext4 -I 256 /dev/sdb2 -b 4096mke2fs 1.41.12 (17-May-2010)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks655360 inodes, 2621440 blocks131072 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=268435456080 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632Writing inode tables: done Creating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: doneThis filesystem will be automatically checked every 39 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override. 提示使用tune2fs修改自动检测文件系统的频率。见下文。 tune2fs修改ext文件系统属性该工具其实没什么太大作用，文件系统创建好后很多属性是固定不能修改的，能修改的属性很有限，且都是无关紧要的。 但有些时候还是可以用到它做些事情，例如刚创建完ext文件系统后会提示修改自检时间。 1234tune2fs [ -c max-mount-counts ] [ -i interval-between-checks ] [ -j ] device-j：将ext2文件系统升级为ext3；-c：修改文件系统最多挂载多少次后进行自检，设置为0或-1将永不自检；-i：修改过了多少时间进行自检。时间单位可以指定为天(默认)/月/星期[d|m|w]，设置为0将永不自检。 例如：tune2fs -i 0 /dev/sdb15.5 查看文件系统状态信息 lsblklsblk(list block devices)用于列出设备及其状态，主要列出非空的存储设备。其实它只会列出/sys/dev/block中的主次设备号文件，且默认只列出非空设备。 1[root@server2 ~]# lsblk 其中上面的几列意义如下： NAME：设备名称；MAJ:MIN：主设备号和此设备号；RM：是否为可卸载设备，1表示可卸载设备。可卸载设备如光盘、USB等。并非能够umount的就是可卸载的；SIZE：设备总空间大小；RO：是否为只读；TYPE：是磁盘disk，还是分区part，亦或是rom，还有loop设备；mountpoint：挂载点。 123456789[root@server2 ~]# lsblk /dev/sdbNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsdb 8:16 0 20G 0 disk├─sdb1 8:17 0 9.5G 0 part /mydata/data└─sdb2 8:18 0 3G 0 part[root@server2 ~]# lsblk /dev/sdb1NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsdb1 8:17 0 9.5G 0 part /mydata/data 另外常用的一个选项是”-f”，它可以查看到文件系统类型，和文件系统的uuid和挂载点。 1234567891011[root@xuexi ~]# lsblk -fNAME FSTYPE LABEL UUID MOUNTPOINTsda ├─sda1 ext4 77b5f0da-b0f9-4054-9902-c6cdacf29f5e /boot├─sda2 ext4 f199fcb4-fb06-4bf5-a1b7-a15af0f7cb47 /└─sda3 swap 6ae3975c-1a2a-46e3-87f3-d5bd3f1eff48 [SWAP]sr0 sdb ├─sdb1 ext4 95e5b9d5-be78-43ed-a06a-97fd1de9a3fe├─sdb2 ext2 45da2d94-190a-4548-85bb-b3c46ae6d9a7└─sdb3 每个已经格式化的文件系统都有其类型和uuid，而没有格式化的设备(如/dev/sdb3)，将只显示一个Name结果，表示该设备还未进行格式化。 blkid虽然它有不少比较强大的功能，但一般只用它一个功能，就是查看器文件系统类型和uuid。 123456789[root@xuexi ~]# blkid/dev/sda1: UUID=&quot;77b5f0da-b0f9-4054-9902-c6cdacf29f5e&quot; TYPE=&quot;ext4&quot;/dev/sda2: UUID=&quot;f199fcb4-fb06-4bf5-a1b7-a15af0f7cb47&quot; TYPE=&quot;ext4&quot;/dev/sda3: UUID=&quot;6ae3975c-1a2a-46e3-87f3-d5bd3f1eff48&quot; TYPE=&quot;swap&quot;/dev/sdb1: UUID=&quot;95e5b9d5-be78-43ed-a06a-97fd1de9a3fe&quot; TYPE=&quot;ext4&quot;/dev/sdb2: UUID=&quot;45da2d94-190a-4548-85bb-b3c46ae6d9a7&quot; TYPE=&quot;ext2&quot;[root@xuexi ~]# blkid /dev/sdb1/dev/sdb1: UUID=&quot;95e5b9d5-be78-43ed-a06a-97fd1de9a3fe&quot; TYPE=&quot;ext4&quot; parted /dev/sda print和fdisk -l1234567891011121314151617181920212223shell&gt; parted /dev/sdb pModel: VMware, VMware Virtual S (scsi)Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 1049kB 10.2GB 10.2GB ext4 2 10.2GB 13.5GB 3221MB ext2 Linux filesystemshell&gt; fdisk -l /dev/sdaDisk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x000cb657 Device Boot Start End Blocks Id System/dev/sda1 * 2048 514047 256000 83 Linux/dev/sda2 514048 37847039 18666496 83 Linux/dev/sda3 37847040 41943039 2048000 82 Linux swap / Solaris 虽然fdisk和gdisk分别是mbr和gpt格式的专用工具，但是仅用于查看信息还是可以的。parted能兼容两者，所以也可以。 file -s12[root@xuexi ~]# file -s /dev/sdb2/dev/sdb2: Linux rev 1.0 ext2 filesystem data (large files) dudu命令用于评估文件的空间占用情况，它会统计每个文件的大小，统计时会递归统计目录中的文件，也就是说，它会遍历整个待统计目录，所以统计速度上可能并不理想。 123456789101112du [OPTION]... [FILE]...选项说明：-a, --all：列出目录中所有文件的统计信息，默认只会列出目录中子目录的统计信息，而不列出文件的统计信息-h, --human-readable：人性化显示大小-0, --null：以空字符结尾，即&quot;\\0&quot;而非换行的&quot;\\n&quot;-S, --separate-dirs：不包含子目录的大小-s, --summarize：对目录做总的统计，不列出目录内文件的大小信息-c,--total：对给出的文件或目录做总计。在统计非同一个目录文件大小时非常有用。见下文例子。--max-depth=N：只列出给定层次的目录统计，如果N=0，则等价于&quot;-s&quot;-x, --one-file-system：忽略不同文件系统上的文件，不对它们进行统计-X, --exclude-from=FILE：从文件中读取要排除的文件--exclude=PATTERN：指定要忽略不统计的文件 注意: (1).上面的选项中，有些是不列出某些项，有些是不统计某些项，它们是不一样的。 (2).如果要统计的目录下挂载了一个文件系统，那么这个文件系统的大小也会被计入该目录的大小中。 12[root@xuexi ~]# du -sh /etc29M /etc 12345678[root@xuexi ~]# du -ah /tmp4.0K /tmp/b.txt4.0K /tmp/a4.0K /tmp/.ICE-unix4.0K /tmp/testdir/subdir0 /tmp/testdir/a.log8.0K /tmp/testdir24K /tmp 12345678910111213[root@xuexi ~]# du -h --max-depth=1 /usr15M /usr/include383M /usr/lib64132K /usr/local391M /usr/share4.0K /usr/etc118M /usr/lib44M /usr/libexec49M /usr/src32M /usr/sbin4.0K /usr/games75M /usr/bin1.1G /usr 123456789101112[root@xuexi ~]# du -h --max-depth=1 --exclude=/usr/lib64 /usr15M /usr/include132K /usr/local391M /usr/share4.0K /usr/etc118M /usr/lib44M /usr/libexec49M /usr/src32M /usr/sbin4.0K /usr/games75M /usr/bin721M /usr 搜索符合条件的文件，然后统计它们的总大小。结合find使用，效果极佳。 12345678[root@xuexi ~]# find /boot/ -type f -name &quot;*.img&quot; -print0 | xargs -0 du -ch28K /boot/grub2/i386-pc/core.img4.0K /boot/grub2/i386-pc/boot.img592K /boot/initrd-plymouth.img44M /boot/initramfs-0-rescue-d13bce5e247540a5b5886f2bf8aabb35.img17M /boot/initramfs-3.10.0-327.el7.x86_64.img16M /boot/initramfs-3.10.0-327.el7.x86_64kdump.img76M total 请注意”-c”和”-s”统计的区别。 1234567[root@xuexi ~]# find /boot/ -type f -name &quot;*.img&quot; -print0 | xargs -0 du -sh28K /boot/grub2/i386-pc/core.img4.0K /boot/grub2/i386-pc/boot.img592K /boot/initrd-plymouth.img44M /boot/initramfs-0-rescue-d13bce5e247540a5b5886f2bf8aabb35.img17M /boot/initramfs-3.10.0-327.el7.x86_64.img16M /boot/initramfs-3.10.0-327.el7.x86_64kdump.img dfdf用于报告磁盘空间使用率，默认显示的大小是1K大小block数量，也就是以k为单位。 和du不同的是，df是读取每个文件系统的superblock信息，所以评估速度非常快。由于是读取superblock，所以如果目录下挂载了另一个文件系统，是不会将此挂载的文件系统计入目录大小的。注意，du和df统计的结果是不一样的，如果对它们的结果不同有兴趣，可参考我的另一篇文章：详细分析du和df的统计结果为什么不一样。 如果用df统计某个文件的空间使用情况，将会转而统计该文件所在文件系统的空间使用情况。 12345678df [OPTION]... [FILE]...选项说明：-h：人性化转换大小的显示单位-i：统计inode使用情况而非空间使用情况-l, --local：只列出本地文件系统的使用情况，不列出网络文件系统信息-T, --print-type：同时输出文件系统类型-t, --type=TYPE：只列出给定文件系统的统计信息-x, --exclude-type=TYPE：指定不显示的文件系统类型的统计信息 示例： 12345678910[root@server2 ~]# df -hTFilesystem Type Size Used Avail Use% Mounted on/dev/sda2 xfs 18G 2.3G 16G 13% /devtmpfs devtmpfs 904M 0 904M 0% /devtmpfs tmpfs 913M 0 913M 0% /dev/shmtmpfs tmpfs 913M 8.6M 904M 1% /runtmpfs tmpfs 913M 0 913M 0% /sys/fs/cgroup/dev/sda1 xfs 247M 110M 137M 45% /boottmpfs tmpfs 183M 0 183M 0% /run/user/0/dev/sdb1 ext4 9.3G 37M 8.8G 1% /mydata/data 12345678910[root@server2 ~]# df -iFilesystem Inodes IUsed IFree IUse% Mounted on/dev/sda2 18666496 106474 18560022 1% /devtmpfs 231218 388 230830 1% /devtmpfs 233586 1 233585 1% /dev/shmtmpfs 233586 479 233107 1% /runtmpfs 233586 13 233573 1% /sys/fs/cgroup/dev/sda1 256000 330 255670 1% /boottmpfs 233586 1 233585 1% /run/user/0/dev/sdb1 625856 14 625842 1% /mydata/data dumpe2fs用于查看ext类文件系统的superblock及块组信息。使用-h选项将只显示superblock信息。 以下是ext4文件系统superblock的信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@xuexi ~]# dumpe2fs -h /dev/sda2dumpe2fs 1.41.12 (17-May-2010)Filesystem volume name: &lt;none&gt;Last mounted on: /Filesystem UUID: f199fcb4-fb06-4bf5-a1b7-a15af0f7cb47Filesystem magic number: 0xEF53Filesystem revision #: 1 (dynamic)Filesystem featurs: has_journal ext_attr resize_inode dir_index filetype needs_recovery exent flex_bg sparse_super large_file huge_file uninit_bg dir_nlink extra_isizeFilesystem flags: signed_directory_hashDefault mount options: user_xattr aclFilesystem state: cleanErrors behavior: ContinueFilesystem OS type: LinuxInode count: 1166880Block count: 4666624Reserved block count: 233331Free blocks: 4196335Free inodes: 1111754First block: 0Block size: 4096Fragment size: 4096Reserved GDT blocks: 1022Blocks per group: 32768Fragments per group: 32768Inodes per group: 8160Inode blocks per group: 510Flex block group size: 16Filesystem created: Sat Feb 25 11:48:47 2017Last mount time: Tue Jun 6 18:13:10 2017Last write time: Sat Feb 25 11:53:49 2017Mount count: 6Maximum mount count: -1Last checked: Sat Feb 25 11:48:47 2017Check interval: 0 (&lt;none&gt;)Lifetime writes: 2657 MBReserved blocks uid: 0 (user root)Reserved blocks gid: 0 (group root)First inode: 11Inode size: 256Required extra isize: 28Desired extra isize: 28Journal inode: 8Default directory hash: half_md4Directory Hash Seed: d4e6493a-09ef-41a1-9d66-4020922f1aa9Journal backup: inode blocksJournal features: journal_incompat_revokeJournal size: 128MJournal length: 32768Journal sequence: 0x00001bd9Journal start: 23358 其中一个块组信息。 123456789[root@xuexi ~]# dumpe2fs /dev/sda2 | tail -7dumpe2fs 1.41.12 (17-May-2010)Group 142: (Blocks 4653056-4666623) [INODE_UNINIT, ITABLE_ZEROED] Checksum 0x64ce, unused inodes 8160 Block bitmap at 4194318 (+4294508558), Inode bitmap at 4194334 (+4294508574) Inode table at 4201476-4201985 (+4294515716) 13568 free blocks, 8160 free inodes, 0 directories, 8160 unused inodes Free blocks: 4653056-4666623 Free inodes: 1158721-1166880 挂载和卸载文件系统在此，只简单介绍mount和umount的用法，至于实现挂载和卸载的机制和原理细节，参看挂载文件系统的细节。 mountmount用来显示挂载信息或者进行文件系统挂载，它的功能及其的强大(强大到离谱)，它不仅支持挂载非常多种文件系统，如ext/xfs/nfs/smbfs/cifs (win上的共享目录)等，还支持共享挂载点、继承挂载点(父子关系)、绑定挂载点、移动挂载点等等功能。在本文只介绍其最简单的挂载功能。 不同的文件系统挂载选项是有所差别的，在挂载过程中如果出错，应该man mount并查看对应文件系统的挂载选项。 mount并非只能挂载文件系统，也可以将目录挂载到另一个目录下，其实它实现的是目录”硬链接”，默认情况下，是无法对目录建立硬链接的，但是通过mount可以完成绑定，绑定后两个目录的inode号是完全相同的，但尽管建立的是目录的”硬链接”，但其实也仅是拿来当软链接用。 以下是ext类文件系统的选项，可能有些选项是不支持其他文件系统的。 1234567891011121314151617181920212223242526mount # 将显示当前已挂载信息mount [-t 欲挂载文件系统类型 ] [-o 特殊选项] 设备名 挂载目录选项说明：-a 将/etc/fstab文件里指定的挂载选项重新挂载一遍。-t 支持ext2/ext3/ext4/vfat/fat/iso9660(光盘默认格式)。 不用-t时默认会调用blkid来获取文件系统类型。-n 不把挂载记录写在/etc/mtab文件中，一般挂载会在/proc/mounts中记录下挂载信息，然后同步到/etc/mtab，指定-n表示不同步该挂载信息。-o 指定挂载特殊选项。下面是两个比较常用的： loop 挂载镜像文件，如iso文件 ro 只读挂载 rw 读写挂载 auto 相当于mount -a dev 如果挂载的文件系统中有设备访问入口则启用它，使其可以作为设备访问入口 default rw,suid,dev,exec,auto,nouser,async,and relatime async 异步挂载，只写到内存 sync 同步挂载，通过挂载位置写入对方硬盘 atime 修改访问时间，每次访问都修改atime会导致性能降低，所以默认是noatime noatime 不修改访问时间，高并发时使用这个选项可以减少磁盘IO nodiratime 不修改文件夹访问时间，高并发时使用这个选项可以减少磁盘IO exec/noexec 挂载后的文件系统里的可执行程序是否可执行，默认是可以执行exec， 优先级高于权限的限定 remount 重新挂载，此时可以不用指定挂载点。 suid/nosuid 对挂载的文件系统启用或禁用suid，对于外来设备最好禁用suid _netdev 需要网络挂载时默认将停留在挂载界面直到加载网络了。使用_netdev可以忽略网络正常挂载。如NFS开机挂载。 user 允许普通用户进行挂载该目录，但只允许挂载者进行卸载该目录 users 允许所有用户挂载和卸载该目录 nouser 禁止普通用户挂载和卸载该目录，这是默认的，默认情况下一个目录不指定user/users时，将只有root能挂载 一般user/users/nouser都用在/etc/fstab中，直接在命令行下使用这几个选项意义不是很大。 例如：(1).挂载CentOS的安装镜像到/mnt。 1mount /dev/cdrom /mnt 其实/dev/cdrom是/dev/sr0的一个软链接，/dev/sr0是光驱设备，所以也可以用/dev/sr0进行挂载。 1mount /dev/sr0 /mnt (2).重新挂载。 1[root@xuexi ~]# mount -t ext4 -o remount /dev/sdb1 /data1 (3).重新挂载文件系统为可读写。 1mount -t ext4 -o rw remount /dev/sdb1 /data1 (4).挂载windows的共享目录。win上共享文件的文件系统是cifs类型，要在Linux上挂载，必须得有mount.cifs命令，如果没有则安装cifs-utils包。 假设win上共享目录的unc路径为\\192.168.100.8\\test，共享给的用户名和密码分别为long3:123，要挂在linux上的/mydata目录上。 1shell&gt; mount.cifs -o username=&quot;long3&quot;,password=&quot;123&quot; //192.168.100.8/test /mydata 注意，如果是比较新版本的win10(2017年之后更新的版本)或较新版本的win server，直接mount.cifs会报错： 123[root@xuexi ~]# mount.cifs -o username=&quot;long3&quot;,password=&quot;123&quot; //192.168.100.8/test /mnt mount error(112): Host is downRefer to the mount.cifs(8) manual page (e.g. man mount.cifs) 这是因为2017年微软的一个补丁禁用了SMBv1协议，通过smbclient的报告可知： 1234[root@xuexi ~]# yum -y install samba-client[root@xuexi ~]# smbclient -L //192.168.100.8Enter root&apos;s password: protocol negotiation failed: NT_STATUS_CONNECTION_RESET 因此，在mount的时候指定cifs(SMB)的版本号为2.0即可。 1[root@xuexi ~]# mount.cifs -o username=&quot;long3&quot;,password=&quot;123&quot;,vers=2.0 //192.168.100.8/test /mnt 但是需要注意，在CentOS 4,5,6下的模块cifs.ko版本(较低)只能使用SMBv1协议，因此即使指定版本号也一样无效。只有在CentOS 7上才能使用SMBv2或SMBv3。 (5).基于ssh挂载远程目录。如何基于ssh像NFS一样挂载远程主机上的目录？可以通过sshfs工具，该工具在fuse-sshfs包中，这个包在epel源中提供。 1yum -y install fuse-sshfs 例如，挂载192.168.100.8上的根目录到本地的/mnt上。 1sshfs 192.168.100.8:/ /mnt 卸载时直接umount即可。 (6).挂载目录到另一个目录下。挂载目录时，挂载目录和挂载点的inode是相同的，它们两者的内容也是完全相同的。 1mount --bind /mydata /mnt (7).查看某个目录是否是挂载点，使用mountpoint命令。 1234567891011[root@xuexi ~]# mountpoint /mydata//mydata/ is a mountpoint[root@xuexi ~]# echo $? 0[root@xuexi ~]# mountpoint /mnt/mnt is not a mountpoint[root@xuexi ~]# echo $? 1 挂载的参数信息存放在/proc/mounts(是/proc/self/mounts的软链接)中，在/proc/self/mountstats和/proc/mountinfo里则记录了更详细的挂载信息。 1234567891011[root@xuexi ~]# cat /proc/mountsrootfs / rootfs rw 0 0proc /proc proc rw,relatime 0 0sysfs /sys sysfs rw,relatime 0 0devtmpfs /dev devtmpfs rw,relatime,size=491000k,nr_inodes=122750,mode=755 0 0devpts /dev/pts devpts rw,relatime,gid=5,mode=620,ptmxmode=000 0 0tmpfs /dev/shm tmpfs rw,relatime 0 0/dev/sda2 / ext4 rw,relatime,barrier=1,data=ordered 0 0/proc/bus/usb /proc/bus/usb usbfs rw,relatime 0 0/dev/sda1 /boot ext4 rw,relatime,barrier=1,data=ordered 0 0none /proc/sys/fs/binfmt_misc binfmt_misc rw,relatime 0 0 文件系统是需要驱动支持的，没有驱动的文件系统也无法挂载，Linux中支持的文件系统驱动在/lib/modules/$(uname -r)/kernel/fs下。 123[root@xuexi ~]# ls /lib/modules/$(uname -r)/kernel/fs/autofs4 cachefiles configfs dlm exportfs ext3 fat fuse jbd jffs2 mbcache.ko nfs_common nls ubifs xfsbtrfs cifs cramfs ecryptfs ext2 ext4 fscache gfs2 jbd2 lockd nfs nfsd squashfs udf 直接挂载镜像文件有时候需要挂载CentOS的镜像文件，在虚拟机中经常是将镜像放入虚拟机的CD/DVD虚拟光驱中，然后在Linux上对/dev/cdrom进行挂载。其实/dev/cdrom是/dev/sr0的一个软链接，/dev/sr0是Linux中的光驱，所以上面的过程相当于是将镜像文件通过虚拟软件的虚拟光驱和linux的光驱连接起来，这样只需要挂载Linux中的光驱就可以了。但是，在非虚拟环境中没有虚拟光驱，而且在Linux中的一个镜像文件难道一定要拷贝到主机上通过虚拟光驱进行连接吗？ mount是一个极其强大的挂载工具，它支持挂载很多种文件类型，其中就支持挂载镜像文件，其实它连挂载目录都支持。 12345678910mount -o loop CentOS-6.6-x86_64-bin-DVD2.iso /mnt[root@xuexi ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTloop0 7:0 0 1.2G 0 loop /mntsda 8:0 0 20G 0 disk├─sda1 8:1 0 250M 0 part /boot├─sda2 8:2 0 17.8G 0 part /└─sda3 8:3 0 2G 0 part [SWAP]sr0 11:0 1 1024M 0 rom umount12umount 设备名或挂载目录umount -lf 强制卸载 卸载时，既可以使用设备名也可以使用挂载点卸载。有时候挂载网络系统(如NFS)时，设备名很长，这时候可以使用挂载点来卸载就方便多了。 如果用户正在访问某个目录或文件，使得卸载一直显示Busy，使用fuser -v DIR可以知道谁正在访问该目录或文件。 123[root@xuexi ~]# fuser -v /root USER PID ACCESS COMMAND/root: root 37453 ..c.. bash 使用-k选项kill掉正在使用目录或文件的进程，使用-km选项kill掉文件系统上的所有进程，然后再umount。 1[root@xuexi ~]# fuser -km /mnt/cdrom;umount /mnt/cdrom 开机自动挂载/etc/fstab通过将挂载选项写入到/etc/fstab中，系统会自动挂载该文件中的配置项。但要注意，该文件在开机的前几个过程中就被读取，所以配置错误很可能会导致开机失败。其中最后两列，它们分别表示备份文件系统和开机自检，一般都可以设置为0。 由于能用的备份工具众多，没人会在这里设置备份，所以备份列设置为0。 最后一列是开机自检设置列，开机自检调用的是fsck程序，所有有些ext类文件系统作为”/“时，可能会设置为1，但是fsck是不支持xfs文件系统的，所以对于xfs文件系统而言，该项必须设置为0。其实无需考虑那么多，直接将这两列设置为0就可以了。 修复错误的/etc/fstab万一/etc/fstab配置错误，导致开机无法加载。这时提示输入root密码进入单人维护模式，只不过担任模式下根文件系统是只读的，哪怕是root也无法直接修改/etc/fstab，所以应该将”/“文件系统进行重新挂载。 执行下面的命令，重挂载根分区，并给读写权限，再去修改错误的fstab文件记录，再重启。 1[root@xuexi ~]# mount -n -o remount,rw / 按需自动挂载(autofs)使用autofs实现需要挂载时就挂载，不需要挂载时5分钟后自动卸载。但是在实际环境中基本不会使用按需挂载。 autofs是一个服务程序，需要让其运行在后台，可以用来挂NFS，也可挂本地的文件系统。 默认不装autofs，需要自己装。 1[root@xuexi ~]# yum install -y autofs autofs实现按需挂载的方式是指定监控目录，可在其配置文件/etc/auto.master中指定。 /etc/auto.master里面只有两列：第一列是监控目录；第二列是记录挂载选项的文件，该文件可以随便取名。 12[root@xuexi ~]# cat /etc/auto.master/share /etc/auto.mount # 监控/share目录，使用/etc/auto.nfs记录挂载选项 上述监控的/share目录，其实这是监控的父目录，在此目录下的目录如/share/data目录可以作为挂载点，当访问到/share/data时就被监控到，然后会按照挂载选项将挂载设备挂载到/share/data上。 上述配置中配置的挂载选项文件是/etc/auto.mount，所以建立此文件，写入挂载选项。 1234567891011[root@xuexi ~]# cat /etc/auto.mount#cd -fstype=iso9660,ro,nosuid,nodev :/dev/cdrom# the following entries are samples to pique your imagination#linux -ro,soft,intr ftp.example.org:/pub/linux#boot -fstype=ext2 :/dev/hda1#floppy -fstype=auto :/dev/fd0#floppy -fstype=ext2 :/dev/fd0#e2floppy -fstype=ext2 :/dev/fd0#jaz -fstype=ext2 :/dev/sdc1#removable -fstype=ext2 :/dev/hdd 该文件有3列： 第一列指定的是在/etc/auto.master指定的/share下的目录/share/data，它是真正的被监控路径，也是挂载点。可使用相对路径data表示/share/data。 第二列是mount的选项，前面使用一个”-“表示，该列可有可无。 第三列是待挂载设备，可以是NFS服务端的共享目录，也可以本地设备。 12[root@xuexi ~]# vim /etc/auto.mountdata -rw,bg,soft,rsize=32768,wsize=32768 192.168.100.61:/data 上面的配置表示当访问到/share/data时，自动使用参数(rw,bg,soft,rsize=32768,wsize=32768)挂载远端192.168.100.61的/data目录到/share/data上。 剩下的步骤就是启动autofs服务。 1[root@xuexi data]# /etc/init.d/autofs restart swap分区虽说个人电脑上基本已经无需设置swap分区了，但是在服务器上还是应该准备swap分区，以做到有备无患和防止众多”玄学”问题。 查看swap使用情况1234567891011[root@xuexi ~]# free total used free shared buffers cachedMem: 1906488 349376 1557112 200 16920 200200-/+ buffers/cache: 132256 1774232Swap: 2097148 0 2097148[root@xuexi ~]# free -m # 以MB显示 total used free shared buffers cachedMem: 1861 341 1520 0 16 195-/+ buffers/cache: 129 1732 # 这个是真正的可用内存空间Swap: 2047 0 2047 # 这个是swap空间，发现一点都没被用 使用mount/lsblk等可以查看出哪个分区在充当swap分区。使用swapon -s也可以直接查看出。 123[root@server2 ~]# swapon -sFilename Type Size Used Priority/dev/sda3 partition 2047996 37064 -1 添加swap分区(1).可以新分一个区，在分区时指定其分区的ID号为SWAP类型。 mbr和gpt格式的磁盘上这个ID可能不太一样，不过一般gpt中的格式是在mbr格式的ID后加上两位数的数值，如mbr中swap的类型ID为82，在gpt中则是8200，在mbr中linux filesystem类型的ID为83，在gpt中则为8300，在mbr中lvm的ID为8e，在gpt中为8e00。 (2).格式化为swap分区：mkswap 123[root@xuexi ~]# mkswap /dev/sdb5Setting up swapspace version 1, size = 1951096 KiBno label, UUID=02e5af44-2a16-479d-b689-4e100af6adf5 (3).加入swap分区空间(swapon)： 1234567[root@xuexi ~]# swapon /dev/sdb5 [root@xuexi ~]# free -m total used free shared buffers cachedMem: 1861 343 1517 0 16 196-/+ buffers/cache: 131 1730Swap: 3953 0 3953 (4).取消swap分区空间(swapoff)： 1234567[root@xuexi ~]# swapoff /dev/sdb5[root@xuexi ~]# free -m total used free shared buffers cachedMem: 1861 343 1518 0 16 196-/+ buffers/cache: 130 1731Swap: 0 0 0 (5).开机自动加载swap分区：修改/etc/fstab，加上一行。 1/dev/sda3 swap swap defaults 0 0","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"DHCP服务","slug":"DHCP 服务","date":"2017-04-09T16:00:00.000Z","updated":"2018-06-15T14:41:09.146Z","comments":true,"path":"2017/04/10/DHCP 服务/","link":"","permalink":"http://yoursite.com/2017/04/10/DHCP 服务/","excerpt":"DHCP前身是BOOTP，在Linux的网卡配置中也能看到显示的是BOOTP，DHCP引进一个bootp没有的概念：租约。bootp分配的地址是永久的，而dhcp分配的地址是可以有期限的 。12[root@xuexi vsftpd]# grep -i bootproto /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=dhcp DHCP可以自动分配IP、子网掩码、网关、DNS。DHCP客户端使用的端口68，服务端使用端口67，使用的UDP应用层的协议。","text":"DHCP前身是BOOTP，在Linux的网卡配置中也能看到显示的是BOOTP，DHCP引进一个bootp没有的概念：租约。bootp分配的地址是永久的，而dhcp分配的地址是可以有期限的 。12[root@xuexi vsftpd]# grep -i bootproto /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=dhcp DHCP可以自动分配IP、子网掩码、网关、DNS。DHCP客户端使用的端口68，服务端使用端口67，使用的UDP应用层的协议。DHCP一般不为服务器分配IP，因为他们要使用固定IP，所以DHCP一般只为办公环境的主机分配IP。 DHCP服务器和客户端需要在一个局域网内，在为客户端分配IP的时候需要进行多次广播。但DHCP也可以为其他网段内主机分配IP，只要连接两个网段中间的路由器能转发DHCP配置请求即可，但这要求路由器配置中继功能。 DHCP客户端请求过程（4步请求过程）1）搜索阶段：客户端广播方式发送报文，搜索DHCP服务器。此时网段内所有机器都收到报文，只有DHCP服务器返回消息。2）提供阶段：众多DHCP服务器返回报文信息，并从地址池找一个IP提供给客户端。因为此时客户端还没有IP，所以返回信息也是以广播的方式返回的。3）选择阶段：选择一个DHCP服务器，使用它提供的IP。然后发送广播包，告诉众多DHCP服务器，其已经选好DHCP服务器以及IP地址。此后没有入选的DHCP就可以将原本想分配的IP分配给其他主机. 客户端选择第一个接收到的IP。谁的IP先到客户端的速度是不可控的。但是如果在配置文件里开启了authoritative选项则表示该服务器是权威服务器，其他DHCP服务器将失效，如果多台服务器都配置了这个权威选项，则还是竞争机制；通过MAC地址给客户端配置固定IP也会优先于普通的动态DHCP分配。另外Windows的DHCP服务端回应Windows客户端比Linux更快。4）确认阶段：DHCP服务器收到回应，向客户端发送一个包含IP的数据包，确认租约，并指定租约时长。如果DHCP服务器要跨网段提供服务，一样是四步请求，只不过是每一步中间都多了一个路由器和DHCP服务器之间的单播通信。 1） 客户端广播方式发送报文，搜索DHCP服务器。所有机器包括路由器都收到报文，路由器配置了中继，知道搜索消息后单播给DHCP服务器；2）DHCP服务器单播返回信息给路由器，路由器再广播给客户端；3）客户端选择DHCP服务器提供的IP，并广播信息告诉它我选好了，路由器单播给DHCP服务器；4）DHCP服务器收到信息将确认信息单播给路由器，路由器单播给客户端。 所以DHCP的4步请求： 12Client--&gt; DHCPDISCOVER # 广播：客户端发现DHCP服务器 DHCPOFFER &lt;-- Server # 广播：服务端提供IP给客户端 12client--&gt; DCHPREQUEST # 广播：客户端请求使用提供的IP DCHPACK &lt;-- Server # 单播：服务端进行确认，订立租约等信息 续租的过程：12client--&gt; DHCPREQUEST # 单播：继续请求使用提供的IP DHCPACK &lt;-- Server # 单播：确认续租 HCP服务器不跨网段提供服务时，它自己的IP地址必须要和地址池中全部IP在同一网络中。DHCP服务器跨网段提供服务时，它自己的IP地址必须要和地址池中的一部分IP在同一网络中，另一部分提供给其他网段。因为如果自己的IP完全不在自己的网络中而只提供其他网段的IP，更好的做法是将DHCP服务器设在那个需要DHCP服务的网络中。当计算机从一个子网移到另一个子网，找的DHCP服务器不同，因为旧的租约还存在，会先续租，新的DHCP服务器肯定拒绝它的续租请求，这时将重新开始四步请求。有些机器希望一直使用一个固定的IP，也就是静态IP，除了手动进行配置，DHCP服务器也可以实现这个功能。DHCP服务器可以根据MAC地址来分配这台机器固定IP地址（保留地址），即使重启或重装了系统也不会改变根据MAC地址分配的地址。假如在一个正常联网有DHCP服务器的网段内因为做实验练习的缘故新建立了一台DHCP服务器，但是这台DHCP服务器不能上网，会导致什么后果？使用DHCP分配地址的客户端至少会有续租的请求，如果没有续租成功，或者有新的计算机加入这个网络，那么进行四步请求，有可能会请求到这个不能连网的DHCP服务器上，那么他也就不能上网了。特别是Windows的DHCP服务端回应Windows客户端速度比Linux回应快。安装和配置DHCP服务123456789[root@xuexi ~]# yum -y install dhcp[root@xuexi ~]# rpm -ql dhcp/etc/dhcp/dhcpd.conf # DHCP配置文件/etc/sysconfig/dhcpd/usr/sbin/dhcpd # DHCP服务程序/usr/sbin/dhcrelay # 中继命令程序，用于跨网段提供DHCP服务/var/lib/dhcpd/dhcpd.leases # 存放租借信息（如IP）和租约信息（如租约时长）/usr/share/doc/dhcp-4.1.1/dhcpd.conf.sample # 配置文件的范例文件 123可以将dhcpd.conf.sample复制到/etc/。 [root@xuexi ~]# cp /usr/share/dhcp-4.1.1/dhcpd.conf.sample /etc/dhcpd.conf 以下是dhcpd.conf中部分配置项。123456789101112131415161718192021# 每行分号结束ddns-update-style none; # 动态dns相关，几乎不开启它。也就是不管它。ignore client-updates; # 和上面的相关，也不管它authoritative # 声明为权威服务器next-server marvin.redhat.com; # PXE环境下指定的提供引导程序的文件服务器# DHCP配置文件里必须配置一个地址池，其和DHCP服务器自身IP在同一网段subnet 10.5.5.0 netmask 255.255.255.224 &#123; range 10.5.5.26 10.5.5.30; # 地址池 option domain-name-servers ns1.internal.example.org; # 为客户端指明DNS服务器地址，可以是多个，最多三个 option domain-name &quot;internal.example.org&quot;; # 为客户端指明DNS名字，定义了它会覆盖客户端/etc/resolv.conf里的配置 option routers 10.5.5.1; # 默认路由，其实就是网关 option broadcast-address 10.5.5.31; # 广播地址，不设置时默认会根据A/B/C类地址自动计算 default-lease-time 600; # 默认租约时长 max-lease-time 7200; # 最大租约时长&#125;#下面的是绑定MAC地址设置保留地址，保留地址不能是地址池中的地址host fantasia &#123; # 固定地址的配置，host后面的是标识符，没意义hardware ethernet 08:00:07:26:c0:a5; fixed-address 192.168.100.3; # 根据MAC地址分配的固定IP &#125; 如果不让dhcp修改/etc/resolv.conf里的内容，就在网卡配置文件/etc/sysconfig/network-scripts/ifcfg-ethX里添加一行选项：PEERDNS=no。在客户端如何获取动态分配的地址呢？方法一：service network restart但是每次重启网络很麻烦，可以使用客户端命令dhclient。方法二：直接执行dhclient命令这种方法下会显示4部请求中需要显示的步骤信息，以及最终分配的地址，所以是一个很好的理解dhcp工作的工具。但是这种方法只能使用一次，第二次执行命令会提示该进程已经在执行，因为dhclient是一个进程。可以kill掉该进程再执行dhclient，或者使用dhclient -d选项。方法三：dhclient -d如何重新获取IP地址每次重启网卡默认都获取的同一个ip，有时候想换个ip都很麻烦。在/var/lib/dhclient/目录下有”.leases”文件，将它们清空或者删除这些文件中对应网卡的部分，再重启网络就可以获取新的动态ip。12345678910111213141516[root@xuexi ~]# cat /var/lib/dhclient/dhclient-eth0.leases lease &#123; interface &quot;eth0&quot;; fixed-address 192.168.100.16; option subnet-mask 255.255.255.0; option routers 192.168.100.2; option dhcp-lease-time 1800; option dhcp-message-type 5; option domain-name-servers 192.168.100.2; option dhcp-server-identifier 192.168.100.254; option broadcast-address 192.168.100.255; option domain-name &quot;localdomain&quot;; renew 3 2017/02/15 12:28:27; rebind 3 2017/02/15 12:42:39; expire 3 2017/02/15 12:46:24;&#125; 或者，在/etc/sysconfig/network-scripts/ifcfg-eth0加入”DHCPRELEASE=yes”。当运行ifdown eth0的时候就会发出dhcprelase报文，查看/etc/sysconfig/network-scripts/ifdown-eth脚本中实际上是调用dhclient命令，用下面这个命令应该也可以。1/sbin/dhclient -r eth0","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"DHCP","slug":"DHCP","permalink":"http://yoursite.com/tags/DHCP/"}]},{"title":"Linux系统中su 和 sudo 的用法","slug":"Linux系统中su 和 sudo 的用法","date":"2017-03-31T16:00:00.000Z","updated":"2018-06-22T02:50:25.947Z","comments":true,"path":"2017/04/01/Linux系统中su 和 sudo 的用法/","link":"","permalink":"http://yoursite.com/2017/04/01/Linux系统中su 和 sudo 的用法/","excerpt":"su切换用户或以指定用户运行命令。 使用su可以指定运行命令的身份(user/group/uid/gid)。 12345678910111213141516171819为了向后兼容，su默认不会改变当前目录，且仅设置HOME和SHELL这两个环境变量(若目标用户非root，则还设置USER和LOGNAME环境变量)。推荐使用--login选项(即&quot;-&quot;选项)避免环境变量混乱。 su [options...] [-] [user [args...]]选项说明：-c command：使用-c选项传递要指定的命令到shell上执行。使用-c执行命令会为每个su都分配新的会话环境-, -l, --login：启动shell作为登录的shell，模拟真正的登录环境。它会做下面几件事： 1.清除除了TERM外的所有环境变量 2.初始化HOME,SHELL,USER,LOGNAME,PATH环境变量 3.进入目标用户的家目录 4.设置argv[0]为&quot;-&quot;以便设置shell作为登录的shell 使用--login的su是交互式登录。不使用--login的su是非交互式登录(除不带任何参数的su外-m, -p, --preserve-environment：保留整个环境变量(不会重新设置HOME,SHELL,USER和LOGNAME)， 保留环境的方法是新用户shell上执行原用户的各配置文件，如~/.bashrc。 当设置了--login时，将忽略该选项-s SHELL：运行指定的shell而非默认shell，选择shell的顺序优先级如下： 1.--shell指定的shell 2.如果使用了--preserve-environment，选择SHELL环境变量的shell 3.选项目标用户在passwd文件中指定的shell 4./bin/sh","text":"su切换用户或以指定用户运行命令。 使用su可以指定运行命令的身份(user/group/uid/gid)。 12345678910111213141516171819为了向后兼容，su默认不会改变当前目录，且仅设置HOME和SHELL这两个环境变量(若目标用户非root，则还设置USER和LOGNAME环境变量)。推荐使用--login选项(即&quot;-&quot;选项)避免环境变量混乱。 su [options...] [-] [user [args...]]选项说明：-c command：使用-c选项传递要指定的命令到shell上执行。使用-c执行命令会为每个su都分配新的会话环境-, -l, --login：启动shell作为登录的shell，模拟真正的登录环境。它会做下面几件事： 1.清除除了TERM外的所有环境变量 2.初始化HOME,SHELL,USER,LOGNAME,PATH环境变量 3.进入目标用户的家目录 4.设置argv[0]为&quot;-&quot;以便设置shell作为登录的shell 使用--login的su是交互式登录。不使用--login的su是非交互式登录(除不带任何参数的su外-m, -p, --preserve-environment：保留整个环境变量(不会重新设置HOME,SHELL,USER和LOGNAME)， 保留环境的方法是新用户shell上执行原用户的各配置文件，如~/.bashrc。 当设置了--login时，将忽略该选项-s SHELL：运行指定的shell而非默认shell，选择shell的顺序优先级如下： 1.--shell指定的shell 2.如果使用了--preserve-environment，选择SHELL环境变量的shell 3.选项目标用户在passwd文件中指定的shell 4./bin/sh 注意：(1). 若su没有给定任何参数，将默认以root身份运行交互式的shell(交互式，所以需要输入密码)，即切换到root用户，但只改变HOME和SHELL环境变量。 (2). su - username是交互式登录，要求密码，会重置整个环境变量，它实际上是在模拟真实的登录环境。 (3). su username是非交互登录，不会重置除HOME/SHELL外的环境变量。例如：用户wangwu家目录为/home/wangwu，其shell为/bin/csh。 123shell&gt; head -1 /etc/passwd ; tail -1 /etc/passwdroot:x:0:0:root:/root:/bin/bashwangwu:x:2002:2002::/home/wangwu:/bin/csh 首先su到wangwu上，再执行一个完全不带参数的su。 123456789shell&gt; su - wangwu # 使用su - username后，以登录shell的方式模拟登录，会重新设置各环境变量。su - username是交互式登录shell&gt; env | egrep -i &apos;^home|^shell|^path|^logname|^user&apos;HOME=/home/wangwuSHELL=/bin/cshUSER=wangwuLOGNAME=wangwuPATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbinPWD=/home/wangwu 123456789shell&gt; su # 不带任何参数的su，是交互式登录切换回root，但只会改变HOME和SHELL环境变量 shell&gt; env | egrep -i &apos;^home|^shell|^path|^logname|^user|^pwd&apos;SHELL=/bin/bashUSER=wangwuPATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbinPWD=/home/wangwuHOME=/rootLOGNAME=wangwu 12345678910shell&gt; su - # su - 的方式切换回rootPassword:shell&gt; env | egrep -i &apos;^home|^shell|^path|^logname|^user|^pwd&apos;SHELL=/bin/bashUSER=rootPATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binPWD=/rootHOME=/rootLOGNAME=root 12345678shell&gt; su wangwu # 再直接su username，它只会重置SHELL和HOME两个环境变量，其他环境变量保持不变shell&gt; env | egrep -i &apos;^home|^shell|^path|^logname|^user|^pwd&apos;SHELL=/bin/cshUSER=wangwuPATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binPWD=/rootHOME=/home/wangwuLOGNAME=wangwu 在某些环境下或脚本中，可能需要临时切换身份执行命令，注意这时候的环境变量是否会改变，否则很可能报错提示命令找不到。 sudosudo可以让一个用户以某个身份(如root或其他用户)执行某些命令，它隐含的执行方式是切换到指定用户再执行命令，因为涉及到了用户的切换，所以环境变量是否重置是需要设置的。 sudo支持插件实现安全策略。默认的安全策略插件是sudoers，它是通过/etc/sudoers或LDAP来配置的。 安全策略是控制用户使用sudo命令时具有什么权限，但要注意，安全策略可能需要用户进行身份认证，如密码认证的机制或其他认证机制，如果开启了认证要求，则在指定时间内未完成认证时sudo会退出，默认超时时间为5分钟。 安全策略支持对认证进行缓存，使得在一定时间内该用户无需再次认证就可以执行sudo命令，默认缓存时间为5分钟，sudo -v可以更新认证缓存。 sudo支持日志审核，可以记录下成功或失败的sudo。 /etc/sudoers文件该文件里主要配置sudo命令时指定的用户和对应的权限。 123456789101112131415161718shell&gt; visudo # 以下选取的是部分行## hostname or IP addresses instead. # 主机别名Host_Alias# Host_Alias FILESERVERS = fs1, fs2# Host_Alias MAILSERVERS = smtp, smtp2## User Aliases # 用户别名User_Alias# User_Alias ADMINS = jsmith, mikem## Command Aliases # 命令别名# Cmnd_Alias SERVICES = /sbin/service, /sbin/chkconfig# Cmnd_Alias LOCATE = /usr/bin/updatedb root ALL=(ALL) ALL # sudo权限的配置# %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS## Allows people in group wheel to run all commands# %wheel ALL=(ALL) ALL## Same thing without a password# %wheel ALL=(ALL) NOPASSWD: ALL 在这个文件里，主要有别名(用户别名，主机别名，命令别名)的配置和sudo权限的配置。 安全策略配置格式为： 12用户名 主机名=(可切换到的用户身份) 权限和命令① ② ③ ④ ①用户名：可以用组，只需在组名前加个百分号%表示。②主机名：表示该用户可以在哪些主机上运行sudo，可以用hostname也可以用ip指定。③可切换的用户身份，即指定执行命令的用户，也可以用组。④权限和命令：允许执行和不允许执行的命令(多个命令间用逗号分隔)和特殊权限，命令可以带其选项及参数。命令要写绝对路径。不允许执行的命令需要在命令前加上”!”来表示。可以使用标签，如NOPASSWD标签表示切换或以指定用户执行该标签后的命令时不需要输入密码。一行写不下时可使用”\\”续行。 标签使用方法：NOPASSWD:/usr/sbin/useradd,PASSWD:/usr/sbin/userdel 它表示useradd命令不需要输入密码，而userdel需要输入密码。对于别名，相当于用户对于用户组。权限配置处都可以使用别名，即①②③④处都能使用别名来配置。例如，主机别名里设置多个主机，以后在②位置处直接使用主机别名。 1FILESERVERS = fs1, fs2 以下是某设置示例：123DEFAULT=/bin/*,/sbin/ldconfig,/sbin/ifconfig,/usr/sbin/useradd,/usr/sbin/userdel,/bin/rpm,/usr/bin/yum,/sbin/service,/sbin/chkconfig,sudoedit /etc/rc.local,sudoedit /etc/hosts,sudoedit /etc/ld.so.conf,/bin/mount,sudoedit /etc/exports,/usr/bin/passwd [!-]*,!/usr/bin/passwd root,/bin/su - [!-]*,!/bin/su - root,!/bin/su root, /bin/bash, /usr/sbin/dmidecode, /usr/sbin/lsof, /usr/bin/du, /usr/bin/python, /usr/sbin/xm,sudoedit /etc/profile,sudoedit /etc/bashrc,/usr/bin/make,sudoedit /etc/security/limits.conf,/etc/init.d/*,/usr/bin/rubyABC ALL=(ALL)NOPASSWD:DEFAULT 其中上面的”/usr/bin/passwd [!-]“表示允许修改加参数的密码。”/bin/su - [!-]“表示允许”su -“到某用户下，但必须给参数。 sudo和sudoedit命令当sudo执行指定的command时，它会调用fork函数，并设置命令的执行环境(如某些环境变量)，然后在子进程中执行command，sudo的主进程等待命令执行完毕，然后传递命令的退出状态码给安全策略并退出。 sudoedit等价于sudo -e，它是以sudo的方式执行文件编辑动作。 1234567891011121314151617181920212223sudo [options] [command]选项说明：-b ：(background)该选项告诉sudo在后台执行指定的命令。 注意，如果使用该选项，将无法使用任务计划(job)来控制维护这些后台进程， 需要交互的命令应该考虑是否真的要后台，因为可能会失败-l[l] [command]：当单独使用-l选项时，将列出(list)用户可执行和被禁止的命令。 当配合command时，且该command是被允许执行的命令，将列出命令的全路径及该命令参数。 如果command是不被允许执行的，则sudo直接以状态码-1退出。 可以指定多个字母&quot;l&quot;来显示更详细的格式-n ：使得sudo变成非交互模式，但如果安全策略是要求输入密码的，则sudo将报错-S ：(stdin)该选项使得sudo从标准输入而非终端设备上读取密码，给定的密码必须在尾部加上换行符-s [command] ：(shell)指定要切换到的shell，如果给定command，则在此shell上执行该命令-U user ：(other user)配合-l选项来指定要列出哪个用户的权限信息-u user ：(user)该选项明确指定要以此处指定的用户而非root来运行command。 若使用uid的方式指定用户，则需要使用&quot;#uid&quot;，但很多时候可能需要对&quot;#&quot;使用&quot;\\&quot;转义，即使用&quot;\\#uid&quot;-E ：(environment)该选项告诉sudo在执行命令时保留自己的环境变量，保留环境变量的方式是执行环境配置文件。 但因为跨了用户，所以很可能某些家目录下的环境配置文件会因为无权限而执行失败，此时sudo将报错 -k [command] ：当单独使用-k选项时，sudo将使得用户的认证缓存失效。下次执行sudo命令需要输入密码。 当配合command时，-k选项将忽略用户的缓存，所以sudo将要求用户输入密码，但这次输入密码不会更新认证缓存 但执行-k选项本身，不需要密码-K ：(sure kill)类似于-k选项，但它会完全移除用户的认证缓存，且不会配合command，执行-K本身不需要密码-v ：(validate)该选项使得sudo更新用户认证缓存-- ：暗示sudo命令行参数到此结束 在sudo上可以直接设置环境变量，它会传递为command的环境。设置的方式为var=value，如LD_LIBRARY_PATH=/usr/local/pkg/lib 由于sudo默认的安全策略插件是sudoers，所以当用户执行sudo时，系统会自动去寻找/etc/sudoers文件(该文件里被root配置了用户对应的权限，也即安全策略)，查看sudo要使用的用户是否有对应的权限，如果有则执行，如果没有权限就失败退出sudo。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"su和sudo","slug":"su和sudo","permalink":"http://yoursite.com/tags/su和sudo/"}]},{"title":"Linux 文件权限管理","slug":"Linux 文件权限管理","date":"2017-03-11T16:00:00.000Z","updated":"2018-06-20T11:35:33.056Z","comments":true,"path":"2017/03/12/Linux 文件权限管理/","link":"","permalink":"http://yoursite.com/2017/03/12/Linux 文件权限管理/","excerpt":"文件/目录的权限文件的权限每个文件都有其所有者(u:user)、所属组(g:group)和其他人(o:other)对它的操作权限，a:all则同时代表这3者。权限包括读(r:read)、写(w:write)、执行(x:execute)。在不同类型的文件上读、写、执行权限的体现有所不同，所以目录权限和普通文件权限要区分开来。在普通文件上： r：可读，可以使用类似cat等命令查看文件内容；读是文件的最基本权限，没有读权限，普通文件的一切操作行为都被限制。","text":"文件/目录的权限文件的权限每个文件都有其所有者(u:user)、所属组(g:group)和其他人(o:other)对它的操作权限，a:all则同时代表这3者。权限包括读(r:read)、写(w:write)、执行(x:execute)。在不同类型的文件上读、写、执行权限的体现有所不同，所以目录权限和普通文件权限要区分开来。在普通文件上： r：可读，可以使用类似cat等命令查看文件内容；读是文件的最基本权限，没有读权限，普通文件的一切操作行为都被限制。w：可写，可以编辑此文件； x：可执行，表示文件可由特定的解释器解释并运行。可以理解为windows中的可执行程序或批处理脚本，双击就能运行起来的文件。 #####在目录上： r：可以对目录执行ls以列出目录内的所有文件；读是文件的最基本权限，没有读权限，目录的一切操作行为都被限制。 w：可以在此目录创建或删除文件/子目录； x：可进入此目录，可使用ls -l查看文件的详细信息。可以理解为windows中双击就进入目录的动作。 如果目录没有x权限，其他人将无法查看目录内文件属性(只能查看到文件类型和文件名，至于为什么，见后文)，所以一般目录都要有x权限。而如果只有执行却没有读权限，则权限拒绝。一般来说，普通文件的默认权限是644(没有执行权限)，目录的默认权限是755(必须有执行权限，否则进不去)，链接文件的权限是777。当然，默认文件的权限设置方法是可以通过umask值来改变的。 权限的表示方式权限的模式有两种体现：数字体现方式和字符体现方式。 权限的数字表示：”-“代表没有权限,用0表示。 123r-----4 w-----2 x-----1 例如：rwx rw- r–对应的数字权限是764，732代表的权限数值表示为rwx -wx -w-。 chmod修改权限能够修改权限的人只有文件所有者和超级管理员。 1234567chmod [OPTION]... MODE[,MODE]... FILE...chmod [OPTION]... num_mode FILE...chmod [OPTION]... --reference=RFILE FILE...选项说明：--reference=RFILE：引用某文件的权限作为权限值-R：递归修改，只对当前已存在的文件有效 (1). 使用数值方式修改权限1shell&gt; chmod 755 /tmp/a.txt (2). 使用字符方式修改权限由于权限属性附在文件所有者、所属组和其它上，它们三者都有独立的权限位，所有者使用字母”u”表示，所属组使用”g”来表示，其他使用”o”来表示，而字母”a”同时表示它们三者。所以使用字符方式修改权限时，需要指定操作谁的权限。 12chmod [ugoa][+ - =] [权限字符] 文件/目录名&quot;+&quot;是加上权限，&quot;-&quot;是减去权限，&quot;=&quot;是直接设置权限 12[root@xuexi tmp]# chmod u-x,g-x,o-x test # 将ugo都去掉x权限，等价于chmod -x test[root@xuexi tmp]# chmod a+x test # 为ugo都加上x权限，等价于chmod +x test chgrp 更改文件和目录的所属组，要求组已经存在。 注意，对于链接文件而言，修改组的作用对象是链接的源文件，而非链接文件本身。 123456chgrp [OPTION]... GROUP FILE...chgrp [OPTION]... --reference=RFILE FILE..选项说明：-R：递归修改--reference=dest_file file_list：引用某文件的group作为文件列表的组,即将file文件列表的组改为dest_file的组 chown chown可以修改文件所有者和所属组。 注意，对于链接文件而言，默认不会穿过链接修改源文件，而是直接修改链接文件本身，这和chgrp的默认是不一样的。 123456789101112chown [OPTION]... [OWNER][:[GROUP]] FILE...chown [OPTION]... [OWNER][.[GROUP]] FILE...chown [OPTION]... --reference=RFILE FILE...选项说明：--from=CURRENT_OWNER:CURRENT_GROUP：只修改当前所有者或所属组为此处指定的值的文件--reference=RFILE：引用某文件的所有者和所属组的值作为新的所有者和所属组-R：递归修改。注意，当指定-R时，且同时指定下面某一个选项时对链接文件有不同的行为 -H：如果chown的文件参数是一个链接到目录的链接文件，则穿过此链接文件修改其源目录的所有者和所属组 -L：目录中遇到的所有链接文件都穿越过去，修改它们的源文件的所有者和所属组 -P：不进行任何穿越，只修改链接文件本身的所有者和所属组。(这是默认值) 这3项若同时指定多项时，则最后一项生效 chown指定所有者和所属组的方式有两种，使用冒号和点。 12345shell&gt; chown root.root testshell&gt; chown root:root testshell&gt; chown root test # 只修改所有者shell&gt; chown :root test # 自修改组shell&gt; chown .root test 实现权限的本质 涉及文件系统的知识点，若不理解，可以先看看文件系统的内容。此处是以ext4文件系统为例的，在其他文件系统上结果可能会有些不一样(centos 7上使用xfs文件系统时结果可能就不一样)，但本质是一样的。 不同的权限表示对文件具有不同能力，如读写执行(rwx)权限，但是它是怎么实现的呢？描述文件权限的数据放在哪里呢？ 首先，权限的元数据放在inode中，严格地说是放在inode table中，因为每个块组的所有inode组成一个inode table。在inode table中使用一列来存放数字型的权限，比如某文件的权限为644。每次用户要对文件进行操作时系统都会先查看权限，确认该用户是否有对应的权限来执行操作。当然，inode table一般都已经加载到内存中，所以每次查询权限的资源消耗是非常小的。 无论是读、写还是执行权限，所体现出来的能力究其本质都是因为它作用在对应文件的data block上。 读权限(r) 对普通文件具有读权限表示的是具有读取该文件内容的能力，对目录具有读权限表示具有浏览该目录中文件或子目录的能力。其本质都是具有读取其data block的能力。 对于普通文件而言，能够读取文件的data block，而普通文件的data block存储的直接就是数据本身， 所以对普通文件具有读权限表示能够读取文件内容。 对于目录文件而言，能够读取目录的data block，而目录文件的data block存储的内容包括但不限于：目录中文件的inode号(并非直接存储，而是存储指向inode table中该inode号的指针)以及这些文件的文件类型、文件名。所以能够读取目录的data block表示仅能获取到这些信息。 目录的data block内容示例如下： 例如：123shell&gt; mkdir -p /mydata/data/testdir/subdir # 创建testdir测试目录和其子目录subdirshell&gt; touch /mydata/data/testdir/a.log # 再在testdir下创建一个普通文件shell&gt; chmod 754 /mydata/data/testdir # 将testdir设置为对其他人只有读权限 然后切换到普通用户查看testdir目录的内容。123456789101112shell&gt; su - wangwushell&gt; ll -ai /mydata/data/testdir/ls: cannot access /mydata/data/testdir/..: Permission deniedls: cannot access /mydata/data/testdir/a.log: Permission deniedls: cannot access /mydata/data/testdir/subdir: Permission deniedls: cannot access /mydata/data/testdir/.: Permission deniedtotal 0? d????????? ? ? ? ? ? .? d????????? ? ? ? ? ? ..? -????????? ? ? ? ? ? a.log? d????????? ? ? ? ? ? subdir 从结果中看出，testdir下的文件名和文件类型是能够读取的，但是其他属性都不能读取到。而且也读取不到inode号，因为它并没有直接存储inode号，而是存储了指向Inode号的指针，要定位到指针的指向需要执行权限。 执行权限(x) 执行权限表示的是能够执行。如何执行？执行这个词不是很好解释，可以简单的类比Windows中的双击行为。例如对目录双击就能进入到目录，对批处理文件双击就能运行(有专门的解释器解释)，对可执行程序双击就能运行等。 当然，读权限是文件的最基本权限，执行权限能正常运行必须得配有读权限。 对目录有执行权限，表示可以通过目录的data block中指向文件inode号的指针定位到inode table中该文件的inode信息，所以可以显示出这些文件的全部属性信息。 写权限(w) 写权限很简单，就是能够将数据写入分配到的data block。 对目录文件具有写权限，表示能够创建和删除文件。目录的写操作实质是能够在目录的data block中创建或删除关于待操作文件的记录。它要求对目录具有执行权限，因为无论是创建还是删除其内文件，都需要将其data block中inode号和inode table中的inode信息关联或删除。 对普通文件具有写权限，实质是能够改写该文件的data block。还是要说明的是，对文件有写权限不代表能够删除该文件，因为删除文件是要在目录的data block中删除该文件的记录，也就是说删除权限是在目录中定义的。 所以，对目录文件和普通文件而言，读、写、执行权限它们的依赖关系如下图所示。 umask说明 umask值用于设置用户在创建文件时的默认权限。对于root用户(实际上是UID小于200的user)，系统默认的umask值是022；对于普通用户和系统用户，系统默认的umask值是002。 默认它们的设置是写在/etc/profile和/etc/bashrc两个环境配置文件中。 1234shell&gt; grep -C 5 -R &apos;umask 002&apos; /etc | grep &apos;umask 022&apos; /etc/bashrc- umask 022/etc/csh.cshrc- umask 022/etc/profile- umask 022 相关设置项如下：12345if [ $UID -gt 199 ] &amp;&amp; [ &quot;`id -gn`&quot; = &quot;`id -un`&quot; ]; then umask 002else umask 022fi 执行umask命令可以查看当前用户的umask值。12[root@xuexi tmp]# umask0022 12[longshuai@xuexi tmp]$ umask0002 执行umask num可以临时修改umask值为num，但这是临时的，要永久有效，需要写入到环境配置文件中，至于写入到/etc/profile、/etc/bashrc、~/.bashrc还是~/.bash_profile中，看你自己的需求了。不过一般来说，不会去永久修改umask值，只会在特殊条件下临时修改下umask值。 umask是如何决定创建文件的默认权限的呢？ 如果创建的是目录，则使用777-umask值，如root的umask=022，则root创建目录时该目录的默认权限为777-022=755，而普通用户创建目录时，权限为777-002=775. 如果创建的是普通文件，在Linux中，深入贯彻了一点：文件默认不应该有执行权限，否则是危险的。所以在计算时，可能会和想象中的结果不一样。如果umask的三位都为偶数，则直接使用666去减掉umask值，因为6减去一个偶数还是偶数，任何位都不可能会有执行权限。如root创建普通文件时默认权限为666-022=644，而普通用户创建普通文件时默认权限为666-002=664。 如果umask值某一位为奇数，则666减去umask值后再在奇数位上加1。如umask=021时，创建文件时默认权限为666-021=645，在奇数位上加1，则为646。 1234[longshuai@xuexi tmp]$ umask 021[longshuai@xuexi tmp]$ touch b.txt[longshuai@xuexi tmp]$ ls -l b.txt-rw-r--rw- 1 longshuai longshuai 0 Jun 7 12:02 b.txt 总之计算出后默认都是没有执行权限的。 文件的扩展ACL权限 在计算机相关领域，所有的ACL(access control list)都表示访问控制列表。 文件的owner/group/others的权限就是一种ACL，它们是基本的ACL。很多时候，只通过这3个权限位是无法完全合理设置权限问题的，例如如何仅设置某单个用户具有什么权限。这时候需要使用扩展ACL。 扩展ACL是一种特殊权限，它是文件系统上功能，用于解决所有者、所属组和其他这三个权限位无法合理设置单个用户权限的问题。所以，扩展ACL可以针对单一使用者，单一档案或目录里的默认权限进行r,w,x的权限规范。 需要明确的是，扩展ACL是文件系统上的功能，且工作在内核，默认在ext4/xfs上都已开启。在下文中，都直接以ACL来表示代替扩展ACL的称呼。 查看文件系统是否开启ACL功能 对于ext家族的文件系统来说，要查看是否开启acl功能，使用dumpe2fs导出文件系统属性即可。 123shell&gt; dumpe2fs -h /dev/sda2 | grep -i acldumpe2fs 1.41.12 (17-May-2010)Default mount options: user_xattr acl 对于xfs文件系统，则没有直接的命令可以输出它的相关信息，需要使用dmesg来查看。其实无需关注它，因为默认xfs会开启acl功能。 123shell&gt; dmesg | grep -i acl[ 1.465903] systemd[1]: systemd 219 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ -LZ4 -SECCOMP +BLKID +ELFUTILS +KMOD +IDN)[ 2.517705] SGI XFS with ACLs, security attributes, no debug enabled 开启ACL功能后，不代表就使用ACL功能。是否使用该功能，不同文件系统控制方法不一样，对于ext家族来说，通过mount挂载选项来控制，而对于xfs文件系统，mount命令根本不支持acl参数(xfs文件系统如何关闭或启用的方法本人也不知道)。 设置和查看ACL设置使用setfacl命令。 12345678910111213setfacl [options] u:[用户列表]:[rwx] 目录/文件名 # 对用户设置使用usetfacl [options] g:[组列表]:[rwx] 目录/文件名 # 对组设置使用g选项说明：-m：设定ACL权限(modify)-x：删除指定的ACL权限，可以指定用户、组和文件来删除(remove)-M：写了ACL条目的文件，将从此文件中读取ACL条目，需要配合-m，所以-M指定的是modify file-X：写了ACL条目的文件，将从此文件中读取ACL条目，需要配合-x，所以-X指定的是remove file-n：不重置mask-b：删除所有的ACL权限-d：设定默认ACL权限，只对目录有效，设置后子目录(文件)继承默认ACL，只对未来文件 有效-k：删除默认ACL权限-R：递归设定ACL权限，只对目录有效，只对已有文件有效 查看使用getfacl命令 1getfacl filename 案例：假设现有目录/data/videos专门存放视频，其中有一个a.avi的介绍性视频。该目录的权限是750。现在有一个新用户加入，但要求该用户对该目录只有查看的权限，且只能看其中一部视频a.avi，另外还要求该用户在此目录下没有创建和删除文件的权限。 1.准备相关环境。123456shell&gt; mkdir -p /data/videosshell&gt; chmod 750 /data/videosshell&gt; touch /data/videos/&#123;a,b&#125;.avishell&gt; echo &quot;xxx&quot; &gt;/data/videos/a.avishell&gt; echo &quot;xxx&quot; &gt;/data/videos/b.avishell&gt; chown -R root.root /data/videos 2.首先设置用户longshuai对/data/videos目录有读和执行权限。1shell&gt; setfacl -m u:longshuai:rx /data/videos 3.现在longshuai对/data/videos目录下的所有文件都有读权限，因为默认文件的权限为644。要设置longshuai只对a.avi有读权限，先设置所有文件的权限都为不可读。1shell&gt; chmod 640 /data/videos/* 4.然后再单独设置a.avi的读权限。1shell&gt; setfacl -m u:longshuai:r /data/videos/a.avi 到此就设置完成了。查看/data/videos/和/data/videos/a.avi上的ACL信息。 12345678910shell&gt; getfacl /data/videos/getfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos/# owner: root# group: rootuser::rwxuser:longshuai:r-x # 用户longshuai在此文件上的权限是r-xgroup::r-xmask::r-xother::--- 12345678910shell&gt; getfacl /data/videos/a.avigetfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos/a.avi# owner: root# group: rootuser::rw-user:longshuai:r-- # 用户longshuai在此文件上的权限是r--group::r--mask::r--other::--- ACL:mask 设置mask后会将mask权限与已有的acl权限进行与计算，计算后的结果会成为新的ACL权限 。 设定mask的方式为：setfacl -m m:[rwx] 目录/文件名 注意：默认每次设置文件的acl都会重置mask为此次给定的用户的值。既然如此，要如何控制文件上的acl呢？如果一个文件上要设置多个用户的acl，重置mask后就会对已有用户的acl重新计算，而使得acl权限得不到有效的控制。使用setfacl的”-n”选项，它表示此次设置不会重置mask值。 例如：当前的acl权限：12345678910shell&gt; getfacl /data/videos getfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwxgroup::r-xmask::rwxother::--- 设置mask值为rx。123456789101112shell&gt; setfacl -m m:rx /data/videosshell&gt; getfacl /data/videos getfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwx #effective:r-xgroup::r-xmask::r-xother::--- 设置mask后，它提示有效权限是r-x。这是rwx和r-x做与运算之后的结果。 再设置longshuai的acl为rwx，然后查看mask，会发现mask也被重置为rwx。 123456789101112shell&gt; setfacl -m u:longshuai:rwx /data/videosshell&gt; getfacl /data/videosgetfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwxgroup::r-xmask::rwxother::--- 所以，在设置文件的acl时，要使用-n选项来禁止重置mask。 1234567891011121314shell&gt; setfacl -m m:rx /data/videosshell&gt; setfacl -n -m u:longshuai:rwx /data/videosshell&gt; getfacl /data/videosgetfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwx #effective:r-xgroup::r-xmask::r-xother::--- 设置递归和默认ACL权限 递归ACL权限只对目录里已有文件有效，默认权限只对未来目录里的文件有效。 设置递归ACL权限： 1setfacl -m u:username:[rwx] -R 目录名 # -R选项只能放在后面。 设置默认ACL权限：1setfacl -m d:u:username:[rwx] 目录名 删除ACL权限123setfacl -x u:用户名 文件名 # 删除指定用户ACLsetfacl -x g:组名 文件名 # 删除指定组名ACLsetfacl -b 文件名 # 指定文件删除ACL，会删除所有ACL 文件隐藏属性 chattr：change file attributes lsattr：list file attributes 12chattr [+ - =] [ai] 文件或目录名 常用的参数是a(append，追加)和i(immutable，不可更改)，其他参数略。 设置了a参数时，文件中将只能增加内容，不能删除数据，且不能打开文件进行任何编辑，哪怕是追加内容也不可以，所以像sed等需要打开文件的再写入数据的工具也无法操作成功。文件也不能被删除。只有root才能设置。 设置了i参数时，文件将被锁定，不能向其中增删改内容，也不能删除修改文件等各种动作。只有root才能设置。可以将其理解为设置了i后，文件将是永恒不变的了，谁都不能动它。 例如，对/etc/shadow文件设置i属性，任何用户包括root将不能修改密码，而且也不能创建用户。1shell&gt; chattr +i /etc/shadow 此时如果新建一个用户。12shell&gt; useradd newlongsuaishell&gt; useradd: cannot open /etc/shadow # 提示文件不能打开，被锁定了 lsattr查看文件设置的隐藏属性。12shell&gt; lsattr /etc/shadow----i--------e- /etc/shadow # i属性说明被锁定了，e是另一种文件属性，忽略它 删除隐藏属性：123shell&gt; chattr -i /etc/shadowshell&gt; lsattr /etc/shadow-------------e- /etc/shadow 再来一例：1234shell&gt; chattr +a test1.txt # 对test1.txt设置a隐藏属性shell&gt; echo 1234&gt;&gt;test1.txt # 追加内容是允许的行为shell&gt; cat /dev/null &gt;test1.txt # 但是清空文件内容是不允许的-bash: test1.txt: Operation not permitted suid/sgid/sbitsuid suid只针对可执行文件，即二进制文件。它的作用是对某个命令(可执行文件)授予所有者的权限，命令执行完成权限就消失。一般是提权为root权限。 例如/etc/shadow文件所有人都没有权限(root除外)，其他用户连看都不允许。 12shell&gt; ls -l /etc/shadow----------. 1 root root 752 Apr 8 12:42 /etc/shadow 但是他们却能修改自己的密码，说明他们一定有一定的权限。这个权限就是suid控制的。 12shell&gt; ls -l /usr/bin/passwd-rwsr-xr-x. 1 root root 30768 Feb 22 2012 /usr/bin/passwd 其中的”s”权限就是suid，它出现在所有者位置上(是root)，其他用户执行passwd命令时，会暂时拥有所有者位的rwx权限，也就是root的权限，所以能向/etc/shadow写入数据。 suid必须和x配合，如果没有x配合，则该suid是空suid，仍然没有执行命令的权限，所有者都没有了x权限，suid依赖于它所以更不可能有x权限。空的suid权限使用大写的”S”表示。 数字4代表suid，如4755。 sgid针对二进制文件和目录。 针对二进制文件时，权限升级为命令的所属组权限。 针对目录时，目录中所建立的文件或子目录的组将继承默认父目录组，其本质还是提升为目录所属组的权限。此时目录应该要有rx权限，普通用户才能进入目录，如果普通用户有w权限，新建的文件和目录则以父目录组为默认组。 以2代表sgid，如2755，和suid组合如6755。 sbit 只对目录有效。对目录设置sbit，将使得目录里的文件只有所有者能删除，即使其他用户在此目录上有rwx权限，即使是root用户。 以1代表sbit。 补充：suid/sgid/sbit的标志位都作用在x位，当原来的x位有x权限时，这些权限位则为s/s/t，如果没有x权限，则变为S/S/T。例如，/tmp目录的权限有个t位，使得该目录里的文件只有其所有者本身能删除。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"权限管理","slug":"权限管理","permalink":"http://yoursite.com/tags/权限管理/"}]},{"title":"安装管理包：LINUX系统中用户、组管理","slug":"LINUX系统中用户、组管理","date":"2017-03-07T16:00:00.000Z","updated":"2018-06-19T11:52:24.588Z","comments":true,"path":"2017/03/08/LINUX系统中用户、组管理/","link":"","permalink":"http://yoursite.com/2017/03/08/LINUX系统中用户、组管理/","excerpt":"用户和组的基本概念 用户和组是操作系统中一种身份认证资源。 每个用户都有用户名、用户的唯一编号uid(user id)、所属组及其默认的shell，可能还有密码、家目录、附属组、注释信息等。 每个组也有自己的名称、组唯一编号gid(group id)。一般来说，gid和uid是可以不相同的，但绝大多数都会让它们保持一致，大致属于约定俗成类的概念吧。","text":"用户和组的基本概念 用户和组是操作系统中一种身份认证资源。 每个用户都有用户名、用户的唯一编号uid(user id)、所属组及其默认的shell，可能还有密码、家目录、附属组、注释信息等。 每个组也有自己的名称、组唯一编号gid(group id)。一般来说，gid和uid是可以不相同的，但绝大多数都会让它们保持一致，大致属于约定俗成类的概念吧。组分为主组(primary group)和辅助组(secondary group)两种，用户一定会属于某个主组，也可以同时加入多个辅助组。 在Linux中，用户分为3类： (1). 超级管理员 超级管理员是最高权限者，它的uid=0，默认超级管理员用户名为root。因为uid默认具有唯一性，所以超级管理员默认只能有一个(如何添加额外的超级管理员，见useradd命令)，但这一个超级管理员的名称并非一定要是root。但是没人会去改root的名称，在后续非常非常多的程序中，都认为超级管理员名称为root，这里要是一改，牵一发而动全身。 (2). 系统用户 有时候需要一类具有某些特权但又不需要登录操作系统的用户，这类用户称为系统用户。它们的uid范围从201到999(不包括1000)，有些老版本范围是1到499(centos 6)，出于安全考虑，它们一般不用来登录，所以它们的shell一般是/sbin/nologin，而且大多数时候它们是没有家目录的。 (3). 普通用户 普通用户是权限受到限制的用户，默认只能执行/bin、/usr/bin、/usr/local/bin和自身家目录下的命令。它们的uid从500开始。尽管普通用户权限收到限制，但是它对自身家目录下的文件是有所有权限的。 超级管理员和其他类型的用户，它们的命令提示符是不一样的。uid=0的超级管理员，命令提示符是”#”，其他的为”$”。 默认root用户的家目录为/root，其他用户的家目录一般在/home下以用户名命名的目录中，如longshuai这个用户的家目录为/home/longshuai。当然，家目录是可以自定义位置和名称的。 用户和组管理相关的文件用户文件/etc/passwd/etc/passwd文件里记录的是操作系统中用户的信息，这里面记录了几行就表示系统中有几个系统用户。它的格式大致如下：12345678910root:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologinshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltftp:x:14:50:FTP User:/var/ftp:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinmysql:x:27:27:MySQL Server:/var/lib/mysql:/bin/bashnginx:x:498:499:Nginx web server:/var/lib/nginx:/sbin/nologinlongshuai:x:1000:1000::/home/longshuai:/bin/bash 每一行表示一个用户，每一行的格式都是6个冒号共7列属性，其中有很多用户的某些列属性是留空的。 1用户名:x:uid:gid:用户注释信息:家目录:使用的shell类型 12345678910111213第一列：用户名。注意两个个特殊的用户名，root、nobody 第二列：x。在以前老版本的系统上，第二列是存放用户密码的，但是密码和用户信息放在一起不便于管理(密钥要保证其特殊属性)，所以后来将密码单独放在另一个文件/etc/shadow中，这里就都写成x了 第三列：uid 第四列：gid 第五列：用户注释信息。 第六列：用户家目录。注意root用户的家目录为/root 第七列：用户的默认shell，虽然叫shell，但其实可以是任意一个可执行程序或脚本。例如上面的/bin/bash、/sbin/nologin、/sbin/shutdown 用户的默认shell表示的是用户登录(如果允许登录)时的环境或执行的命令。例如shell为/bin/bash时，表示登录时就执行/bin/bash命令进入bash环境；shell为/sbin/nologin表示该用户不能登录，之所以不能登录不是因为指定了这个特殊的程序，而是由/sbin/nologin这个程序的功能实现的，假如修改Linux的源代码，将/sbin/nologin这个程序变成可登录，那么shell为/sbin/nologin时也是可以登录的。 密码文件/etc/shadow /etc/shadow文件中存放的是用户的密码信息。该文件具有特殊属性，除了超级管理员，任何人都不能直接读取和修改该文件，而用户自身之所以能修改密码，则是因为该文件的suid属性，使得修改密码时临时提升为root权限。 该文件的格式大致如下： root:$6$hS4yqJu7WQfGlk0M$Xj/SCS5z4BWSZKN0raNncu6VMuWdUVbDScMYxOgB7mXUj./dXJN0zADAXQUMg0CuWVRyZUu6npPLWoyv8eXPA.::0:99999:7::: ftp::16659:0:99999:7::: nobody::16659:0:99999:7::: longshuai:$6$8LGe6Eh6$vox9.OF3J9nD0KtOYj2hE9DjfU3iRN.v3up4PbKKGWLOy3k1Up50bbo7Xii/Uti05hlqhktAf/dZFy2RrGp5W/:17323:0:99999:7::: 每一行表示一个用户密码的属性，有8个冒号共9列属性。 第一列：用户名。 第二列：加密后的密码。但是这一列是有玄机的，有些特殊的字符表示特殊的意义。①.该列留空，即”::”，表示该用户没有密码。②.该列为”!”，即”:!:”，表示该用户被锁，被锁将无法登陆，但是可能其他的登录方式是不受限制的，如ssh key的方式，su的方式。③.该列为”“，即”::”，也表示该用户被锁，和”!”效果是一样的。④.该列以”!”或”!!”开头，则也表示该用户被锁。⑤.该列为”!!”，即”:!!:”，表示该用户从来没设置过密码。⑥.如果格式为”$id$salt$hashed”，则表示该用户密码正常。其中$id$的id表示密码的加密算法，$1$表示使用MD5算法，$2a$表示使用Blowfish算法，”$2y$”是另一算法长度的Blowfish,”$5$”表示SHA-256算法，而”$6$”表示SHA-512算法，可见上面的结果中都是使用sha-512算法的。$5$和$6$这两种算法的破解难度远高于MD5。$salt$是加密时使用的salt，$hashed才是真正的密码部分。 第三列：从1970年1月1日到上次密码修改经过的时间(天数)。通过计算现在离1970年1月1日的天数减去这个值，结果就是上次修改密码到现在已经经过了多少天，即现在的密码已经使用了多少天。 第四列：密码最少使用期限(天数)。省略或者0表示不设置期限。例如，刚修改完密码又想修改，可以限制多久才能再次修改 第五列：密码最大使用期限(天数)。超过了它不一定密码就失效，可能下一个字段设置了过期后的宽限天数。设置为空时将永不过期，后面设置的提醒和警告将失效。root等一些用户的已经默认设置为了99999，表示永不过期。如果值设置小于最短使用期限，用户将不能修改密码。 第六列：密码过期前多少天就开始提醒用户密码将要过期。空或0将不提醒。 第七列：密码过期后宽限的天数，在宽限时间内用户无法使用原密码登录，必须改密码或者联系管理员。设置为空表示没有强制的宽限时间，可以过期后的任意时间内修改密码。 第八列：帐号过期时间。从1970年1月1日开始计算天数。设置为空帐号将永不过期，不能设置为0。不同于密码过期，密码过期后账户还有效，改密码后还能登录；帐号过期后帐号失效，修改密码重设密码都无法使用该帐号。 第九列：保留字段。 组文件/etc/group和/etc/gshadow 大致知道有这么两个文件即可，至于文件中的内容无需关注。 /etc/group包含了组信息。每行一个组，每一行3个冒号共4列属性。 1root:x:0: longshuai:x:500: xiaofang:x:501:zhangsan,lisi 第一列：组名。第二列：占位符。第三列：gid。第四列：该组下的user列表，这些user成员以该组做为辅助组，多个成员使用逗号隔开。 /etc/gshadow包含了组密码信息 骨架目录/etc/skel 骨架目录中的文件是每次新建用户时，都会复制到新用户家目录里的文件。默认只有3个环境配置文件，可以修改这里面的内容，或者添加几个文件在骨架目录中，以后新建用户时就会自动获取到这些环境和文件。 12345shell&gt; ls –l -A /etc/skeltotal 12-rw-r--r--. 1 root root 18 Oct 16 2014 .bash_logout-rw-r--r--. 1 root root 176 Oct 16 2014 .bash_profile-rw-r--r--. 1 root root 124 Oct 16 2014 .bashrc 删除家目录下这些文件，会导致某些设置出现问题。例如删除”.bashrc”这个文件，会导致提示符变异的问题，如下右图。 要解决这个问题，只需拷贝一个正常的.bashrc文件到其家目录中即可。一般还会修改该文件的所有者和权限。 /etc/login.defs 设置用户帐号限制的文件。该文件里的配置对root用户无效。 如果/etc/shadow文件里有相同的选项，则以/etc/shadow里的设置为准，也就是说/etc/shadow的配置优先级高于/etc/login.defs。 该文件有很多配置项，文件的默认内容只给出了一小部分，若想知道全部的配置项以及配个配置项的详细说明，可以”man 5 login.defs”查看。 123456789101112131415161718192021222324252627282930313233343536373839404142[root@xuexi ~]# less /etc/login.defs#QMAIL_DIR Maildir # QMAIL_DIR是Qmail邮件的目录，所以可以不设置它MAIL_DIR /var/spool/mail # 默认邮件根目录，即信箱#MAIL_FILE .mail # mail文件的格式是.mail# Password aging controls:PASS_MAX_DAYS 99999 # 密码最大有效期(天)PASS_MIN_DAYS 0 # 两次密码修改之间最小时间间隔PASS_MIN_LEN 5 # 密码最短长度PASS_WARN_AGE 7 # 密码过期前给警告信息的时间# 控制useradd创建用户时自动选择的uid范围# Min/max values for automatic uid selection in useraddUID_MIN 1000UID_MAX 60000# System accountsSYS_UID_MIN 201SYS_UID_MAX 999# 控制groupadd创建组时自动选择的gid范围# Min/max values for automatic gid selection in groupaddGID_MIN 1000GID_MAX 60000# System accountsSYS_GID_MIN 201SYS_GID_MAX 999# 设置此项后，在删除用户时，将自动删除用户拥有的at/cron/print等job#USERDEL_CMD /usr/sbin/userdel_local# 控制useradd添加用户时是否默认创建家目录，useradd -m选项会覆盖此处设置CREATE_HOME yes# 设置创建家目录时的umask值，若不指定则默认为022UMASK 077# 设置此项表示当组中没有成员时自动删除该组# 且useradd是否同时创建同用户名的主组。(该文件中并没有此项说明，来自于man useradd中-g选项的说明)USERGROUPS_ENAB yes# 设置用户和组密码的加密算法ENCRYPT_METHOD SHA512 注意，/etc/login.defs中的设置控制的是shadow-utils包中的组件，也就是说，该组件中的工具执行操作时会读取该文件中的配置。该组件中包含下面的程序：12345678910111213141516171819202122/usr/bin/gpasswd ：administer /etc/group and /etc/gshadow/usr/bin/newgrp ：log in to a new group，可用来修改gid，哪怕是正在登陆的会话也可以修改/usr/bin/sg ：execute command as different group ID/usr/sbin/groupadd ：添加组/usr/sbin/groupdel ：删除组/usr/sbin/groupmems ：管理当前用户的主组中的成员，root用户则可以指定要管理的组/usr/sbin/groupmod ：modify a group definition on the system/usr/sbin/grpck ：verify integrity of group files/usr/sbin/grpconv ：无视它/usr/sbin/grpunconv ：无视它/usr/sbin/pwconv ：无视它/usr/sbin/pwunconv ：无视它/usr/sbin/adduser ：是useradd的一个软链接，添加用户/usr/sbin/chpasswd ：update passwords in batch mode/usr/sbin/newusers ：update and create new users in batch/usr/sbin/pwck ：verify integrity of passsword files/usr/sbin/useradd ：添加用户/usr/sbin/userdel ：删除用户/usr/sbin/usermod ：重定义用户信息/usr/sbin/vigr ：edit the group and shadow-group file/usr/sbin/vipw ：edit the password and shadow-password file/usr/bin/lastlog ：输出所有用户或给定用户最近登录信息 /etc/default/useradd 创建用户时的默认配置。useradd -D修改的就是此文件 。 12345678910[root@xuexi ~]# cat /etc/default/useradd # useradd defaults fileGROUP=100 # 在useradd使用-N或/etc/login.defs中USERGROUPS_ENAB=no时表示创建用户时不创建同用户名的主组(primary group)， # 此时新建的用户将默认以此组为主组，网上关于该设置的很多说明都是错的，具体可看man useradd的-g选项或useradd -D的-g选项HOME=/home # 把用户的家目录建在/home中INACTIVE=-1 # 是否启用帐号过期设置(是帐号过期不是密码过期)，-1表示不启用EXPIRE= # 帐号过期时间，不设置表示不启用SHELL=/bin/bash # 新建用户默认的shell类型SKEL=/etc/skel # 指定骨架目录，前文的/etc/skel就在这里CREATE_MAIL_SPOOL=yes # 是否创建用户mail缓冲 man useradd的useradd -D选项介绍部分说明了这些项的意义。 用户和组管理命令useradd和adduseradduser是useradd的一个软链接。123456789101112131415161718192021222324252627282930313233useradd [options] login_name选项说明：-b：指定家目录的basedir，默认为/home目录-d：指定用户家目录，不写时默认为/home/user_name-m：要创建家目录时，若家目录不存在则自动创建，若不指定该项且/etc/login.defs中的CREATE_HOME未启用时将不会创建家目录-M：显式指明不要创建家目录，会覆盖/etc/login.defs中的CREATE_HOME设置 -g：指定用户主组，要求组已存在-G：指定用户的辅助组，多个组以逗号分隔-N：明确指明不要创建和用户名同名的组名-U：明确指明要创建一个和用户名同名的组，并将用户加入到此组中-o：允许创建一个重复UID的用户，只有和-u选项同时使用时才生效-r：创建一个系统用户。useradd命令不会为此选项的系统用户创建家目录，除非明确使用-m选项-s：指定用户登录的shell，默认留空。此时将选择/etc/default/useradd中的SHELL变量设置-u：指定用户uid，默认uid必须唯一，除非使用了-o选项-c：用户的注释信息 -k：指定骨架目录(skeleton)-K：修改/etc/login.defs文件中有关于用户的配置项，不能修改组相关的配置。设置方式为KEY=VALUE，如-K UID_MIN=100-D：修改useradd创建用户时的默认选项，就修改/etc/default/useradd文件-e：帐户过期时间，格式为&quot;YYYY-MM-DD&quot;-f：密码过期后，该账号还能存活多久才被禁用，设置为0表示密码过期立即禁用帐户，设置为-1表示禁用此功能-l：不要将用户的信息写入到lastlog和faillog文件中。默认情况下，用户信息会写入到这两个文件中useradd -D [options]修改/etc/default/useradd文件选项说明：不加任何选项时会列出默认属性-b, --base-dir BASE_DIR-e, --expiredate EXPIRE_DATE-f, --inactive INACTIVE-g, --gid GROUP-s, --shell SHELL 示例：1234567891011121314151617181920[root@xuexi ~]# useradd -D -e &quot;2016-08-20&quot; # 设置用户2016-08-20过期[root@xuexi ~]# useradd -DGROUP=100HOME=/homeINACTIVE=-1EXPIRE=2016-08-20SHELL=/bin/bashSKEL=/etc/skelCREATE_MAIL_SPOOL=yes[root@xuexi ~]# cat /etc/default/useradd# useradd defaults fileGROUP=100HOME=/homeINACTIVE=-1EXPIRE=2016-08-20SHELL=/bin/bashSKEL=/etc/skelCREATE_MAIL_SPOOL=yes useradd创建用户时，默认会自动创建一个和用户名相同的用户组，这是/etc/login.defs中的USERGROUP_ENAB变量控制的。 useradd创建普通用户时，不加任何和家目录相关的选项时，是否创建家目录是由/etc/login.defs中的CREATE_HOME变量控制的。 批量创建用户newusers newusers用于批量创建或修改已有用户信息。在创建用户时，它会读取/etc/login.defs文件中的配置项。 newusers [options] [file] newusers命令从file中或标准输入中读取要创建或修改用户的信息，文件中每行格式都一样，一行代表一个用户。格式如下： 1pw_name:pw_passwd:pw_uid:pw_gid:pw_gecos:pw_dir:pw_shell 各列的意义如下： pw_name：用户名，若不存在则新创建，否则修改已存在用户的信息 pw_passwd：用户密码，该项使用明文密码，在修改或创建用户时会按照指定的算法自动对其进行加密转换 pw_uid：指定uid，留空则自动选择uid。如果该项为已存在的用户名，则使用该用户的uid，但不建议这么做，uid应尽量保证唯一性 pw_gid：用户主组的gid或组名。若给定组不存在，则自动创建组。若留空，则创建同用户名的组，gid将自动选择 pw_gecos：用户注释信息 pw_dir：指定用户家目录，若不存在则自动创建。留空则不创建。：注意，newusers命令不会递归创建父目录，父目录不存在时将会给出信息，但newusers命令仍会继续执行：以完成创建剩下的用户，所以这些错误的用户家目录需要手动去创建。 pw_shell：指定用户的默认shell newusers [options] [file] 选项说明： -c：指定加密方法，可选DES,MD5,NONE,SHA256和SHA512 -r：创建一个系统用户newusers首先尝试创建或修改所有指定的用户，然后将信息写入到user和group的文件中。如果尝试创建或修改用户过程中发生错误，则所有动作都将回滚，但如果在写入过程中发生错误，则写入成功的不会回滚，这将可能导致文件的不一致性。要检查用户、组文件的一致性，可以使用showdow-utils包提供的grpck和pwck命令。 示例：12345678910111213shell&gt; cat /tmp/userfilezhangsan:123456:2000:2000::/home/zhangsan:/bin/bashlisi:123456:::::/bin/bashshell&gt; newusers -c SHA512 /tmp/userfile shell&gt; tail -2 /etc/passwdzhangsan:x:2000:2000::/home/zhangsan:/bin/bashlisi:x:2001:2001:::/bin/bashshell&gt; tail -2 /etc/shadowzhangsan:$6$aI1Mk/krF$xN0TFOIRibrb/mYngJ/sV3M7g4zOxqOh8CWyDlI0uwmr5qNTzsmwauRFvCpfLtvtiJYZ/5bil.XfJMNB.sqDY1:17323:0:99999:7:::lisi:$6$bngXo/V6wWW$.TlQCJtEm9krBX0Oiep/iahS59a/BwVYcSc8F9lAnMGF55K6W5YoUZ2nK6WkMta3p7sihkxHm/AuNrrJ6hqNn1:17323:0:99999:7::: groupadd创建一个新组。1234567groupadd [options] group 选项说明： -f：如果要创建的组已经存在，默认会错误退出，使用该选项则强制创建且以正确状态退出，只不过gid可能会不受控制。-g：指定gid，默认gid必须唯一，除非使用了-o选项。-K：修改/etc/login.defs中关于组相关的配置项。配置方式为KEY=VALUE，例如-K GID_MIN=100 -K GID_MAX=499-o：允许创建一个非唯一gid的组-r：创建系统组 修改密码passwd 修改密码的工具。默认passwd命令不允许为用户创建空密码。 passwd修改密码前会通过pam认证用户，pam配置文件中与此相关的设置项如下： 123456789101112131415passwd password requisite pam_cracklib.so retry=3passwd password required pam_unix.so use_authtok命令的用法如下：passwd options [username]选项说明：-l：锁定指定用户的密码，在/etc/shadow的密码列加上前缀&quot;!&quot;或&quot;!!&quot;。这种锁定不是完全锁定，使用ssh公钥还是能登录。要完全锁定，使用chage -E 0来设置帐户过期。-u：解锁-l锁定的密码，解锁的方式是将/etc/shadow的密码列的前缀&quot;!&quot;或&quot;!!&quot;移除掉。但不能移除只有&quot;!&quot;或&quot;!!&quot;的项。--stdin：从标准输入中读取密码-d：删除用户密码，将/etc/shadow的密码列设置为空-f：指定强制操作-e：强制密码过期，下次登录将强制要求修改密码-n：密码最小使用天数-x：最大密码使用天数-w：过期前几天开始提示用户密码将要过期-i：设置密码过期后多少天，用户才过期。用户过期将被禁用，修改密码也无法登陆。 批量修改密码chpasswd 以批处理模式从标准输入中获取提供的用户和密码来修改用户密码，可以一次修改多个用户密码。也就是说不用交互。适用于一次性创建了多个用户时为他们提供密码。 1234chpasswd [-e -c] &quot;user:passwd&quot;-c：指定加密算法，可选的算法有DES,MD5,NONE,SHA256和SHA512user:passwd为用户密码对，其中默认passwd是明文密码，可以指定多对，每行一个用户密码对。前提是用户是已存在的。-e：passwd默认使用的是明文密码，如果要使用密文，则使用-e选项。参见man chpasswd chpasswd会读取/etc/login.defs中的相关配置，修改成功后会将密码信息写入到密码文件中。 该命令的修改密码的处理方式是先在内存中修改，如果所有用户的密码都能设置成功，然后才写入到磁盘密码文件中。在内存中修改过程中出错，则所有修改都回滚，但若在写入密码文件过程中出错，则成功的不会回滚。 示例：修改单个用户密码。1shell&gt; echo &quot;user1:123456&quot; | chpasswd -c SHA512 修改多个用户密码，则提供的每个用户对都要分行。1shell&gt; echo -e &apos;usertest:123456\\nusertest2:123456&apos; | chpasswd 更方便的是写入到文件中，每行一个用户密码对。12345shell&gt; cat /tmp/passwdfilezhangsan:123456lisi:123456shell&gt; chapasswd -c SHA512 &lt;/tmp/passwdfile chage chage命令主要修改或查看和密码时间相关的内容。具体的看man文档，可能用到的两个选项如下： -l：列出指定用户密码相关信息 -E：指定帐户(不是密码)过期时间，所以是强锁定，如果指定为0，则立即过期，即直接锁定该用户 12345678910111213141516171819[root@server2 ~]# chage -l zhangsanLast password change : Jun 06, 2017Password expires : neverPassword inactive : neverAccount expires : neverMinimum number of days between password change : 0Maximum number of days between password change : 99999Number of days of warning before password expires : 7[root@server2 ~]# chage -E 0 zhangsan[root@server2 ~]# chage -l zhangsan Last password change : Jun 06, 2017Password expires : neverPassword inactive : neverAccount expires : Jan 01, 1970Minimum number of days between password change : 0Maximum number of days between password change : 99999Number of days of warning before password expires : 7 删除用户和组userdel命令用于删除用户。123userdel [options] login_name-r：递归删除家目录，默认不删除家目录。-f：强制删除用户，即使这个用户正处于登录状态。同时也会强制删除家目录。 一般不直接删除家目录，即不用-r，可以vim /etc/passwd，将不需要的用户直接注释掉。 groupdel命令删除组。如果要删除的组是某用户的主组，需要先删除主组中的用户。 usermod 修改帐户属性信息。必须要确保在执行该命令的时候，待修改的用户没有在执行进程。 1234567891011121314151617181920usermod [options] login选项说明：-l：修改用户名，仅仅只是改用户名，其他的一切都不会改动(uid、家目录等)-u：新的uid，新的uid必须唯一，除非同时使用了-o选项-g：修改用户主组，可以是以gid或组名。对于那些以旧组为所属组的文件(除原家目录)，需要重新手动修改其所属组-m：移动家目录内容到新的位置，该选项只在和-d选项一起使用时才生效-d：修改用户的家目录位置，若不存在则自动创建。默认旧的家目录不会删除 如果同时指定了-m选项，则旧的家目录中的内容会移到新家目录 如果当前用户家目录不存在或没有家目录，则也不会创建新的家目录-o：允许用户使用非唯一的UID-s：修改用的shell，留空则选择默认shell-c：修改用户注释信息-a：将用户以追加的方式加入到辅助组中，只能和-G选项一起使用-G：将用户加入指定的辅助组中，若此处未列出某组，而此前该用户又是该组成员，则会删除该组中此成员-L：锁定用户的密码，将在/etc/shadow的密码列加上前缀&quot;!&quot;或&quot;!!&quot;-U：解锁用户的密码，解锁的方式是移除shadow文件密码列的前缀&quot;!&quot;或&quot;!!&quot;-e：帐户过期时间，时间格式为&quot;YYYY-MM-DD&quot;，如果给一个空的参数，则立即禁用该帐户-f：密码过期后多少天，帐户才过期被禁用，0表示密码过期帐户立即禁用，-1表示禁用该功能 同样，还有groupmod修改组信息，用法非常简单，几乎也用不上，不多说了。 vipw和vigr vipw和vigr是编辑用户和组文件的工具，vipw可以修改/etc/passwd和/etc/shadow，vigr可以修改/etc/group和/etc/gshadow，用这两个工具比较安全，在修改的时候会检查文件的一致性。 删除用户出错时，提示用户正在被进程占用。可以使用vi编辑/etc/paswd和/etc/shadow文件将该用户对应的行删除掉。也可以使用vipw和vipw -s来分别编辑/etc/paswd和/etc/shadow文件。它们的作用是一样的。 手动创建用户 手动创建用户的全过程：需要管理员权限。 在/etc/group中添加用户所属组的相关信息。如果用户还有辅助组则在对应组中加入该用户作为成员。在/etc/passwd和/etc/shadow中添加用户相关信息。此时指定的家目录还不存在，密码不存在，所以/etc/shadow的密码位使用”!!”代替。创建家目录，并复制骨架目录中的文件到家目录中。 12shell&gt; mkdir /home/user_nameshell&gt; cp -r /etc/skel /home/user_name。 修改家目录及子目录的所有者和属组。 1shell&gt; chown -R user_name:user_name /home/user_name 修改家目录及子目录的权限。例如设置组和其他用户无任何权限但所有者有。 1shell&gt; chmod -R 700 /home/user_name 到此为止，用户已经创建完成了，只是没有密码，所以只能su，不能登录。 生成密码。使用openssl passwd生成密码。但openssl passwd生成的密码只能是MD5算法的，很容易被破解 1shell&gt; openssl passwd -1 -salt &apos;123456&apos; # 生成使用md5算法的密码，然后将生成的密码复制到/etc/shadow对应用户的密码位。其中-1是指md5，-salt &apos;12345678&apos;是使用8位的字符创建密码的杂项。 直接使用passwd命令创建密码 测试手动创建的用户是否可以正确登录。 以下是全过程。 12345678shell&gt; mkdir /tmp/12;cp /etc/group /etc/passwd /etc/shadow /tmp/12/ # 备份这些文件shell&gt; echo &quot;userX:x:666&quot; &gt;&gt; /etc/groupshell&gt; echo &quot;userX:x:666:666::/home/userX:/bin/bash&quot; &gt;&gt; /etc/passwdshell&gt; echo &apos;userX:!!:17121:0:99999::::&apos; &gt;&gt; /etc/shadowshell&gt; cp -r /etc/skel /home/userXshell&gt; chown -R userX:userX /home/userXshell&gt; chmod -R go= /home/userXshell&gt; passwd --stdin userX &lt;&lt;&lt; &apos;123456&apos; 测试使用userX是否可以登录。 如果是使用openssl passwd创建的密码。那么使用下面的方法将这部分密码替换到/etc/shadow中。 123shell&gt; field=$(tail -1 /etc/shadow | cut -d&quot;:&quot; -f2)shell&gt; password=$(openssl passwd -1 -salt &apos;abcdefg&apos; 123456)shell&gt; sed -i &apos;$s%&apos;$field&apos;%&apos;$password&apos;%&apos; /etc/shadow 其他用户相关命令finger查看用户信息 从CentOS 6版本开始就没有该命令了，要先安装。 12345678910shell&gt; yum -y install fingershell&gt; useradd zhangsanshell&gt; finger zhangsanLogin: zhangsan Name:Directory: /home/zhangsan Shell: /bin/bashNever logged in.No mail.No Plan. id1234id username-u：得到uid-n：得到用户名而不是uid-z：无任何空白字符输出模式，不能在默认的格式下使用。 示例：1234567891011shell&gt; id rootuid=0(root) gid=0(root) groups=0(root)shell&gt; id wangwuuid=500(wangwu) gid=500(wangwu) groups=500(wangwu)shell&gt; id -u wangwu500shell&gt; id -u -z wangwu2002[root@server2 ~]# users 查看当前正在登陆的用户名。 last 查看最近登录的用户列表，其实last查看的是/var/log/wtmp文件。 -n 显示行数：列出最近几次登录的用户 1234567[root@xuexi ~]# last -4root pts/0 192.168.100.1 Wed Mar 30 15:16 still logged in root pts/1 192.168.100.1 Wed Mar 30 14:21 - 14:21 (00:00) root pts/1 192.168.100.1 Wed Mar 30 14:04 - 14:10 (00:06) root pts/0 192.168.100.1 Wed Mar 30 13:12 - 15:16 (02:04) wtmp begins Thu Feb 18 20:59:39 2016 lastb 查看谁尝试登陆过但没有登录成功的。即能够审核和查看谁曾经不断的登录，可能那就是黑客。 -n:只列出最近的n个尝试对象。 who和w 都是查看谁登录过，并干了什么事 w查看的信息比who多。 123456789shell&gt; whoroot tty1 2017-06-07 00:49root pts/0 2017-06-07 02:06 (192.168.100.1)shell&gt; w08:26:38 up 18:48, 2 users, load average: 0.00, 0.01, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot tty1 00:49 7:36m 0.24s 0.24s -bashroot pts/0 192.168.100.1 02:06 6.00s 0.97s 0.02s w 其中w的第一行，分别表示当前时间，已开机时长，当前在线用户，过去1、5、15分钟的平均负载率。这一行和uptime命令获取的信息是完全一致的。 lastlog 可以查看登录的来源IP -u 指定查看用户 1234567891011shell&gt; lastlog|head -n 10Username Port From Latestroot pts/0 192.168.100.1 Wed Mar 30 15:16:25 +0800 2016bin **Never logged in**daemon **Never logged in**adm **Never logged in**lp **Never logged in**sync **Never logged in**shutdown **Never logged in**halt **Never logged in**mail **Never logged in**","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"用户组","slug":"用户组","permalink":"http://yoursite.com/tags/用户组/"}]},{"title":"DNS 服务从基础到深入","slug":"DNS 服务从基础到深入","date":"2017-02-14T16:00:00.000Z","updated":"2018-06-15T12:22:30.217Z","comments":true,"path":"2017/02/15/DNS 服务从基础到深入/","link":"","permalink":"http://yoursite.com/2017/02/15/DNS 服务从基础到深入/","excerpt":"一 简介 DNS是Domain name system的简称，有些地方也称为Domain name server，这东西是一个很大的话题。如果不是要配置DNS服务，只需要理解DNS的解析流程和DNS有关的基本知识即可。如果要配置DNS服务，则可以看完全文。推荐阅读书籍：《DNS &amp; bind》，第四版有中文版，第五版目前只有英文版。 DNS必懂基础","text":"一 简介 DNS是Domain name system的简称，有些地方也称为Domain name server，这东西是一个很大的话题。如果不是要配置DNS服务，只需要理解DNS的解析流程和DNS有关的基本知识即可。如果要配置DNS服务，则可以看完全文。推荐阅读书籍：《DNS &amp; bind》，第四版有中文版，第五版目前只有英文版。 DNS必懂基础 DNS主要是用于将域名解析为IP地址的协议，有时候也用于将IP地址反向解析成域名，所以DNS可以实现双向解析。DNS可以使用TCP和UDP的53端口，基本使用UDP协议的53端口。 域的分类 域是分层管理的，就像中国的行政级别。最高层的域是根域(root)”.”，就是一个点，它就像国家主席一样。全球只有13个根域服务器，基本上都在美国，中国一台根域服务器都没有。根域的下一层就是第二层次的顶级域（TLD）了，那么它就是各省省长了。顶级域一般两种划分方法：按国家划分和按组织性质划分。 ◇ 按国家划分：.cn(中国)、.tw(台湾)、.hk(香港)。基本都是两个字母的。◇ 按组织性质划分：.org、.net、.com、.edu、.gov、.cc等。◇ 反向域：arpa。这是反向解析的特殊顶级域。 顶级域下来就是普通的域，公司或个人在互联网上注册的域名一般都是这些普通的域，如baidu.com。 主机名、域名、FQDN 以百度(www.baidu.com)和百度贴吧(tieba.baidu.com)来举例。 ◇ 域名不论是www.baidu.com还是tieba.baidu.com，它们的域名都是baidu.com，严格地说是&quot;baidu.com.&quot;。这是百度所购买的com域下的一个子域名。 ◇ 主机名对于www.baidu.com来说，主机名是www，对于tieba.baidu.com来说，主机名是tieba。其实严格来说，www.baidu.com和tieba.baidu.com才是主机名，它们都是baidu.com域下的主机。一个域下可以定义很多主机，只需配置好它的主机名和对应主机的IP地址即可。 ◇ FQDNFQDN是Fully Qualified Domain Name的缩写，称为完全合格域名，是指包含了所有域的主机名，其中包括根域。FQDN可以说是主机名的一种完全表示形式，它从逻辑上准确地表示出主机在什么地方。 例如www.baidu.com的FQDN是&quot;www.baidu.com.&quot;，com后面还有个点，这是根域；tieba.baidu.com的FQDN是&quot;tieba.baidu.com.&quot;。 域的分层授权 域是从上到下授权的，每一层都只负责自己的直辖下层，而不负责下下层。例如根域给顶级域授权，顶级域给普通域授权，但是根域不会给普通域授权。和现实中的行政管理不一样，域的授权和管理绝对不会向下越级，因为它根本不知道下下级的域名是否存在。 DNS解析流程 以访问www.baidu.com为例。 (1).客户端要访问www.baidu.com，首先会查找本机DNS缓存，再查找自己的hosts文件，还没有的话就找DNS服务器（这个DNS服务器就是计算机里设置指向的DNS）。 (2).DNS服务器收到询问请求，首先查看自己是否有www.baidu.com的缓存，如果有就直接返回给客户端，没有就越级上访到根域&quot;.&quot;，并询问根域。 (3).根域看到是找.com域的，把到.com域的路(地址)告诉DNS服务器，让DNS服务器去找.com询问。 (4).DNS服务器去找.com，”.com”一看是自己辖下的baidu.com，就把baidu.com的IP地址给DNS服务器，让它去找baidu.com。 (5).DNS找到baidu.com，baidu.com发现DNS服务器要找的是自己区域里的www主机，就把这个主机IP地址给了DNS服务器。 (6).DNS服务器把得到的www.baidu.com的IP结果告诉客户端，并缓存一份结果在自己机器中(默认会缓存，因为该服务器允许为客户端递归，否则不会缓存非权威数据)。 (7).客户端得到回答的IP地址后缓存下来，并去访问www.baidu.com，然后www.baidu.com就把页面内容发送给客户端，也就是百度页面。 最后要说明的是： 1.本机查找完缓存后如果没有结果，会先查找hosts文件，如果没有找到再把查询发送给DNS服务器，但这仅仅是默认情况，这个默认顺序是可以改变的。在/etc/nsswitch.conf中有一行” hosts: files dns”就是定义先查找hosts文件还是先提交给DNS服务器的，如果修改该行为”hosts: dns files”则先提交给DNS服务器，这种情况下hosts文件几乎就不怎么用的上了。 2.由于缓存是多层次缓存的，所以真正的查询可能并没有那么多步骤，上图的步骤是完全没有所需缓存的查询情况。假如某主机曾经向DNS服务器提交了www.baidu.com的查询，那么在DNS服务器上除了缓存了www.baidu.com的记录，还缓存了&quot;.com&quot;和&quot;baidu.com&quot;的记录，如果再有主机向该DNS服务器提交ftp.baidu.com的查询，那么将跳过&quot;.&quot;和&quot;.com&quot;的查询过程直接向baidu.com发出查询请求。 /etc/resolv.conf文件 这个文件主要用于定义dns指向，即查询主机名时明确指定使用哪个dns服务器。该文件的详细说明见Linux网络管理之：/etc/resolv.conf。 例如此文件中指定了”nameserver 8.8.8.8”，则每当要查询主机名时，都会向8.8.8.8这台dns服务器发起递归查询，这台dns服务器会帮忙查找到最终结果并返回给你。 当然，在后文的实验测试过程中，使用了另一种方式指定要使用的dns服务器：dig命令中使用”@dns_server”。 DNS术语递归查询和迭代查询 例如A主机要查询C域中的一个主机，A所指向的DNS服务器为B，递归和迭代查询的方式是这样的： 递归查询：A –&gt; B –&gt; C –&gt; B –&gt; A 迭代查询：A –&gt; B A –&gt; C –&gt; A 将递归查询和迭代查询的方式放到查询流程中，就如下图所示。(未标出Client指向的DNS服务器) 也就是说，递归的意思是找了谁谁就一定要给出答案。那么允许递归的意思就是帮忙去找位置，如A对B允许递归，那么B询问A时，A就去帮忙找答案，如果A不允许对B递归，那么A就会告诉B的下一层域的地址让B自己去找。 可以想象，如果整个域系统都使用递归查询，那些公共的根域和顶级域会忙到死，因此更好的方案就是把这些压力分散到每个个人定制的DNS服务器。 所以DNS的解析流程才会如下图。并且在客户端到DNS服务器端的这一阶段是递归查询，从DNS服务器之后的是迭代查询。也就是说，顶级域和根域出于性能的考虑，是不允许给其他任何机器递归的。 为什么客户端到DNS服务器阶段是递归查询？因为客户端本身不是DNS服务器，它自己是找不到互联网上的域名地址的，所以只能询问DNS服务器，最后一定由DNS服务器来返回答案，所以DNS服务器需要对这个客户端允许递归。因此，dns解析器(nslookup、host、dig等)所发出的查询都是递归查询。 权威服务器和(非)权威应答 权威服务器（权威者）可以理解为直接上层域的DNS服务器。例如www.baidu.com这台主机的上层域是baidu.com，那么对www来说，它的权威服务器就是baidu.com这个域内负责解析的DNS服务器，而对于baidu.com这个主机来说，它的权威服务器是.com这个域负责解析的DNS服务器。 更具体的说，某域的权威服务器是可以直接查看该域数据(即区域数据文件)的DNS服务器，主、从DNS服务器都是权威服务器。 只有权威服务器给出的应答才是权威应答，否则就是非权威应答。为什么呢？因为一个域中所有的主机都是在DNS服务器中的区域数据文件中记录的，对于主机来说，它们的位置只有直接上层才知道在哪里。 因此如果解析www.baidu.com时要获得权威应答，应该将DNS指向baidu.com这个域内负责解析的DNS服务器。 只有权威服务器直接给出的答案才是永远正确的，通过缓存得到的答案基本都是非权威应答。当然这不是一定的，因为权威服务器给的答案也是缓存中的结果，但是这是权威答案。DNS服务器缓存解析的数据库时间长度是由权威服务器决定的。 DNS缓存 在Client和DNS服务器这些个人订制的DNS解析系统中都会使用缓存来加速解析以减少网络流量和查询压力，就算是解析不到的否定答案也会缓存。 但是要访问的主机IP可能会改变，所有使用缓存得到的答案不一定是对的，因此缓存给的答案是非权威的，只有对方主机的上一级给的答案才是权威答案。缓存给的非权威答案应该设定缓存时间，这个缓存时间的长短由权威者指定。 另外访问某个域下根本不存在的主机，这个域的DNS服务器也会给出答案，但是这是否定答案，否定答案也会缓存，并且有缓存时间。例如某个Client请求51cto.com域下的ftp主机，但是实际上51cto.com下面可能根本没有这个ftp主机，那么51cto.com就会给否定答案，为了防止Client不死心的访问ftp搞破坏，51cto.com这个域负责解析的DNS服务器有必要给Client指定否定答案的缓存时间。 主、从dns服务器 dns服务器也称为name server，每个域都必须有dns服务器负责该域相关数据的解析。但dns服务器要负责整个域的数据解析，压力相对来说是比较大的，且一旦出现问题，整个域都崩溃无法向外提供服务，这是非常严重的事。所以，无论是出于负载均衡还是域数据安全可用的考虑，两台dns服务器已经是最低要求了，多数时候应该配置多台dns服务器。 多台dns服务器之间有主次之分，主dns服务器称为master，从dns服务器称为slave。slave上的域数据都是从master上获取的，这样slave和master就都能向外提供名称解析服务。 资源记录(Resource Record,RR) 对于提供DNS服务的系统(DNS服务器)，域名相关的数据都需要存储在文件(区域数据文件)中。这些数据分为多种类别，每种类别存储在对应的资源记录(resource record,RR)中。也就是说，资源记录既用来区分域数据的类型，也用来存储对应的域数据。 DNS的internet类中有非常多的资源记录类型。常用的是SOA记录、NS记录、A记录(IPV6则为AAAA记录)、PTR记录、CNAME记录、MX记录等。 (1).SOA记录：start of authority，起始授权机构。该记录存储了一系列数据，若不明白SOA记录，请结合下面的NS记录，SOA更多的信息见”子域”部分的内容。格式如下：123456longshuai.com. IN SOA dnsserver.longshuai.com. mail.longshuai.com. ( 1 3h 1h 1w 1h ) 第四列指定了”dnsserver.longshuai.com.”为该域的master DNS服务器。 第五列是该域的管理员邮箱地址，但注意不能使用@格式的邮箱，而是要将@符号替换为点”.”，正如上面的例子”mail.longshuai.com.”，其实际表示的是”mail@longshuai.com“。 第六列使用括号将几个值包围起来。第一个值是区域数据文件的序列编号serial，每次修改此区域数据文件都需要修改该编号值以便让slave dns服务器同步该区域数据文件。第二个值是刷新refresh时间间隔，表示slave dns服务器找master dns服务器更新区域数据文件的时间间隔。第三个值是重试retry时间间隔，表示slave dns服务器找master dns服务器更新区域数据文件时，如果联系不上master，则等待多久再重试联系，该值一般比refresh时间短，否则该值表示的重试就失去了意义。第四个值是过期expire时间值，表示slave dns服务器上的区域数据文件多久过期。第五个值是negative ttl，表示客户端找dns服务器解析时，否定答案的缓存时间长度。这几个值可以分行写，也可以直接写在同一行中使用空格分开，所以，上面的SOA记录可以写成如下格式： 1longshuai.com. IN SOA dnsserver.longshuai.com. mail.longshuai.com. ( 1 3h 1h 1w 1h ) 前三列是声明性的语句，表示”longshuai.com.”这个域内的起始授权机构为第四列的值”dnsserver.longshuai.com.”所表示的主机。第五列和第六列是SOA的附加属性数据。 每个区域数据文件中都有且仅能有一个SOA记录，且一般都定义为区域数据文件中的资源记录。 注意，资源记录的作用之一是存储域相关的对应数据，所以第4、5、6列表示的是该SOA记录所存储的相关值。 (2).NS记录：name server，存储的是该域内的dns服务器相关信息。即NS记录标识了哪台服务器是DNS服务器。格式如下：1longshuai.com. IN NS dnsserver.longshuai.com. 前三列仍然是声明性语句，表示”longshuai.com.”域内的DNS服务器(name server)为第四列值所表示的”dnsserver.longshuai.com.”主机。 如果一个域内有多个dns服务器，则必然有主次之分，即master和slave之分。但在NS记录上并不能体现主次关系。例如： 12longshuai.com. IN NS dnsserver1.longshuai.com.longshuai.com. IN NS dnsserver2.longshuai.com. 表示主机”dnsserver1.longshuai.com.”和主机”dnsserver2.longshuai.com.”都是域”longshuai.com.”内的dns服务器，但没有区分出主次dns服务器。 很多人搞不懂SOA记录，也很容易混淆SOA和NS记录。其实，仅就它们的主要作用而言，NS记录仅仅只是声明该域内哪台主机是dns服务器，用来提供名称解析服务，NS记录不会区分哪台dns服务器是master哪台dns服务器是slave。而SOA记录则用于指定哪个NS记录对应的主机是master dns服务器，也就是从多个dns服务器中挑选一台任命其为该域内的master dns服务器，其他的都是slave，都需要从master上获取域相关数据。由此，SOA的名称”起始授权机构”所表示的意思也就容易理解了。 (3).A记录：address，存储的是域内主机名所对应的ip地址。格式如下：1dnsserver.longshuai.com. IN A 172.16.10.15 客户端之所以能够解析到主机名对应的ip地址，就是因为dns服务器中的有A记录存储了主机名和ip的对应关系。AAAA记录存储的是主机名和ipv6地址的对应关系。 (4).PTR记录：pointer，和A记录相反，存储的是ip地址对应的主机名，该记录只存在于反向解析的区域数据文件中(并非一定)。格式如下：116.10.16.172.in-addr.arpa. IN PTR www.longshuai.com. 表示解析172.16.10.16地址时得到主机名”www.longshuai.com.&quot;的结果。 (5).CNAME记录：canonical name，表示规范名的意思，其所代表的记录常称为别名记录。之所以如此称呼，就是因为为规范名起了一个别名。什么是规范名？可以简单认为是fqdn。格式如下：1www1.longshuai.com. IN CNAM www.longshuai.com. 最后一列就是规范名，而第一列是规范名即最后一列的别名。当查询”www1.longshuai.com.”，dns服务器会找到它的规范名”www.longshuai.com.&quot;，然后再查询规范名的A记录，也就获得了对应的IP地址并返回给客户端。 CNAME记录非常重要，很多时候使用CNAME可以解决很复杂的问题。而且目前常用的CDN技术有一个步骤就是在dns服务器上设置CNAME记录，将客户端对资源的请求引导到与它同网络环境(电信、网通)以及地理位置近的缓存服务器上。关于CDN的简介，见下文CDN和DNS的关系。 (6).MX记录：mail exchanger，邮件交换记录。负责转发或处理该域名内的邮件。和邮件服务器有关，且话题较大，所以不多做叙述，如有深入的必要，请查看《dns &amp; bind》中”Chapter 5. DNS and Electronic Mail”。 关于资源记录，最需要明确的概念就是它不仅仅用来区分和标识区域数据的类型，还用来存储对应的域数据。 安装阶段请关注下一章！","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"DNS","slug":"DNS","permalink":"http://yoursite.com/tags/DNS/"}]},{"title":"安装管理包：rpm包和yum包","slug":"rpm管理包 和 yum管理包(1)","date":"2017-01-31T16:00:00.000Z","updated":"2018-06-19T08:08:02.964Z","comments":true,"path":"2017/02/01/rpm管理包 和 yum管理包(1)/","link":"","permalink":"http://yoursite.com/2017/02/01/rpm管理包 和 yum管理包(1)/","excerpt":"包基础知识包名称 在rhel/centos/fedora上，包的名称以rpm结尾，分为二进制包和源码包。源码包以”.src.rpm”结尾，它是未编译过的包，可以自行进行编译或者用其制作自己的二进制rpm包，非”.src.rpm”结尾的包都是二进制包，都是已经编译完成的，安装rpm包的过程实际上就是将包中的文件复制到Linux上，有可能还会在复制文件的前后执行一些命令，如创建一个必要的用户，删除非必要文件等。","text":"包基础知识包名称 在rhel/centos/fedora上，包的名称以rpm结尾，分为二进制包和源码包。源码包以”.src.rpm”结尾，它是未编译过的包，可以自行进行编译或者用其制作自己的二进制rpm包，非”.src.rpm”结尾的包都是二进制包，都是已经编译完成的，安装rpm包的过程实际上就是将包中的文件复制到Linux上，有可能还会在复制文件的前后执行一些命令，如创建一个必要的用户，删除非必要文件等。 注意区分源码包和源码的概念，源码一般是打包压缩后的文件(如.tar.gz结尾的文件)。源码包中包含了源码，还包含了一些有助于制作二进制rpm的文件。最有力的说明就是源码编译安装的程序都没有服务启动脚本(/etc/init.d/下对应的启动脚本)，而二进制rpm包安装的就有，因为二进制rpm包都是通过源码包”.src.rpm”定制而来，在源码包中提供了必要的文件(如服务启动脚本)，并在安装rpm的时候复制到指定路径下。 回归正题，一个rpm包的名称分为包全名和包名，包全名如httpd-2.2.15-39.el6.centos.x86_64.rpm，包全名中各部分的意义如下：123456httpd 包名2.2.15 版本号，版本号格式[ 主版本号.[ 次版本号.[ 修正号 ] ] ]39 软件发布次数el6.centos 适合的操作系统平台以及适合的操作系统版本x86_64 适合的硬件平台，硬件平台根据cpu来决定，有i386、i586、i686、x86_64、noarch或者省略，noarch或省略表示不区分硬件平台rpm 软件包后缀扩展名 使用rpm工具管理包时，如果要操作未安装的包，则使用包全名，如安装包，查看未安装包的信息等；如果要操作已安装的rpm包，则只需要给定其包名即可，如查询已装包生成了哪些文件，查看已装包的信息等。 而对于yum工具来说，只需给定其包名即可，若有需要，再指定版本号，如明确指明要安装1.6.10版本的tree工具，yum install tree-1.6.10。 rpm管理包 rpm包被安装后，会在/var/lib/rpm下会建立已装rpm数据库，以后有任何rpm的升级、查询、版本比较等包的操作都是从这个目录下获取信息并完成相应操作的。 12345[root@xuexi ~]# ls /var/lib/rpm/ Basenames __db.003 Group Packages Requirename TriggernameConflictname __db.004 Installtid Providename Requireversion__db.001 Dirnames Name Provideversion Sha1header__db.002 Filedigests Obsoletename Pubkeys Sigmd5 安装包后的文件分布 rpm安装完成后，相关的文件会复制到多个目录下(具体复制的路径是在制作rpm包时指定的)。一般来说，分布形式差不多如下表。 123456789101112/etc放置配置文件的目录/bin、/sbin、/usr/bin或/usr/sbin一些可执行文件/lib、/lib64、/usr/lib(/usr/lib64)一些库文件/usr/include一些头文件/usr/share/doc一些基本的软件使用手册与帮助文件/usr/share/man一些 man page 档案 rpm安装、升级、卸载 rpm工具安装、升级和卸载的功能都很少使用。对于安装来说，它需要人为解决包的依赖关系，这是极其令人恶心的事对于升级来说，基本上都会使用yum工具进行安装和升级，而卸载行为在Linux上很少出现，大不了直接覆盖重装。 12345678910111213rpm -ivhUe --nodeps --test --force --prefix选项说明：-i 表示安装，install的意思-v 显示安装信息，还可以&quot;-vv&quot;、&quot;-vvv&quot;，v提供的越多显示信息越多-h 显示安装进度，以#显示安装的进度-U 升级或升级包-F 只升级已安装的包-e 卸载包，卸载也有依赖性,&quot;--erase&quot;--nodeps 忽略依赖性强制安装或卸载(no dependencies)--test 测试是否能够成功安装指定的rpm包--prefix 新路径 自行指定安装路径而不是使用默认路径，基本上都不支持该功能，功能极其简单的软件估计才支持重定位安装路径--force 强制动作--replacepkgs 替换安装，即重新覆盖安装。 有时误删文件可以不用卸载再装，直接使用–replacepkgs选项再次安装即可。 rpm包另一个缺陷是只能安装本地或给定url路径的rpm包。 注意：不要对内核进行升级；多版本的内核可以并存，因此可以执行安装操作。rpm查询功能 rpm工具的安装功能很少使用，毕竟解决依赖关系是不是件容易的事。但是rpm的查询功能则非常实用。 123456789-q[p] -q查询已安装的包，-qp查询未安装的包。它们都可接下面的参数 -a 查询所有已安装的包，也可以指定通配符名称进行查询 -i 查询指定包的信息（版本、开发商、安装时间等）。从这里面可以查看到软件包属于哪个包组。 -l 查询包的文件列表和目录（包在生产的时候就指定了文件路径，因此可查未装包） -R 查询包的依赖性（Required） -c 查询安装后包生成的配置文件 -d 查询安装后包生成的帮助文档-f 查询系统文件属于哪个已安装的包（接的是文件而不是包）--scripts 查询包相关的脚本文档。脚本文档分四类：安装前运行、安装后运行、卸载前运行、卸载后运行 例如：(1).查询文件/etc/yum.conf是通过哪个包安装的。12[root@xuexi cdrom]# rpm -qf /etc/yum.confyum-3.2.29-60.el6.centos.noarch (2).查询安装httpd时生成了哪些目录和文件，还可以过滤出提供了哪些命令行工具。12rpm -ql httpdrpm -ql httpd | grep &apos;bin/&apos; (3).查询某个未安装包的依赖性如zip-3.0-1.el6.x86_64.rpm的依赖性。123456789101112[root@xuexi cdrom]# rpm -qRp zip-3.0-1.el6.x86_64.rpmlibc.so.6()(64bit) libc.so.6(GLIBC_2.2.5)(64bit) libc.so.6(GLIBC_2.3)(64bit) libc.so.6(GLIBC_2.3.4)(64bit) libc.so.6(GLIBC_2.4)(64bit) libc.so.6(GLIBC_2.7)(64bit) rpmlib(CompressedFileNames) &lt;= 3.0.4-1rpmlib(FileDigests) &lt;= 4.6.0-1rpmlib(PayloadFilesHavePrefix) &lt;= 4.0-1rtld(GNU_HASH) rpmlib(PayloadIsXz) &lt;= 5.2-1 实际上，查看包的依赖性时，使用yum-utils包中的repoquery工具更好，”repoquery -R pkg_name”会更简洁。yum-utils中包含了好几个非常实用的包管理工具，可以大致都了解下。 提取rpm包中文件 安装rpm包会安装rpm中所有文件，如果将某个文件删除了，除了重装rpm，还可以通过从rpm包提取缺失文件的方式来修复。在win上安装个万能压缩工具”好压”，可以直接打开rpm包，然后从中解压需要的文件出来。但是在Linux上，过程还是有点小复杂的，其中涉及了cpio这个古来的归档工具。 方法：使用rpm2cpio命令组合cpio -idv命令的方式来提取。 rpm2cpio是将rpm转换为cpio格式归档文件的命令，有了cpio文件，就可以使用cpio命令对其进行相关的操作。 cpio命令是从归档文件中提取文件或向归档文件中写入文件的工具，一般都从标准输入或输出操作归档文件，所以都使用管道或重定向符号。 1234-i： 运行在copy-in模式，即从归档文件中将文件copy出来，即提取文件（提取）-o： 运行在copy-out模式，将文件copy到归档文件中，即将文件拷贝到归档文件中（写入）-d： 需要目录时自动建立目录-v： 显示信息 提取rpm包文件的一般格式为以下格式：1rpm2cpio package_full_name|cpio -idv dir_name 例如，删除/bin/ls文件，将导致ls命令不可用，使用文件提取的方式去修复。1234567891011121314151617181920[root@xuexi cdrom]# which ls # 查找需要删除的ls文件位置alias ls=&apos;ls --color=auto&apos; /bin/ls[root@xuexi cdrom]# rpm -qf /bin/ls # 查找ls命令属于哪个包coreutils-8.4-37.el6.x86_64[root@xuexi cdrom]# rm -f /bin/ls # 删除ls命令[root@xuexi cdrom]# ls # ls命令已不可用-bash: /bin/ls: No such file or directory[root@xuexi ~]# yumdownloader coreutils # 下载所需的rpm包[root@xuexi ~]# rpm2cpio coreutils-8.4-37.el6.x86_64.rpm | cpio -id ./bin/ls # 提取bin/ls到当前目录下[root@xuexi ~]# dir ~/bin # 使用dir命令查看已经提取成功，dir命令功能等价于lsls[root@xuexi tmp]# cp bin/ls /bin/ # 复制ls命令到/bin下[root@xuexi tmp]# ls # 测试，ls已经可用 yum管理包 yum工具通过仓库的方式简化rpm包的管理。它从仓库中搜索相关的软件包，并自动下载和解决软件包的依赖性，非常方便。 /etc/yum.conf /etc/yum.conf是yum的默认文件，里面配置的也是全局默认项。 1234567891011121314[root@server2 ~]# cat /etc/yum.conf[main]cachedir=/var/cache/yum/$basearch/$releasever # 缓存目录keepcache=0 # 是否保留缓存，设置为1时，安装包时所下载的包将不会被删除debuglevel=2 # 调试信息的级别logfile=/var/log/yum.log # 日志文件位置exactarch=1 # 设置为1将只会安装和系统架构完全匹配的包obsoletes=1 # 是否允许更新旧的包gpgcheck=1 # 是否要进行gpg checkplugins=1 # 是否允许使用yum插件installonly_limit=5bugtracker_url=http://bugs.centos.org/set_project.php?project_id=23&amp;ref=http://bugs.centos.org/bug_report_page.php?category=yumdistroverpkg=centos-release # 指定基准包，yum会根据这个包判断发行版本 配置yum仓库 首先配置yum仓库，配置文件为/etc/yum.conf和/etc/yum.repos.d/中的”.repo”文件，其中/etc/yum.conf配置的是仓库的默认项，一般配置yum源都是在/etc/yum.repos.d/*.repo中配置。注意，该目录中任意repo文件都会被读取。 默认/etc/yum.repos.d/下会有以下几个仓库文件，除了CentOS-Base.repo，其他的都可以删掉，基本没用。 123[root@xuexi yum.repos.d]# ls /etc/yum.repos.d/CentOS-Base.repo CentOS-fasttrack.repo CentOS-Vault.repoCentOS-Debuginfo.repo CentOS-Media.repo repo文件的配置格式如下：12345678910111213141516[root@xuexi yum.repos.d]# vim CentOS-Base.repo[base] # 仓库ID，ID必须保证唯一性name # 仓库名称，可随意命名mirrorlist # 该地址下包含了仓库地址列表，包含一个或多个镜像站点，和baseurl使用一个就可以了#baseurl # 仓库地址。网络上的地址则写网络地址，本地地址则写本地地址，格式为“file://”后接路径，如file:///mnt/cdromgpgcheck=1 # 指定是否需要签名，1表示需要，0表示不需要gpgkey= # 签名文件的路径enable # 该仓库是否生效，enable=1表示生效，enable=0表示不生效cost= # 开销越高，优先级越低【repo配置文件中可用的宏：】$releasever：程序的版本，对Yum而言指的是redhat-relrase版本。只替换为主版本号，如Redhat6.5 则替换为6$arch：系统架构$basharch：系统基本架构，如i686，i586等的基本架构为i386$YUM0-9：在系统定义的环境变量，可以在yum中使用 repo配置示例：配置epel仓库 系统发行商在系统中放置的rpm包一般版本都较老，可能有些包有较大的延后性。而epel是由fedora社区维护的高质量高可靠性的安装源，有很多包是比系统包更新的，且多出很多系统没有的包。总之，用到epel的机会很多很多，所以就拿来当配置示例了。 有两种方式可以使用epel源。方法一：安装epel-release-noarch.rpm1shell&gt; rpm -ivh epel-release-latest-6.noarch.rpm 安装后会在/etc/yum.repo.d/目录下生成两个epel相关的repo文件，其中一个是epel.repo。此文件中epel的源设置在了fedora的镜像站点上，这对国内网来说可能会较慢，可以修改它为下面的内容。 12345678[epel]name=Extra Packages for Enterprise Linux 6 - $basearchbaseurl=http://mirrors.sohu.com/fedora-epel/6Server/$basearch/#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-6&amp;arch=$basearchfailovermethod=priorityenabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 方法二：直接增加epel仓库在/etc/yum.repos.d/下任意一个repo文件中添加上epel的仓库即可。12345[epel]name=epelbaseurl=http://mirrors.sohu.com/fedora-epel/6Server/$basearch/enabled=1gpgcheck=0 然后清除缓存再建立缓存即可。1shell&gt; yum clean all ; yum makecache yum命令不同的版本，yum命令可能功能上有所不同，例如在CentOS 7上的yum有–downloadonly的功能，而在CentOS 6.6上就没有(更新yum包后就有了)。此处介绍几个yum命令。1234567891011121314151617181920212223242526272829303132333435Usage: yum [options] COMMANDList of Commands:help 命令的帮助信息，用法：yum help command，如yum help install则查看install命令的用法说明clean 清除缓存数据，如yum clean allmakecache 生成元数据缓存数据，yum makecachedeplist 列出包的依赖关系erase 卸载包fs 为当前文件系统创建快照，或者列出或删除当前已有快照。快照是非常有用的，升级或打补丁前拍个快照，就能放心地升级或打补丁了fssnapshot 同fs一样groups 操作包组history 查看yum事务信息，yum是独占模式的进程，所以有时候查看事务信息还是有用的info 输出包或包组的信息，例如该包是谁制作的，大概是干什么用的，来源于哪个包组等信息install 包安装命令list 列出包名，一般会结合grep来搜索包，如yum list all | grep -i zabbixprovides 搜索给定的内容是谁提供的，可用来搜索来源于个包，如CentOS 7上mysql被mariadb替代，搜索Mysql提供者时就能找出包mariadbreinstall 重新安装包repolist 列出可用的仓库列表search 给定字符串搜索相关包，并给出相关包较为详细的信息update 更新包 Options: -R [minutes], --randomwait=[minutes]：最多等待时间 -q, --quiet 安静模式 -v, --verbose 详细模式 -y, --assumeyes 对所有问题回答yes --assumeno 对所有问题回答no --enablerepo=[repo] 启用一个或多个仓库，可用通配符通配仓库ID --disablerepo=[repo] 禁用一个或多个仓库，可用通配符通配仓库ID -x [package], --exclude=[package] 通配要排除的包 --nogpgcheck 禁用gpgcheck --color=COLOR 带颜色 --downloadonly 仅下载包，不安装或升级。默认下载在yum的缓存目录中，默认为/var/cache/yum/$basearch/$releasever --downloaddir=DLDIR 指定下载目录 很多时候，yum操作失败的原因是repo的配置错误，或者缓存未更新。 yum操作包组1234567[root@server2 ~]# yum help groupsLoaded plugins: fastestmirror, langpacksgroups [list|info|summary|install|upgrade|remove|mark] [GROUP]Display, or use, the groups informationaliases: group, grouplist, groupinfo, groupinstall, groupupdate, groupremove, grouperase 所以，可以使用别名group, grouplist, groupinfo, groupinstall, groupupdate, groupremove, grouperase替代相应的命令。 如安装包组yum groups install pkg_groupname，也可以yum groupinstall pkg_groupname。 源码编译安装程序源码编译的几个阶段拿到源码的压缩包后，首先就是解压，这就不需说了。解压后，进入解压目录，这是必须动作，之后就是源码编译的一般步骤。并非适用所有程序的编译，但知道过程之后也可以举一反三了。 1.阅读解压目录中的INSTALL/README文件。如果不是对着官方手册或文档，那么在安装前务必读一读INSTALL文件或README文件，只需读其中如何安装的部分即可。 2.解压后的目录里一般还有configure文件（也可能是config文件）。执行”./configure”或带有编译选项的”./configure”，检查系统环境是否符合满足安装要求，并将定义好的安装配置写入和系统环境信息写入Makefile文件中。里面包含了如何编译、启用哪些功能、安装路径等信息。 3.执行make命令进行编译。make命令会根据Makefile文件进行编译。编译工作主要是调用编译器(如gcc)将源码编译为可执行文件，通常需要一些函数库才能产生一个完整的可执行文件。 4.make install将上一步所编译的数据复制到指定的目录下。这就已经完成编译程序的过程了。 configure脚本的通用功能 configure一般都会接受以下几个编译选项： –prefix= ：指定安装的路径–sysconfdir= ：指定配置文件目录–enable-feature ：启用某个特性–disable-fecture ：禁用特性–with-function ：启用某功能–without-function ：禁用某功能 不同的程序，其configure选项不尽相同，应使用”./configure –help”获取具体的信息。 源码编译安装须知 1.上面的每一个步骤都不能出错，否则后一步都不能正常进行。 2.上面的步骤每一步如果出现警告或错误，如果步骤未停止而是继续，则属于可忽略错误或警告，不影响安装。但是进行的步骤停止了出现警告或错误，则根据步骤考虑对策。可以使用“$?”命令查看上一个命令是否正确执行，如果是返回0则是正确，其他的则是错误。 3.卸载时，只需删除安装目录即可。因此，若要便于删除，最好将源码程序安装在/usr/local/对应的目录下。例如apache2安装在/usr/local/apache2下。 4.通过源码编译的软件，需要做一些后续操作，虽非必须，但是都是个性化定制，方便以后的操作。个性化定制大致包括以下几项：(1).将安装路径下的命令路径加入到环境变量。 123shell&gt; echo &quot;export PATH=/usr/local/apache/bin:$PATH&quot; &gt; /etc/profile.d/apache.shshell&gt; chmod +x /etc/profile.d/apache.shshell&gt; source /etc/profile.d/apache.sh (2).按需求定制服务启动脚本，并考虑是否加入开机启动项。 (3).输出头文件和库文件。 头文件库文件很多时候只是为其他程序提供的，所以可能不输出它们的路径也不会影响该程序的运行。 123456# 输出头文件shell&gt; ln -s /usr/local/apache/include /usr/include/apache# 输出库文件shell&gt; echo &quot;/usr/local/apache/lib&quot; &gt;/etc/ld.so.conf.d/apache.confshell&gt; ldconfig (4).导出man路径 1shell&gt; echo &quot;MANPATH /usr/local/apache/man&quot; &gt;&gt; /etc/man.conf","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"rpm","slug":"rpm","permalink":"http://yoursite.com/tags/rpm/"}]},{"title":"Linux 的一些基础练习题","slug":"Linux 的一些基础练习题","date":"2016-11-28T16:00:00.000Z","updated":"2018-06-10T13:16:34.982Z","comments":true,"path":"2016/11/29/Linux 的一些基础练习题/","link":"","permalink":"http://yoursite.com/2016/11/29/Linux 的一些基础练习题/","excerpt":"练习题：1，显示当前时间，格式为：2016-06-18 10:20:30 答案：date “+%F,%T” 或者 date “+%F %H:%M:%S” 2，显示前天是星期几？ 答案：date -d “-2 day” +%A 知识点：一 ，date +%s 是把当前时间转化为秒数 二， date -d @”1523604170″ 把秒数转化回来","text":"练习题：1，显示当前时间，格式为：2016-06-18 10:20:30 答案：date “+%F,%T” 或者 date “+%F %H:%M:%S” 2，显示前天是星期几？ 答案：date -d “-2 day” +%A 知识点：一 ，date +%s 是把当前时间转化为秒数 二， date -d @”1523604170″ 把秒数转化回来 3，今天18:30自动关机，并提示用户。 答案：hutdown -h 18:30 “dao dian guan ji，18:30” 如果想取消此操作输入： shutdown -c 4，在本机字符终端登录时，除显示原有信息外，在显示当前登录终端号，主机名和当前时间。 答案：vim /etc/profile.d/kaiji.sh 进去后输入：#**echo your hostname is hostnamewho am i 5，显示/var目录下所有以l开头，以一个小写字母结尾，且中间出现至少一位数字的文件或目录。 答案：ls /var/l[0-9][[:lower:]] 6，显示/etc目录下以任意一位数字开头，且以非数字结尾的文件或目录。 答案：ls /etc/[0-9]*[^0-9] 7，显示/etc/目录下以非字母开头，后面跟了一个字母及其他任意长度任意字符的文件或目录。 答案：ls /etc/[^[:alpha:]][a-zA-Z]* 8，显示/etc/目录下所有以rc开头，并后面是0-6之间的数字，其他为任意字符的文件或目录。 答案：ls /etc/rc[0-6]* 9，显示/etc目录下，所有以.d结尾的文件或目录。 答案：ls /etc/*.d 10，显示/etc目录下，所有.conf结尾，且以m,n,r,p开头的文件或目录。 答案：ls /etc/[m,n,r,p]*.conf 11，只显示/root下的隐藏文件和目录。 只显示/etc下的非隐藏目录 答案：ls -d /root/. ls /etc/[^.]/ -d 12，定义别名命令baketc,每天将/etc/目录下的所有文件，备份到/app独立的子目录下，并要求子目录格式为backupYYYY-mm-dd备份过程可见。 答案：alias baketc=”cp -av /etc /data/backupdate +%F” 13，创建/app/rootdir目录，并复制/root下所有文件到该目录内，要求保留原有权限。 答案：mkdir -p /app/rootdir cp -a /root /app/rootdir/ 14，如何创建/testdir/dir1/x,/testdir/dir/y,/testdir/dir/x/a,/testdir/dir/x/b,/testdir/dir/y/a,/testdir/dir/y/b. 答案：mkdir -p /testdir/dir1/{x,y}/{a,b} 15，如何创建/testdir/dir2/x,/testdir/dir2/y,/testdir/dir2/x/a,/testdir/dir2/x/b. 答案：mkdir -p /testdir/dir2/{x/{a,b},y} 16，如何创建/testdir/dir3,/testdir/dir4,/testdir/dir5,/testdir/dir5/dir6,/testdir/dir5/dir7. 答案：mkdir -p /testdir/{dir3,dir4,dir5/{dir6,dir7}} 17，将/etc/issue文件中的内容转化为大写后保存至/tmp/issue.out文件中。 答案：cat /etc/issue | tr “[a-z]” “[A-Z]” &gt; /tmp/issue.out 18，将当前系统登录用户的信息转换为大写后保存至/tmp/who.out文件中。 答案：who | tr “[a-z]” “[A-Z]” &gt;/tmp/who.out 19，一个linux用户给root发邮件，要求邮件标题为” help”,邮件正文如下：Heello,i am 用户名，The system version is here ,please help me to check it,thanks! 操作系统版本信息 答案：mail -s “help” root &lt;&lt;123 Hello,I am $USERThe system version is here,please help me to check it,thanks!cat /etc/centos-release123 20,将/root/下文件列表，显示成一行，并文件名之间用空格隔开。 答案：ls /root | tr “\\n” ” ” 21，计算1+2+3+..+99+100的总和。 答案：echo {1..100}|tr ” ” “+”|bc 22，删除Windows文本文件中的^M字符 答案：tr -d “\\15” win.txt 23，处理字符串 “xt.,l 1 jr#!$mn 2 c*/fe 3 uz 4” ,只保留其中的数字和空格。 答案：echo “xt.,l 1 jr#hostnamemn 2 c*/fe 3 uz 4” |tr -dc “[:digit:][:space:]” 24,将PATH变量每个目录显示在独立的一行。 答案：echo $PATH |tr “:” “\\n” 25，将指定文件中0-9分别代替成a-j . 答案：先创建文件touch f1 给f1 vim 输入0-9 cat f1 | tr “[0-9]” “[a-j]” 26，将文件/etc/centos-release中每个单词（由字母组成）显示在独立的一行，并无空行。 答案：cat /etc/centos-release |tr -c “[:alpha:]” ” ” |tr -s ” ” “\\n” 27，创建用户gentoo,附加组为bin和root,默认shell为/bin/csh,注释信息为”Gentoo Distribution”. 答案：useradd -G bin,root -s /bin/csh -c “Gentoo Distribution” gentoo 28，创建下面的用户，组和组成员关系名字为webs的组 用户nginx使用webs作为附加组 用户varnish,也使用webs作为附加组用户mysql,不可交互登录系统，且不是webs的成员，nbinx,varnish,mysql密码都是magedu 答案：12345678groupadd webs useradd -G webs nginx useradd -G webs varnish useradd -s /sbin/nologin masql echo magedu |passwd –stdin nginx; echo magedu |passwd –stdin varnish; echo magedu |passwd –stdin mysql; 29，当用户docker对/testdir 目录无执行权限时，意味着无法做哪些操作？ 答案： 不能cd进去，不能查看文件详细属性，也不能去访问目录里的文件内容（即使有读权限）。 30，当用户mongodb对/testdir 目录无读权限时，意味着无法做哪些操作？ 答案：不能对目录下的文件进行访问。 31， 当用户redis 对/testdir 目录无写权限时，该目录下的只读文件file1是否可修改和删除？ 答案：不能，因为对目录没有权限，所以不能。文件能不能删，不由文件决定，而由目录决定。 32，当用户zabbix对/testdir 目录有写和执行权限时，该目录下的只读文件file1是否可修改和删除？ 答案：可以修改和删除 33，复制/etc/fstab 文件到/var/tmp 下，设置文件所有者为tomcat 读写权限，所属组为apps组有读写权限，其他人无权限。 123456答案：（一）cp -a /etc/fstab /var/tmp （二） useradd tomcat （三） groupadd apps （四） chown tomcat /var/tmp （五） chgrp apps /var/tmp （六） chmod 660 /var/tmp 34，误删除了用户git的家目录，请重建并恢复该用户家目录及相应的权限属性。 1234答案： rm -rf /home/git ; mkdir /home/git; cp -a /etc/skel/.[^.]* /home/git; chown -R git:git /home/git; 35,在/testdir/dir 里创建的新文件自动属于webs组，组apps的成员如:tomcat能对这些新文件有读写权限，组dbs的成员如：mysql只能对新文件有读权限，其他用户（不属于webs,apps,dbs）不能访问文件夹。 1234567答案： mkdir -p /testdir/dir chgrp webs /testdir/dir chmod g=s /testdir/dir setfacl -m g:apps:rw /testdir/dir setfacl -m g:dbs:r /testdir/dir chmod o= /testdir/dir 36，备份/testdir/dir 里所有文件的ACL权限到/root/acl.txt中，清除/testdir/dir中所有ACL权限，最后还原ACL权限。 123答案： getfacl -R /testdir/dir &gt; /root/acl.txt setfacl -b /testdir/dir setfacl -R –set-file=acl.txt /testdir/dir 37, 找出ifconfig “网卡名” 命令结果中本机的IPv4地址。 12345答案：（方法一）ifconfig ens33 | grep netmask | tr -s ” ” “:” |cut -d: -f3（方法二）ifconfig ens33 |egrep -o \\&lt;“(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])”\\&gt;（方法三）ifconfig ens33 | sed -n “2p” | sed -r s’@(.*inet)(.*)( netmask.*)@\\2@’ 38，查出分区空间使用率的最大百分比值。 123答案：（方法一）df | grep ^/dev | tr -s ” ” “:” | cut -d: -f5 |cut -d% -f1 | sort -nr | head -n1（方法二） df | grep -o “[0-9]\\&#123;1,3\\&#125;%” |grep -o “[0-9]\\+” |sort -nr |head -n1 39，查出用户UID最大值得用户名，UID及shell类型。 1答案：cat /etc/passwd |sort -nr -t: -k3 |head -n1 |cut -d: -f1,3,7 40，查出/tmp的权限，以数字方式显示 1答案：stat /tmp |head -n4|tail -n1|cut -d/ -f1|cut -d&apos;(‘ -f2 41， 统计当前连接本机的每个远程主机IP的连接数，并从大到小排序。 12答案： 先从桌面获取rz 获取文件，再进行处理。 cat access_log |egrep -o “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;”|sort|uniq -dc|sort -nr 42,显示/proc/meminfo 文件中以大小s开头的行（要求：使用两种方法） 123答案：（方法一）cat /proc/meminfo |egrep -oi ^s.*（方法二）cat /proc/meminfo |egrep ^[Ss].* 43，显示/etc/passwd文件中不以/bin/bash结尾的行。 1答案：cat /etc/passwd |egrep -v /bin/bash$ 44，显示用户rpc默认的shell程序。 123答案：（方法一）cat /etc/passwd |egrep rpc|cut -d: -f1,7（方法二）cat /etc/passwd |egrep rpc|sed -r ‘s/(.*:)([^:]+:?$)/\\2/’ 45，找出/etc/passwd 中的两位或三位数 1答案：cat /etc/passwd | egrep -o “[0-9]&#123;2,3&#125;” 46，显示Centos7的/etc/grub2.cfg文件中，至少以一个空白字符开头的且后面有非空白字符的行。 1答案：cat /etc/grub2.cfg |egrep ^[[:space:]][^[:space:]].*$ 47，找出”netstat -tan” 命令结果中以LISTEN后跟任意多个空白字符结尾的行。 1答案：netstat -tan |egrep .*LISTEN[[:space:]]+ 48, 显示Centos7上所有系统用户的用户名和UID。 1答案：cat /etc/passwd |egrep .*/sbin/nologin$ |cut -d: -f1,3 49，添加用户bash,testbash,basher,sh,nologin(其shell为/sbin/nologin),找出/etc/passwd用户名和shell同名的行。 1答案：cat /etc/passwd | egrep “^(.*)(:.*)\\1$” 50，利用df和grep，去出磁盘各分区利用率，并从大到小排序。 1答案：df |grep ^/dev |tr -s ” ” “:”|cut -d: -f5 |cut -d% -f1 |sort -nr|head -n1 51，显示三个用户root,mage,wang的UID和默认shell. 1答案：cat /etc/passwd |egrep ^”(root|mage|wang)” |cut -d: -f1,3,7 52，找出/etc/rc.d/init.d/functions文件中行首为某单词（包括下划线）后面跟一个小括号的行。 1答案：cat /etc/rc.d/init.d/functions | egrep “^[a-zA-Z_]+.*” 53，使用egrep取出/etc/rc.d/init.d/functions中其基名。 1答案：echo /etc/rc.d/init.d/functions |egrep -o “[^/]*/?$” 54，使用egrep取出上面 路径的目录名。 123答案：（方法一）echo /etc/rc.d/init.d/functions |egrep -o “/.*/”（方法二）echo /etc/rc.d/init.d/functions |egrep -o “(/).*\\1” 55，统计last命令中以root登录的每个主机IP地址登录次数。 1答案： last |egrep root |egrep “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;”|tr -s ” ” “:”|sort -t: -k3|cut -d: -f3|uniq -dc 56，利用扩展正则表达式分别表示0-9,10-99，100-199,200-249,250-255. 1答案： [0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5] 57,显示ifconfig命令结果中所有IPV4地址。 1答案： ifconfig | egrep -o “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;” 58，将此字符串：welcome to magedu linux 中的每个字符去重并排序，重复次数多的放在最前面。 1答案： echo “welcometomagedulinux” |grep -o “.”|sort|uniq -c|sort -nr 59，复制/etc/profile至/tmp/目录，用查找替换命令删除/tmp/profile文件中的行首的空白字符。 12345答案：cp /etc/profile /tmp/ vim /tmp/profile 命令模式下按“:”进入扩展模式输入 %s/^[[:space:]]*//g 60, 复制/etc/rc.d/init.d/functions文件至/tmp目录，用查找替换命令为/tmp/functions的每行开头为空白字符的行的行首添加一个#号。 1234567答案： cp /etc/rc.d/init.d/functions /tmp vim /tmp/functions 命令模式下按“:”进入扩展模式输入 %s/^[[:space:]] */#&amp;/ 或者 %s/[[:space:]]\\+.∗[[:space:]]\\+.∗/#\\1/g 61, 在VIM中设置tab缩进为4个字符。 1234567答案： vim /etc/vimrc 在文件最后添加： set ts=4 set expandtab set autoindent :wq 62，复制/etc/rc.d/init.d/functions文件至/tmp目录，替换/tmp/functions文件中的/etc/sysconfig/init为/var/log. 答案：cp /etc/rc.d/init.d/functions /tmpvim /tmp/functions命令模式下按“:”进入扩展模式输入 %s@\\/etc\\/sysconfig\\/init@\\/var\\/log@ 63, 删除/tmp/functions文件中所有以#开头，且#后面至少有一个空白字符的行的行首的#号。 答案：vim /tmp/functions命令模式下按“:”进入扩展模式输入%s@^#”“+.∗”“+.∗@\\1@ 64, 编写脚本/root/bin/systeminfo.sh,显示当前主机系统信息，包括主机名，IPV4，操作系统版本，内核版本，CPU型号，内存大小，硬盘大小。 答案： vim /root/bin/systeminfo.sh #** echo hostnameecho ifconfig ens33 | egrep -o “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]).){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])>“|head -n1 echo cat /etc/centos-release echo uname -r echo lscpu |grep “^Model name.*” |cut -d: -f2|tr -s “ “ echo cat /proc/meminfo |head -n1 echo lsblk |grep ‘^sda’|tr -s “ “ “%”|cut -d% -f4 :wq 65, 编写脚本/root/bin/backup.sh,可实现每日将/etc/目录备份到/root/etcYYY-mm-dd中。 vim /root/bin/backup.shcp -a /etc /root/etcdate +%F:wq 66,编写脚本/root/bin/disk.sh,显示当前硬盘分区中空间利用率最大的值。 答案： e=df|egrep ^/dev |tr -s “ “ “:”|cut -d: -f5|cut -d% -f1|sort -nr|head -n1 echo $e ：wq 67, 编写脚本/root/bin/links.sh ，显示正连接本主机的每个远程主机的IPV4地址和连接数，并按连接数从大到小排序。 答案： vim /root/bin/linsk.sh a=cat access_log |egrep -o &quot;\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;&quot;|sort|uniq -c|sort -nr echo $a 68, 编写脚本/root/bin/sumid.sh ,计算/etc/passwd 文件中的第10个用户和第20用户的ID之和。 答案：vim /root/bin/sumid.sha=cat /etc/passwd | head -n10 |tail -n1|cut -d: -f3 b=cat /etc/passwd | head -n20 |tail -n1|cut -d: -f3 let c=a+b 或 d=$[ a+b ] echo $d 69, 编写脚本/root/bin/sumspace.sh ,传递两个文件路径作为参数给脚本，计算这两个文件中所有空白行之和。 12345答案： vim /root/bin/sumspace.sh a=cat f1 |egrep ^[[:space:]]*$ |wc -l b=cat f2 |egrep ^[[:space:]]*$ |wc -l let c=a+b 70, 编写脚本/root/bin/sumfile.sh ,统计/etc ,/var,/usr 目录中共有多少个一级子目录和文件。 答案：vim /root/bin/sumfile.sha=ls /etc/ |wc -lb=ls /var/ |wc -l c=ls /usr/ |wc -llet d=a+b+c 71, 编写脚本/root/bin/argsnum.sh ,接受一个文件路径作为参数；如果参数个数小于1，则提示用户 “至少应该给一个参数”，并立即退出；如果参数个数不少于1，则显示第一个参数所指向的文件中的空白行数。 答案：vim /root/bin/argsnum.sh [ $# -lt 1] &amp;&amp; echo “At least one parameter should be given” &amp;&amp; exit[ $# -ge 1] &amp;&amp; echo egrep “^[[:space:]]*$” $1|wc -l 73, 编写脚本/root/bin/hostping.sh ,接受一个主机的IPV4地址做为参数，测试是否可连通。如果能ping通，则提示用户 “该IP地址可以访问” ；如果不可ping通，则提示用户 “该IP地址不可访问”。 答案：vim /root/bin/hostping.sh [[ $1 =~ “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]]]).){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])>” ]] || echo { “IP error”;exit; } ping $1 &amp;&amp; echo “This address can be accessed”|| echo “This address cannot be accessed” 74, 编写脚本/root/bin/checkdisk.sh , 检查磁盘分区空间和inode使用率，如果超过80%，就发广播警告空间将满。 答案：vim /root/bin/checkdisk.sh a=df |egrep ^/dev |tr -s “ “ “:” |cut -d: -f5 |cut -d% -f1|sort -nr|head -n1[[ $a -ge 80 ]] &amp;&amp; echo “zhao huo la ” || echo { “yi qie zheng chang”;exit; } 75, 编写脚本/bin/per.sh ,判断当前用户对指定参数文件，是否不可读并且不可写。 答案：[ -not -r $1 -a -not -w $1 ] &amp;&amp; echo “bu ke du ”[ −r$1−o−w$1−r$1−o−w$1 ] || echo “ke du ” 76，编写脚本/root/bin/excute.sh ,判断参数文件是否为sh后缀的普通文件，如果是，添加所有人可执行权限，否则提示用户非脚本文件。 答案：vim /root/bin/excute.sh[[ $1 =~ .*sh$ ]] &amp;&amp; chmod +x $1 || echo “bu shi jiao ben wen jian “","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"练习题","slug":"练习题","permalink":"http://yoursite.com/tags/练习题/"}]}]}