{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"","slug":"Linux 防火墙各种规则实战应用","date":"2018-08-09T07:50:51.234Z","updated":"2018-08-09T07:50:32.128Z","comments":true,"path":"2018/08/09/Linux 防火墙各种规则实战应用/","link":"","permalink":"http://yoursite.com/2018/08/09/Linux 防火墙各种规则实战应用/","excerpt":"layout: posttitle: Linux 防火墙各种规则实战应用date: 2017-7-03tags: Linux 防火墙 防火墙的概念iptables的基本认识iptables的组成iptables的基本语法iptables之forward的概念iptables之地址转换法则SNAT源地址转换的具体实现DNAT目标地址转换的具体实现firewalld介绍firewalld配置命令rich规则 安全技术入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络 访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主， 提供有针对性的指导措施和安全决策依据。一般采用旁路部署方式入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包 的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析 判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般 采用在线部署方式防火墙（ FireWall ）：隔离功能，工作在网络或主机边缘，对进出网络或主机的 数据包基于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一 组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允 许访问的策略","text":"layout: posttitle: Linux 防火墙各种规则实战应用date: 2017-7-03tags: Linux 防火墙 防火墙的概念iptables的基本认识iptables的组成iptables的基本语法iptables之forward的概念iptables之地址转换法则SNAT源地址转换的具体实现DNAT目标地址转换的具体实现firewalld介绍firewalld配置命令rich规则 安全技术入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络 访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主， 提供有针对性的指导措施和安全决策依据。一般采用旁路部署方式入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包 的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析 判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般 采用在线部署方式防火墙（ FireWall ）：隔离功能，工作在网络或主机边缘，对进出网络或主机的 数据包基于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一 组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允 许访问的策略 防火墙的分类防火墙的分类主机防火墙：服务范围为当前主机网络防火墙：服务范围为防火墙一侧的局域网硬件防火墙：在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件 实现，Checkpoint,NetScreen 软件防火墙：运行于通用硬件平台之上的防火墙的应用软件网络层防火墙：OSI下面第三层 应用层防火墙/代理服务器：代理网关，OSI七层 网络型防火墙网络层防火墙 包过滤防火墙 网络层对数据包进行选择，选择的依据是系统内设置的过滤逻辑，被称为访问控制 列表（ACL），通过检查数据流中每个数据的源地址，目的地址，所用端口号和协议 状态等因素，或他们的组合来确定是否允许该数据包通过 优点：对用户来说透明，处理速度快且易于维护 缺点：无法检查应用层数据，如病毒等 应用层防火墙应用层防火墙/代理服务型防火墙（Proxy Service） 将所有跨越防火墙的网络通信链路分为两段 内外网用户的访问都是通过代理服务器上的“链接”来实现 优点：在应用层对数据进行检查，比较安全 缺点：增加防火墙的负载 现实生产环境中所使用的防火墙一般都是二者结合体 即先检查网络数据，通过之后再送到应用层去检查 iptables的基本认识Netfilter组件 内核空间，集成在linux内核中 扩展各种网络服务的结构化底层框架 内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、FORWARD、 PREROUTING、POSTROUTING)，而这五个hook function向用户开放，用户可以通过一 个命令工具（iptables）向其写入规则 由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则被分组放 在链（chain）上 三种报文流向： 流入本机：PREROUTING –&gt; INPUT–&gt;用户空间进程 流出本机：用户空间进程 –&gt;OUTPUT–&gt; POSTROUTING 转发：PREROUTING –&gt; FORWARD –&gt; POSTROUTING iptables的基本认识防火墙工具iptables 命令行工具，工作在用户空间 用来编写规则，写好的规则被送往netfilter，告诉内核如何去处理信息包firewalld CentOS 7引入了新的前端管理工具管理工具： firewall-cmd 命令行 firewall-config 图形 iptables的组成 iptables由四个表和五个链以及一些规则组成 四个表table：filter、nat、mangle、raw filter表:过滤规则表，根据预定义的规则过滤符合条件的数据包 nat表:network address translation 地址转换规则表 mangle:修改数据标记位规则表 Raw:关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度 优先级由高到低的顺序为:raw–&gt;mangle–&gt;nat–&gt;filter 五个内置链chain INPUT OUTPUT FORWARD PREROUTING POSTROUTING IPTABLES和路由路由功能发生的时间点 报文进入本机后 • 判断目标主机是否为本机 是：INPUT 否：FORWARD 报文离开本机之前 • 判断由哪个接口送往下一跳内核中数据包的传输过程 内核中数据包的传输过程 当一个数据包进入网卡时，数据包首先进入PREROUTING链，内核根据数据包目的 IP判断是否需要转送出去 如果数据包就是进入本机的，数据包就会沿着图向下移动，到达INPUT链。数据包 到达INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些 数据包经过OUTPUT链，然后到达POSTROUTING链输出 如果数据包是要转发出去的，且内核允许转发，数据包就会向右移动，经过 FORWARD链，然后到达POSTROUTING链输出 iptables规则规则rule：根据规则的匹配条件尝试匹配报文，对匹配成功的报文根据规则定义的 处理动作作出处理 匹配条件：默认为与条件，同时满足 基本匹配：IP,端口,TCP的Flags（SYN,ACK等） 扩展匹配：通过复杂高级功能匹配 处理动作：称为target，跳转目标 内建处理动作：ACCEPT(接受),DROP（抛弃）,REJECT（拒绝）,SNAT,DNATMASQUERADE,MARK,LOG… 自定义处理动作：自定义chain，利用分类管理复杂情形规则要添加在链上，才生效；添加在自定义上不会自动生效链chain： 内置链：每个内置链对应于一个钩子函数 自定义链：用于对内置链进行扩展或补充，可实现更灵活的规则组织管理机制； 只有Hook钩子调用自定义链时，才生效 定义防火墙规则应注意： 条件越严的、越苛刻的、范围小的尽量放在前面，相对不太严格的、宽松的放在后面，这个宽松说得是指范围。 在防火墙规则中，如果没有定义任何规则时，系统默认的规则是 ACCEPT 的。 也可以把默认的规则进行修改，如： 把默认规则改为 DROP （注意，改之前一定要把自己本机摘出来，不然自己也不能连接了） iptables -A INPUT -s 192.168.30.1 -j ACCEPT # 表示在规则中添加192.168.30.1 主机访问时允许连接。iptables -P INPUT DROP # 表示把默认规则改为 DROP 也可以把规则里面的任意一条进行修改 ，如：原来在规则中 192.168.30.6 这个主机是拒绝的，编号没第二条，现在要把他改为接受 iptables -R INPUT 2 -s 192.168.30.6 -j ACCEPT 这就表示把192.168.30.6 这台主机改为 接受，允许连接。 iptables -F : 清空所有规则 iptables -vnL –line-numbers : 表示查看规则中的信息，并且前面带有编号 iptables添加要点 iptables规则添加时考量点 要实现哪种功能：判断添加在哪张表上 报文流经的路径：判断添加在哪个链上 报文的流向：判断源和目的 匹配规则：业务需要 链上规则的次序，即为检查的次序，因此隐含一定的法则 同类规则(访问同一应用)，匹配范围小的放上面 不同类规则(访问不同应用)，匹配到报文频率较大的放上面 将那些可由一条规则描述的多个规则合并为一个 设置默认策略 实验环境准备： Centos7: systemctl stop firewalld.service systemctl disable firewalld. service Centos6:service iptables stop; chkconfig iptables off iptables命令man 8 iptables iptables [-t table] {-A|-C|-D} chain rule-specification iptables [-t table] -I chain [rulenum] rule-specification iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options…] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name rule-specification = [matches…] [target] match = -m matchname [per-match-options] target = -j targetname [per-target-options] iptables命令 规则格式：iptables [-t table] SUBCOMMAND chain [-m matchname [per-matchoptions]] -j targetname [per-target-options] -t table： raw, mangle, nat, [filter]默认 SUBCOMMAND： 1、链管理： -N：new, 自定义一条新的规则链 -X：delete，删除自定义的空的规则链 -P：Policy，设置默认策略；对filter表中的链而言，其默认策略有： ACCEPT：接受 DROP：丢弃 -E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除 现在有几个组，分别为 web fileshare mange ， 其中 web 组中定义了 http httpd 两种协议 fileshare 组中定义了 samba ftp 两种协议 ， mange 组中定义了 ssh telnet 两种协议 将来对组进行定义相应的规则、自定义的链，将来看到组名就代表着组中的成员，自定义的链将来必须跟系统自带的链相关联才能起效果 创建一个自定义的链iptables -N WEB也可以把自定义的链给删除了iptables -X WEB接下来给这个自定义的链加规则，怎么加呢，我们希望 http https 属于这个链，希望将来别的主机可以通过 这个种协议来访问本机。iptables -A WEB -p tcp -m multiport –dports 80,443 -j ACCEPT现在这个规则还不能使用，还需要把这个自定义链关联到 系统自带的链上去iptables -A INPUT -j WEB 表示客户端访问本机的 input时 ，会跳转到 web 链上去，如果 web 链上有符合条件的就直接回应，如果没有就继续回到 input 继续往下匹配 修改自定义链这样就可以实现模块化，INPUT 链中只定各自 自定义的链，然后把规则定义在各自自定义链中，将来想修改 INPUT 链中的规则时 就不用直接修改 input 了，把对应的自定义链修改就可以了。比如 ： 现在想增加一条规则，允许客户端访问本机的 8080 端口，就可以直接在 WEB 链中添加规则就可以。 iptables -A WEB -p tcp –dport 8080 -j ACCEPT这样客户端就可以访问本机的8080端口了也可以直接在原来的规则上进行修改ipyables -R WEB 1 -p -m multiport –dports 80,445,8080 -j ACCEPT 删除一个自定义链先把关联在系统自带链中的规则进行删除iptables -D INPUT 1再把自定义链中的规则清空iptables -D WEB 1最后删除自定义链iptables -X WEB 注意： 创建一个成熟的自定义链，需要先创建一个自定义链，再给它定义规则，最后把关联到系统自带的链上。 删除的时应先把系统自带链中的自定义链规则删除，再把自定义链中的规则删除，最后再删除自定义链。 必须按照顺序来，不然会报错。这就是自定义链的内容，一般在生产中，定义的规则比较复杂时，就可以采用这种自定义链来进行管理，就相当于把系统自带链模块化了。 iptables命令2、查看： -L：list, 列出指定鏈上的所有规则，本选项须置后 -n：numberic，以数字格式显示地址和端口号 -v：verbose，详细信息 -vv 更详细-x：exactly，显示计数器结果的精确值,而非单位转换后的易读值 –line-numbers：显示规则的序号常用组合： –vnL –vvnxL –line-numbers -S selected,以iptables-save 命令格式显示链上规则 iptables命令 3、规则管理： -A：append，追加 -I：insert, 插入，要指明插入至的规则编号，默认为第一条 -D：delete，删除 (1) 指明规则序号 (2) 指明规则本身-R：replace，替换指定链上的指定规则编号 -F：flush，清空指定的规则链-Z：zero，置零 iptables的每条规则都有两个计数器 (1) 匹配到的报文的个数 (2) 匹配到的所有报文的大小之和chain：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING iptables命令 匹配条件 基本：通用的，PARAMETERS 扩展：需加载模块，MATCH EXTENTIONS 1、基本匹配条件：无需加载模块，由iptables/netfilter自行提供 [!]-s, –source address[/mask][,…]：源IP地址或范围 [!] -d, –destination address[/mask][,…]：目标IP地址或范围 [!] -p, –protocol protocol：指定协议，可使用数字如0（all） protocol: tcp, udp, icmp, icmpv6, udplite,esp, ah, sctp, mh or “all“ 参看：/etc/protocols [!] -i, –in-interface name：报文流入的接口；只能应用于数据报文流入环节，只应用于 INPUT、FORWARD、PREROUTING链 [!] -o, –out-interface name：报文流出的接口；只能应用于数据报文流出的环节，只应用 于FORWARD、OUTPUT、POSTROUTING链 iptables命令 2 扩展匹配条件：需要加载扩展模块（/usr/lib64/xtables/*.so），方可生效 查看帮助 man iptables-extensions (1)隐式扩展：在使用-p选项指明了特定的协议时，无需再用-m选项指明扩展模块的扩展 机制，不需要手动加载扩展模块 tcp协议的扩展选项 [!] –source-port, –sport port[:port]：匹配报文源端口,可为端口范围 [!] –destination-port,–dport port[:port]：匹配报文目标端口,可为范围 [!] –tcp-flags mask comp mask 需检查的标志位列表，用,分隔 例如 SYN,ACK,FIN,RST comp 在mask列表中必须为1的标志位列表，无指定则必须为0，用,分隔 tcp协议的扩展选项示例： –tcp-flags SYN,ACK,FIN,RST SYN 表示要检查的标志位为 SYN,ACK,FIN,RST四个，其中SYN必须为1，余下的必须为0 –tcp-flags SYN,ACK,FIN,RST SYN,ACK –tcp-flags ALL ALL –tcp_flags ALLNONE [!] –syn：用于匹配第一次握手 相当于：–tcp-flags SYN,ACK,FIN,RST SYN iptables命令udp [!] –source-port, –sport port[:port]：匹配报文的源端口；可以是端口 范围 [!] –destination-port,–dport port[:port]：匹配报文的目标端口；可以 是端口范围icmp [!] –icmp-type {type[/code]|typename} type/code 0/0 echo-reply icmp应答 8/0 echo-request icmp请求 也可以指定协议制定端口来定义规则如： 拒绝 192.168.30.6 这台主机访问本机的 tcp 445 139 这两个端口iptables -A INPUT -s 192.168.30.6 -p tcp –dport 445 -j REJECTiptables -A INPUT -s 192.168.30.6 -p tcp –dport 139 -j REJECT 设定规则拒绝 tcp 协议第一次握手iptables -A INPUT -p tcp –syn -j REJECT 这种设定表示任何主机都不能连接本机，但是已经连接上的用户继续维护，新建连接的主机被拒绝了。 现在有两台主机，192.168.30.7 192.168.30.6 ，现在要求 192.168.30.7 能 ping 通 192.168.30.6 ，但是 192.168.30.6 ping 不同 192.168.30.7 ，操作如下：在 192.168.30.7 主机上输入 ： iptables -A INPUT -p icmp –icmp-type 8 -j REJECT 这样也就实现了上面的效果 (2)显式扩展：必须使用-m选项指明要调用的扩展模块的扩展机制，要手动加载 扩展模块 [-m matchname [per-match-options]] 现在要求其他主机不能访问本机的 80 21 445 这三个端口，操作如下：iptables -A INPUT -p tcp -m multiport –dports 21,80,445 -j REJECT 在生产中，一般配置服务器，都只对外开放特定的端口 80 22 ，剩余其他的都不允许访问。现在模拟一下，先拿一台主机禁止任何主机访问，然后在进行开启 80 22 两个端口加策略时首先把本机先摘出来再进行加策略先把全部禁止访问iptables -A INPUT -s 192.168.30.1 -j REJECTiptables -A OUTPUT -d 192.168.30.1 -j REJECTiptables -A INPUT -j REJECTiptables -A OUTPUT -j REJECT然后再把 80 22 两个端口开放出来iptables -I INPUT -p tcp -m multiport -dports 22,80 -j ACCEPTiptables -I OUTPUT -p tcp -m multiport -sports 22,80 -j ACCEPT 这样就满足了以上要求 现在有要求，要求其他任意主机只允许访问本机的 samba httpd ssh 三种服务，剩余其他都不允许。同样先把所有端口都禁止然后在进行开放特定端口禁止之前先把本机摘出来iptables -A INPUT -s 192.168.30.1 -j REJECTiptables -A OUTPUT -d 192.168.30.1 -j REJECTiptables -A INPUT -j REJECTiptables -A OUTPUT -j REJECT然后在开放特定端口iptables -I INPUT -p tcp -m multiport -dports 22,80,139,445 -j ACCEPTiptables -I INPUT 2 -p udp -m multiport -dports 137,138 -j ACCEPT因为 samba 服务有四个端口，tcp 139 445 udp 137 138 这样就实现以上要求 iptables命令 处理动作： -j targetname [per-target-options] 简单： ACCEPT，DROP扩展： REJECT：–reject-with:icmp-port-unreachable默认 RETURN：返回调用链 REDIRECT：端口重定向 LOG：记录日志，dmesg MARK：做防火墙标记 DNAT：目标地址转换 SNAT：源地址转换 MASQUERADE：地址伪装 … 自定义链： iptables命令显式扩展：必须显式地指明使用的扩展模块进行的扩展使用帮助： CentOS 6: man iptables CentOS 7: man iptables-extensions 1、multiport扩展 以离散方式定义多端口匹配,最多指定15个端口 [!] –source-ports,–sports port[,port|,port:port]… 指定多个源端口 [!] –destination-ports,–dports port[,port|,port:port]… 指定多个目标端口 [!] –ports port[,port|,port:port]…多个源或目标端口 示例： iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.10 -p tcp -m multiport –dports 20:22,80 -j ACCEPT iptables命令2、iprange扩展指明连续的（但一般不是整个网络）ip地址范围 [!] –src-range from[-to] 源IP地址范围 [!] –dst-range from[-to] 目标IP地址范围 示例： iptables -A INPUT -d 172.16.1.100 -p tcp –dport 80 -m iprange –srcrange 172.16.1.5-172.16.1.10 -j DROP iptables命令3、mac扩展 指明源MAC地址适用于：PREROUTING, FORWARD，INPUT chains [!] –mac-source XX:XX:XX:XX:XX:XX 示例： iptables -A INPUT -s 172.16.0.100 -m mac –mac-source 00:50:56:12:34:56 -j ACCEPT iptables -A INPUT -s 172.16.0.100 -j REJECT iptables命令4、string扩展对报文中的应用层数据做字符串模式匹配检测 –algo {bm|kmp}：字符串匹配检测算法 bm：Boyer-Moore kmp：Knuth-Pratt-Morris –from offset 开始偏移–to offset 结束偏移 [!] –string pattern：要检测的字符串模式 [!] –hex-string pattern：要检测字符串模式，16进制格式 示例： iptables -A OUTPUT -s 172.16.100.10 -d 0/0 -p tcp –sport 80 -m string - -algo bm –string “google” -j REJECT 现在客户端可以访问主服务器的 80 端口，主服务器上有两个外部网页，一个是 mage 网页，一个是 google 网页，现在要求客户端访问本机的80 端口时，只能查看到 mage 页面，不能查看 googe 页面。怎么操作？ 在服务器端iptables -A INPUT -s 192.168.30.1 -j REJECTiptables -A INPUT -j REJECTiptables -A INPUT -p tcp –dport 80 -j ACCEPTecho welcome to magedu &gt; /var/www/html/index1.htmlecho welcome to google &gt; /var/www/html/index2.htmliptables -A OUTPUT -m string –algo bm –string “google” -j REJECT这样客户端访问本机的 80 端口时就不能查看到 google 页面，而 magedu 页面还能访问。 5、time扩展根据将报文到达的时间与指定的时间范围进行匹配–datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] 日期 –datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]] –timestart hh:mm[:ss] 时间 –timestop hh:mm[:ss] [!] –monthdays day[,day…] 每个月的几号 [!] –weekdays day[,day…] 星期几 –kerneltz：内核时区，不建议使用，CentOS7系统默认为UTC注意： centos6 不支持kerneltz ，–localtz指定本地时区(默认) 示例： iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.10 -p tcp –dport 80 -m time –timestart 14:30 –timestop 18:30 –weekdays Sat,Sun –kerneltz -j DROP iptables命令6、connlimit扩展 根据每客户端IP做并发连接数数量匹配可防止CC(Challenge Collapsar挑战黑洞)攻击 –connlimit-upto n：连接的数量小于等于n时匹配–connlimit-above n：连接的数量大于n时匹配 通常分别与默认的拒绝或允许策略配合使用 示例： iptables -A INPUT -d 172.16.100.10 -p tcp –dport 22 -m connlimit –connlimit-above 2 -j REJECT iptables命令7、limit扩展 基于收发报文的速率做匹配 令牌桶过滤器 (限流，达到一定程度就要限流) –limit rate[/second|/minute|/hour|/day] （表示按时间限制） –limit-burst number （初始值，表示这设定的值之前不限，超过就开始限）示例： iptables -I INPUT -d 172.16.100.10 -p icmp –icmp-type 8 -m limit –limit 10/minute – limit-burst 5 -j ACCEPT 表示前 五个 不限，超过五个每秒钟只限 十个 iptables -I INPUT 2 -p icmp -j REJECT iptables命令8、state扩展根据”连接追踪机制“去检查连接的状态，较耗资源conntrack机制：追踪本机上的请求和响应之间的关系状态有如下几种： NEW：新发出请求；连接追踪信息库中不存在此连接的相关信息条目，因 此，将其识别为第一次发出的请求 ESTABLISHED：NEW状态之后，连接追踪信息库中为其建立的条目失效之 前期间内所进行的通信状态 RELATED：新发起的但与已有连接相关联的连接，如：ftp协议中的数据连 接与命令连接之间的关系 INVALID：无效的连接，如flag标记不正确 UNTRACKED：未进行追踪的连接，如raw表中关闭追踪 iptables命令 [!] –state state 示例： iptables -A INPUT -d 172.16.1.10 -p tcp -m multiport –dports 22,80 -m state – state NEW,ESTABLISHED -j ACCEPT iptables -A OUTPUT -s 172.16.1.10 -p tcp -m multiport –sports 22,80 -m state – state ESTABLISHED -j ACCEPT 已经追踪到的并记录下来的连接信息库 /proc/net/nf_conntrack 调整连接追踪功能所能够容纳的最大连接数量 /proc/sys/net/nf_conntrack_max 如果修改这个值，如： echo net.nf_conntrack_max=2000000 &gt;&gt; /etc/sysctl.conf 生效一下 ： sysctl -p 这个值也不是越大越好，值越大性能消耗就越多 不同的协议的连接追踪时长 /proc/sys/net/netfilter/注意：CentOS7 需要加载模块： modprobe nf_conntrack iptables命令 iptables的链接跟踪表最大容量为/proc/sys/net/nf_conntrack_max，各种状态的超 时链接会从表中删除；当模板满载时，后续连接可能会超时 解决方法两个： (1) 加大nf_conntrack_max 值 vi /etc/sysctl.conf net.nf_conntrack_max = 393216 net.netfilter.nf_conntrack_max = 393216(2) 降低 nf_conntrack timeout时间 vi /etc/sysctl.conf net.netfilter.nf_conntrack_tcp_timeout_established = 300 net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60 net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120 iptables -t nat -L -n iptables命令 开放被动模式的ftp服务 (1) 装载ftp连接追踪的专用模块： 跟踪模块路径： /lib/modules/kernelversion/kernel/net/netfilter vim /etc/sysconfig/iptables-config 配置文件 IPTABLES_MODULES=“nf_conntrack_ftp” modproble nf_conntrack_ftp (2) 放行请求报文： 命令连接：NEW, ESTABLISHED 数据连接：RELATED, ESTABLISHED iptables –I INPUT -d LocalIP -p tcp -m state –state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -d LocalIP -p tcp –dport 21 -m state –state NEW -j ACCEPT (3) 放行响应报文： iptables -I OUTPUT -s LocalIP -p tcp -m state –state ESTABLISHED -j ACCEPT 开放被动模式的ftp服务示例yum install vsftpdsystemctl start vsftpdmodprobe nf_conntrack_ftpiptables -Fiptables -A INPUT -m state –state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -p tcp –dport 21 -m state –state NEW -j ACCEPTiptables -A OUTPUT -m state –state ESTABLISHED -j ACCEPTiptables -P INPUT DROPiptables -P OUTPUT DROPiptables -vnL iptables命令Target： ACCEPT， DROP， REJECT， RETURN LOG， SNAT， DNAT， REDIRECT， MASQUERADE，.. LOG: 非中断target,本身不拒绝和允许,放在拒绝和允许规则前 并将日志记录在/var/log/messages系统日志中 –log-level level 级别： emerg, alert, crit, error, warning, notice, info or debug –log-prefix prefix 日志前缀，用于区别不同的日志，最多29个字符示例：iptables -I INPUT -s 10.0.1.0/24 -p tcp -m multiport –dports 80,21,22,23 -m state –state NEW -j LOG –log-prefix “new connections: “ 一般在生产中一般不加，除非用于排错等可能添加 iptables命令任何不允许的访问，应该在请求到达时给予拒绝规则在链接上的次序即为其检查时的生效次序基于上述，规则优化 1 安全放行所有入站和出站的状态为ESTABLISHED状态连接 2 谨慎放行入站的新请求 3 有特殊目的限制访问功能，要在放行规则之前加以拒绝 4 同类规则（访问同一应用），匹配范围小的放在前面，用于特殊处理 5 不同类的规则（访问不同应用），匹配范围大的放在前面 6 应该将那些可由一条规则能够描述的多个规则合并为一条 7 设置默认策略，建议白名单（只放行特定连接） 1） iptables -P，不建议 2） 建议在规则的最后定义规则做为默认策略 在生产中，搭建 LAMP 架构，该怎么来添加防火墙策略。如： 有三台服务器，A B C ，A 用来做 apache + php-fpm ， B 用来做 mysql 数据库， C 是管理服务器。然后在不同服务器上添加策略lampclient —&gt; apache+php-fpm A –&gt; mysql B A ：添加前把策略先清空一下iptables -F然后把本服务器回环地址摘出来，因为 apache 连接 php-fpm 程序时，要连接 php-fpm 的9000 端口，而这个连接是在本机连接的，所以如果不加这条规则，外部服务器将无法连接 php 程序。iptables -A INPUT -i lo -j ACCEPT接下来开启本服务器的 80 端口允许所有人能够访问iptables -A INPUT -p tcp –dport 80 -j ACCEPT接下来还要把管理服务器的 22 端口摘出来，保证能够远程连接进行管路iptables -A INPUT -s CIP -p tcp –dport 22 -j ACCEPT添加禁止所有连接本服务器的策略iptables -A INPUT -j REJECT B:先清空所有策略iptables -F允许外部服务器连接本服务器的 3306 端口iptables -A INPUT -s AIP -p tcp –dport 3306 -j ACCEPT开启本服务器的 22 端口，允许管理服务器能够远程管理iptables -A INPUT -s CIP -p tcp –dport 22 -j ACCEPT添加禁止所有连接本服务器的策略iptables -A INPUT -j REJECT iptables命令规则有效期限： 使用iptables命令定义的规则，手动删除之前，其生效期限为kernel存活期限保存规则： 保存规则至指定的文件CentOS 6 service iptables save 将规则覆盖保存至/etc/sysconfig/iptables文件中 CentOS 7 可用下面方法保存规则 iptables-save &gt; /PATH/TO/SOME_RULES_FILE 生产中添加完规则以后一定要保存在文件中，不然重启服务或机器规则会清空的。如： iptables-save &gt; “（这个文件由自己设定，如：/etc/iptables-20180701）”如果把规则清空后还可以还原 如：iptables-restore &lt; /etc/iptables-20180701这样还是手动执行的，如果想机器重启后开机这些规则自动就启用，可以写到启动服务脚本中chmod +x /etc/rc.d/rc.localecho ‘iptables-restore &lt; /etc/iptables-20180701’ &gt;&gt; /etc/rc.d/rc.local或者写进计划任务中vim /etc/crontabiptables-restore &lt; /etc/iptables-20180701不过一般还是建议放在服务脚本中 而 centos 6 上不用这么做，因为 在 6 上就有 iptables 这个服务，我们只需用把规则写进文件中，然后这个服务设为开机启动就可以。 iptables命令CentOS 6： service iptables restart 会自动从/etc/sysconfig/iptables 重新载入规则CentOS 7 重新载入预存规则文件中规则： iptables-restore &lt; /PATH/FROM/SOME_RULES_FILE -n, –noflush：不清除原有规则 -t, –test：仅分析生成规则集，但不提交 开机自动重载规则开机自动重载规则文件中的规则： (1) 用脚本保存各iptables命令；让此脚本开机后自动运行/etc/rc.d/rc.local文件中添加脚本路径 /PATH/TO/SOME_SCRIPT_FILE(2) 用规则文件保存各规则，开机时自动载入此规则文件中的规则 /etc/rc.d/rc.local文件添加 iptables-restore &lt; /PATH/FROM/IPTABLES_RULES_FILE(3)自定义Unit File，进行iptables-restore 网络防火墙iptables/netfilter网络防火墙： (1) 充当网关(2) 使用filter表的FORWARD链 注意的问题： (1) 请求-响应报文均会经由FORWARD链，要注意规则的方向性 (2) 如果要启用conntrack机制，建议将双方向的状态为ESTABLISHED的报 文直接放行 公司中的网络是一台服务器跟外网连接的，然后公司中的其他主机连接外网都有这台主机进行转发，然后在这台主机的网络防火墙中设定公司里在每礼拜 1 3 5 的早上9点钟到下午的6点钟都能上网，并且什么时候都不能登录“youku”这样的网站。先把”youku”的这种网络加进规则中iptables -I FORWORD -m string –algo bm –sting “youku.com” -j REJECT在设定规定时间内不能上网的规则iptables -A FORWORD -m time –timestart 1:00 –timestop 10:00 –weekdays 1,3,5 -j REJECT这样就可以实现以上要求 现在又有要求，要做到只允许公司内容可以连接互联网上的服务器，但是互联网上的服务器不能连接公司内部网络。还是在公司内部往外转发的这台服务器上制定防火墙规则先把所有连接都拒绝iptables -A FORWORD -j REJECT在设定外网连接公司内网时只有已经连接的状态或者是有关联连接的这种状态才允许连进公司内网中iptables -I FORWORD -m state –state ESTABLISHED,RELATED -j ACCEPT在设定新状态连接只能是公司内网连接外网，外网不能连接内网,如： 内网网段是 192.168.30.0/24iptables -I FORWORD 2 -s 192.168.30.0/24 -m state –state NEW -j ACCEPT这样就实现了外网不能访问内网，实现了公司安全。 现在又有新的要求了，公司内部搭建了一个外部服务器，允许外网的任意客户端只能对公司内部的这一台服务器进行访问，怎么添加规则？外部服务器的IP 为 192.168.30.7还是在转发外网的服务器上添加规则，在上面的规则基础上进行添加iptables -I FORWORD 2 -d 192.168.30.7 -p tcp –dport 80 -m state NEW -j ACCEPT这样就实现了外网只能连接内网的 外部服务器，其他的服务器不能访问，但是内网可以随意访问外网。 私有地址端：分别为 A : 10.0.0.0/8 B ： 172.16.0.0/16 - 172.31.0.0/16 合成超网为 ： 172.16.0.0/12 C : 192.168.0.0/24 - 192.168.255.0/24 合成超网 ： 192.168.0.0/16 NATNAT: network address translation PREROUTING，INPUT，OUTPUT，POSTROUTING 请求报文：修改源/目标IP，由定义如何修改 响应报文：修改源/目标IP，根据跟踪机制自动实现SNAT：source NAT POSTROUTING, INPUT 让本地网络中的主机通过某一特定地址访问外部网络，实现地址伪装 请求报文：修改源IPDNAT：destination NAT PREROUTING , OUTPUT 把本地网络中的主机上的某服务开放给外部网络访问(发布服务和端口映射)， 但隐藏真实IP 请求报文：修改目标IPPNAT: port nat，端口和IP都进行修改 SNATnat表的target： SNAT：固定IP –to-source [ipaddr[-ipaddr]][:port[-port]] –randomiptables -t nat -A POSTROU TING -s LocalNET ! -d LocalNet -j SNAT –tosource ExtIP示例： iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j SNAT – to-source 172.18.1.6-172.18.1.9 SNATMASQUERADE：动态IP，如拨号网络 –to-ports port[-port] –randomiptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j MASQUERADE示例： iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j MASQUERADE 实验： 实现 SNAT那三台主机来模拟拓扑，一个为局域网地址： 192.168.30.0/24 ， 一个为外网地址 ： 10.0.0.0/8 还有一个为 NAT 服务器，服务器上有两个网卡，一个内网网卡接口IP 为 192.168.30.17 另一个外网网卡接口IP 为 10.0.0.254现在要求局域网里的主机通过 NAT 服务器能够访问外网中的服务器 接下来首先来配置 NAT 服务器iptables -t nat -A POSTROUTING -s 192.168.30.0/24 -j SNAT –to-source 10.0.0.254这个规则是 NAT 服务器连接外网的地址是固定的，是静态地址或者 NAT 服务器是动态地址，连接外网的地址不是固定的，可以这样添加：iptables -t nat -A POSTROUTING -s 192.168.30.0/24 -j MASQUERADE 实验 ： 实现 DNATiptables -t nat -A PREROUTING -d 10.0.0.254 -p tcp –dport 80 -j DNAT –to-destination 192.168.30.7 表示外网客户端访问 NAT 服务器的80 端口时，就自动转发到内网中端口为 80 的外部服务器192.168.30.7 这台主机，不过也有可能内部端口不是80 ，为8080 也能转发。 DNATDNAT--to-destination [ipaddr[-ipaddr]][:port[-port]] iptables -t nat -A PREROUTING -d ExtIP -p tcp|udp –dport PORT -j DNAT –to-destination InterSeverIP[:PORT]示例： iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp –dport 22 -j DNAT –to-destination 10.0.1.22 iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp –dport 80 -j DNAT –to-destination 10.0.1.22:8080 转发REDIRECT： NAT表 可用于：PREROUTING OUTPUT 自定义链 通过改变目标IP和端口，将接受的包转发至不同端口 –to-ports port[-port] 示例： iptables -t nat -A PREROUTING -d 172.16.100.10 -p tcp –dport 80 -j REDIRECT –to-ports 8080 现在公司有一外部服务器，端口为80，但是为了防止黑客攻击，一般都把端口号进行修改，如： 修改为 8080，但是外界客户访问时访问的是 80 端口，所以就要在防火墙策略中实现端口转发，如下：iptables -t nat -A PREROUTING -d 192.168.30.7 -p tcp –dport 80 -j REDIRECT –to-ports 8080表示客户端访问公司里外部服务器 192.168.30.7 这台服务器的 80 端口时，就给转发到设定的8080端口，是把本机的80 转发为 8080 注意： 这个规则是在外部服务器上添加，不在 NAT 服务器上这就叫做端口转发 firewalld服务firewalld是CentOS 7.0新推出的管理netfilter的工具firewalld是配置和监控防火墙规则的系统守护进程。可以实现 iptables,ip6tables,ebtables的功能firewalld服务由firewalld包提供firewalld支持划分区域zone,每个zone可以设置独立的防火墙规则归入zone顺序： 先根据数据包中源地址，将其纳为某个zone 纳为网络接口所属zone 纳入默认zone，默认为public zone,管理员可以改为其它zone网卡默认属于public zone,lo网络接口属于trusted zone firewalld配置firewall-cmd –get-services 查看预定义服务列表 /usr/lib/firewalld/services/*.xml预定义服务的配置三种配置方法 firewall-config （firewall-config包）图形工具 firewall-cmd （firewalld包）命令行工具 /etc/firewalld 配置文件，一般不建议 firewall-cmd 命令选项–get-zones 列出所有可用区域–get-default-zone 查询默认区域–set-default-zone=设置默认区域–get-active-zones 列出当前正使用的区域–add-source=[–zone=]添加源地址的流量到指定区域，如 果无–zone= 选项，使用默认区域–remove-source= [–zone=] 从指定区域中删除源地址的 流量，如无–zone= 选项，使用默认区域–add-interface=[–zone=] 添加来自于指定接口 的流量到特定区域，如果无–zone= 选项，使用默认区域 firewall-cmd 命令选项–change-interface=[–zone=] 改变指定接口至新的 区域，如果无–zone= 选项，使用默认区域–add-service= [–zone=] 允许服务的流量通过，如果 无–zone= 选项，使用默认区域–add-port=[–zone=] 允许指定端口和协议 的流量，如果无–zone= 选项，使用默认区域 firewall-cmd 命令选项–remove-service= [–zone=] 从区域中删除指定服 务，禁止该服务流量，如果无–zone= 选项，使用默认区域–remove-port=[–zone=] 从区域中删除 指定端口和协议，禁止该端口的流量，如果无–zone= 选项，使用默认区域–reload 删除当前运行时配置，应用加载永久配置–list-services 查看开放的服务 –list-ports 查看开放的端口–list-all [–zone=] 列出指定区域的所有配置信息，包括接口，源 地址，端口，服务等，如果无–zone= 选项，使用默认区域 firewall-cmd 命令示例查看默认zone firewall-cmd –get-default-zone默认zone设为dmz firewall-cmd –set-default-zone=dmz在internal zone中增加源地址192.168.0.0/24的永久规则 firewall-cmd –permanent –zone=internal –addsource=192.168.0.0/24在internal zone中增加协议mysql的永久规则 firewall-cmd –permanent –zone=internal –add-service=mysql加载新规则以生效 firewall-cmd –reload 实验：配置firewalldsystemctl mask iptablessystemctl mask ip6tablessystemctl status firewalldsystemctl enable firewalldsystemctl start firewalldfirewall-cmd –get-default-zonefirewall-cmd –set-default-zone publicfirewall-cmd –permanent –zone=public –list-allfirewall-cmd –permanent –zone=public –add-port 8080/tcpfirewall-cmd —reload 其它规则当基本firewalld语法规则不能满足要求时，可以使用以下更复杂的规则rich-rules 富规则，功能强,表达性语言Direct configuration rules 直接规则，灵活性差帮助：man 5 firewalld.direct 管理rich规则rich规则比基本的firewalld语法实现更强的功能，不仅实现允许/拒绝，还可以 实现日志syslog和auditd，也可以实现端口转发，伪装和限制速率rich语法： rule [source] [destination] service|port|protocol|icmp-block|masquerade|forward-port [log] [audit] [accept|reject|drop]man 5 firewalld.richlanguage 规则规则实施顺序： 该区域的端口转发，伪装规则 该区域的日志规则 该区域的允许规则 该区域的拒绝规则每个匹配的规则生效，所有规则都不匹配，该区域默认规则生效 rich规则示例拒绝从192.168.0.11的所有流量，当address 选项使用source 或 destination 时，必须用family= ipv4 |ipv6.firewall-cmd –permanent –zone=classroom –add-rich-rule=’rule family=ipv4 source address=192.168.0.11/32 reject‘限制每分钟只有两个连接到ftp服务 firewall-cmd –add-rich-rule=‘rule service name=ftp limit value=2/m accept’抛弃esp（ IPsec 体系中的一种主要协议）协议的所有数据包 firewall-cmd –permanent –add-rich-rule=’rule protocol value=esp drop’接受所有192.168.1.0/24子网端口5900-5905范围的TCP流量 firewall-cmd –permanent –zone=vnc –add-rich-rule=’rule family=ipv4 source address=192.168.1.0/24 port port=5900-5905 protocol=tcp accept’ rich日志规则实例接受ssh新连接，记录日志到syslog的notice级别，每分钟最多三条信息 firewall-cmd –permanent –zone=work –add-rich-rule=’rule service name=”ssh” log prefix=”ssh “ level=”notice” limit value=”3/m” accept从2001:db8::/64子网的DNS连接在5分钟内被拒绝，并记录到日志到audit,每 小时最大记录一条信息 firewall-cmd –add-rich-rule=’rule family=ipv6 source address=”2001:db8::/64” service name=”dns” audit limit value=”1/h” reject’ –timeout=300","categories":[],"tags":[]},{"title":"keepalived 各种高可用实战演练","slug":"keepalived 各种高可用实战演练","date":"2017-09-13T16:00:00.000Z","updated":"2018-08-09T08:32:08.128Z","comments":true,"path":"2017/09/14/keepalived 各种高可用实战演练/","link":"","permalink":"http://yoursite.com/2017/09/14/keepalived 各种高可用实战演练/","excerpt":"实验： 实现单主模型和双主模型的高可用。任何做实验前都要保证时间同步。 timedatectl set-timezone Asia/Shanghai 还有防火墙、SElinux 等都设置完毕。 现在准备两个主机，R1 R2 ，分别在两台主机上安装 keepalived ，各自配置成急群众的两个节点。 第一步，先把这两台主机配置成单主模型的集群，来验证地址是否能流动。 第二步，用两个虚拟路由器工作在双主模型下。 单主模型：两台主机 在第一台主机上修改 keepalived 配置文件","text":"实验： 实现单主模型和双主模型的高可用。任何做实验前都要保证时间同步。 timedatectl set-timezone Asia/Shanghai 还有防火墙、SElinux 等都设置完毕。 现在准备两个主机，R1 R2 ，分别在两台主机上安装 keepalived ，各自配置成急群众的两个节点。 第一步，先把这两台主机配置成单主模型的集群，来验证地址是否能流动。 第二步，用两个虚拟路由器工作在双主模型下。 单主模型：两台主机 在第一台主机上修改 keepalived 配置文件 1234567891011121314vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125; 在第二台主机上修改 keepalived 配置文件 1234567891011121314vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125; 然后在两台主机上各装上一个外部服务器 web1 web2 ，设置好外部主页面。就可以在客户端访问虚拟ip 192.168.1.188 了，刚开始一直是 web1 接受访问，一旦 web1 宕机， web2 就自动接受访问。这就是单主模型的高可用。 双主模型 ： 两台主机 在第一台主机上修改配置文件 12345678910111213141516171819202122232425262728vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125;vrrp_instance VI_2 &#123; state BACKUP interface ens33 virtual_router_id 22 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.199/24 brd 192.168.1.255 dev ens33 &#125;&#125; 在第二台主机上修改配置文件 12345678910111213141516171819202122232425262728vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 11 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125;vrrp_instance VI_2 &#123; state MASTER interface ens33 virtual_router_id 22 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.199/24 brd 192.168.1.255 dev ens33 &#125;&#125; 这就实现了双主模型的配置，然后在两台主机上安装外部服务器 web1 web2 ，设置好外部页面。在客户端访问 虚拟ip 192.168.1.188 显示的是 web1 ，访问虚拟 ip 192.168.1.199 显示的是 web2两台主机上都有对应的两个虚拟ip ，只是优先级不同，两个主机对两个虚拟主机ip 都有一个优先级高的，一旦有一个主机的虚拟ip宕机，这个虚拟ip就会在另外一个优先级相对较低的主机上继续运行，这样就可以保证两个虚拟ip 都能高可用。这就是双主模型的高可用。 实验： 实现 DR 模型ipvs 的高可用准备4台主机进行模拟实验，两台为前端进行高可用的调度器，另外两台为后端提供外部服务器的 relo-server 先在前端两个调度器上安装 keepalived 服务，并修改配置文件 单主模型：两台主机 在第一台主机上修改 keepalived 配置文件 123456789101112131415161718192021222324252627282930vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125; 在第二台主机上修改 keepalived 配置文件 vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125;&#125; 然后再在两台主及的keepalived 的配置文件中添加相同的内容 12345678910111213141516171819202122232425262728293031virtual_server 192.168.1.188 80 &#123; delay_loop 2 lb_algo rr lb_kind DR protocol TCP real_server 192.168.1.133 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 2 nb_get_retry 3 delay_before_retry 1 &#125; &#125; real_server 192.168.1.134 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 2 nb_get_retry 3 delay_before_retry 1 &#125; &#125;&#125; 接下来在另外两台主机上配置后端 relo-server 服务器 先修改四个内核参数，为了方便使用，可以写成脚本进行实现，顺便也可以在脚本中把 VIP 直接绑定在两个主机上。 1234567891011121314151617181920212223242526vim neihe.sh #!/bin/bash vip=&quot;192.168.1.188&quot; mask=&quot;255.255.255.255&quot; iface=&quot;lo:0&quot; case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $iface $vip netmask $mask broadcast $vip up rouconfig add -host $vip dev $iface ;; stop) ifconfig $iface down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce ;; esac 脚本写完后在两个主机上都执行一下。 然后在两台主机上安装外部服务器 httpd yum install httpd 设置外部主页面，在生产中正规两个外部服务器的主页面应该是一样的，但在这为了看到实验效果故意设为不一样的。 在 web1 上设置主页面 echo web1 &gt; /var/www/html/index.html 在 web2 上设置主页面 echo web1 &gt; /var/www/html/index.html 并把两个外部服务启动起来 systemctl start httpd 然后把前端调度器上的 keepalived 服务也启动起来 systemctl start keepalived 还有一般启动服务后就会在 iptables 规则中生成相应的规则。为了方便看规则，在前面两个调度器上安装 ipvs 服务 yum install ipvsadm 然后用命令 ipvsadm -Ln 就可以查看生成的规则 还有要在前面两台主机上用命令 iptables -F 清空一下防火墙规则，因为在配置 keepalived 服务时会自动生成一些和规则，这些规则会影响客户端访问外部服务。 最后就可以在客户端主机上进行访问测试了 注意，在客户端访问的地址一定是 VIP 地址 如： curl 192.168.1.188 实验: 实现 keepalived 高可用 nginx准备四台主机来模拟这个实验，两个主机做 nginx 的 keepalived 高可用 ，另外两个做后端提供外部服务的服务器。 先在前面两个主机上安装 nginx keepalived 两个服务 先配置第一个代理服务器上的 keepalived 的配置文件 ，所有格式如下： vim /etc/keepalived/keepalived.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_iptables vrrp_mcast_group4 224.0.123.132&#125;vrrp_script ngxhealth &#123; script &quot;killall -0 nginx &amp;&amp; exit 0 || exit 1&quot; interval 1# auth_pass 12345 weight -5&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 11 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125; track_interface &#123; ens33 &#125; track_script &#123; ngxhealth &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;vrrp_instance VI_2 &#123; state BACKUP interface ens33 virtual_router_id 22 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.199/24 brd 192.168.1.255 dev ens33 &#125;&#125; 接下配置 nginx 的配置文件 vim /etc/nginx/conf.d/www.conf 123456789101112upstream websrvs &#123; server 192.168.1.133:80; server 192.168.1.134:80;&#125;server &#123; listen 80 default_server; server_name zuyu.magedu.com; root /usr/share/nginx/html; location / &#123; proxy_pass http://websrvs; &#125;&#125; 并写一个测试脚本vim /etc/keepalived/notify.sh 1234567891011121314151617181920212223242526#!/bin/bash#!/bin/bash # contact=&apos;root@localhost&apos; notify() &#123; local mailsubject=&quot;$(hostname) to be $1, vip floating&quot; local mailbody=&quot;$(date +&apos;%F %T&apos;): vrrp transition, $(hostname) changed to be $1&quot; echo &quot;$mailbody&quot; | mail -s &quot;$mailsubject&quot; $contact &#125; case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo &quot;Usage: $(basename $0) &#123;master|backup|fault&#125;&quot; exit 1 ;; esac 配置完后启动 nginx keepalived 的服务 systemctl start nginx keepalived 这样第一个前端代理服务器的配置就配好了。 接下配置第二个前端的代理服务器 先配置 keepalived 的配置文件，所以格式如下： vim /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_iptables vrrp_mcast_group4 224.0.123.132&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 11 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.188/24 brd 192.168.1.255 dev ens33 &#125; track_script &#123; ngxhealth &#125; vrrp_script &#123; ngxhealth &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;vrrp_instance VI_2 &#123; state MASTER interface ens33 virtual_router_id 22 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345 &#125; virtual_ipaddress &#123; 192.168.1.199/24 brd 192.168.1.255 dev ens33 &#125;&#125;vrrp_script ngxhealth &#123; script &quot;killall -0 nginx &amp;&amp; exit 0 || exit 1&quot; interval 1 weight -5&#125; 接下来配置 nginx 服务的配置文件 vim /etc/nginx/conf.d/www.conf 12345678910111213141516171819202122232425upstream websrvs &#123; server 192.168.1.133:80; server 192.168.1.134:80;&#125;server &#123; listen 80 default_server; server_name anmo.magedu.com; root /usr/share/nginx/html; location / &#123; proxy_pass http://websrvs; &#125;&#125;upstream websrvs &#123; server 192.168.1.133:80; server 192.168.1.134:80;&#125;server &#123; listen 80 default_server; server_name anmo.magedu.com; root /usr/share/nginx/html; location / &#123; proxy_pass http://websrvs; &#125;&#125; 并写一个测试脚本vim /etc/keepalived/notify.sh 1234567891011121314151617181920212223242526#!/bin/bash#!/bin/bash # contact=&apos;root@localhost&apos; notify() &#123; local mailsubject=&quot;$(hostname) to be $1, vip floating&quot; local mailbody=&quot;$(date +&apos;%F %T&apos;): vrrp transition, $(hostname) changed to be $1&quot; echo &quot;$mailbody&quot; | mail -s &quot;$mailsubject&quot; $contact &#125; case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo &quot;Usage: $(basename $0) &#123;master|backup|fault&#125;&quot; exit 1 ;; esac 配置完后启动 nginx keepalived 的服务 systemctl start nginx keepalived 这样第二个前端代理服务器的配置也配置好了。 接下来就要配置后端提供外部服务的服务器了。 先在两台主机上安装外部服务 httpd 并设置外部主页面 在web1 服务器上设置页面： echo web1 &gt; /var/www/html/index.html 在web2 服务器上设置页面： echo web2 &gt; /var/www/html/index.html在生产中这两个主机上的页面应该是相同的，在这是为了查看实验效果，故意不一样。在两台主机上都设置好以后，然后都启动服务systemctl start httpd 最后就可以在浏览器测试了，在浏览器上输入 VIP 的地址，在这有两个 VIP 地址，如果输入两个中的某一个 VIP 地址都可以访问到后端服务的外部页面，并且轮询，说明成功。还可以当掉一个 nginx 服务器测试都没有问题的。再生产中无非就是在 DNS 服务器的配置上添加两条 A 记录，把域名解析到这两个 VIP 即可。 这就是高可用的负载均衡前端接入的调度器集群了。测试时可以用命令 tcpdump -i ens33 -nn host 224.0.123.132 到此就实现了 在双主模式下工作的 keepalived 高可用的 nginx调度。OpenAIS RedHat 5 : cman + rgmanager,conga(WebGUI): RHCS(Cluster Suite)(集群套件) RedHat 6 : cman + rgmanager,corosync + pacemaker RedHat 7 : corosync + pacemaker CRM （Cluster Resource Manager）：集群资源管理器LRM(local Resource Manager):本地资源管理器","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"keepalied","slug":"keepalied","permalink":"http://yoursite.com/tags/keepalied/"}]},{"title":"HAproxy 原理介绍","slug":"HAproxy 原理介绍","date":"2017-08-27T16:00:00.000Z","updated":"2018-08-09T08:28:45.910Z","comments":true,"path":"2017/08/28/HAproxy 原理介绍/","link":"","permalink":"http://yoursite.com/2017/08/28/HAproxy 原理介绍/","excerpt":"课前扩展：运维人员的三大核心工作： 发布； 变更； 故障处理； 扩展： 向上，向外。 什么是无状态跟有状态？ 一个客户端向服务器发起多次请求，后一次的请求跟前一次的请求是隔离的，独立的，相互没有关系的，这就叫无状态。 如果后一次的请求必须建立在前一次请求之上，这种就叫做有状态请求。 HAproxy 是一个代理服务器，但他天然是一个能在代理时做负载均衡调度的服务器两个特点： 反代 mode http ： 七层反代 要根据用户的资源请求做分离跳读 ssl/tls 会话卸载器 mode tcp： 伪四层反代 为什么说是伪四层呢，因为它依旧受限于七层的并发连接数。 调度器 支持众多的调度算法 如：轮询，加权轮询等；","text":"课前扩展：运维人员的三大核心工作： 发布； 变更； 故障处理； 扩展： 向上，向外。 什么是无状态跟有状态？ 一个客户端向服务器发起多次请求，后一次的请求跟前一次的请求是隔离的，独立的，相互没有关系的，这就叫无状态。 如果后一次的请求必须建立在前一次请求之上，这种就叫做有状态请求。 HAproxy 是一个代理服务器，但他天然是一个能在代理时做负载均衡调度的服务器两个特点： 反代 mode http ： 七层反代 要根据用户的资源请求做分离跳读 ssl/tls 会话卸载器 mode tcp： 伪四层反代 为什么说是伪四层呢，因为它依旧受限于七层的并发连接数。 调度器 支持众多的调度算法 如：轮询，加权轮询等； HAProxy：HAproxy 也使用事件驱动模型，单进程来相应多请求的模式工作。 但是建议工作在单进程模式下，足以提供交大并发的请求，这样更容易排查和定义故障问题。 http://www.haproxy.org http://www.haproxy.com 文档： http://cbonte.github.io/haproxy-dconv/ HAProxy is a TCP/HTTP reverse proxy which is particularly suited for high availability environments. Indeed, it can: : - route HTTP requests depending on statically assigned cookies # 是一个 HTTP 的路由器，能够把 HTTP 请求路由至最佳节点，还支持做静态 COOKIES 绑定以后做会话连线。 : - spread load among several servers while assuring server persistence # 能否实现调度 : through the use of HTTP cookies # 可以实现对于 HTTP cookies 的高效利用 : - switch to backup servers in the event a main server fails # 在主服务器宕机是可启用备用服务器，通常叫做 抱歉服务器 : - accept connections to special ports dedicated to service monitoring : - stop accepting connections without breaking existing ones : - add, modify, and delete HTTP headers in both directions : - block requests matching particular patterns : - report detailed status to authenticated users from a URI intercepted by the application 版本：1.4, 1.5, 1.6, 1.7 以后不管搭建什么服务，时间一定都要同步，很关键也很重要。 同步时间有一个命令： timedatectl set-timezone Asia/Shanghai 搭建架构时，在所有架构中的服务器上都执行这个命令。 程序环境： 主程序：/usr/sbin/haproxy 主配置文件：/etc/haproxy/haproxy.cfg Unit file：/usr/lib/systemd/system/haproxy.service 配置段： global：全局配置段 进程及安全配置相关的参数 性能调整相关参数 Debug参数 用户列表 peers # 同等端点的兄弟服务器的位置跟通讯方法 proxies：代理配置段 defaults：为frontend, listen, backend提供默认配置； fronted：前端，相当于nginx, server {} backend：后端，相当于nginx, upstream {} listen：同时拥前端和后端 简单的配置示例： frontend web bind *:80 default_backend websrvs backend websrvs balance roundrobin server srv1 192.168.1.132:80 check weight 2 server srv2 192.168.1.134:80 check IaaS, PaaS, SaaS LBaaS, DBaaS, FWaaS, FaaS(Serverless), … OpenShift(PaaS): HAPorxy, Ingress Controller global配置参数： 进程及安全管理：chroot, daemon，user, group, uid, gid log：定义全局的syslog服务器；最多可以定义两个； log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [max level [min level]] log &lt;address&gt; :表示日志发送给哪个 syslog 服务器 [len &lt;length&gt;] ：记录日志的最大长度是多长 &lt;facility&gt; [max level [min level]] : 最大日志级别跟最低日志级别 如何启用日志功能？ 在 hapeoxy 配置文件中复制日志格式到 /etc/syslog.conf 中的对应的语句块中。 如： 复制 haproxy 配置文件中的 local2.* /var/log/haproxy.log 到 /etc/syslog.conf 文件中对应的语句块中，并重启服务 最后客户端的访问日志就会记录在 /var/log/haproxy.log 文件中 nbproc &lt;number&gt;：要启动的haproxy的进程数量； ulimit-n &lt;number&gt;：每个haproxy进程可打开的最大文件数； 性能调整： maxconn &lt;number&gt;：设定每个haproxy进程所能接受的最大并发连接数；Sets the maximum per-process number of concurrent connections to &lt;number&gt;. 总体的并发连接数：nbproc * maxconn maxconnrate &lt;number&gt;：Sets the maximum per-process number of connections per second to &lt;number&gt;. 每个进程每秒种所能创建的最大连接数量； maxsessrate &lt;number&gt;： 每个进程每秒钟能够创建的会话速率 maxsslconn &lt;number&gt;: Sets the maximum per-process number of concurrent SSL connections to &lt;number&gt;. 设定每个haproxy进程所能接受的ssl的最大并发连接数； spread-checks &lt;0..50, in percent&gt; 代理配置段： - defaults &lt;name&gt; - frontend &lt;name&gt; - backend &lt;name&gt; - listen &lt;name&gt; A &quot;frontend&quot; section describes a set of listening sockets accepting client connections. A &quot;backend&quot; section describes a set of servers to which the proxy will connect to forward incoming connections. A &quot;listen&quot; section defines a complete proxy with its frontend and backend parts combined in one section. It is generally useful for TCP-only traffic. All proxy names must be formed from upper and lower case letters, digits, &apos;-&apos; (dash), &apos;_&apos; (underscore) , &apos;.&apos; (dot) and &apos;:&apos; (colon). 区分字符大小写； 配置参数： bind：Define one or several listening addresses and/or ports in a frontend. bind [&lt;address&gt;]:&lt;port_range&gt; [, ...] [param*] listen http_proxy bind :80,:443 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy # 这个参数只能用在 frontend 和 listen 语句块中。 balance：后端服务器组内的服务器调度算法 balance &lt;algorithm&gt; [ &lt;arguments&gt; ] balance url_param &lt;param&gt; [check_post] 算法： roundrobin：Each server is used in turns, according to their weights. server options： weight # 动态算法：支持权重的运行时调整，支持慢启动；每个后端中最多支持4095个server； static-rr： 静态算法：不支持权重的运行时调整及慢启动；后端主机数量无上限； leastconn： 推荐使用在具有较长会话的场景中，例如MySQL、LDAP等； first： 根据服务器在列表中的位置，自上而下进行调度；前面服务器的连接数达到上限，新请求才会分配给下一台服务； source：源地址hash； 将同一个地址发过来的请求一直发往一个后端服务器 除权取余法（静态数组取模法）： 一致性哈希： uri： 对URI的左半部分做hash计算，并由服务器总权重相除以后派发至某挑出的服务器； # 如果在生产中，调度器后面是缓存服务器，uri 就要用一致性哈希的动态算法。 &lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; 左半部分：/&lt;path&gt;;&lt;params&gt; 整个uri：/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; username=jerry url_param：对用户请求的uri的&lt;params&gt;部分中的参数的值作hash计算，并由服务器总权重相除以后派发至某挑出的服务器；通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server； hdr(&lt;name&gt;)：对于每个http请求，此处由&lt;name&gt;指定的http首部将会被取出做hash计算； 并由服务器总权重相除以后派发至某挑出的服务器；没有有效值的会被轮询调度； hdr(Cookie) rdp-cookie rdp-cookie(&lt;name&gt;) hash-type：哈希算法 hash-type &lt;method&gt; &lt;function&gt; &lt;modifier&gt; map-based：除权取余法，哈希数据结构是静态的数组； consistent：一致性哈希，哈希数据结构是一个树； &lt;function&gt; is the hash function to be used : 哈希函数 sdbm djb2 wt6 default_backend &lt;backend&gt; 设定默认的backend，用于frontend中； default-server [param*] 为backend中的各server设定默认选项； server &lt;name&gt; &lt;address&gt;[:[port]] [param*] 定义后端主机的各服务器及其选项； server &lt;name&gt; &lt;address&gt;[:port] [settings ...] default-server [settings ...] &lt;name&gt;：服务器在haproxy上的内部名称；出现在日志及警告信息中； &lt;address&gt;：服务器地址，支持使用主机名； [:[port]]：端口映射；省略时，表示同bind中绑定的端口； [param*]：参数 maxconn &lt;maxconn&gt;：当前server的最大并发连接数； backlog &lt;backlog&gt;：当前server的连接数达到上限后的后援队列长度； backup：设定当前server为备用服务器； check：对当前server做健康状态检测； addr ：检测时使用的IP地址； port ：针对此端口进行检测； inter &lt;delay&gt;：连续两次检测之间的时间间隔，默认为2000ms; rise &lt;count&gt;：连续多少次检测结果为“成功”才标记服务器为可用；默认为2； fall &lt;count&gt;：连续多少次检测结果为“失败”才标记服务器为不可用；默认为3； 注意：option httpchk，&quot;smtpchk&quot;, &quot;mysql-check&quot;, &quot;pgsql-check&quot; and &quot;ssl-hello-chk&quot; 用于定义应用层检测方法； cookie &lt;value&gt;：为当前server指定其cookie值，用于实现基于cookie的会话黏性； disabled：标记为不可用； on-error &lt;mode&gt;：后端服务故障时的行动策略； - fastinter: force fastinter - fail-check: simulate a failed check, also forces fastinter (default) - sudden-death: simulate a pre-fatal failed health check, one more failed check will mark a server down, forces fastinter - mark-down: mark the server immediately down and force fastinter redir &lt;prefix&gt;：将发往此server的所有GET和HEAD类的请求重定向至指定的URL； weight &lt;weight&gt;：权重，默认为1; OK --&gt; PROBLEM OK --&gt; PROBLEM --&gt; PROBLEM --&gt; PROBLEM PROBLEM --&gt; OK 统计接口启用相关的参数： stats enable (加在前端后端都可以) 启用统计页；基于默认的参数启用stats page； - stats uri : /haproxy?stats - stats realm : &quot;HAProxy Statistics&quot; - stats auth : no authentication - stats scope : no restriction stats auth &lt;user&gt;:&lt;passwd&gt; 认证时的账号和密码，可使用多次；（启用账号密码） stats realm &lt;realm&gt; 认证时的realm；（提示语） stats uri &lt;prefix&gt; 自定义stats page uri stats refresh &lt;delay&gt; 设定自动刷新时间间隔； stats admin { if | unless } &lt;cond&gt; 启用stats page中的管理功能 配置示例：（为了信息安全，可以专门给状态信息加端口） listen stats bind :9099 stats enable stats realm HAPorxy\\ Stats\\ Page stats auth admin:admin stats admin if TRUE maxconn &lt;conns&gt;：为指定的frontend定义其最大并发连接数；默认为2000； Fix the maximum number of concurrent connections on a frontend. mode { tcp|http|health } 定义haproxy的工作模式； tcp：基于layer4实现代理；可代理mysql, pgsql, ssh, ssl等协议； http：仅当代理的协议为http时使用； health：工作为健康状态检查的响应模式，当连接请求到达时回应“OK”后即断开连接； 示例： listen ssh bind :22022 balance leastconn mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check cookie &lt;name&gt; [ rewrite | insert | prefix ] [ indirect ] [ nocache ] [ postonly ] [ preserve ] [ httponly ] [ secure ] [ domain &lt;domain&gt; ]* [ maxidle &lt;idle&gt; ] [ maxlife &lt;life&gt; ] &lt;name&gt;：is the name of the cookie which will be monitored, modified or inserted in order to bring persistence. rewirte：重写； insert：插入； prefix：前缀； 基于cookie的session sticky的实现： backend websrvs cookie WEBSRV insert nocache indirect server srv1 172.16.100.6:80 weight 2 check rise 1 fall 2 maxconn 3000 cookie srv1 server srv2 172.16.100.7:80 weight 1 check rise 1 fall 2 maxconn 3000 cookie srv2 option forwardfor [ except &lt;network&gt; ] [ header &lt;name&gt; ] [ if-none ] Enable insertion of the X-Forwarded-For header to requests sent to servers 在由haproxy发往后端主机的请求报文中添加“X-Forwarded-For”首部，其值前端客户端的地址；用于向后端主发送真实的客户端IP； [ except &lt;network&gt; ]：请求报请来自此处指定的网络时不予添加此首部； [ header &lt;name&gt; ]：使用自定义的首部名称，而非“X-Forwarded-For”； errorfile &lt;code&gt; &lt;file&gt; Return a file contents instead of errors generated by HAProxy &lt;code&gt;：is the HTTP status code. Currently, HAProxy is capable of generating codes 200, 400, 403, 408, 500, 502, 503, and 504. &lt;file&gt;：designates a file containing the full HTTP response. 示例： errorfile 400 /etc/haproxy/errorfiles/400badreq.http errorfile 408 /dev/null # workaround Chrome pre-connect bug errorfile 403 /etc/haproxy/errorfiles/403forbid.http errorfile 503 /etc/haproxy/errorfiles/503sorry.http errorloc &lt;code&gt; &lt;url&gt; errorloc302 &lt;code&gt; &lt;url&gt; errorfile 403 http://www.magedu.com/error_pages/403.html reqadd &lt;string&gt; [{if | unless} &lt;cond&gt;] Add a header at the end of the HTTP request rspadd &lt;string&gt; [{if | unless} &lt;cond&gt;] Add a header at the end of the HTTP response # 给客户端法响应报文时给报文头部添加信息 rspadd X-Via:\\ HAPorxy reqdel &lt;search&gt; [{if | unless} &lt;cond&gt;] reqidel &lt;search&gt; [{if | unless} &lt;cond&gt;] (ignore case) Delete all headers matching a regular expression in an HTTP request rspdel &lt;search&gt; [{if | unless} &lt;cond&gt;] rspidel &lt;search&gt; [{if | unless} &lt;cond&gt;] (ignore case) Delete all headers matching a regular expression in an HTTP response rspidel Server.* # 给客户端发送响应报文时可以删除报文头部的信息 日志系统： log： log global log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [&lt;level&gt; [&lt;minlevel&gt;]] no log 注意： 默认发往本机的日志服务器； (1) local2.* /var/log/local2.log (2) $ModLoad imudp $UDPServerRun 514 log-format &lt;string&gt;： 课外实践：参考文档实现combined格式的记录 capture cookie &lt;name&gt; len &lt;length&gt; Capture and log a cookie in the request and in the response. capture request header &lt;name&gt; len &lt;length&gt; Capture and log the last occurrence of the specified request header. capture request header X-Forwarded-For len 15 capture response header &lt;name&gt; len &lt;length&gt; Capture and log the last occurrence of the specified response header. capture response header Content-length len 9 capture response header Location len 15 为指定的MIME类型启用压缩传输功能 compression algo &lt;algorithm&gt; ...：启用http协议的压缩机制，指明压缩算法gzip, deflate； compression type &lt;mime type&gt; ...：指明压缩的MIME类型；常适用于压缩的类型为文本类型； 对后端服务器做http协议的健康状态检测： option httpchk option httpchk &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt; 定义基于http协议的7层健康状态检测机制； http-check expect [!] &lt;match&gt; &lt;pattern&gt; Make HTTP health checks consider response contents or specific status codes. 连接超时时长： timeout client &lt;timeout&gt; # 面向客户端的超时时间 Set the maximum inactivity time on the client side. 默认单位是毫秒; timeout server &lt;timeout&gt; # 面向服务器端的超时时间 Set the maximum inactivity time on the server side. timeout http-keep-alive &lt;timeout&gt; 持久连接的持久时长； timeout http-request &lt;timeout&gt; Set the maximum allowed time to wait for a complete HTTP request timeout connect &lt;timeout&gt; Set the maximum time to wait for a connection attempt to a server to succeed. timeout client-fin &lt;timeout&gt; Set the inactivity timeout on the client side for half-closed connections. timeout server-fin &lt;timeout&gt; Set the inactivity timeout on the server side for half-closed connections. use_backend &lt;backend&gt; [{if | unless} &lt;condition&gt;] Switch to a specific backend if/unless an ACL-based condition is matched. 当符合指定的条件时使用特定的backend； block { if | unless } &lt;condition&gt; # 阻止谁来访问 Block a layer 7 request if/unless a condition is matched acl invalid_src src 172.16.200.2 block if invalid_src errorfile 403 /etc/fstab http-request { allow | deny } [ { if | unless } &lt;condition&gt; ] Access control for Layer 7 requests tcp-request connection {accept|reject} [{if | unless} &lt;condition&gt;] Perform an action on an incoming connection depending on a layer 4 condition 示例： listen ssh bind :22022 balance leastconn acl invalid_src src 172.16.200.2 tcp-request connection reject if invalid_src mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check backup acl： The use of Access Control Lists (ACL) provides a flexible solution to perform content switching and generally to take decisions based on content extracted from the request, the response or any environmental status. acl &lt;aclname&gt; &lt;criterion&gt; [flags] [operator] [&lt;value&gt;] ... &lt;aclname&gt;：ACL names must be formed from upper and lower case letters, digits, &apos;-&apos; (dash), &apos;_&apos; (underscore) , &apos;.&apos; (dot) and &apos;:&apos; (colon).ACL names are case-sensitive. &lt;value&gt;的类型： - boolean - integer or integer range - IP address / network - string (exact, substring, suffix, prefix, subdir, domain) - regular expression （以正则表达式做匹配） - hex block （以 16 进制的代码块做匹配） &lt;flags&gt; -i : ignore case during matching of all subsequent patterns. # 不区分字符大小写 -m : use a specific pattern matching method -n : forbid the DNS resolutions （禁止 DNS 做名字解析） -u : force the unique id of the ACL （要求 ACL必须使用唯一的名称） -- : force end of flags. Useful when a string looks like one of the flags. [operator] 匹配整数值：eq、ge、gt、le、lt 匹配字符串： - exact match (-m str) : the extracted string must exactly match the patterns ; - substring match (-m sub) : the patterns are looked up inside the extracted string, and the ACL matches if any of them is found inside ; - prefix match (-m beg) : the patterns are compared with the beginning of the extracted string, and the ACL matches if any of them matches. - suffix match (-m end) : the patterns are compared with the end of the extracted string, and the ACL matches if any of them matches. - subdir match (-m dir) : the patterns are looked up inside the extracted string, delimited with slashes (&quot;/&quot;), and the ACL matches if any of them matches. - domain match (-m dom) : the patterns are looked up inside the extracted string, delimited with dots (&quot;.&quot;), and the ACL matches if any of them matches. acl作为条件时的逻辑关系： - AND (implicit) - OR (explicit with the &quot;or&quot; keyword or the &quot;||&quot; operator) - Negation with the exclamation mark (&quot;!&quot;) if invalid_src invalid_port # 并且的关系，两个都得满足 if invalid_src || invalid_port # 或者的关系，有一个满足就行 if ! invalid_src invalid_port # 表示不满足第一个，但满足第二个就行 &lt;criterion&gt; ： dst : ip dst_port : integer src : ip src_port : integer acl invalid_src src 172.16.200.2 path : string This extracts the request&apos;s URL path, which starts at the first slash and ends before the question mark (without the host part). /path;&lt;params&gt; path : exact string match path_beg : prefix match # 前缀匹配 path_dir : subdir match # 路径子串匹配 path_dom : domain match # 子域名匹配 path_end : suffix match # 后缀匹配 path_len : length match # 路径的长度匹配 path_reg : regex match # 路径的正则表达式匹配 path_sub : substring match # 子串匹配 path_beg /images/ path_end .jpg .jpeg .png .gif path_reg ^/images.*\\.jpeg$ path_sub image path_dir jpegs path_dom ilinux /images/jpegs/20180312/logo.jpg url : string This extracts the request&apos;s URL as presented in the request. A typical use is with prefetch-capable caches, and with portals which need to aggregate multiple information from databases and keep them in caches. url : exact string match url_beg : prefix match url_dir : subdir match url_dom : domain match url_end : suffix match url_len : length match url_reg : regex match url_sub : substring match req.hdr([&lt;name&gt;[,&lt;occ&gt;]]) : string This extracts the last occurrence of header &lt;name&gt; in an HTTP request. hdr([&lt;name&gt;[,&lt;occ&gt;]]) : exact string match hdr_beg([&lt;name&gt;[,&lt;occ&gt;]]) : prefix match hdr_dir([&lt;name&gt;[,&lt;occ&gt;]]) : subdir match hdr_dom([&lt;name&gt;[,&lt;occ&gt;]]) : domain match hdr_end([&lt;name&gt;[,&lt;occ&gt;]]) : suffix match hdr_len([&lt;name&gt;[,&lt;occ&gt;]]) : length match hdr_reg([&lt;name&gt;[,&lt;occ&gt;]]) : regex match hdr_sub([&lt;name&gt;[,&lt;occ&gt;]]) : substring match 示例： acl bad_curl hdr_sub(User-Agent) -i curl block if bad_curl status : integer Returns an integer containing the HTTP status code in the HTTP response. Pre-defined ACLs ACL name Equivalent to Usage FALSE always_false never match HTTP req_proto_http match if protocol is valid HTTP HTTP_1.0 req_ver 1.0 match HTTP version 1.0 HTTP_1.1 req_ver 1.1 match HTTP version 1.1 HTTP_CONTENT hdr_val(content-length) gt 0 match an existing content-length HTTP_URL_ABS url_reg ^[^/:]*:// match absolute URL with scheme HTTP_URL_SLASH url_beg / match URL beginning with &quot;/&quot; HTTP_URL_STAR url * match URL equal to &quot;*&quot; LOCALHOST src 127.0.0.1/8 match connection from local host METH_CONNECT method CONNECT match HTTP CONNECT method METH_GET method GET HEAD match HTTP GET or HEAD method METH_HEAD method HEAD match HTTP HEAD method METH_OPTIONS method OPTIONS match HTTP OPTIONS method METH_POST method POST match HTTP POST method METH_TRACE method TRACE match HTTP TRACE method RDP_COOKIE req_rdp_cookie_cnt gt 0 match presence of an RDP cookie REQ_CONTENT req_len gt 0 match data in the request buffer TRUE always_true always match WAIT_END wait_end wait for end of content analysis HAProxy：global, proxies（fronted, backend, listen, defaults） balance： roundrobin, static-rr leastconn first source hdr(&lt;name&gt;) uri (hash-type) url_param Nginx调度算法：ip_hash, hash, leastconn, lvs调度算法： rr/wrr/sh/dh, lc/wlc/sed/nq/lblc/lblcr 基于ACL的动静分离示例： frontend web *:80 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js .html .txt .htm use_backend staticsrvs if url_static default_backend appsrvs backend staticsrvs balance roundrobin server stcsrv1 172.16.100.6:80 check backend appsrvs balance roundrobin server app1 172.16.100.7:80 check server app1 172.16.100.7:8080 check listen stats bind :9091 stats enable stats auth admin:admin stats admin if TRUE 配置HAProxy支持https协议： 1 支持ssl会话； bind *:443 ssl crt /PATH/TO/SOME_PEM_FILE crt后的证书文件要求PEM格式，且同时包含证书和与之匹配的所有私钥； cat demo.crt demo.key &gt; demo.pem 2 把80端口的请求重向定443； bind *:80 redirect scheme https if !{ ssl_fc } 另一种配置：对非ssl的任何url的访问统统定向至https主机的主页； redirect location https://172.16.0.67/ if !{ ssl_fc } 3 如何向后端传递用户请求的协议和端口 http_request set-header X-Forwarded-Port %[dst_port] http_request add-header X-Forwared-Proto https if { ssl_fc } 配置时常用的功能： http --&gt; https mode http 压缩、条件式转发、算法、stats page、自定义错误页、访问控制、日志功能 最大并发连接； global, defaults, frontend, listen, server 基于cookie的session粘滞 后端主机的健康状态检测 请求和响应报文首部的操纵 实践（博客）作业： http: (1) 动静分离部署wordpress，动静都要能实现负载均衡，要注意会话的问题； (2) 在haproxy和后端主机之间添加varnish进行缓存； (3) 给出设计拓扑，写成博客； (4) haproxy的设定要求： (a) stats page，要求仅能通过本地访问使用管理接口； (b) 动静分离； (c) 分别考虑不同的服务器组的调度算法； (4) 压缩合适的内容类型；","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"haproxy","slug":"haproxy","permalink":"http://yoursite.com/tags/haproxy/"}]},{"title":"LAMP 架构的各种演示","slug":"LAMP 架构的各种演示","date":"2017-06-10T16:00:00.000Z","updated":"2018-08-09T07:56:59.155Z","comments":true,"path":"2017/06/11/LAMP 架构的各种演示/","link":"","permalink":"http://yoursite.com/2017/06/11/LAMP 架构的各种演示/","excerpt":"实验： LAMP 实现phpMyadmin先装包yum -y install httpd mariadb-server php php-mysqlsystemctl start httpdsystemctl start mariadb然后从官网上下载对应版本的phpMyadmin下载：https://www.phpmyadmin.net/downloads/然后进行解包，注意解包时一定要解在 /var/www/html 目录下cd /var/www/html unzip phpMyAdmin-4.0.10.20-all-languages.zip解完包后给改个名mv phpMyAdmin-4.0.10.20-all-languages pma找到类似于配置文件的一个文件给他改名cp config.sample.inc.php config.inc.php还需要安装一个工具包yum -y install php-mbstring安装完重启服务systemctl reload httpd这样就可以打开浏览器进行访问了，但是显示的界面让输入账号密码。注意这儿的账号密码是相对于 mysql 的账号密码所以还要在数据库中设置账号密码，我们可以跑一下安全脚本来生成账号密码。mysql_secure_installation然后就可以在浏览器上输入账号密码就入了，这样就可以在图形界面来管理数据库了。","text":"实验： LAMP 实现phpMyadmin先装包yum -y install httpd mariadb-server php php-mysqlsystemctl start httpdsystemctl start mariadb然后从官网上下载对应版本的phpMyadmin下载：https://www.phpmyadmin.net/downloads/然后进行解包，注意解包时一定要解在 /var/www/html 目录下cd /var/www/html unzip phpMyAdmin-4.0.10.20-all-languages.zip解完包后给改个名mv phpMyAdmin-4.0.10.20-all-languages pma找到类似于配置文件的一个文件给他改名cp config.sample.inc.php config.inc.php还需要安装一个工具包yum -y install php-mbstring安装完重启服务systemctl reload httpd这样就可以打开浏览器进行访问了，但是显示的界面让输入账号密码。注意这儿的账号密码是相对于 mysql 的账号密码所以还要在数据库中设置账号密码，我们可以跑一下安全脚本来生成账号密码。mysql_secure_installation然后就可以在浏览器上输入账号密码就入了，这样就可以在图形界面来管理数据库了。 实验：实现LAMP 搭建个人博客wordpress （基于上面实验的状态）先从官网上下载相应的包 https://cn.wordpress.org/下载包 wordpress-4.9.4-zh_CN.tar.gz然后进行解压缩，但是解压缩要指定一各路径，在生产中如果整个网站都用来搭建博客，那就解压缩到 /var/www/html 目录下，我们现在在一台主机上，所以放在一个子目录下。 tar xf wordpress-4.9.4-zh_CN.tar.gz -C /var/www/html/解压后会在/var/www/html/ 目录下生成一个文件夹wordpresscd wordpress还是找到配置文件然后进行改名cp wp-config-sample.php wp-config.php 然后对这个文件进行修改，把自己设置的数据库信息填上去 然后就可以在浏览器上访问这个目录了 http://192.168.1.136/wordpress就会看到输入账号密码界面，在上面填写相关信息 成功后就会在刚才创建的那个数据库 wpdb 中生成一些表，创建时是空的。然后就可以点击上面的登录进行登录了。这样就可以在上面进行操作了，写文章等。到此就实现了个人博客搭建 CentOS7源码编译Php-xcache加速访问官网：http://xcache.lighttpd.net/wiki/ReleaseArchive下载包 xcache-3.2.0.tar.gz先解压 tar xvf xcache-3.2.0.tar.gz解压完会生成 xcache-3.2.0 这个文件夹安装开发包组yum groupinstall “development tools” 按平时编译安装现在一般就跑一下编译脚本 configure ，但是 cd xcache-3.2.0 这个目录发现没有这个脚本，所以先装一个包yum -y install php-devel装完后然后跑一下 phpize 这个程序来生成编译环境跑完这个程序会发现在xcache-3.2.0 目录下生成了 configure 这个脚本接下来就可以运行了 注意编译前一定要在 xcache-3.2.0 这个目录下./configure –enable-xcache –with-php-config=/usr/bin/php-config make &amp;&amp; make install编译完后就会在 /usr/lib64/php/modules/ 目录下生成 xcache.so 这个模块然后我们需用来加载下这个模块让系统知道cp xcache-3.2.0/xcache.ini /etc/php.d/最后重启服务就可以使用了 systemctl restart httpd 实验： 实现 fastcgi 模式的LAMP （基于一台主机）先装包yum install httpd php-fpm php-mysql mariadb-server装完后查看下 php-fpm 包的结构 /etc/php-fpm.conf 这是主配置文件 /etc/php-fpm.d/www.conf 这是与Apache 相关的配置文件 /usr/sbin/php-fpm 这是主程序启动 php-fpm 服务systemctl start php-fpm因为客户端向 apache 访问 php 程序时， apache 要知道 php程序放在哪，所以要在 httpd 的配置文件中添加相关内容。 1234vim /etc/httpd/conf.d/fcgi.conf 在里面添加 DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/var/www/html/$1 启动服务 systemctl start httpd mariadb到此 LAMP 架构配置就搭建好了 接下来就可以测试一下现在 /var/www/html/ 目录下创建一个文件 index.php .编辑此文件 vim index.php在里面添加 1234567&gt;?php$dsn=&apos;mysql:host=localhost;dbname=mysql&apos;;$username=&apos;root&apos;;$passwd=&apos;&apos;;$dbh=new PDO($dsn,$username,$passwd);var_dump($dbh);?&gt; 接下来就可以打开浏览器进行访问了。 现在我们可以把各个服务分别放在不同主机上，准备三台主机，分别为 192.168.30.7 192.168.30.17 192.168.30.27 。 安装前在各台主机上把 SElinux 和 iptables 都关掉。 192.168.30.7 用来当做apache 服务器 192.168。30.17 用来当做 php-fpm 服务器 192.168.30.27 用来当做 mysql 服务器在 192.168.30.17 主机上安装 yum install php-fpm php-mysql在 192.168.30.27 主机上安装 yum install mariadb-server在 192.168.30.7 主机上安装 yum install httpd 接下来先来配置后端数据库，来到 192.168.30.27 主机上连接数据库，先创建一个账号 grant all on . to test@’192.168.30.17’ identified by ‘centos’;flush privileges; 重新加载数据库 接下来来到 192.168.30.17 这台主机上修改 php-fpm 的配置文件 vim /etc/php-fpm.d/www.conf在里面进行修改 把 listen = 127.0.0.1:9000 修改为 listen = 9000 把 listen.allowed_clients = 127.0.0.1 这行注释掉然后启动服务 systemctl start php-fpm创建文件夹 mkdir /data/www 在这个目录下在创建一个文件 vim index.html在里面添加内容 1234567891011121314&lt;?phptry &#123; $user=&apos;test&apos;; $pass=&apos;centos&apos;; $dbh = new PDO(&apos;mysql:host=192.168.30.27;dbname=mysql&apos;, $user, $pass); foreach($dbh-&gt;query(&apos;SELECT user,host from user&apos;) as $row) &#123; print_r($row); &#125; $dbh = null;&#125; catch (PDOException $e) &#123; print &quot;Error!: &quot; . $e-&gt;getMessage() . &quot;&lt;br/&gt;&quot;; die();&#125;?&gt; 来到 192.168.30.7 这台主机上修改 httpd 的配置文件 vim /etc/httpd/conf.d/fcgi.conf在里面添加 123DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://192.168.30.17:9000/data/www/$1 重启服务systemctl restart httpd 到此各个主机上的服务就配置好了，接下来就可以进行测试访问了打开浏览器 输入 192.168.30.7 （注意：这块是访问外部服务器的地址），如果访问结果显示出数据库内容说明搭建成功。 现在在这个架构上搭建一个应用 ， Discuz 论坛来到 192.168.30.17 主机上，把从官网下载的相应包传送到这台主机上。 Discuz_x3.2_SC_UTF8.zip这是个压缩包，所以先解压缩unzip Discuz_x3.2_SC_UTF8.zip解完后会生成很多文件夹 ，我们用 upload 这个文件夹cd upload/如果想整个网站做这个论坛就把所有文件都复制过去cp -r * /data/www/现在还要给 apache 用户添加这个目录的权限，将来 apache 会在这个目录下生成一些配置文件setfacl -R -m u:apache:rwx /data/www接下来就可以在浏览器上进行访问了 192.168.30.7/install/index.php就会显示一些信息 点击我同意 然后进行填写信息即可。 但是会发现搭建是搭建成功了，只有文字，没有图片。因为 php 程序是支持动态页面的，对静态页面兼容性不好，一般在生产中默认也是把这两个服务放在一台主机上的，现在就把 httpd 和 php-fpm 放在一台主机上就不会出现这样的情况。 现在再192.168.30.17 这台主机上安装 httpd 服务yum install httpd 修改配置文件 vim /etc/httpd/conf.d/fcgi.conf 在里面添加 123DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/data/www/$1 并且在主配置文件中把网站默认路径修改为我们创建的这个目录 vim /etc/httpd/conf/httpd.conf 在里面进行修改 DocumentRoot “/data/www/“ 并且要进行授权 重启服务systemctl restart httpd然后在拿浏览器进行访问 ，这回访问的就是 192.168.30.17就会看到正常页面了。到此就实现了LAMP 搭建应用。 现在又有新的要求了，要求实现虚拟主机，在同一台主机上搭建 wordpress 和 Discuz 。现在已经实现了一个Discuz ，那怎么实现另一个呢，将来要实现的结果是在浏览器上访问 www.bbs.com 是 Discuz ，访问 www.blog.com 是 wordpress。 还是在 192.168.30.17 这台主机上 首先查看目录 cd /data目录下现在只有一个 www/ 目录，这个目录是存放论坛的数据现在再创建一个文件夹来存放博客 mkdir www2/接下来把 wordpress 包传送到这台主机上wordpress-4.9.4-zh_CN.tar.gz进行解压缩tar xvf wordpress-4.9.4-zh_CN.tar.gz解压完后把解压的数据全部复制到 /data/www2/目录下cp -r wordpress/* /data/www2/复制完后 cd 到 /data/www2/ 目录下把配置文件进行改名并修改内容cp wp-config-sample.php wp-config.php 修改这个配置文件时先要创建一个数据库，因为这个配置文件中要连接数据库和用户账号密码等。 所以回到 192.168.30.27 主机上 连接到数据库创建一个数据库 create database wpdb;然后又回到 192.168.30.17 主机上cd /data/www2/ 目录下 修改配置文件 vim wp-config.php在里面修改 到这 wordpress 就做完了接下来准备虚拟主机的配置 cd 到 /etc/httpd/conf.d/ 目录下vim vhosts.conf在里面添加内容 123456789101112131415161718192021&lt;virtualhost *:80servername www.bbs.comdocumentroot /data/wwwDirectoryIndex index.phpProxyPassMatch off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/data/www/$1&lt;directory /data/wwwrequire all granted&lt;/directory&lt;/virtualhost&lt;virtualhost *:80&gt;servername www.blog.comdocumentroot /data/www2DirectoryIndex index.phpProxyPassMatch off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/data/www2/$1&lt;directory /data/www2&gt;require all granted&lt;/directory&gt;&lt;/virtualhost&gt; 重启服务systemctl restart httpd 接下来就可以找个主机当客户端进行访问测试了。现在用 192.168.30.6 这台主机进行测试访问。测试前先在这台主机的 hosts 文件中添加 域名 vim /etc/hosts 在里面添加 192.168.30.17 www.bbs.com www.blog.com然后打开图形界面浏览器 分别访问两个地址 filefox www.bbs.com filefox www.blog.com 实验：实现 CentOS7 fpm方式源码编译安装LAMP现在准备一台主机，192.168.30.17 ， 192.168.30.17 主机上安装 apache ,php-fpm，mariadb,编译前我们要先规划一下思路，先编译谁再编译谁，顺序一定要搞清。现在我们先编译 apache ，再编译 mariadb ， 最后编译 php-fpm ，把架构搭建好以后，最后那博客搭建就OK 。 接下来我们进行编译 首先准备各种源码包，版本环境apr-1.6.3.tar.gzapr-util-1.6.1.tar.gzhttpd-2.4.33.tar.bz2mariadb-10.2.15-linux-x86_64.tar.gzphp-7.1.18.tar.bz2wordpress-4.9.4-zh_CN.tar.gz 这些包在相应的官网上都可以下载到接下来创建一个文件夹把这些包 都放进去mkdir srcsmv .gz .bz2 srcs/ 1, 接下来先编译安装 httpd ，因为 httpd 依赖于 apr ，所以也要安装上。先解包cd /root/srcs/tar xvf apr-1.6.3.tar.gztar xvf apr-util-1.6.1.tar.gztar xvf httpd-2.4.33.tar.bz2解包完后生成三个文件夹 apr-1.6.3 apr-util-1.6.1 httpd-2.4.33把三个软件都放在一块进行编译，都放在 httpd 的 srclib/ 文件夹下并改名。 mv apr-1.6.3 httpd-2.4.33/srclib/apr mv apr-util-1.6.1 httpd-2.4.33/srclib/apr-util/然后 cd 切入 httpd-2.4.33 这个目录下进行编译编译前先把一些依赖性的包先装上。yum groupinstall “development tools”yum install openssl-devel pcre-devel expat-devel ./configure –prefix=/app/httpd24 \\ –sysconfdir=/etc/httpd24 \\–enableso \\–enable-ssl \\–enable-cgi \\ –enable-rewrite \\ –with-zlib \\ –with-pcre \\–with-includedapr \\–enable-modules=most \\–enable-mpms-shared=all \\–with-mpm=prefork如果编译完发现少编译了一些选项等，可以用命令 make clean 清理了重新编译。make -j 4 &amp;&amp; make install编译完后 cd /app/httpd24/ 目录下 添加 PATH 变量echo PATH=/app/httpd24/bin:$PATH &gt; /etc/profile.d/lamp.sh生效一下 . /etc/profile.d/lamp.sh可以查看下他的各种文件的路径主页面放在 /app/httpd24/htdocs 文件下配置文件放在 /app/httpd24/conf/httpd.conf 文件中然后用启动工具 apachectl 启动服务这样外部服务就基本上配置完了 2, 接下来安装数据库 mariadb （在生产中是编译安装的，因为源码编译数据库有点慢，这次就拿二进制编译代替了） 先解包 cd /root/srcs/ tar xvf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/local/ 解包完后 cd 到 /usr/local/ 目录下创建软连接 ， 并且软连接的名字必须叫 mysqlln -s mariadb-10.2.15-linux-x86_64.tar.gz mysql创建 mysql 账号uaeradd -r -s /sbin/nologin mysql修改 mysql/ 目录所有者所属组chown -R mysql.mysql mysql/接下来创建一个存放用户数据的目录并修改属性mkdir /data/mysql -pvchown mysql.mysql /data/mysql/然后添加 PATH 变量 vim /etc/profile.d/lamp.sh在原来的基础上修改为： PATH=/app/httpd24/bin:/usr/local/mysql/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin/:/usr/bin:/root/bin修改完后生效一下 . /etc/profile.d/lamp.sh接下来跑一个脚本cd /usr/local/mysql. /scripts/mysql_install_db –datadir=/data/mysql –user=mysql接下来拷贝 服务脚本和配置文件cp support-files/my-huge.cnf /etc/my.cnfcp support-files/mysql.server /etc/init.d/mysqld修改配置文件 vim /etc/my.cnf在里面添加 datadir= /data/mysql log_bin接下来就准备启动了chkconfig –add mysqldservice mysqld start接下里连接到数据库中创建一个数据库和一个账号将来给 wordpress 用的。create database wpdb;grant all on wpdb.* to wpuser@’192.168.30.%’ identified by ‘centos’;重新加载数据库 flush privileges;到此数据库就配置完毕了。 3, 接下来编译 安装 fastcgi 模式的 php 先解包cd /root/srcstar xvf php-7.1.18.tar.bz2解完包后会生成一个文件夹 php-7.1.18然后 cd 到 php-7.1.18 目录下进行编译编译前先把一些依赖的包先装上yum install libxm12-devel bzipz-devel libmcrypt-devel ./configure –prefix=/app/php \\–enable-mysqlnd \\–with-mysqli=mysqlnd \\ –with-openssl \\ –with-pdo-mysql=mysqlnd \\ –enable-mbstring \\ –with-freetype-dir \\–with-jpeg-dir \\ –with-png-dir \\–with-zlib \\–with-libxml-dir=/usr \\ –enable-xml \\ –enable-sockets \\–enable-fpm \\–with-config-file-path=/etc \\ –with-config-file-scan-dir=/etc/php.d \\ –enable-maintainer-zts \\–disable-fileinfomake -j 4 &amp;&amp; make installcd /root/srcs/php-7.1.18编译完后添加PATH 变量 vim /etc/profile.d/lamp.sh在原来的基础上修改为： PATH=/app/php/bin:/app/php/sbin:/app/httpd24/bin:/usr/local/mysql/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin/:/usr/bin:/root/bin修改完后生效一下 . /etc/profile.d/lamp.sh接下来准备php 的配置文件cp php.ini-production /etc/php.ini还要准备一个服务脚本cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm并且给这个文件加权限chmod +x /etc/init.d/php-fpm还要添加到服务chkconfig –add php-fpmchkconfig php-fpm on接下来还要准备一个配置文件cd /app/php/etc/cp php-fpm.conf.default php-fpm.confcd php-fpm.dcp www.conf.default www.conf接下来启动服务service php-fpm start到此 php 就准备好了 4, 接下来准备一下 worepress先解包，但是解包要接到外部服务的访问页面路径下cd /app/httpd24/htdocs/tar xvf /root/srcs/wordpress-4.9.4-zh_CN.tar.gz .接完后就生成一个文件夹 wordpress如果将来搭建的这个网站只用来做博客用就可以把 wordpress 这个文件夹下的数据全部移动到当前目录下mv wordpress/* .然后把配置文件的名字修改一下,并修改配置文件cp wp-config-sample.php wp-config.phpvim wp-config.php这样 wordpress 就准备好了 5, 接下来还要对 httpd 的配置文件 进行修改 vim /app/httpd24/conf/httpd.conf在里面进行修改 取消下面两行的注释 1234567891011LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 修改下面行，添加 index.php ，如下: &lt;IFModule dir_module&gt; DirectoryIndex index.php index.html &lt;/IFModule&gt; 还要添加下面四行 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 修改完后需要把 apache 服务停了在重新启动apachectl stopapachectl 到此所有配置就完成了，就可以拿浏览器进行连接了，如： 192.168.30.17如果成功，就会显示出安装博客的页面，然后就可以设置账号密码进行安装了。注意： 这个账号密码是将来管理博客后台的账号密码。 CentOS6编译安装PHP-FPM模式的LAMP编译httpd和二进制安装mariadb安装相关包 bzip2-devel libxml2-devel libmcrypt-devel(epel源)编译安装phpcd php-5.6.30/./configure –prefix=/app/php5 –with-mysql=/usr/local/mysql –withopenssl –with-mysqli=/usr/local/mysql/bin/mysql_config –enablembstring –with-freetype-dir –with-jpeg-dir –with-png-dir –with-zlib –with-libxml-dir=/usr –enable-xml –enable-sockets –enable-fpm – with-mcrypt –with-config-file-path=/etc/php5 –with-config-filescan-dir=/etc/php5.d –with-bz2make -j 4 &amp;&amp; make install CentOS6编译安装PHP-FPM模式的LAMP实现php的配置文件和服务脚本mkdir /etc/php5 /etc/php5.d/cd php-5.6.30/cp php.ini-production /etc/php5/php.ini cp sapi/fpm/init.d.php-fpm /etc/rc.d/init.d/php-fpmchmod +x /etc/rc.d/init.d/php-fpmchkconfig –add php-fpmchkconfig –list php-fpm CentOS6编译安装PHP-FPM模式的LAMP编辑php配置文件cd /app/php5/etccp php-fpm.conf.default php-fpm.confvim /app/php5/etc/php-fpm.conf pm.max_children = 50 pm.start_servers = 5 pm.min_spare_servers = 2pm.max_spare_servers = 5 和pm.start_servers一致 pid = /app/php5/var/run/php-fpm.pid service php-fpm restart 实验：CentOS6编译安装PHP-FPM模式的LAMP修改httpd24的配置文件vim /app/apache24/conf/httpd.conf 说明：启用httpd的相关模块 在Apache httpd 2.4以后已经专门有一个模块针对FastCGI的实现，此模块为 mod_proxy_fcgi.so，它其实是作为mod_proxy.so模块的扩充，因此，这两个 模块都要加载去掉下面两行注释 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 添加如下二行 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps定位至DirectoryIndex index.html修改为：DirectoryIndex index.php index.html 加下面两行 ProxyRequests Off 关闭正向代理 ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 service httpd24 restart 测试vim /app/httpd24/htdocs/index.php如下：&lt;?php$link = mysql_connect(‘127.0.0.1’,’root’,’magedu’);if ($link)echo “Success…”;else echo “Failure…”; mysql_close();phpinfo();?&gt;","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"LAMP","slug":"LAMP","permalink":"http://yoursite.com/tags/LAMP/"}]},{"title":"ext 文件系统机制原理","slug":"ext 文件系统机制原理","date":"2017-04-19T16:00:00.000Z","updated":"2018-06-25T11:32:23.414Z","comments":true,"path":"2017/04/20/ext 文件系统机制原理/","link":"","permalink":"http://yoursite.com/2017/04/20/ext 文件系统机制原理/","excerpt":"将磁盘进行分区，分区是将磁盘按柱面进行物理上的划分。划分好分区后还要进行格式化，然后再挂载才能使用(不考虑其他方法)。格式化分区的过程其实就是创建文件系统。 文件系统的类型有很多种，如CentOS 5和CentOS 6上默认使用的ext2/ext3/ext4，CentOS 7上默认使用的xfs，windows上的NTFS，光盘类的文件系统ISO9660，MAC上的混合文件系统HFS，网络文件系统NFS，Oracle研发的btrfs，还有老式的FAT/FAT32等。 本文将非常全面且详细地对ext家族的文件系统进行介绍。有ext2/ext3/ext4，ext3是有日志的ext2改进版，ext4对相比ext3做了非常多的改进。虽然xfs/btrfs等文件系统有所不同，但它们只是在实现方式上不太同，再加上属于自己的特性而已。","text":"将磁盘进行分区，分区是将磁盘按柱面进行物理上的划分。划分好分区后还要进行格式化，然后再挂载才能使用(不考虑其他方法)。格式化分区的过程其实就是创建文件系统。 文件系统的类型有很多种，如CentOS 5和CentOS 6上默认使用的ext2/ext3/ext4，CentOS 7上默认使用的xfs，windows上的NTFS，光盘类的文件系统ISO9660，MAC上的混合文件系统HFS，网络文件系统NFS，Oracle研发的btrfs，还有老式的FAT/FAT32等。 本文将非常全面且详细地对ext家族的文件系统进行介绍。有ext2/ext3/ext4，ext3是有日志的ext2改进版，ext4对相比ext3做了非常多的改进。虽然xfs/btrfs等文件系统有所不同，但它们只是在实现方式上不太同，再加上属于自己的特性而已。 文件系统的组成部分block的出现硬盘的读写IO一次是一个扇区512字节，如果要读写大量文件，以扇区为单位肯定很慢很消耗性能，所以Linux中通过文件系统控制使用”块”为读写单元。现在的文件系统上，块的大小一般为1024bytes(1K)或2048bytes(2K)或4096bytes(4K)。比如需要读一个或多个块时，文件系统的IO管理器通知磁盘控制器要读取哪些块的数据，硬盘控制器将这些块按扇区读取出来，再通过硬盘控制器将这些扇区数据重组返回给计算机。 block的出现使得在文件系统层面上读写性能大大提高，也大量减少了碎片。但是它的副作用是可能造成空间浪费。由于文件系统以block为读写单元，即使存储的文件只有1K大小也将占用一个block，剩余的空间完全是浪费的。在某些业务需求下可能大量存储小文件，这会浪费大量的空间。 尽管有缺点，但是其优点足够明显，在当下硬盘容量廉价且追求性能的时代，使用block是一定的。 inode的出现如果存储的1个文件占用了大量的block读取时会如何？假如block大小为1KB，仅仅存储一个10M的文件就需要10240个block，而且这些blocks很可能在位置上是不连续在一起的(不相邻)，读取该文件时难道要从前向后扫描整个文件系统的块，然后找出属于该文件的块吗？显然是不应该这么做的，因为太慢太傻瓜式了。再考虑一下，读取一个只占用1个block的文件，难道只读取一个block就结束了吗？并不是，仍然是扫描整个文件系统的所有block，因为它不知道什么时候扫描到，扫描到了它也不知道这个文件是不是已经完整而不需要再扫描其他的block。 另外，每个文件都有属性(如权限、大小、时间戳等)，这些属性类的元数据存储在哪里呢？难道也和文件的数据部分存储在块中吗？如果一个文件占用多个block那是不是每个属于该文件的block都要存储一份文件元数据？但是如果不在每个block中存储元数据文件系统又怎么知道某一个block是不是属于该文件呢？但是显然，每个数据block中都存储一份元数据太浪费空间。 文件系统设计者当然知道这样的存储方式很不理想，所以需要优化存储方式。如何优化？对于这种类似的问题的解决方法是使用索引，通过扫描索引找到对应的数据，而且索引可以存储部分数据。 在文件系统上索引技术具体化为索引节点(index node)，在索引节点上存储的部分数据即为文件的属性元数据及其他少量信息。一般来说索引占用的空间相比其索引的文件数据而言占用的空间就小得多，扫描它比扫描整个数据要快得多，否则索引就没有存在的意义。这样一来就解决了前面所有的问题。 在文件系统上的术语中，索引节点称为inode。在inode中存储了inode号、文件类型、权限、文件所有者、大小、时间戳等元数据信息，最重要的是还存储了指向属于该文件block的指针，这样读取inode就可以找到属于该文件的block，进而读取这些block并获得该文件的数据。由于后面还会介绍一种指针，为了方便称呼和区分，暂且将这个inode记录中指向文件data block的指针称之为block指针，。 一般inode大小为128字节或256字节，相比那些MB或GB计算的文件数据而言小得多的多，但也要知道可能一个文件大小小于inode大小，例如只占用1个字节的文件。 bmap出现在向硬盘存储数据时，文件系统需要知道哪些块是空闲的，哪些块是已经占用了的。最笨的方法当然是从前向后扫描，遇到空闲块就存储一部分，继续扫描直到存储完所有数据。 优化的方法当然也可以考虑使用索引，但是仅仅1G的文件系统就有1KB的block共1024*1024=1048576个，这仅仅只是1G，如果是100G、500G甚至更大呢，仅仅使用索引索引的数量和空间占用也将极大，这时就出现更高一级的优化方法：使用块位图(bitmap简称bmap)。 位图只使用0和1标识对应block是空闲还是被占用，0和1在位图中的位置和block的位置一一对应，第一位标识第一个块，第二个位标识第二个块，依次下去直到标记完所有的block。 考虑下为什么块位图更优化。在位图中1个字节8个位，可以标识8个block。对于一个block大小为1KB、容量为1G的文件系统而言，block数量有10241024个，所以在位图中使用10241024个位共1024*1024/8=131072字节=128K，即1G的文件只需要128个block做位图就能完成一一对应。通过扫描这100多个block就能知道哪些block是空闲的，速度提高了非常多。 但是要注意，bmap的优化针对的是写优化，因为只有写才需要找到空闲block并分配空闲block。对于读而言，只要通过inode找到了block的位置，cpu就能迅速计算出block在物理磁盘上的地址，cpu的计算速度是极快的，计算block地址的时间几乎可以忽略，那么读速度基本认为是受硬盘本身性能的影响而与文件系统无关。大多数稍大一点的文件可能都会存储在不连续的block上，而且使用了一段时间的文件系统可能会有不少碎片，这时硬盘的随机读取性能直接决定读数据的速度，这也是机械硬盘速度相比固态硬盘慢的多的多的原因之一，而且固态硬盘的随机读和连续读取速度几乎是一致的，对它来说，文件系统碎片的多少并不会影响读取速度。 虽然bmap已经极大的优化了扫描，但是仍有其瓶颈：如果文件系统是100G呢？100G的文件系统要使用128*100=12800个1KB大小的block，这就占用了12.5M的空间了。试想完全扫描12800个很可能不连续的block这也是需要占用一些时间的，虽然快但是扛不住每次存储文件都要扫描带来的巨大开销。 所以需要再次优化，如何优化？简而言之就是将文件系统划分开形成块组，至于块组的介绍放在后文。 inode表的出现回顾下inode相关信息：inode存储了inode号、文件属性元数据、指向文件占用的block的指针；每一个inode占用128字节或256字节。 现在又出现问题了，一个文件系统中可以说有无数多个文件，每一个文件都对应一个inode，难道每一个仅128字节的inode都要单独占用一个block进行存储吗？这太浪费空间了。 所以更优的方法是将多个inode合并存储在block中，对于128字节的inode，一个block存储8个inode，对于256字节的inode，一个block存储4个inode。这就使得每个存储inode的块都不浪费。 在ext文件系统上，将这些物理上存储inode的block组合起来，在逻辑上形成一张inode表(inode table)来记录所有的inode。 举个例子，每一个家庭都要向派出所登记户口信息，通过户口本可以知道家庭住址，而每个镇或街道的派出所将本镇或本街道的所有户口整合在一起，要查找某一户地址时，在派出所就能快速查找到。inode table就是这里的派出所。它的内容如下图所示。 实际上，在文件系统创建完成后所有的inode号都已经分配好并记录到inode table中了，只不过被使用的inode号所在的行还有文件属性的元数据信息和block位置信息，而未被使用的inode号只有一个inode号而已而没有其他信息而已。 再细细一思考，就能发现一个大的文件系统仍将占用大量的块来存储inode，想要找到其中的一个inode记录也需要不小的开销，尽管它们已经形成了一张逻辑上的表，但扛不住表太大记录太多。那么如何快速找到inode，这同样是需要优化的，优化的方法是将文件系统的block进行分组划分，每个组中都存有本组inode table范围、bmap等。 imap的出现前面说bmap是块位图，用于标识文件系统中哪些block是空闲哪些block是占用的。 对于inode也一样，在存储文件(Linux中一切皆文件)时需要为其分配一个inode号。但是在格式化创建文件系统后所有的inode号都是被事先设定好存放在inode table中的，因此产生了问题：要为文件分配哪一个inode号呢？又如何知道某一个inode号是否已经被分配了呢？ 既然是”是否被占用”的问题，使用位图是最佳方案，像bmap记录block的占用情况一样。标识inode号是否被分配的位图称为inodemap简称为imap。这时要为一个文件分配inode号只需扫描imap即可知道哪一个inode号是空闲的。 imap存在着和bmap和inode table一样需要解决的问题：如果文件系统比较大，imap本身就会很大，每次存储文件都要进行扫描，会导致效率不够高。同样，优化的方式是将文件系统占用的block划分成块组，每个块组有自己的imap范围。 块组的出现前面一直提到的优化方法是将文件系统占用的block划分成块组(block group)，解决bmap、inode table和imap太大的问题。 在物理层面上的划分是将磁盘按柱面划分为多个分区，即多个文件系统；在逻辑层面上的划分是将文件系统划分成块组。每个文件系统包含多个块组，每个块组包含多个元数据区和数据区：元数据区就是存储bmap、inode table、imap等的数据；数据区就是存储文件数据的区域。注意块组是逻辑层面的概念，所以并不会真的在磁盘上按柱面、按扇区、按磁道等概念进行划分。 块组的划分块组在文件系统创建完成后就已经划分完成了，也就是说元数据区bmap、inode table和imap等信息占用的block以及数据区占用的block都已经划分好了。那么文件系统如何知道一个块组元数据区包含多少个block，数据区又包含多少block呢？ 它只需确定一个数据——每个block的大小，再根据bmap至多只能占用一个完整的block的标准就能计算出块组如何划分。如果文件系统非常小，所有的bmap总共都不能占用完一个block，那么也只能空闲bmap的block了。 每个block的大小在创建文件系统时可以人为指定，不指定也有默认值。 假如现在block的大小是1KB，一个bmap完整占用一个block能标识1024*8= 8192个block(当然这8192个block是数据区和元数据区共8192个，因为元数据区分配的block也需要通过bmap来标识)。每个block是1K，每个块组是8192K即8M，创建1G的文件系统需要划分1024/8=128个块组，如果是1.1G的文件系统呢？128+12.8=128+13=141个块组。 每个组的block数目是划分好了，但是每个组设定多少个inode号呢？inode table占用多少block呢？这需要由系统决定了，因为描述”每多少个数据区的block就为其分配一个inode号”的指标默认是我们不知道的，当然创建文件系统时也可以人为指定这个指标或者百分比例。见后文”inode深入”。 使用dumpe2fs可以将ext类的文件系统信息全部显示出来，当然bmap是每个块组固定一个block的不用显示，imap比bmap更小所以也只占用1个block不用显示。 下图是一个文件系统的部分信息，在这些信息的后面还有每个块组的信息，其实这里面的很多信息都可以通过几个比较基本的元数据推导出来。 从这张表中能计算出文件系统的大小，该文件系统共4667136个blocks，每个block大小为4K，所以文件系统大小为4667136*4/1024/1024=17.8GB。 也能计算出分了多少个块组，因为每一个块组的block数量为32768，所以块组的数量为4667136/32768=142.4即143个块组。由于块组从0开始编号，所以最后一个块组编号为Group 142。如下图所示是最后一个块组的信息。 文件系统的完整结构将上文描述的bmap、inode table、imap、数据区的blocks和块组的概念组合起来就形成了一个文件系统，当然这还不是完整的文件系统。完整的文件系统如下图。 首先，该图中多了Boot Block、Super Block、GDT、Reserver GDT这几个概念。下面会分别介绍它们。 然后，图中指明了块组中每个部分占用的block数量，除了superblock、bmap、imap能确定占用1个block，其他的部分都不能确定占用几个block。 最后，图中指明了Superblock、GDT和Reserved GDT是同时出现且不一定存在于每一个块组中的，也指明了bmap、imap、inode table和data blocks是每个块组都有的。 引导块即上图中的Boot Block部分，也称为boot sector。它位于分区上的第一个块，占用1024字节，并非所有分区都有这个boot sector，只有装了操作系统的主分区和装了操作系统的逻辑分区才有。里面存放的也是boot loader，这段boot loader称为VBR(主分区装操作系统时)或EBR(扩展分区装操作系统时)，这里的Boot loader和mbr上的boot loader是存在交错关系的。开机启动的时候，首先加载mbr中的bootloader，然后定位到操作系统所在分区的boot serctor上加载此处的boot loader。如果是多系统，加载mbr中的bootloader后会列出操作系统菜单，菜单上的各操作系统指向它们所在分区的boot sector上。它们之间的关系如下图所示。 但是，这种方式的操作系统菜单早已经弃之不用了，而是使用grub来管理启动菜单。尽管如此，在安装操作系统时，仍然有一步是选择boot loader安装位置的步骤。 超级块(superblock)既然一个文件系统会分多个块组，那么文件系统怎么知道分了多少个块组呢？每个块组又有多少block多少inode号等等信息呢？还有，文件系统本身的属性信息如各种时间戳、block总数量和空闲数量、inode总数量和空闲数量、当前文件系统是否正常、什么时候需要自检等等，它们又存储在哪里呢？ 毫无疑问，这些信息必须要存储在block中。存储这些信息占用1024字节，所以也要一个block，这个block称为超级块(superblock)，它的block号可能为0也可能为1。如果block大小为1K，则引导块正好占用一个block，这个block号为0，所以superblock的号为1；如果block大小大于1K，则引导块和超级块同置在一个block中，这个block号为0。总之superblock的起止位置是第二个1024(1024-2047)字节。 使用df命令读取的就是每个文件系统的superblock，所以它的统计速度非常快。相反，用du命令查看一个较大目录的已用空间就非常慢，因为不可避免地要遍历整个目录的所有文件。 12345[root@xuexi ~]# df -hTFilesystem Type Size Used Avail Use% Mounted on/dev/sda3 ext4 18G 1.7G 15G 11% /tmpfs tmpfs 491M 0 491M 0% /dev/shm/dev/sda1 ext4 190M 32M 149M 18% /boot superblock对于文件系统而言是至关重要的，超级块丢失或损坏必将导致文件系统的损坏。所以旧式的文件系统将超级块备份到每一个块组中，但是这又有所空间浪费，所以ext2文件系统只在块组0、1和3、5、7幂次方的块组中保存超级块的信息，如Group9、Group25等。尽管保存了这么多的superblock，但是文件系统只使用第一个块组即Group0中超级块信息来获取文件系统属性，只有当Group0上的superblock损坏或丢失才会找下一个备份超级块复制到Group0中来恢复文件系统。 下图是一个ext4文件系统的superblock的信息，ext家族的文件系统都能使用dumpe2fs -h获取。 块组描述符表(GDT)既然文件系统划分了块组，那么每个块组的信息和属性元数据又保存在哪里呢？ ext文件系统每一个块组信息使用32字节描述，这32个字节称为块组描述符，所有块组的块组描述符组成块组描述符表GDT(group descriptor table)。 虽然每个块组都需要块组描述符来记录块组的信息和属性元数据，但是不是每个块组中都存放了块组描述符。ext文件系统的存储方式是：将它们组成一个GDT，并将该GDT存放于某些块组中，存放GDT的块组和存放superblock和备份superblock的块相同，也就是说它们是同时出现在某一个块组中的。读取时也总是读取Group0中的块组描述符表信息。 假如block大小为4KB的文件系统划分了143个块组，每个块组描述符32字节，那么GDT就需要143*32=4576字节即两个block来存放。这两个GDT block中记录了所有块组的块组信息，且存放GDT的块组中的GDT都是完全相同的。 下图是一个块组描述符的信息(通过dumpe2fs获取)。 保留GDT(Reserved GDT)保留GDT用于以后扩容文件系统使用，防止扩容后块组太多，使得块组描述符超出当前存储GDT的blocks。保留GDT和GDT总是同时出现，当然也就和superblock同时出现了。 例如前面143个块组使用了2个block来存放GDT，但是此时第二个block还空余很多空间，当扩容到一定程度时2个block已经无法再记录块组描述符了，这时就需要分配一个或多个Reserverd GDT的block来存放超出的块组描述符。 由于新增加了GDT block，所以应该让每一个保存GDT的块组都同时增加这一个GDT block，所以将保留GDT和GDT存放在同一个块组中可以直接将保留GDT变换为GDT而无需使用低效的复制手段备份到每个存放GDT的块组。 同理，新增加了GDT需要修改每个块组中superblock中的文件系统属性，所以将superblock和Reserverd GDT/GDT放在一起又能提升效率。 Data Block 如上图，除了Data Blocks其他的部分都解释过了。data block是直接存储数据的block，但事实上并非如此简单。 数据所占用的block由文件对应inode记录中的block指针找到，不同的文件类型，数据block中存储的内容是不一样的。以下是Linux中不同类型文件的存储方式。 对于常规文件，文件的数据正常存储在数据块中。 对于目录，该目录下的所有文件和一级子目录的目录名存储在数据块中。 文件名不是存储在其自身的inode中，而是存储在其所在目录的data block中。 对于符号链接，如果目标路径名较短则直接保存在inode中以便更快地查找，如果目标路径名较长则分配一个数据块来保存。 设备文件、FIFO和socket等特殊文件没有数据块，设备文件的主设备号和次设备号保存在inode中。 常规文件的存储就不解释了，下面分别解释特殊文件的存储方式。 目录文件的data block对于目录文件，其inode记录中存储的是目录的inode号、目录的属性元数据和目录文件的block指针，这里面没有存储目录自身文件名的信息。 而其data block的存储方式则如下图所示。 由图可知，在目录文件的数据块中存储了其下的文件名、目录名、目录本身的相对名称”.”和上级目录的相对名称”..”，还存储了指向inode table中这些文件名对应的inode号的指针(并非直接存储inode号码)、目录项长度rec_len、文件名长度name_len和文件类型file_type。注意到除了文件本身的inode记录了文件类型，其所在的目录的数据块也记录了文件类型。由于rec_len只能是4的倍数，所以需要使用”\\0”来填充name_len不够凑满4倍数的部分。至于rec_len具体是什么，只需知道它是一种偏移即可。 目录的data block中并没有直接存储目录中文件的inode号，它存储的是指向inode table中对应文件inode号的指针，暂且称之为inode指针(至此，已经知道了两种指针：一种是inode table中每个inode记录指向其对应data block的block指针，一个此处的inode指针)。一个很有说服力的例子，在目录只有读而没有执行权限的时候，使用”ls -l”是无法获取到其内文件inode号的，这就表明没有直接存储inode号。实际上，因为在创建文件系统的时候，inode号就已经全部划分好并在每个块组的inode table中存放好，inode table在块组中是有具体位置的，如果使用dumpe2fs查看文件系统，会发现每个块组的inode table占用的block数量是完全相同的，如下图是某分区上其中两个块组的信息，它们都占用249个block。 除了inode指针，目录的data block中还使用数字格式记录了文件类型，数字格式和文件类型的对应关系如下图。 注意到目录的data block中前两行存储的是目录本身的相对名称”.”和上级目录的相对名称”..”，它们实际上是目录本身的硬链接和上级目录的硬链接。硬链接的本质后面说明。 由此也就容易理解目录权限的特殊之处了。目录文件的读权限(r)和写权限(w)，都是针对目录文件的数据块本身。由于目录文件内只有文件名、文件类型和inode指针，所以如果只有读权限，只能获取文件名和文件类型信息，无法获取其他信息，尽管目录的data block中也记录着文件的inode指针，但定位指针是需要x权限的，因为其它信息都储存在文件自身对应的inode中，而要读取文件inode信息需要有目录文件的执行权限通过inode指针定位到文件对应的inode记录上。以下是没有目录x权限时的查询状态，可以看到除了文件名和文件类型，其余的全是”?”。 123456[lisi4@xuexi tmp]$ ll -i dls: cannot access d/hehe: Permission deniedls: cannot access d/haha: Permission deniedtotal 0? d????????? ? ? ? ? ? haha? -????????? ? ? ? ? ? hehe 注意，xfs文件系统和ext文件系统不一样，它连文件类型都无法获取。 符号链接存储方式符号链接即为软链接，类似于Windows操作系统中的快捷方式，它的作用是指向原文件或目录。 软链接之所以也被称为特殊文件的原因是：它一般情况下不占用data block，仅仅通过它对应的inode记录就能将其信息描述完成；符号链接的大小是其指向目标路径占用的字符个数，例如某个符号链接的指向方式为”rmt –&gt; ../sbin/rmt”，则其文件大小为11字节；只有当符号链接指向的目标的路径名较长(60个字节)时文件系统才会划分一个data block给它；它的权限如何也不重要，因它只是一个指向原文件的”工具”，最终决定是否能读写执行的权限由原文件决定，所以很可能ls -l查看到的符号链接权限为777。 注意，软链接的block指针存储的是目标文件名。也就是说，链接文件的一切都依赖于其目标文件名。这就解释了为什么/mnt的软链接/tmp/mnt在/mnt挂载文件系统后，通过软链接就能进入/mnt所挂载的文件系统。究其原因，还是因为其目标文件名”/mnt”并没有改变。 例如以下筛选出了/etc/下的符号链接，注意观察它们的权限和它们占用的空间大小。 1234567891011121314151617[root@xuexi ~]# ll /etc/ | grep &apos;^l&apos;lrwxrwxrwx. 1 root root 56 Feb 18 2016 favicon.png -&gt; /usr/share/icons/hicolor/16x16/apps/system-logo-icon.pnglrwxrwxrwx. 1 root root 22 Feb 18 2016 grub.conf -&gt; ../boot/grub/grub.conflrwxrwxrwx. 1 root root 11 Feb 18 2016 init.d -&gt; rc.d/init.dlrwxrwxrwx. 1 root root 7 Feb 18 2016 rc -&gt; rc.d/rclrwxrwxrwx. 1 root root 10 Feb 18 2016 rc0.d -&gt; rc.d/rc0.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc1.d -&gt; rc.d/rc1.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc2.d -&gt; rc.d/rc2.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc3.d -&gt; rc.d/rc3.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc4.d -&gt; rc.d/rc4.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc5.d -&gt; rc.d/rc5.dlrwxrwxrwx. 1 root root 10 Feb 18 2016 rc6.d -&gt; rc.d/rc6.dlrwxrwxrwx. 1 root root 13 Feb 18 2016 rc.local -&gt; rc.d/rc.locallrwxrwxrwx. 1 root root 15 Feb 18 2016 rc.sysinit -&gt; rc.d/rc.sysinitlrwxrwxrwx. 1 root root 14 Feb 18 2016 redhat-release -&gt; centos-releaselrwxrwxrwx. 1 root root 11 Apr 10 2016 rmt -&gt; ../sbin/rmtlrwxrwxrwx. 1 root root 14 Feb 18 2016 system-release -&gt; centos-release 设备文件、FIFO、套接字文件关于这3种文件类型的文件只需要通过inode就能完全保存它们的信息，它们不占用任何数据块，所以它们是特殊文件。 设备文件的主设备号和次设备号也保存在inode中。以下是/dev/下的部分设备信息。注意到它们的第5列和第6列信息，它们分别是主设备号和次设备号，主设备号标识每一种设备的类型，次设备号标识同种设备类型的不同编号；也注意到这些信息中没有大小的信息，因为设备文件不占用数据块所以没有大小的概念。 1234567891011[root@xuexi ~]# ll /dev | tailcrw-rw---- 1 vcsa tty 7, 129 Oct 7 21:26 vcsa1crw-rw---- 1 vcsa tty 7, 130 Oct 7 21:27 vcsa2crw-rw---- 1 vcsa tty 7, 131 Oct 7 21:27 vcsa3crw-rw---- 1 vcsa tty 7, 132 Oct 7 21:27 vcsa4crw-rw---- 1 vcsa tty 7, 133 Oct 7 21:27 vcsa5crw-rw---- 1 vcsa tty 7, 134 Oct 7 21:27 vcsa6crw-rw---- 1 root root 10, 63 Oct 7 21:26 vga_arbitercrw------- 1 root root 10, 57 Oct 7 21:26 vmcicrw-rw-rw- 1 root root 10, 56 Oct 7 21:27 vsockcrw-rw-rw- 1 root root 1, 5 Oct 7 21:26 zero inode基础知识每个文件都有一个inode，在将inode关联到文件后系统将通过inode号来识别文件，而不是文件名。并且访问文件时将先找到inode，通过inode中记录的block位置找到该文件。 硬链接虽然每个文件都有一个inode，但是存在一种可能：多个文件的inode相同，也就即inode号、元数据、block位置都相同，这是一种什么样的情况呢？能够想象这些inode相同的文件使用的都是同一条inode记录，所以代表的都是同一个文件，这些文件所在目录的data block中的inode指针目的地都是一样的，只不过各指针对应的文件名互不相同而已。这种inode相同的文件在Linux中被称为”硬链接”。 硬链接文件的inode都相同，每个文件都有一个”硬链接数”的属性，使用ls -l的第二列就是被硬链接数，它表示的就是该文件有几个硬链接。 1234567[root@xuexi ~]# ls -ltotal 48drwxr-xr-x 5 root root 4096 Oct 15 18:07 700-rw-------. 1 root root 1082 Feb 18 2016 anaconda-ks.cfg-rw-r--r-- 1 root root 399 Apr 29 2016 Identity.pub-rw-r--r--. 1 root root 21783 Feb 18 2016 install.log-rw-r--r--. 1 root root 6240 Feb 18 2016 install.log.syslog 例如下图描述的是dir1目录中的文件name1及其硬链接dir2/name2，右边分别是它们的inode和datablock。这里也看出了硬链接文件之间唯一不同的就是其所在目录中的记录不同。注意下图中有一列Link Count就是标记硬链接数的属性。 每创建一个文件的硬链接，实质上是多一个指向该inode记录的inode指针，并且硬链接数加1。 删除文件的实质是删除该文件所在目录data block中的对应的inode指针，所以也是减少硬链接次数，由于block指针是存储在inode中的，所以不是真的删除数据，如果仍有其他指针指向该inode，那么该文件的block指针仍然是可用的。当硬链接次数为1时再删除文件就是真的删除文件了，此时inode记录中block指针也将被删除。 不能跨分区创建硬链接，因为不同文件系统的inode号可能会相同，如果允许创建硬链接，复制到另一个分区时inode可能会和此分区已使用的inode号冲突。 硬链接只能对文件创建，无法对目录创建硬链接。之所以无法对目录创建硬链接，是因为文件系统已经把每个目录的硬链接创建好了，它们就是相对路径中的”.”和”..”，分别标识当前目录的硬链接和上级目录的硬链接。每一个目录中都会包含这两个硬链接，它包含了两个信息：(1)一个没有子目录的目录文件的硬链接数是2，其一是目录本身，即该目录datablock中的”.”，其二是其父目录datablock中该目录的记录，这两者都指向同一个inode号；(2)一个包含子目录的目录文件，其硬链接数是2+子目录数，因为每个子目录都关联一个父目录的硬链接”..”。很多人在计算目录的硬链接数时认为由于包含了”.”和”..”，所以空目录的硬链接数是2，这是错误的，因为”..”不是本目录的硬链接。另外，还有一个特殊的目录应该纳入考虑，即”/“目录，它自身是一个文件系统的入口，是自引用(下文中会解释自引用)的，所以”/“目录下的”.”和”..”的inode号相同，它自身不占用硬链接，因为其datablock中只记录inode号相同的”.”和”..”，不再像其他目录一样还记录一个名为”/“的目录，所以”/“的硬链接数也是2+子目录数，但这个2是”.”和”..”的结果。 12[root@xuexi ~]# ln /tmp /mydataln: `/tmp&apos;: hard link not allowed for directory 为什么文件系统自己创建好了目录的硬链接就不允许人为创建呢？从”.”和”..”的用法上考虑，如果当前目录为/usr，我们可以使用”./local”来表示/usr/local，但是如果我们人为创建了/usr目录的硬链接/tmp/husr，难道我们也要使用”/tmp/husr/local”来表示/usr/local吗？这其实已经是软链接的作用了。若要将其认为是硬链接的功能，这必将导致硬链接维护的混乱。 不过，通过mount工具的”–bind”选项，可以将一个目录挂载到另一个目录下，实现伪”硬链接”，它们的内容和inode号是完全相同的。 硬链接的创建方法： ln file_target link_name 。 软链接软链接就是字符链接，链接文件默认指的就是字符链接文件(注意不是字符设备)，使用”l”表示其类型。 软链接在功能上等价与Windows系统中的快捷方式，它指向原文件，原文件损坏或消失，软链接文件就损坏。可以认为软链接inode记录中的指针内容是目标路径的字符串。 创建方式： ln –s source_file softlink_name ，记住是source_file&lt;–link_name的指向关系(反箭头)，以前我老搞错位置。 查看软链接的值： readlink softlink_name 在设置软链接的时候，source_file虽然不要求是绝对路径，但建议给绝对路径。是否还记得软链接文件的大小？它是根据软链接所指向路径的字符数计算的，例如某个符号链接的指向方式为”rmt –&gt; ../sbin/rmt”，它的文件大小为11字节，也就是说只要建立了软链接后，软链接的指向路径是不会改变的，仍然是”../sbin/rmt”。如果此时移动软链接文件本身，它的指向是不会改变的，仍然是11个字符的”../sbin/rmt”，但此时该软链接父目录下可能根本就不存在/sbin/rmt，也就是说此时该软链接是一个被破坏的软链接。 inode深入inode大小和划分inode大小为128字节的倍数，最小为128字节。它有默认值大小，它的默认值由/etc/mke2fs.conf文件中指定。不同的文件系统默认值可能不同。 12345678910111213141516[root@xuexi ~]# cat /etc/mke2fs.conf[defaults] base_features = sparse_super,filetype,resize_inode,dir_index,ext_attr enable_periodic_fsck = 1 blocksize = 4096 inode_size = 256 inode_ratio = 16384[fs_types] ext3 = &#123; features = has_journal &#125; ext4 = &#123; features = has_journal,extent,huge_file,flex_bg,uninit_bg,dir_nlink,extra_isize inode_size = 256 &#125; 同样观察到这个文件中还记录了blocksize的默认值和inode分配比率inode_ratio。inode_ratio=16384表示每16384个字节即16KB就分配一个inode号，由于默认blocksize=4KB，所以每4个block就分配一个inode号。当然分配的这些inode号只是预分配，并不真的代表会全部使用，毕竟每个文件才会分配一个inode号。但是分配的inode自身会占用block，而且其自身大小256字节还不算小，所以inode号的浪费代表着空间的浪费。 既然知道了inode分配比率，就能计算出每个块组分配多少个inode号，也就能计算出inode table占用多少个block。 如果文件系统中大量存储电影等大文件，inode号就浪费很多，inode占用的空间也浪费很多。但是没办法，文件系统又不知道你这个文件系统是用来存什么样的数据，多大的数据，多少数据。 当然inodesize、inode分配比例、blocksize都可以在创建文件系统的时候人为指定。 ext文件系统预留的inode号Ext预留了一些inode做特殊特性使用，如下：某些可能并非总是准确，具体的inode号对应什么文件可以使用”find / -inum NUM”查看。 123456789101112Ext4的特殊inodeInode号 用途0 不存在0号inode1 虚拟文件系统，如/proc和/sys2 根目录3 ACL索引4 ACL数据5 Boot loader6 未删除的目录7 预留的块组描述符inode8 日志inode11 第一个非预留的inode，通常是lost+found目录 所以在ext4文件系统的dumpe2fs信息中，能观察到fisrt inode号可能为11也可能为12。 并且注意到”/“的inode号为2，这个特性在文件访问时会用上。 需要注意的是，每个文件系统都会分配自己的inode号，不同文件系统之间是可能会出现使用相同inode号文件的。例如： 123456[root@xuexi ~]# find / -ignore_readdir_race -inum 2 -ls 2 4 dr-xr-xr-x 22 root root 4096 Jun 9 09:56 / 2 2 dr-xr-xr-x 5 root root 1024 Feb 25 11:53 /boot 2 0 c--------- 1 root root Jun 7 02:13 /dev/pts/ptmx 2 0 -rw-r--r-- 1 root root 0 Jun 6 18:13 /proc/sys/fs/binfmt_misc/status 2 0 drwxr-xr-x 3 root root 0 Jun 6 18:13 /sys/fs 从结果中可见，除了根的Inode号为2，还有几个文件的inode号也是 2，它们都属于独立的文件系统，有些是虚拟文件系统，如/proc和/sys。 ext2/3的inode直接、间接寻址前文说过，inode中保存了blocks指针，但是一条inode记录中能保存的指针数量是有限的，否则就会超出inode大小(128字节或256字节)。 在ext2和ext3文件系统中，一个inode中最多只能有15个指针，每个指针使用i_block[n]表示。 前12个指针i_block[0]到i_block[11]是直接寻址指针，每个指针指向一个数据区的block。如下图所示。 第13个指针i_block[12]是一级间接寻址指针，它指向一个仍然存储了指针的block即i_block[12] –&gt; Pointerblock –&gt; datablock。 第14个指针i_block[13]是二级间接寻址指针，它指向一个仍然存储了指针的block，但是这个block中的指针还继续指向其他存储指针的block，即i_block[13] –&gt; Pointerblock1 –&gt; PointerBlock2 –&gt; datablock。 第15个指针i_block[14]是三级间接寻址指针，它指向一个任然存储了指针的block，这个指针block下还有两次指针指向。即i_block[13] –&gt; Pointerblock1 –&gt; PointerBlock2 –&gt; PointerBlock3 –&gt; datablock。 其中由于每个指针大小为4字节，所以每个指针block能存放的指针数量为BlockSize/4byte。例如blocksize为4KB，那么一个Block可以存放4096/4=1024个指针。 如下图。 为什么要分间接和直接指针呢？如果一个inode中15个指针全是直接指针，假如每个block的大小为1KB，那么15个指针只能指向15个block即15KB的大小，由于每个文件对应一个inode号，所以就限制了每个文件最大为15*1=15KB，这显然是不合理的。 如果存储大于15KB的文件而又不太大的时候，就占用一级间接指针i_block[12]，这时可以存放指针数量为1024/4+12=268，所以能存放268KB的文件。 如果存储大于268K 的文件而又不太大的时候，就继续占用二级指针i_block[13]，这时可以存放指针数量为[1024/4]^2+1024/4+12=65804，所以能存放65804KB=64M左右的文件。 如果存放的文件大于64M，那么就继续使用三级间接指针i_block[14]，存放的指针数量为[1024/4]^3+[1024/4]^2+[1024/4]+12=16843020个指针，所以能存放16843020KB=16GB左右的文件。 如果blocksize=4KB呢？那么最大能存放的文件大小为([4096/4]^3+[4096/4]^2+[4096/4]+12)*4/1024/1024/1024=4T左右。当然这样计算出来的不一定就是最大能存放的文件大小，它还受到另一个条件的限制。这里的计算只是表明一个大文件是如何寻址和分配的。 其实看到这里的计算数值，就知道ext2和ext3对超大文件的存取效率是低下的，它要核对太多的指针，特别是4KB大小的blocksize时。而ext4针对这一点就进行了优化，ext4使用extent的管理方式取代ext2和ext3的块映射，大大提高了效率也降低了碎片。 单文件系统中文件操作的原理在Linux上执行删除、复制、重命名、移动等操作时，它们是怎么进行的呢？还有访问文件时是如何找到它的呢？其实只要理解了前文中介绍的几个术语以及它们的作用就很容易知道文件操作的原理了。 注：在这一小节所解释的都是在单个文件系统下的行为，在多个文件系统中如何请看下一个小节：多文件系统关联。 读取文件当执行”cat /var/log/messages”命令在系统内部进行了什么样的步骤呢？该命令能被成功执行涉及了cat命令的寻找、权限判断以及messages文件的寻找和权限判断等等复杂的过程。这里只解释和本节内容相关的如何寻找到被cat的/var/log/messages文件。 找到根文件系统的块组描述符表所在的blocks，读取GDT(已在内存中)找到inode table的block号。 因为GDT总是和superblock在同一个块组，而superblock总是在分区的第1024-2047个字节，所以很容易就知道第一个GDT所在的块组以及GDT在这个块组中占用了哪些block。其实GDT早已经在内存中了，在系统开机的时候会挂在根文件系统，挂载的时候就已经将所有的GDT放进内存中。 在inode table的block中定位到根”/“的inode，找出”/“指向的data block。 前文说过，ext文件系统预留了一些inode号，其中”/“的inode号为2，所以可以根据inode号直接定位根目录文件的data block。 在”/“的datablock中记录了var目录名和指向var目录文件inode的指针，并找到该inode记录，inode记录中存储了指向var的block指针，所以也就找到了var目录文件的data block。 通过var目录的inode指针，可以寻找到var目录的inode记录，但是指针定位的过程中，还需要知道该inode记录所在的块组以及所在的inode table，所以需要读取GDT，同样，GDT已经缓存到了内存中。 在var的data block中记录了log目录名和其inode指针，通过该指针定位到该inode所在的块组及所在的inode table，并根据该inode记录找到log的data block。 在log目录文件的data block中记录了messages文件名和对应的inode指针，通过该指针定位到该inode所在的块组及所在的inode table，并根据该inode记录找到messages的data block。 最后读取messages对应的datablock。将上述步骤中GDT部分的步骤简化后比较容易理解。如下:找到GDT–&gt;找到”/“的inode–&gt;找到/的数据块读取var的inode–&gt;找到var的数据块读取log的inode–&gt;找到log的数据块读取messages的inode–&gt;找到messages的数据块并读取它们。 删除、重命名和移动文件注意这里是不跨越文件系统的操作行为。 删除文件分为普通文件和目录文件，知道了这两种类型的文件的删除原理，就知道了其他类型特殊文件的删除方法。 对于删除普通文件：(1)找到文件的inode和data block(根据前一个小节中的方法寻找)；(2)将inode table中该inode记录中的data block指针删除；(3)在imap中将该文件的inode号标记为未使用；(4)在其所在目录的data block中将该文件名所在的记录行删除，删除了记录就丢失了指向inode的指针；(5)将bmap中data block对应的block号标记为未使用。 对于删除目录文件：找到目录和目录下所有文件、子目录、子文件的inode和data block；在imap中将这些inode号标记为未使用；将bmap中将这些文件占用的 block号标记为未使用；在该目录的父目录的data block中将该目录名所在的记录行删除。需要注意的是，删除父目录data block中的记录是最后一步，如果该步骤提前，将报目录非空的错误，因为在该目录中还有文件占用。 关于上面的(2)-(5)：当(2)中删除data block指针后，将无法再找到这个文件的数据；当(3)标记inode号未使用，表示该inode号可以被后续的文件重用；当(4)删除目录data block中关于该文件的记录，真正的删除文件，外界再也定位也无法看到这个文件了；当(5)标记data block为未使用后，表示开始释放空间，这些data block可以被其他文件重用。 注意，在第(5)步之前，由于data block还未被标记为未使用，在superblock中仍然认为这些data block是正在使用中的。这表示尽管文件已经被删除了，但空间却还没有释放，df也会将其统计到已用空间中(df是读取superblock中的数据块数量，并计算转换为空间大小)。 什么时候会发生这种情况呢？当一个进程正在引用文件时将该文件删除，就会出现文件已删除但空间未释放的情况。这时步骤已经进行到(4)，外界无法再找到该文件，但由于进程在加载该文件时已经获取到了该文件所有的data block指针，该进程可以获取到该文件的所有数据，但却暂时不会释放该文件空间。直到该进程结束，文件系统才将未执行的步骤(5)继续完成。这也是为什么有时候du的统计结果比df小的原因，关于du和df统计结果的差别，详细内容见：详细分析du和df的统计结果为什么不一样。 重命名文件分为同目录内重命名和非同目录内重命名。非同目录内重命名实际上是移动文件的过程，见下文。 同目录内重命名文件的动作仅仅只是修改所在目录data block中该文件记录的文件名部分，不是删除再重建的过程。 如果重命名时有文件名冲突(该目录内已经存在该文件名)，则提示是否覆盖。覆盖的过程是覆盖目录data block中冲突文件的记录。例如/tmp/下有a.txt和a.log，若将a.txt重命名为a.log，则提示覆盖，若选择覆盖，则/tmp的data block中关于a.log的记录被覆盖，此时它的指针是指向a.txt的inode。 移动文件同文件系统下移动文件实际上是修改目标文件所在目录的data block，向其中添加一行指向inode table中待移动文件的inode指针，如果目标路径下有同名文件，则会提示是否覆盖，实际上是覆盖目录data block中冲突文件的记录，由于同名文件的inode记录指针被覆盖，所以无法再找到该文件的data block，也就是说该文件被标记为删除(如果多个硬链接数，则另当别论)。 所以在同文件系统内移动文件相当快，仅仅在所在目录data block中添加或覆盖了一条记录而已。也因此，移动文件时，文件的inode号是不会改变的。 对于不同文件系统内的移动，相当于先复制再删除的动作。见后文。 关于文件移动，在Linux环境下有一个非常经典网上却又没任何解释的问题：/tmp/a/a能覆盖为/tmp/a吗？答案是不能，但windows能。为什么不能？见mv的一个经典问题(mv的本质)。 存储和复制文件对于文件存储 (1).读取GDT，找到各个(或部分)块组imap中未使用的inode号，并为待存储文件分配inode号； (2).在inode table中完善该inode号所在行的记录； (3).在目录的data block中添加一条该文件的相关记录； (4).将数据填充到data block中。注意，填充到data block中的时候会调用block分配器：一次分配4KB大小的block数量，当填充完4KB的data block后会继续调用block分配器分配4KB的block，然后循环直到填充完所有数据。也就是说，如果存储一个100M的文件需要调用block分配器100*1024/4=25600次。 另一方面，在block分配器分配block时，block分配器并不知道真正有多少block要分配，只是每次需要分配时就分配，在每存储一个data block前，就去bmap中标记一次该block已使用，它无法实现一次标记多个bmap位。这一点在ext4中进行了优化。 (5)填充完之后，去inode table中更新该文件inode记录中指向data block的寻址指针。 对于复制，完全就是另一种方式的存储文件。步骤和存储文件的步骤一样。 多文件系统关联在单个文件系统中的文件操作和多文件系统中的操作有所不同。本文将对此做出非常详细的说明。 根文件系统的特殊性这里要明确的是，任何一个文件系统要在Linux上能正常使用，必须挂载在某个已经挂载好的文件系统中的某个目录下，例如/dev/cdrom挂载在/mnt上，/mnt目录本身是在”/“文件系统下的。而且任意文件系统的一级挂载点必须是在根文件系统的某个目录下，因为只有”/“是自引用的。这里要说明挂载点的级别和自引用的概念。 假如/dev/sdb1挂载在/mydata上，/dev/cdrom挂载在/mydata/cdrom上，那么/mydata就是一级挂载点，此时/mydata已经是文件系统/dev/sdb1的入口了，而/dev/cdrom所挂载的目录/mydata/cdrom是文件系统/dev/sdb1中的某个目录，那么/mydata/cdrom就是二级挂载点。一级挂载点必须在根文件系统下，所以可简述为：文件系统2挂载在文件系统1中的某个目录下，而文件系统1又挂载在根文件系统中的某个目录下。 再解释自引用。首先要说的是，自引用的只能是文件系统，而文件系统表现形式是一个目录，所以自引用是指该目录的data block中，”.”和”..”的记录中的inode指针都指向inode table中同一个inode记录，所以它们inode号是相同的，即互为硬链接。而根文件系统是唯一可以自引用的文件系统。 1234[root@xuexi /]# ll -ai /total 102 2 dr-xr-xr-x. 22 root root 4096 Jun 6 18:13 . 2 dr-xr-xr-x. 22 root root 4096 Jun 6 18:13 .. 由此也能解释cd /.和cd /..的结果都还是在根下，这是自引用最直接的表现形式。 1234[root@xuexi tmp]# cd /.[root@xuexi /]#[root@xuexi tmp]# cd /..[root@xuexi /]# 注意，根目录下的”.”和”..”都是”/“目录的硬链接，且其datablock中不记录名为”/“的条目，因此除去根目录下子目录数后的硬链接数为2。 1234[root@server2 tmp]# a=$(ls -ld / | awk &apos;&#123;print $2&#125;&apos;)[root@server2 tmp]# b=$(ls -l / | grep &quot;^d&quot; |wc -l)[root@server2 tmp]# echo $((a - b))2 挂载文件系统的细节挂载文件系统到某个目录下，例如”mount /dev/cdrom /mnt”，挂载成功后/mnt目录中的文件全都暂时不可见了，且挂载后权限和所有者(如果指定允许普通用户挂载)等的都改变了，知道为什么吗？ 下面就以通过”mount /dev/cdrom /mnt”为例，详细说明挂载过程中涉及的细节。 在将文件系统/dev/cdrom(此处暂且认为它是文件系统)挂载到挂载点/mnt之前，挂载点/mnt是根文件系统中的一个目录，”/“的data block中记录了/mnt的一些信息，其中包括inode指针inode_n，而在inode table中，/mnt对应的inode记录中又存储了block指针block_n，此时这两个指针还是普通的指针。 当文件系统/dev/cdrom挂载到/mnt上后，/mnt此时就已经成为另一个文件系统的入口了，因此它需要连接两边文件系统的inode和data block。但是如何连接呢？如下图。 在根文件系统的inode table中，为/mnt重新分配一个inode记录m，该记录的block指针block_m指向文件系统/dev/cdrom中的data block。既然为/mnt分配了新的inode记录m，那么在”/“目录的data block中，也需要修改其inode指针为inode_m以指向m记录。同时，原来inode table中的inode记录n就被标记为暂时不可用。 block_m指向的是文件系统/dev/cdrom的data block，所以严格说起来，除了/mnt的元数据信息即inode记录m还在根文件系统上，/mnt的data block已经是在/dev/cdrom中的了。这就是挂载新文件系统后实现的跨文件系统，它将挂载点的元数据信息和数据信息分别存储在不同的文件系统上。 挂载完成后，将在/proc/self/{mounts,mountstats,mountinfo}这三个文件中写入挂载记录和相关的挂载信息，并会将/proc/self/mounts中的信息同步到/etc/mtab文件中，当然，如果挂载时加了-n参数，将不会同步到/etc/mtab。 而卸载文件系统，其实质是移除临时新建的inode记录(当然，在移除前会检查是否正在使用)及其指针，并将指针指回原来的inode记录，这样inode记录中的block指针也就同时生效而找回对应的data block了。由于卸载只是移除inode记录，所以使用挂载点和文件系统都可以实现卸载，因为它们是联系在一起的。 下面是分析或结论。 (1).挂载点挂载时的inode记录是新分配的。 挂载前挂载点/mnt的inode号1234[root@server2 tmp]# ll -id /mnt100663447 drwxr-xr-x. 2 root root 6 Aug 12 2015 /mnt[root@server2 tmp]# mount /dev/cdrom /mnt 挂载后挂载点的inode号12[root@server2 tmp]# ll -id /mnt 1856 dr-xr-xr-x 8 root root 2048 Dec 10 2015 mnt 由此可以验证，inode号确实是重新分配的。 (2).挂载后，挂载点的内容将暂时不可见、不可用，卸载后文件又再次可见、可用。 123# 在挂载前，向挂载点中创建几个文件[root@server2 tmp]# touch /mnt/a.txt[root@server2 tmp]# mkdir /mnt/abcdir 12345678910111213141516171819202122232425# 挂载[root@server2 tmp]# mount /dev/cdrom /mnt# 挂载后，挂载点中将找不到刚创建的文件[root@server2 tmp]# ll /mnttotal 636-r--r--r-- 1 root root 14 Dec 10 2015 CentOS_BuildTagdr-xr-xr-x 3 root root 2048 Dec 10 2015 EFI-r--r--r-- 1 root root 215 Dec 10 2015 EULA-r--r--r-- 1 root root 18009 Dec 10 2015 GPLdr-xr-xr-x 3 root root 2048 Dec 10 2015 imagesdr-xr-xr-x 2 root root 2048 Dec 10 2015 isolinuxdr-xr-xr-x 2 root root 2048 Dec 10 2015 LiveOSdr-xr-xr-x 2 root root 612352 Dec 10 2015 Packagesdr-xr-xr-x 2 root root 4096 Dec 10 2015 repodata-r--r--r-- 1 root root 1690 Dec 10 2015 RPM-GPG-KEY-CentOS-7-r--r--r-- 1 root root 1690 Dec 10 2015 RPM-GPG-KEY-CentOS-Testing-7-r--r--r-- 1 root root 2883 Dec 10 2015 TRANS.TBL# 卸载后，挂载点/mnt中的文件将再次可见[root@server2 tmp]# umount /mnt[root@server2 tmp]# ll /mnttotal 0drwxr-xr-x 2 root root 6 Jun 9 08:18 abcdir-rw-r--r-- 1 root root 0 Jun 9 08:18 a.txt 之所以会这样，是因为挂载文件系统后，挂载点原来的inode记录暂时被标记为不可用，关键是没有指向该inode记录的inode指针了。在卸载文件系统后，又重新启用挂载点原来的inode记录，”/“目录下的mnt的inode指针又重新指向该inode记录。 (3).挂载后，挂载点的元数据和data block是分别存放在不同文件系统上的。 (4).挂载点即使在挂载后，也还是属于源文件系统的文件。 多文件系统操作关联假如下图中的圆代表一块硬盘，其中划分了3个区即3个文件系统。其中根是根文件系统，/mnt是另一个文件系统A的入口，A文件系统挂载在/mnt上，/mnt/cdrom也是一个文件系统B的入口，B文件系统挂载在/mnt/cdrom上。每个文件系统都维护了一些inode table，这里假设图中的inode table是每个文件系统所有块组中的inode table的集合表。 如何读取/var/log/messages呢？这是和”/“在同一个文件系统的文件读取，在前面单文件系统中已经详细说明了。 但如何读取A文件系统中的/mnt/a.log呢？首先，从根文件系统找到/mnt的inode记录，这是单文件系统内的查找；然后根据此inode记录的block指针，定位到/mnt的data block中，这些block是A文件系统的data block；然后从/mnt的data block中读取a.log记录，并根据a.log的inode指针定位到A文件系统的inode table中对应a.log的inode记录；最后从此inode记录的block指针找到a.log的data block。至此，就能读取到/mnt/a.log文件的内容。 下图能更完整的描述上述过程。 那么又如何读取/mnt/cdrom中的/mnt/cdrom/a.rpm呢？这里cdrom代表的文件系统B挂载点位于/mnt下，所以又多了一个步骤。先找到”/“，再找到根中的mnt，进入到mnt文件系统中，找到cdrom的data block，再进入到cdrom找到a.rpm。也就是说，mnt目录文件存放位置是根，cdrom目录文件存放位置是mnt，最后a.rpm存放的位置才是cdrom。 继续完善上图。如下。 ext3文件系统的日志功能相比ext2文件系统，ext3多了一个日志功能。 在ext2文件系统中，只有两个区：数据区和元数据区。如果正在向data block中填充数据时突然断电，那么下一次启动时就会检查文件系统中数据和状态的一致性，这段检查和修复可能会消耗大量时间，甚至检查后无法修复。之所以会这样是因为文件系统在突然断电后，它不知道上次正在存储的文件的block从哪里开始、哪里结束，所以它会扫描整个文件系统进行排除(也许是这样检查的吧)。 而在创建ext3文件系统时会划分三个区：数据区、日志区和元数据区。每次存储数据时，先在日志区中进行ext2中元数据区的活动，直到文件存储完成后标记上commit才将日志区中的数据转存到元数据区。当存储文件时突然断电，下一次检查修复文件系统时，只需要检查日志区的记录，将bmap对应的data block标记为未使用，并把inode号标记未使用，这样就不需要扫描整个文件系统而耗费大量时间。 虽说ext3相比ext2多了一个日志区转写元数据区的动作而导致ext3相比ext2性能要差一点，特别是写众多小文件时。但是由于ext3其他方面的优化使得ext3和ext2性能几乎没有差距。 ext4文件系统回顾前面关于ext2和ext3文件系统的存储格式，它使用block为存储单元，每个block使用bmap中的位来标记是否空闲，尽管使用划分块组的方法优化提高了效率，但是一个块组内部仍然使用bmap来标记该块组内的block。对于一个巨大的文件，扫描整个bmap都将是一件浩大的工程。另外在inode寻址方面，ext2/3使用直接和间接的寻址方式，对于三级间接指针，可能要遍历的指针数量是非常非常巨大的。 ext4文件系统的最大特点是在ext3的基础上使用区(extent，或称为段)的概念来管理。一个extent尽可能的包含物理上连续的一堆block。inode寻址方面也一样使用区段树的方式进行了改进。默认情况下，EXT4不再使用EXT3的block mapping分配方式 ，而改为Extent方式分配。 (1). 关于EXT4的结构特征 EXT4在总体结构上与EXT3相似，大的分配方向都是基于相同大小的块组，每个块组内分配固定数量的inode、可能的superblock(或备份)及GDT。 EXT4的inode 结构做了重大改变，为增加新的信息，大小由EXT3的128字节增加到默认的256字节，同时inode寻址索引不再使用EXT3的”12个直接寻址块+1个一级间接寻址块+1个二级间接寻址块+1个三级间接寻址块”的索引模式，而改为4个Extent片断流，每个片断流设定片断的起始block号及连续的block数量(有可能直接指向数据区，也有可能指向索引块区)。 片段流即下图中索引节点(inde node block)部分的绿色区域，每个15字节，共60字节。 (2). EXT4删除数据的结构更改。 EXT4删除数据后，会依次释放文件系统bitmap空间位、更新目录结构、释放inode空间位。 (3). ext4使用多block分配方式。 在存储数据时，ext3中的block分配器一次只能分配4KB大小的Block数量，而且每存储一个block前就标记一次bmap。假如存储1G的文件，blocksize是4KB，那么每存储完一个Block就将调用一次block分配器，即调用的次数为10241024/4KB=262144次，标记bmap的次数也为10241024/4=262144次。 而在ext4中根据区段来分配，可以实现调用一次block分配器就分配一堆连续的block，并在存储这一堆block前一次性标记对应的bmap。这对于大文件来说极大的提升了存储效率。 ext类的文件系统的缺点最大的缺点是它在创建文件系统的时候就划分好一切需要划分的东西，以后用到的时候可以直接进行分配，也就是说它不支持动态划分和动态分配。对于较小的分区来说速度还好，但是对于一个超大的磁盘，速度是极慢极慢的。例如将一个几十T的磁盘阵列格式化为ext4文件系统，可能你会因此而失去一切耐心。 除了格式化速度超慢以外，ext4文件系统还是非常可取的。当然，不同公司开发的文件系统都各有特色，最主要的还是根据需求选择合适的文件系统类型。 虚拟文件系统VFS每一个分区格式化后都可以建立一个文件系统，Linux上可以识别很多种文件系统，那么它是如何识别的呢？另外，在我们操作分区中的文件时，并没有指定过它是哪个文件系统的，各种不同的文件系统如何被我们用户以无差别的方式操作呢？这就是虚拟文件系统的作用。 虚拟文件系统为用户操作各种文件系统提供了通用接口，使得用户执行程序时不需要考虑文件是在哪种类型的文件系统上，应该使用什么样的系统调用来操作该文件。有了虚拟文件系统，只要将所有需要执行的程序调用VFS的系统调用就可以了，剩下的动作由VFS来帮忙完成。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"DHCP服务","slug":"DHCP 服务","date":"2017-04-09T16:00:00.000Z","updated":"2018-06-15T14:41:09.146Z","comments":true,"path":"2017/04/10/DHCP 服务/","link":"","permalink":"http://yoursite.com/2017/04/10/DHCP 服务/","excerpt":"DHCP前身是BOOTP，在Linux的网卡配置中也能看到显示的是BOOTP，DHCP引进一个bootp没有的概念：租约。bootp分配的地址是永久的，而dhcp分配的地址是可以有期限的 。12[root@xuexi vsftpd]# grep -i bootproto /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=dhcp DHCP可以自动分配IP、子网掩码、网关、DNS。DHCP客户端使用的端口68，服务端使用端口67，使用的UDP应用层的协议。","text":"DHCP前身是BOOTP，在Linux的网卡配置中也能看到显示的是BOOTP，DHCP引进一个bootp没有的概念：租约。bootp分配的地址是永久的，而dhcp分配的地址是可以有期限的 。12[root@xuexi vsftpd]# grep -i bootproto /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=dhcp DHCP可以自动分配IP、子网掩码、网关、DNS。DHCP客户端使用的端口68，服务端使用端口67，使用的UDP应用层的协议。DHCP一般不为服务器分配IP，因为他们要使用固定IP，所以DHCP一般只为办公环境的主机分配IP。 DHCP服务器和客户端需要在一个局域网内，在为客户端分配IP的时候需要进行多次广播。但DHCP也可以为其他网段内主机分配IP，只要连接两个网段中间的路由器能转发DHCP配置请求即可，但这要求路由器配置中继功能。 DHCP客户端请求过程（4步请求过程）1）搜索阶段：客户端广播方式发送报文，搜索DHCP服务器。此时网段内所有机器都收到报文，只有DHCP服务器返回消息。2）提供阶段：众多DHCP服务器返回报文信息，并从地址池找一个IP提供给客户端。因为此时客户端还没有IP，所以返回信息也是以广播的方式返回的。3）选择阶段：选择一个DHCP服务器，使用它提供的IP。然后发送广播包，告诉众多DHCP服务器，其已经选好DHCP服务器以及IP地址。此后没有入选的DHCP就可以将原本想分配的IP分配给其他主机. 客户端选择第一个接收到的IP。谁的IP先到客户端的速度是不可控的。但是如果在配置文件里开启了authoritative选项则表示该服务器是权威服务器，其他DHCP服务器将失效，如果多台服务器都配置了这个权威选项，则还是竞争机制；通过MAC地址给客户端配置固定IP也会优先于普通的动态DHCP分配。另外Windows的DHCP服务端回应Windows客户端比Linux更快。4）确认阶段：DHCP服务器收到回应，向客户端发送一个包含IP的数据包，确认租约，并指定租约时长。如果DHCP服务器要跨网段提供服务，一样是四步请求，只不过是每一步中间都多了一个路由器和DHCP服务器之间的单播通信。 1） 客户端广播方式发送报文，搜索DHCP服务器。所有机器包括路由器都收到报文，路由器配置了中继，知道搜索消息后单播给DHCP服务器；2）DHCP服务器单播返回信息给路由器，路由器再广播给客户端；3）客户端选择DHCP服务器提供的IP，并广播信息告诉它我选好了，路由器单播给DHCP服务器；4）DHCP服务器收到信息将确认信息单播给路由器，路由器单播给客户端。 所以DHCP的4步请求： 12Client--&gt; DHCPDISCOVER # 广播：客户端发现DHCP服务器 DHCPOFFER &lt;-- Server # 广播：服务端提供IP给客户端 12client--&gt; DCHPREQUEST # 广播：客户端请求使用提供的IP DCHPACK &lt;-- Server # 单播：服务端进行确认，订立租约等信息 续租的过程：12client--&gt; DHCPREQUEST # 单播：继续请求使用提供的IP DHCPACK &lt;-- Server # 单播：确认续租 HCP服务器不跨网段提供服务时，它自己的IP地址必须要和地址池中全部IP在同一网络中。DHCP服务器跨网段提供服务时，它自己的IP地址必须要和地址池中的一部分IP在同一网络中，另一部分提供给其他网段。因为如果自己的IP完全不在自己的网络中而只提供其他网段的IP，更好的做法是将DHCP服务器设在那个需要DHCP服务的网络中。当计算机从一个子网移到另一个子网，找的DHCP服务器不同，因为旧的租约还存在，会先续租，新的DHCP服务器肯定拒绝它的续租请求，这时将重新开始四步请求。有些机器希望一直使用一个固定的IP，也就是静态IP，除了手动进行配置，DHCP服务器也可以实现这个功能。DHCP服务器可以根据MAC地址来分配这台机器固定IP地址（保留地址），即使重启或重装了系统也不会改变根据MAC地址分配的地址。假如在一个正常联网有DHCP服务器的网段内因为做实验练习的缘故新建立了一台DHCP服务器，但是这台DHCP服务器不能上网，会导致什么后果？使用DHCP分配地址的客户端至少会有续租的请求，如果没有续租成功，或者有新的计算机加入这个网络，那么进行四步请求，有可能会请求到这个不能连网的DHCP服务器上，那么他也就不能上网了。特别是Windows的DHCP服务端回应Windows客户端速度比Linux回应快。安装和配置DHCP服务123456789[root@xuexi ~]# yum -y install dhcp[root@xuexi ~]# rpm -ql dhcp/etc/dhcp/dhcpd.conf # DHCP配置文件/etc/sysconfig/dhcpd/usr/sbin/dhcpd # DHCP服务程序/usr/sbin/dhcrelay # 中继命令程序，用于跨网段提供DHCP服务/var/lib/dhcpd/dhcpd.leases # 存放租借信息（如IP）和租约信息（如租约时长）/usr/share/doc/dhcp-4.1.1/dhcpd.conf.sample # 配置文件的范例文件 123可以将dhcpd.conf.sample复制到/etc/。 [root@xuexi ~]# cp /usr/share/dhcp-4.1.1/dhcpd.conf.sample /etc/dhcpd.conf 以下是dhcpd.conf中部分配置项。123456789101112131415161718192021# 每行分号结束ddns-update-style none; # 动态dns相关，几乎不开启它。也就是不管它。ignore client-updates; # 和上面的相关，也不管它authoritative # 声明为权威服务器next-server marvin.redhat.com; # PXE环境下指定的提供引导程序的文件服务器# DHCP配置文件里必须配置一个地址池，其和DHCP服务器自身IP在同一网段subnet 10.5.5.0 netmask 255.255.255.224 &#123; range 10.5.5.26 10.5.5.30; # 地址池 option domain-name-servers ns1.internal.example.org; # 为客户端指明DNS服务器地址，可以是多个，最多三个 option domain-name &quot;internal.example.org&quot;; # 为客户端指明DNS名字，定义了它会覆盖客户端/etc/resolv.conf里的配置 option routers 10.5.5.1; # 默认路由，其实就是网关 option broadcast-address 10.5.5.31; # 广播地址，不设置时默认会根据A/B/C类地址自动计算 default-lease-time 600; # 默认租约时长 max-lease-time 7200; # 最大租约时长&#125;#下面的是绑定MAC地址设置保留地址，保留地址不能是地址池中的地址host fantasia &#123; # 固定地址的配置，host后面的是标识符，没意义hardware ethernet 08:00:07:26:c0:a5; fixed-address 192.168.100.3; # 根据MAC地址分配的固定IP &#125; 如果不让dhcp修改/etc/resolv.conf里的内容，就在网卡配置文件/etc/sysconfig/network-scripts/ifcfg-ethX里添加一行选项：PEERDNS=no。在客户端如何获取动态分配的地址呢？方法一：service network restart但是每次重启网络很麻烦，可以使用客户端命令dhclient。方法二：直接执行dhclient命令这种方法下会显示4部请求中需要显示的步骤信息，以及最终分配的地址，所以是一个很好的理解dhcp工作的工具。但是这种方法只能使用一次，第二次执行命令会提示该进程已经在执行，因为dhclient是一个进程。可以kill掉该进程再执行dhclient，或者使用dhclient -d选项。方法三：dhclient -d如何重新获取IP地址每次重启网卡默认都获取的同一个ip，有时候想换个ip都很麻烦。在/var/lib/dhclient/目录下有”.leases”文件，将它们清空或者删除这些文件中对应网卡的部分，再重启网络就可以获取新的动态ip。12345678910111213141516[root@xuexi ~]# cat /var/lib/dhclient/dhclient-eth0.leases lease &#123; interface &quot;eth0&quot;; fixed-address 192.168.100.16; option subnet-mask 255.255.255.0; option routers 192.168.100.2; option dhcp-lease-time 1800; option dhcp-message-type 5; option domain-name-servers 192.168.100.2; option dhcp-server-identifier 192.168.100.254; option broadcast-address 192.168.100.255; option domain-name &quot;localdomain&quot;; renew 3 2017/02/15 12:28:27; rebind 3 2017/02/15 12:42:39; expire 3 2017/02/15 12:46:24;&#125; 或者，在/etc/sysconfig/network-scripts/ifcfg-eth0加入”DHCPRELEASE=yes”。当运行ifdown eth0的时候就会发出dhcprelase报文，查看/etc/sysconfig/network-scripts/ifdown-eth脚本中实际上是调用dhclient命令，用下面这个命令应该也可以。1/sbin/dhclient -r eth0","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"DHCP","slug":"DHCP","permalink":"http://yoursite.com/tags/DHCP/"}]},{"title":"Linux 文件权限管理","slug":"Linux 文件权限管理","date":"2017-03-11T16:00:00.000Z","updated":"2018-06-20T11:35:33.056Z","comments":true,"path":"2017/03/12/Linux 文件权限管理/","link":"","permalink":"http://yoursite.com/2017/03/12/Linux 文件权限管理/","excerpt":"文件/目录的权限文件的权限每个文件都有其所有者(u:user)、所属组(g:group)和其他人(o:other)对它的操作权限，a:all则同时代表这3者。权限包括读(r:read)、写(w:write)、执行(x:execute)。在不同类型的文件上读、写、执行权限的体现有所不同，所以目录权限和普通文件权限要区分开来。在普通文件上： r：可读，可以使用类似cat等命令查看文件内容；读是文件的最基本权限，没有读权限，普通文件的一切操作行为都被限制。","text":"文件/目录的权限文件的权限每个文件都有其所有者(u:user)、所属组(g:group)和其他人(o:other)对它的操作权限，a:all则同时代表这3者。权限包括读(r:read)、写(w:write)、执行(x:execute)。在不同类型的文件上读、写、执行权限的体现有所不同，所以目录权限和普通文件权限要区分开来。在普通文件上： r：可读，可以使用类似cat等命令查看文件内容；读是文件的最基本权限，没有读权限，普通文件的一切操作行为都被限制。w：可写，可以编辑此文件； x：可执行，表示文件可由特定的解释器解释并运行。可以理解为windows中的可执行程序或批处理脚本，双击就能运行起来的文件。 #####在目录上： r：可以对目录执行ls以列出目录内的所有文件；读是文件的最基本权限，没有读权限，目录的一切操作行为都被限制。 w：可以在此目录创建或删除文件/子目录； x：可进入此目录，可使用ls -l查看文件的详细信息。可以理解为windows中双击就进入目录的动作。 如果目录没有x权限，其他人将无法查看目录内文件属性(只能查看到文件类型和文件名，至于为什么，见后文)，所以一般目录都要有x权限。而如果只有执行却没有读权限，则权限拒绝。一般来说，普通文件的默认权限是644(没有执行权限)，目录的默认权限是755(必须有执行权限，否则进不去)，链接文件的权限是777。当然，默认文件的权限设置方法是可以通过umask值来改变的。 权限的表示方式权限的模式有两种体现：数字体现方式和字符体现方式。 权限的数字表示：”-“代表没有权限,用0表示。 123r-----4 w-----2 x-----1 例如：rwx rw- r–对应的数字权限是764，732代表的权限数值表示为rwx -wx -w-。 chmod修改权限能够修改权限的人只有文件所有者和超级管理员。 1234567chmod [OPTION]... MODE[,MODE]... FILE...chmod [OPTION]... num_mode FILE...chmod [OPTION]... --reference=RFILE FILE...选项说明：--reference=RFILE：引用某文件的权限作为权限值-R：递归修改，只对当前已存在的文件有效 (1). 使用数值方式修改权限1shell&gt; chmod 755 /tmp/a.txt (2). 使用字符方式修改权限由于权限属性附在文件所有者、所属组和其它上，它们三者都有独立的权限位，所有者使用字母”u”表示，所属组使用”g”来表示，其他使用”o”来表示，而字母”a”同时表示它们三者。所以使用字符方式修改权限时，需要指定操作谁的权限。 12chmod [ugoa][+ - =] [权限字符] 文件/目录名&quot;+&quot;是加上权限，&quot;-&quot;是减去权限，&quot;=&quot;是直接设置权限 12[root@xuexi tmp]# chmod u-x,g-x,o-x test # 将ugo都去掉x权限，等价于chmod -x test[root@xuexi tmp]# chmod a+x test # 为ugo都加上x权限，等价于chmod +x test chgrp 更改文件和目录的所属组，要求组已经存在。 注意，对于链接文件而言，修改组的作用对象是链接的源文件，而非链接文件本身。 123456chgrp [OPTION]... GROUP FILE...chgrp [OPTION]... --reference=RFILE FILE..选项说明：-R：递归修改--reference=dest_file file_list：引用某文件的group作为文件列表的组,即将file文件列表的组改为dest_file的组 chown chown可以修改文件所有者和所属组。 注意，对于链接文件而言，默认不会穿过链接修改源文件，而是直接修改链接文件本身，这和chgrp的默认是不一样的。 123456789101112chown [OPTION]... [OWNER][:[GROUP]] FILE...chown [OPTION]... [OWNER][.[GROUP]] FILE...chown [OPTION]... --reference=RFILE FILE...选项说明：--from=CURRENT_OWNER:CURRENT_GROUP：只修改当前所有者或所属组为此处指定的值的文件--reference=RFILE：引用某文件的所有者和所属组的值作为新的所有者和所属组-R：递归修改。注意，当指定-R时，且同时指定下面某一个选项时对链接文件有不同的行为 -H：如果chown的文件参数是一个链接到目录的链接文件，则穿过此链接文件修改其源目录的所有者和所属组 -L：目录中遇到的所有链接文件都穿越过去，修改它们的源文件的所有者和所属组 -P：不进行任何穿越，只修改链接文件本身的所有者和所属组。(这是默认值) 这3项若同时指定多项时，则最后一项生效 chown指定所有者和所属组的方式有两种，使用冒号和点。 12345shell&gt; chown root.root testshell&gt; chown root:root testshell&gt; chown root test # 只修改所有者shell&gt; chown :root test # 自修改组shell&gt; chown .root test 实现权限的本质 涉及文件系统的知识点，若不理解，可以先看看文件系统的内容。此处是以ext4文件系统为例的，在其他文件系统上结果可能会有些不一样(centos 7上使用xfs文件系统时结果可能就不一样)，但本质是一样的。 不同的权限表示对文件具有不同能力，如读写执行(rwx)权限，但是它是怎么实现的呢？描述文件权限的数据放在哪里呢？ 首先，权限的元数据放在inode中，严格地说是放在inode table中，因为每个块组的所有inode组成一个inode table。在inode table中使用一列来存放数字型的权限，比如某文件的权限为644。每次用户要对文件进行操作时系统都会先查看权限，确认该用户是否有对应的权限来执行操作。当然，inode table一般都已经加载到内存中，所以每次查询权限的资源消耗是非常小的。 无论是读、写还是执行权限，所体现出来的能力究其本质都是因为它作用在对应文件的data block上。 读权限(r) 对普通文件具有读权限表示的是具有读取该文件内容的能力，对目录具有读权限表示具有浏览该目录中文件或子目录的能力。其本质都是具有读取其data block的能力。 对于普通文件而言，能够读取文件的data block，而普通文件的data block存储的直接就是数据本身， 所以对普通文件具有读权限表示能够读取文件内容。 对于目录文件而言，能够读取目录的data block，而目录文件的data block存储的内容包括但不限于：目录中文件的inode号(并非直接存储，而是存储指向inode table中该inode号的指针)以及这些文件的文件类型、文件名。所以能够读取目录的data block表示仅能获取到这些信息。 目录的data block内容示例如下： 例如：123shell&gt; mkdir -p /mydata/data/testdir/subdir # 创建testdir测试目录和其子目录subdirshell&gt; touch /mydata/data/testdir/a.log # 再在testdir下创建一个普通文件shell&gt; chmod 754 /mydata/data/testdir # 将testdir设置为对其他人只有读权限 然后切换到普通用户查看testdir目录的内容。123456789101112shell&gt; su - wangwushell&gt; ll -ai /mydata/data/testdir/ls: cannot access /mydata/data/testdir/..: Permission deniedls: cannot access /mydata/data/testdir/a.log: Permission deniedls: cannot access /mydata/data/testdir/subdir: Permission deniedls: cannot access /mydata/data/testdir/.: Permission deniedtotal 0? d????????? ? ? ? ? ? .? d????????? ? ? ? ? ? ..? -????????? ? ? ? ? ? a.log? d????????? ? ? ? ? ? subdir 从结果中看出，testdir下的文件名和文件类型是能够读取的，但是其他属性都不能读取到。而且也读取不到inode号，因为它并没有直接存储inode号，而是存储了指向Inode号的指针，要定位到指针的指向需要执行权限。 执行权限(x) 执行权限表示的是能够执行。如何执行？执行这个词不是很好解释，可以简单的类比Windows中的双击行为。例如对目录双击就能进入到目录，对批处理文件双击就能运行(有专门的解释器解释)，对可执行程序双击就能运行等。 当然，读权限是文件的最基本权限，执行权限能正常运行必须得配有读权限。 对目录有执行权限，表示可以通过目录的data block中指向文件inode号的指针定位到inode table中该文件的inode信息，所以可以显示出这些文件的全部属性信息。 写权限(w) 写权限很简单，就是能够将数据写入分配到的data block。 对目录文件具有写权限，表示能够创建和删除文件。目录的写操作实质是能够在目录的data block中创建或删除关于待操作文件的记录。它要求对目录具有执行权限，因为无论是创建还是删除其内文件，都需要将其data block中inode号和inode table中的inode信息关联或删除。 对普通文件具有写权限，实质是能够改写该文件的data block。还是要说明的是，对文件有写权限不代表能够删除该文件，因为删除文件是要在目录的data block中删除该文件的记录，也就是说删除权限是在目录中定义的。 所以，对目录文件和普通文件而言，读、写、执行权限它们的依赖关系如下图所示。 umask说明 umask值用于设置用户在创建文件时的默认权限。对于root用户(实际上是UID小于200的user)，系统默认的umask值是022；对于普通用户和系统用户，系统默认的umask值是002。 默认它们的设置是写在/etc/profile和/etc/bashrc两个环境配置文件中。 1234shell&gt; grep -C 5 -R &apos;umask 002&apos; /etc | grep &apos;umask 022&apos; /etc/bashrc- umask 022/etc/csh.cshrc- umask 022/etc/profile- umask 022 相关设置项如下：12345if [ $UID -gt 199 ] &amp;&amp; [ &quot;`id -gn`&quot; = &quot;`id -un`&quot; ]; then umask 002else umask 022fi 执行umask命令可以查看当前用户的umask值。12[root@xuexi tmp]# umask0022 12[longshuai@xuexi tmp]$ umask0002 执行umask num可以临时修改umask值为num，但这是临时的，要永久有效，需要写入到环境配置文件中，至于写入到/etc/profile、/etc/bashrc、~/.bashrc还是~/.bash_profile中，看你自己的需求了。不过一般来说，不会去永久修改umask值，只会在特殊条件下临时修改下umask值。 umask是如何决定创建文件的默认权限的呢？ 如果创建的是目录，则使用777-umask值，如root的umask=022，则root创建目录时该目录的默认权限为777-022=755，而普通用户创建目录时，权限为777-002=775. 如果创建的是普通文件，在Linux中，深入贯彻了一点：文件默认不应该有执行权限，否则是危险的。所以在计算时，可能会和想象中的结果不一样。如果umask的三位都为偶数，则直接使用666去减掉umask值，因为6减去一个偶数还是偶数，任何位都不可能会有执行权限。如root创建普通文件时默认权限为666-022=644，而普通用户创建普通文件时默认权限为666-002=664。 如果umask值某一位为奇数，则666减去umask值后再在奇数位上加1。如umask=021时，创建文件时默认权限为666-021=645，在奇数位上加1，则为646。 1234[longshuai@xuexi tmp]$ umask 021[longshuai@xuexi tmp]$ touch b.txt[longshuai@xuexi tmp]$ ls -l b.txt-rw-r--rw- 1 longshuai longshuai 0 Jun 7 12:02 b.txt 总之计算出后默认都是没有执行权限的。 文件的扩展ACL权限 在计算机相关领域，所有的ACL(access control list)都表示访问控制列表。 文件的owner/group/others的权限就是一种ACL，它们是基本的ACL。很多时候，只通过这3个权限位是无法完全合理设置权限问题的，例如如何仅设置某单个用户具有什么权限。这时候需要使用扩展ACL。 扩展ACL是一种特殊权限，它是文件系统上功能，用于解决所有者、所属组和其他这三个权限位无法合理设置单个用户权限的问题。所以，扩展ACL可以针对单一使用者，单一档案或目录里的默认权限进行r,w,x的权限规范。 需要明确的是，扩展ACL是文件系统上的功能，且工作在内核，默认在ext4/xfs上都已开启。在下文中，都直接以ACL来表示代替扩展ACL的称呼。 查看文件系统是否开启ACL功能 对于ext家族的文件系统来说，要查看是否开启acl功能，使用dumpe2fs导出文件系统属性即可。 123shell&gt; dumpe2fs -h /dev/sda2 | grep -i acldumpe2fs 1.41.12 (17-May-2010)Default mount options: user_xattr acl 对于xfs文件系统，则没有直接的命令可以输出它的相关信息，需要使用dmesg来查看。其实无需关注它，因为默认xfs会开启acl功能。 123shell&gt; dmesg | grep -i acl[ 1.465903] systemd[1]: systemd 219 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ -LZ4 -SECCOMP +BLKID +ELFUTILS +KMOD +IDN)[ 2.517705] SGI XFS with ACLs, security attributes, no debug enabled 开启ACL功能后，不代表就使用ACL功能。是否使用该功能，不同文件系统控制方法不一样，对于ext家族来说，通过mount挂载选项来控制，而对于xfs文件系统，mount命令根本不支持acl参数(xfs文件系统如何关闭或启用的方法本人也不知道)。 设置和查看ACL设置使用setfacl命令。 12345678910111213setfacl [options] u:[用户列表]:[rwx] 目录/文件名 # 对用户设置使用usetfacl [options] g:[组列表]:[rwx] 目录/文件名 # 对组设置使用g选项说明：-m：设定ACL权限(modify)-x：删除指定的ACL权限，可以指定用户、组和文件来删除(remove)-M：写了ACL条目的文件，将从此文件中读取ACL条目，需要配合-m，所以-M指定的是modify file-X：写了ACL条目的文件，将从此文件中读取ACL条目，需要配合-x，所以-X指定的是remove file-n：不重置mask-b：删除所有的ACL权限-d：设定默认ACL权限，只对目录有效，设置后子目录(文件)继承默认ACL，只对未来文件 有效-k：删除默认ACL权限-R：递归设定ACL权限，只对目录有效，只对已有文件有效 查看使用getfacl命令 1getfacl filename 案例：假设现有目录/data/videos专门存放视频，其中有一个a.avi的介绍性视频。该目录的权限是750。现在有一个新用户加入，但要求该用户对该目录只有查看的权限，且只能看其中一部视频a.avi，另外还要求该用户在此目录下没有创建和删除文件的权限。 1.准备相关环境。123456shell&gt; mkdir -p /data/videosshell&gt; chmod 750 /data/videosshell&gt; touch /data/videos/&#123;a,b&#125;.avishell&gt; echo &quot;xxx&quot; &gt;/data/videos/a.avishell&gt; echo &quot;xxx&quot; &gt;/data/videos/b.avishell&gt; chown -R root.root /data/videos 2.首先设置用户longshuai对/data/videos目录有读和执行权限。1shell&gt; setfacl -m u:longshuai:rx /data/videos 3.现在longshuai对/data/videos目录下的所有文件都有读权限，因为默认文件的权限为644。要设置longshuai只对a.avi有读权限，先设置所有文件的权限都为不可读。1shell&gt; chmod 640 /data/videos/* 4.然后再单独设置a.avi的读权限。1shell&gt; setfacl -m u:longshuai:r /data/videos/a.avi 到此就设置完成了。查看/data/videos/和/data/videos/a.avi上的ACL信息。 12345678910shell&gt; getfacl /data/videos/getfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos/# owner: root# group: rootuser::rwxuser:longshuai:r-x # 用户longshuai在此文件上的权限是r-xgroup::r-xmask::r-xother::--- 12345678910shell&gt; getfacl /data/videos/a.avigetfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos/a.avi# owner: root# group: rootuser::rw-user:longshuai:r-- # 用户longshuai在此文件上的权限是r--group::r--mask::r--other::--- ACL:mask 设置mask后会将mask权限与已有的acl权限进行与计算，计算后的结果会成为新的ACL权限 。 设定mask的方式为：setfacl -m m:[rwx] 目录/文件名 注意：默认每次设置文件的acl都会重置mask为此次给定的用户的值。既然如此，要如何控制文件上的acl呢？如果一个文件上要设置多个用户的acl，重置mask后就会对已有用户的acl重新计算，而使得acl权限得不到有效的控制。使用setfacl的”-n”选项，它表示此次设置不会重置mask值。 例如：当前的acl权限：12345678910shell&gt; getfacl /data/videos getfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwxgroup::r-xmask::rwxother::--- 设置mask值为rx。123456789101112shell&gt; setfacl -m m:rx /data/videosshell&gt; getfacl /data/videos getfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwx #effective:r-xgroup::r-xmask::r-xother::--- 设置mask后，它提示有效权限是r-x。这是rwx和r-x做与运算之后的结果。 再设置longshuai的acl为rwx，然后查看mask，会发现mask也被重置为rwx。 123456789101112shell&gt; setfacl -m u:longshuai:rwx /data/videosshell&gt; getfacl /data/videosgetfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwxgroup::r-xmask::rwxother::--- 所以，在设置文件的acl时，要使用-n选项来禁止重置mask。 1234567891011121314shell&gt; setfacl -m m:rx /data/videosshell&gt; setfacl -n -m u:longshuai:rwx /data/videosshell&gt; getfacl /data/videosgetfacl: Removing leading &apos;/&apos; from absolute path names# file: data/videos# owner: root# group: rootuser::rwxuser:longshuai:rwx #effective:r-xgroup::r-xmask::r-xother::--- 设置递归和默认ACL权限 递归ACL权限只对目录里已有文件有效，默认权限只对未来目录里的文件有效。 设置递归ACL权限： 1setfacl -m u:username:[rwx] -R 目录名 # -R选项只能放在后面。 设置默认ACL权限：1setfacl -m d:u:username:[rwx] 目录名 删除ACL权限123setfacl -x u:用户名 文件名 # 删除指定用户ACLsetfacl -x g:组名 文件名 # 删除指定组名ACLsetfacl -b 文件名 # 指定文件删除ACL，会删除所有ACL 文件隐藏属性 chattr：change file attributes lsattr：list file attributes 12chattr [+ - =] [ai] 文件或目录名 常用的参数是a(append，追加)和i(immutable，不可更改)，其他参数略。 设置了a参数时，文件中将只能增加内容，不能删除数据，且不能打开文件进行任何编辑，哪怕是追加内容也不可以，所以像sed等需要打开文件的再写入数据的工具也无法操作成功。文件也不能被删除。只有root才能设置。 设置了i参数时，文件将被锁定，不能向其中增删改内容，也不能删除修改文件等各种动作。只有root才能设置。可以将其理解为设置了i后，文件将是永恒不变的了，谁都不能动它。 例如，对/etc/shadow文件设置i属性，任何用户包括root将不能修改密码，而且也不能创建用户。1shell&gt; chattr +i /etc/shadow 此时如果新建一个用户。12shell&gt; useradd newlongsuaishell&gt; useradd: cannot open /etc/shadow # 提示文件不能打开，被锁定了 lsattr查看文件设置的隐藏属性。12shell&gt; lsattr /etc/shadow----i--------e- /etc/shadow # i属性说明被锁定了，e是另一种文件属性，忽略它 删除隐藏属性：123shell&gt; chattr -i /etc/shadowshell&gt; lsattr /etc/shadow-------------e- /etc/shadow 再来一例：1234shell&gt; chattr +a test1.txt # 对test1.txt设置a隐藏属性shell&gt; echo 1234&gt;&gt;test1.txt # 追加内容是允许的行为shell&gt; cat /dev/null &gt;test1.txt # 但是清空文件内容是不允许的-bash: test1.txt: Operation not permitted suid/sgid/sbitsuid suid只针对可执行文件，即二进制文件。它的作用是对某个命令(可执行文件)授予所有者的权限，命令执行完成权限就消失。一般是提权为root权限。 例如/etc/shadow文件所有人都没有权限(root除外)，其他用户连看都不允许。 12shell&gt; ls -l /etc/shadow----------. 1 root root 752 Apr 8 12:42 /etc/shadow 但是他们却能修改自己的密码，说明他们一定有一定的权限。这个权限就是suid控制的。 12shell&gt; ls -l /usr/bin/passwd-rwsr-xr-x. 1 root root 30768 Feb 22 2012 /usr/bin/passwd 其中的”s”权限就是suid，它出现在所有者位置上(是root)，其他用户执行passwd命令时，会暂时拥有所有者位的rwx权限，也就是root的权限，所以能向/etc/shadow写入数据。 suid必须和x配合，如果没有x配合，则该suid是空suid，仍然没有执行命令的权限，所有者都没有了x权限，suid依赖于它所以更不可能有x权限。空的suid权限使用大写的”S”表示。 数字4代表suid，如4755。 sgid针对二进制文件和目录。 针对二进制文件时，权限升级为命令的所属组权限。 针对目录时，目录中所建立的文件或子目录的组将继承默认父目录组，其本质还是提升为目录所属组的权限。此时目录应该要有rx权限，普通用户才能进入目录，如果普通用户有w权限，新建的文件和目录则以父目录组为默认组。 以2代表sgid，如2755，和suid组合如6755。 sbit 只对目录有效。对目录设置sbit，将使得目录里的文件只有所有者能删除，即使其他用户在此目录上有rwx权限，即使是root用户。 以1代表sbit。 补充：suid/sgid/sbit的标志位都作用在x位，当原来的x位有x权限时，这些权限位则为s/s/t，如果没有x权限，则变为S/S/T。例如，/tmp目录的权限有个t位，使得该目录里的文件只有其所有者本身能删除。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"权限管理","slug":"权限管理","permalink":"http://yoursite.com/tags/权限管理/"}]},{"title":"DNS 服务从基础到深入","slug":"DNS 服务从基础到深入","date":"2017-02-14T16:00:00.000Z","updated":"2018-06-15T12:22:30.217Z","comments":true,"path":"2017/02/15/DNS 服务从基础到深入/","link":"","permalink":"http://yoursite.com/2017/02/15/DNS 服务从基础到深入/","excerpt":"一 简介 DNS是Domain name system的简称，有些地方也称为Domain name server，这东西是一个很大的话题。如果不是要配置DNS服务，只需要理解DNS的解析流程和DNS有关的基本知识即可。如果要配置DNS服务，则可以看完全文。推荐阅读书籍：《DNS &amp; bind》，第四版有中文版，第五版目前只有英文版。 DNS必懂基础","text":"一 简介 DNS是Domain name system的简称，有些地方也称为Domain name server，这东西是一个很大的话题。如果不是要配置DNS服务，只需要理解DNS的解析流程和DNS有关的基本知识即可。如果要配置DNS服务，则可以看完全文。推荐阅读书籍：《DNS &amp; bind》，第四版有中文版，第五版目前只有英文版。 DNS必懂基础 DNS主要是用于将域名解析为IP地址的协议，有时候也用于将IP地址反向解析成域名，所以DNS可以实现双向解析。DNS可以使用TCP和UDP的53端口，基本使用UDP协议的53端口。 域的分类 域是分层管理的，就像中国的行政级别。最高层的域是根域(root)”.”，就是一个点，它就像国家主席一样。全球只有13个根域服务器，基本上都在美国，中国一台根域服务器都没有。根域的下一层就是第二层次的顶级域（TLD）了，那么它就是各省省长了。顶级域一般两种划分方法：按国家划分和按组织性质划分。 ◇ 按国家划分：.cn(中国)、.tw(台湾)、.hk(香港)。基本都是两个字母的。◇ 按组织性质划分：.org、.net、.com、.edu、.gov、.cc等。◇ 反向域：arpa。这是反向解析的特殊顶级域。 顶级域下来就是普通的域，公司或个人在互联网上注册的域名一般都是这些普通的域，如baidu.com。 主机名、域名、FQDN 以百度(www.baidu.com)和百度贴吧(tieba.baidu.com)来举例。 ◇ 域名不论是www.baidu.com还是tieba.baidu.com，它们的域名都是baidu.com，严格地说是&quot;baidu.com.&quot;。这是百度所购买的com域下的一个子域名。 ◇ 主机名对于www.baidu.com来说，主机名是www，对于tieba.baidu.com来说，主机名是tieba。其实严格来说，www.baidu.com和tieba.baidu.com才是主机名，它们都是baidu.com域下的主机。一个域下可以定义很多主机，只需配置好它的主机名和对应主机的IP地址即可。 ◇ FQDNFQDN是Fully Qualified Domain Name的缩写，称为完全合格域名，是指包含了所有域的主机名，其中包括根域。FQDN可以说是主机名的一种完全表示形式，它从逻辑上准确地表示出主机在什么地方。 例如www.baidu.com的FQDN是&quot;www.baidu.com.&quot;，com后面还有个点，这是根域；tieba.baidu.com的FQDN是&quot;tieba.baidu.com.&quot;。 域的分层授权 域是从上到下授权的，每一层都只负责自己的直辖下层，而不负责下下层。例如根域给顶级域授权，顶级域给普通域授权，但是根域不会给普通域授权。和现实中的行政管理不一样，域的授权和管理绝对不会向下越级，因为它根本不知道下下级的域名是否存在。 DNS解析流程 以访问www.baidu.com为例。 (1).客户端要访问www.baidu.com，首先会查找本机DNS缓存，再查找自己的hosts文件，还没有的话就找DNS服务器（这个DNS服务器就是计算机里设置指向的DNS）。 (2).DNS服务器收到询问请求，首先查看自己是否有www.baidu.com的缓存，如果有就直接返回给客户端，没有就越级上访到根域&quot;.&quot;，并询问根域。 (3).根域看到是找.com域的，把到.com域的路(地址)告诉DNS服务器，让DNS服务器去找.com询问。 (4).DNS服务器去找.com，”.com”一看是自己辖下的baidu.com，就把baidu.com的IP地址给DNS服务器，让它去找baidu.com。 (5).DNS找到baidu.com，baidu.com发现DNS服务器要找的是自己区域里的www主机，就把这个主机IP地址给了DNS服务器。 (6).DNS服务器把得到的www.baidu.com的IP结果告诉客户端，并缓存一份结果在自己机器中(默认会缓存，因为该服务器允许为客户端递归，否则不会缓存非权威数据)。 (7).客户端得到回答的IP地址后缓存下来，并去访问www.baidu.com，然后www.baidu.com就把页面内容发送给客户端，也就是百度页面。 最后要说明的是： 1.本机查找完缓存后如果没有结果，会先查找hosts文件，如果没有找到再把查询发送给DNS服务器，但这仅仅是默认情况，这个默认顺序是可以改变的。在/etc/nsswitch.conf中有一行” hosts: files dns”就是定义先查找hosts文件还是先提交给DNS服务器的，如果修改该行为”hosts: dns files”则先提交给DNS服务器，这种情况下hosts文件几乎就不怎么用的上了。 2.由于缓存是多层次缓存的，所以真正的查询可能并没有那么多步骤，上图的步骤是完全没有所需缓存的查询情况。假如某主机曾经向DNS服务器提交了www.baidu.com的查询，那么在DNS服务器上除了缓存了www.baidu.com的记录，还缓存了&quot;.com&quot;和&quot;baidu.com&quot;的记录，如果再有主机向该DNS服务器提交ftp.baidu.com的查询，那么将跳过&quot;.&quot;和&quot;.com&quot;的查询过程直接向baidu.com发出查询请求。 /etc/resolv.conf文件 这个文件主要用于定义dns指向，即查询主机名时明确指定使用哪个dns服务器。该文件的详细说明见Linux网络管理之：/etc/resolv.conf。 例如此文件中指定了”nameserver 8.8.8.8”，则每当要查询主机名时，都会向8.8.8.8这台dns服务器发起递归查询，这台dns服务器会帮忙查找到最终结果并返回给你。 当然，在后文的实验测试过程中，使用了另一种方式指定要使用的dns服务器：dig命令中使用”@dns_server”。 DNS术语递归查询和迭代查询 例如A主机要查询C域中的一个主机，A所指向的DNS服务器为B，递归和迭代查询的方式是这样的： 递归查询：A –&gt; B –&gt; C –&gt; B –&gt; A 迭代查询：A –&gt; B A –&gt; C –&gt; A 将递归查询和迭代查询的方式放到查询流程中，就如下图所示。(未标出Client指向的DNS服务器) 也就是说，递归的意思是找了谁谁就一定要给出答案。那么允许递归的意思就是帮忙去找位置，如A对B允许递归，那么B询问A时，A就去帮忙找答案，如果A不允许对B递归，那么A就会告诉B的下一层域的地址让B自己去找。 可以想象，如果整个域系统都使用递归查询，那些公共的根域和顶级域会忙到死，因此更好的方案就是把这些压力分散到每个个人定制的DNS服务器。 所以DNS的解析流程才会如下图。并且在客户端到DNS服务器端的这一阶段是递归查询，从DNS服务器之后的是迭代查询。也就是说，顶级域和根域出于性能的考虑，是不允许给其他任何机器递归的。 为什么客户端到DNS服务器阶段是递归查询？因为客户端本身不是DNS服务器，它自己是找不到互联网上的域名地址的，所以只能询问DNS服务器，最后一定由DNS服务器来返回答案，所以DNS服务器需要对这个客户端允许递归。因此，dns解析器(nslookup、host、dig等)所发出的查询都是递归查询。 权威服务器和(非)权威应答 权威服务器（权威者）可以理解为直接上层域的DNS服务器。例如www.baidu.com这台主机的上层域是baidu.com，那么对www来说，它的权威服务器就是baidu.com这个域内负责解析的DNS服务器，而对于baidu.com这个主机来说，它的权威服务器是.com这个域负责解析的DNS服务器。 更具体的说，某域的权威服务器是可以直接查看该域数据(即区域数据文件)的DNS服务器，主、从DNS服务器都是权威服务器。 只有权威服务器给出的应答才是权威应答，否则就是非权威应答。为什么呢？因为一个域中所有的主机都是在DNS服务器中的区域数据文件中记录的，对于主机来说，它们的位置只有直接上层才知道在哪里。 因此如果解析www.baidu.com时要获得权威应答，应该将DNS指向baidu.com这个域内负责解析的DNS服务器。 只有权威服务器直接给出的答案才是永远正确的，通过缓存得到的答案基本都是非权威应答。当然这不是一定的，因为权威服务器给的答案也是缓存中的结果，但是这是权威答案。DNS服务器缓存解析的数据库时间长度是由权威服务器决定的。 DNS缓存 在Client和DNS服务器这些个人订制的DNS解析系统中都会使用缓存来加速解析以减少网络流量和查询压力，就算是解析不到的否定答案也会缓存。 但是要访问的主机IP可能会改变，所有使用缓存得到的答案不一定是对的，因此缓存给的答案是非权威的，只有对方主机的上一级给的答案才是权威答案。缓存给的非权威答案应该设定缓存时间，这个缓存时间的长短由权威者指定。 另外访问某个域下根本不存在的主机，这个域的DNS服务器也会给出答案，但是这是否定答案，否定答案也会缓存，并且有缓存时间。例如某个Client请求51cto.com域下的ftp主机，但是实际上51cto.com下面可能根本没有这个ftp主机，那么51cto.com就会给否定答案，为了防止Client不死心的访问ftp搞破坏，51cto.com这个域负责解析的DNS服务器有必要给Client指定否定答案的缓存时间。 主、从dns服务器 dns服务器也称为name server，每个域都必须有dns服务器负责该域相关数据的解析。但dns服务器要负责整个域的数据解析，压力相对来说是比较大的，且一旦出现问题，整个域都崩溃无法向外提供服务，这是非常严重的事。所以，无论是出于负载均衡还是域数据安全可用的考虑，两台dns服务器已经是最低要求了，多数时候应该配置多台dns服务器。 多台dns服务器之间有主次之分，主dns服务器称为master，从dns服务器称为slave。slave上的域数据都是从master上获取的，这样slave和master就都能向外提供名称解析服务。 资源记录(Resource Record,RR) 对于提供DNS服务的系统(DNS服务器)，域名相关的数据都需要存储在文件(区域数据文件)中。这些数据分为多种类别，每种类别存储在对应的资源记录(resource record,RR)中。也就是说，资源记录既用来区分域数据的类型，也用来存储对应的域数据。 DNS的internet类中有非常多的资源记录类型。常用的是SOA记录、NS记录、A记录(IPV6则为AAAA记录)、PTR记录、CNAME记录、MX记录等。 (1).SOA记录：start of authority，起始授权机构。该记录存储了一系列数据，若不明白SOA记录，请结合下面的NS记录，SOA更多的信息见”子域”部分的内容。格式如下：123456longshuai.com. IN SOA dnsserver.longshuai.com. mail.longshuai.com. ( 1 3h 1h 1w 1h ) 第四列指定了”dnsserver.longshuai.com.”为该域的master DNS服务器。 第五列是该域的管理员邮箱地址，但注意不能使用@格式的邮箱，而是要将@符号替换为点”.”，正如上面的例子”mail.longshuai.com.”，其实际表示的是”mail@longshuai.com“。 第六列使用括号将几个值包围起来。第一个值是区域数据文件的序列编号serial，每次修改此区域数据文件都需要修改该编号值以便让slave dns服务器同步该区域数据文件。第二个值是刷新refresh时间间隔，表示slave dns服务器找master dns服务器更新区域数据文件的时间间隔。第三个值是重试retry时间间隔，表示slave dns服务器找master dns服务器更新区域数据文件时，如果联系不上master，则等待多久再重试联系，该值一般比refresh时间短，否则该值表示的重试就失去了意义。第四个值是过期expire时间值，表示slave dns服务器上的区域数据文件多久过期。第五个值是negative ttl，表示客户端找dns服务器解析时，否定答案的缓存时间长度。这几个值可以分行写，也可以直接写在同一行中使用空格分开，所以，上面的SOA记录可以写成如下格式： 1longshuai.com. IN SOA dnsserver.longshuai.com. mail.longshuai.com. ( 1 3h 1h 1w 1h ) 前三列是声明性的语句，表示”longshuai.com.”这个域内的起始授权机构为第四列的值”dnsserver.longshuai.com.”所表示的主机。第五列和第六列是SOA的附加属性数据。 每个区域数据文件中都有且仅能有一个SOA记录，且一般都定义为区域数据文件中的资源记录。 注意，资源记录的作用之一是存储域相关的对应数据，所以第4、5、6列表示的是该SOA记录所存储的相关值。 (2).NS记录：name server，存储的是该域内的dns服务器相关信息。即NS记录标识了哪台服务器是DNS服务器。格式如下：1longshuai.com. IN NS dnsserver.longshuai.com. 前三列仍然是声明性语句，表示”longshuai.com.”域内的DNS服务器(name server)为第四列值所表示的”dnsserver.longshuai.com.”主机。 如果一个域内有多个dns服务器，则必然有主次之分，即master和slave之分。但在NS记录上并不能体现主次关系。例如： 12longshuai.com. IN NS dnsserver1.longshuai.com.longshuai.com. IN NS dnsserver2.longshuai.com. 表示主机”dnsserver1.longshuai.com.”和主机”dnsserver2.longshuai.com.”都是域”longshuai.com.”内的dns服务器，但没有区分出主次dns服务器。 很多人搞不懂SOA记录，也很容易混淆SOA和NS记录。其实，仅就它们的主要作用而言，NS记录仅仅只是声明该域内哪台主机是dns服务器，用来提供名称解析服务，NS记录不会区分哪台dns服务器是master哪台dns服务器是slave。而SOA记录则用于指定哪个NS记录对应的主机是master dns服务器，也就是从多个dns服务器中挑选一台任命其为该域内的master dns服务器，其他的都是slave，都需要从master上获取域相关数据。由此，SOA的名称”起始授权机构”所表示的意思也就容易理解了。 (3).A记录：address，存储的是域内主机名所对应的ip地址。格式如下：1dnsserver.longshuai.com. IN A 172.16.10.15 客户端之所以能够解析到主机名对应的ip地址，就是因为dns服务器中的有A记录存储了主机名和ip的对应关系。AAAA记录存储的是主机名和ipv6地址的对应关系。 (4).PTR记录：pointer，和A记录相反，存储的是ip地址对应的主机名，该记录只存在于反向解析的区域数据文件中(并非一定)。格式如下：116.10.16.172.in-addr.arpa. IN PTR www.longshuai.com. 表示解析172.16.10.16地址时得到主机名”www.longshuai.com.&quot;的结果。 (5).CNAME记录：canonical name，表示规范名的意思，其所代表的记录常称为别名记录。之所以如此称呼，就是因为为规范名起了一个别名。什么是规范名？可以简单认为是fqdn。格式如下：1www1.longshuai.com. IN CNAM www.longshuai.com. 最后一列就是规范名，而第一列是规范名即最后一列的别名。当查询”www1.longshuai.com.”，dns服务器会找到它的规范名”www.longshuai.com.&quot;，然后再查询规范名的A记录，也就获得了对应的IP地址并返回给客户端。 CNAME记录非常重要，很多时候使用CNAME可以解决很复杂的问题。而且目前常用的CDN技术有一个步骤就是在dns服务器上设置CNAME记录，将客户端对资源的请求引导到与它同网络环境(电信、网通)以及地理位置近的缓存服务器上。关于CDN的简介，见下文CDN和DNS的关系。 (6).MX记录：mail exchanger，邮件交换记录。负责转发或处理该域名内的邮件。和邮件服务器有关，且话题较大，所以不多做叙述，如有深入的必要，请查看《dns &amp; bind》中”Chapter 5. DNS and Electronic Mail”。 关于资源记录，最需要明确的概念就是它不仅仅用来区分和标识区域数据的类型，还用来存储对应的域数据。 安装阶段请关注下一章！","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"DNS","slug":"DNS","permalink":"http://yoursite.com/tags/DNS/"}]},{"title":"Linux 的一些基础练习题","slug":"Linux 的一些基础练习题","date":"2016-11-28T16:00:00.000Z","updated":"2018-06-10T13:16:34.982Z","comments":true,"path":"2016/11/29/Linux 的一些基础练习题/","link":"","permalink":"http://yoursite.com/2016/11/29/Linux 的一些基础练习题/","excerpt":"练习题：1，显示当前时间，格式为：2016-06-18 10:20:30 答案：date “+%F,%T” 或者 date “+%F %H:%M:%S” 2，显示前天是星期几？ 答案：date -d “-2 day” +%A 知识点：一 ，date +%s 是把当前时间转化为秒数 二， date -d @”1523604170″ 把秒数转化回来","text":"练习题：1，显示当前时间，格式为：2016-06-18 10:20:30 答案：date “+%F,%T” 或者 date “+%F %H:%M:%S” 2，显示前天是星期几？ 答案：date -d “-2 day” +%A 知识点：一 ，date +%s 是把当前时间转化为秒数 二， date -d @”1523604170″ 把秒数转化回来 3，今天18:30自动关机，并提示用户。 答案：hutdown -h 18:30 “dao dian guan ji，18:30” 如果想取消此操作输入： shutdown -c 4，在本机字符终端登录时，除显示原有信息外，在显示当前登录终端号，主机名和当前时间。 答案：vim /etc/profile.d/kaiji.sh 进去后输入：#**echo your hostname is hostnamewho am i 5，显示/var目录下所有以l开头，以一个小写字母结尾，且中间出现至少一位数字的文件或目录。 答案：ls /var/l[0-9][[:lower:]] 6，显示/etc目录下以任意一位数字开头，且以非数字结尾的文件或目录。 答案：ls /etc/[0-9]*[^0-9] 7，显示/etc/目录下以非字母开头，后面跟了一个字母及其他任意长度任意字符的文件或目录。 答案：ls /etc/[^[:alpha:]][a-zA-Z]* 8，显示/etc/目录下所有以rc开头，并后面是0-6之间的数字，其他为任意字符的文件或目录。 答案：ls /etc/rc[0-6]* 9，显示/etc目录下，所有以.d结尾的文件或目录。 答案：ls /etc/*.d 10，显示/etc目录下，所有.conf结尾，且以m,n,r,p开头的文件或目录。 答案：ls /etc/[m,n,r,p]*.conf 11，只显示/root下的隐藏文件和目录。 只显示/etc下的非隐藏目录 答案：ls -d /root/. ls /etc/[^.]/ -d 12，定义别名命令baketc,每天将/etc/目录下的所有文件，备份到/app独立的子目录下，并要求子目录格式为backupYYYY-mm-dd备份过程可见。 答案：alias baketc=”cp -av /etc /data/backupdate +%F” 13，创建/app/rootdir目录，并复制/root下所有文件到该目录内，要求保留原有权限。 答案：mkdir -p /app/rootdir cp -a /root /app/rootdir/ 14，如何创建/testdir/dir1/x,/testdir/dir/y,/testdir/dir/x/a,/testdir/dir/x/b,/testdir/dir/y/a,/testdir/dir/y/b. 答案：mkdir -p /testdir/dir1/{x,y}/{a,b} 15，如何创建/testdir/dir2/x,/testdir/dir2/y,/testdir/dir2/x/a,/testdir/dir2/x/b. 答案：mkdir -p /testdir/dir2/{x/{a,b},y} 16，如何创建/testdir/dir3,/testdir/dir4,/testdir/dir5,/testdir/dir5/dir6,/testdir/dir5/dir7. 答案：mkdir -p /testdir/{dir3,dir4,dir5/{dir6,dir7}} 17，将/etc/issue文件中的内容转化为大写后保存至/tmp/issue.out文件中。 答案：cat /etc/issue | tr “[a-z]” “[A-Z]” &gt; /tmp/issue.out 18，将当前系统登录用户的信息转换为大写后保存至/tmp/who.out文件中。 答案：who | tr “[a-z]” “[A-Z]” &gt;/tmp/who.out 19，一个linux用户给root发邮件，要求邮件标题为” help”,邮件正文如下：Heello,i am 用户名，The system version is here ,please help me to check it,thanks! 操作系统版本信息 答案：mail -s “help” root &lt;&lt;123 Hello,I am $USERThe system version is here,please help me to check it,thanks!cat /etc/centos-release123 20,将/root/下文件列表，显示成一行，并文件名之间用空格隔开。 答案：ls /root | tr “\\n” ” ” 21，计算1+2+3+..+99+100的总和。 答案：echo {1..100}|tr ” ” “+”|bc 22，删除Windows文本文件中的^M字符 答案：tr -d “\\15” win.txt 23，处理字符串 “xt.,l 1 jr#!$mn 2 c*/fe 3 uz 4” ,只保留其中的数字和空格。 答案：echo “xt.,l 1 jr#hostnamemn 2 c*/fe 3 uz 4” |tr -dc “[:digit:][:space:]” 24,将PATH变量每个目录显示在独立的一行。 答案：echo $PATH |tr “:” “\\n” 25，将指定文件中0-9分别代替成a-j . 答案：先创建文件touch f1 给f1 vim 输入0-9 cat f1 | tr “[0-9]” “[a-j]” 26，将文件/etc/centos-release中每个单词（由字母组成）显示在独立的一行，并无空行。 答案：cat /etc/centos-release |tr -c “[:alpha:]” ” ” |tr -s ” ” “\\n” 27，创建用户gentoo,附加组为bin和root,默认shell为/bin/csh,注释信息为”Gentoo Distribution”. 答案：useradd -G bin,root -s /bin/csh -c “Gentoo Distribution” gentoo 28，创建下面的用户，组和组成员关系名字为webs的组 用户nginx使用webs作为附加组 用户varnish,也使用webs作为附加组用户mysql,不可交互登录系统，且不是webs的成员，nbinx,varnish,mysql密码都是magedu 答案：12345678groupadd webs useradd -G webs nginx useradd -G webs varnish useradd -s /sbin/nologin masql echo magedu |passwd –stdin nginx; echo magedu |passwd –stdin varnish; echo magedu |passwd –stdin mysql; 29，当用户docker对/testdir 目录无执行权限时，意味着无法做哪些操作？ 答案： 不能cd进去，不能查看文件详细属性，也不能去访问目录里的文件内容（即使有读权限）。 30，当用户mongodb对/testdir 目录无读权限时，意味着无法做哪些操作？ 答案：不能对目录下的文件进行访问。 31， 当用户redis 对/testdir 目录无写权限时，该目录下的只读文件file1是否可修改和删除？ 答案：不能，因为对目录没有权限，所以不能。文件能不能删，不由文件决定，而由目录决定。 32，当用户zabbix对/testdir 目录有写和执行权限时，该目录下的只读文件file1是否可修改和删除？ 答案：可以修改和删除 33，复制/etc/fstab 文件到/var/tmp 下，设置文件所有者为tomcat 读写权限，所属组为apps组有读写权限，其他人无权限。 123456答案：（一）cp -a /etc/fstab /var/tmp （二） useradd tomcat （三） groupadd apps （四） chown tomcat /var/tmp （五） chgrp apps /var/tmp （六） chmod 660 /var/tmp 34，误删除了用户git的家目录，请重建并恢复该用户家目录及相应的权限属性。 1234答案： rm -rf /home/git ; mkdir /home/git; cp -a /etc/skel/.[^.]* /home/git; chown -R git:git /home/git; 35,在/testdir/dir 里创建的新文件自动属于webs组，组apps的成员如:tomcat能对这些新文件有读写权限，组dbs的成员如：mysql只能对新文件有读权限，其他用户（不属于webs,apps,dbs）不能访问文件夹。 1234567答案： mkdir -p /testdir/dir chgrp webs /testdir/dir chmod g=s /testdir/dir setfacl -m g:apps:rw /testdir/dir setfacl -m g:dbs:r /testdir/dir chmod o= /testdir/dir 36，备份/testdir/dir 里所有文件的ACL权限到/root/acl.txt中，清除/testdir/dir中所有ACL权限，最后还原ACL权限。 123答案： getfacl -R /testdir/dir &gt; /root/acl.txt setfacl -b /testdir/dir setfacl -R –set-file=acl.txt /testdir/dir 37, 找出ifconfig “网卡名” 命令结果中本机的IPv4地址。 12345答案：（方法一）ifconfig ens33 | grep netmask | tr -s ” ” “:” |cut -d: -f3（方法二）ifconfig ens33 |egrep -o \\&lt;“(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])”\\&gt;（方法三）ifconfig ens33 | sed -n “2p” | sed -r s’@(.*inet)(.*)( netmask.*)@\\2@’ 38，查出分区空间使用率的最大百分比值。 123答案：（方法一）df | grep ^/dev | tr -s ” ” “:” | cut -d: -f5 |cut -d% -f1 | sort -nr | head -n1（方法二） df | grep -o “[0-9]\\&#123;1,3\\&#125;%” |grep -o “[0-9]\\+” |sort -nr |head -n1 39，查出用户UID最大值得用户名，UID及shell类型。 1答案：cat /etc/passwd |sort -nr -t: -k3 |head -n1 |cut -d: -f1,3,7 40，查出/tmp的权限，以数字方式显示 1答案：stat /tmp |head -n4|tail -n1|cut -d/ -f1|cut -d&apos;(‘ -f2 41， 统计当前连接本机的每个远程主机IP的连接数，并从大到小排序。 12答案： 先从桌面获取rz 获取文件，再进行处理。 cat access_log |egrep -o “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;”|sort|uniq -dc|sort -nr 42,显示/proc/meminfo 文件中以大小s开头的行（要求：使用两种方法） 123答案：（方法一）cat /proc/meminfo |egrep -oi ^s.*（方法二）cat /proc/meminfo |egrep ^[Ss].* 43，显示/etc/passwd文件中不以/bin/bash结尾的行。 1答案：cat /etc/passwd |egrep -v /bin/bash$ 44，显示用户rpc默认的shell程序。 123答案：（方法一）cat /etc/passwd |egrep rpc|cut -d: -f1,7（方法二）cat /etc/passwd |egrep rpc|sed -r ‘s/(.*:)([^:]+:?$)/\\2/’ 45，找出/etc/passwd 中的两位或三位数 1答案：cat /etc/passwd | egrep -o “[0-9]&#123;2,3&#125;” 46，显示Centos7的/etc/grub2.cfg文件中，至少以一个空白字符开头的且后面有非空白字符的行。 1答案：cat /etc/grub2.cfg |egrep ^[[:space:]][^[:space:]].*$ 47，找出”netstat -tan” 命令结果中以LISTEN后跟任意多个空白字符结尾的行。 1答案：netstat -tan |egrep .*LISTEN[[:space:]]+ 48, 显示Centos7上所有系统用户的用户名和UID。 1答案：cat /etc/passwd |egrep .*/sbin/nologin$ |cut -d: -f1,3 49，添加用户bash,testbash,basher,sh,nologin(其shell为/sbin/nologin),找出/etc/passwd用户名和shell同名的行。 1答案：cat /etc/passwd | egrep “^(.*)(:.*)\\1$” 50，利用df和grep，去出磁盘各分区利用率，并从大到小排序。 1答案：df |grep ^/dev |tr -s ” ” “:”|cut -d: -f5 |cut -d% -f1 |sort -nr|head -n1 51，显示三个用户root,mage,wang的UID和默认shell. 1答案：cat /etc/passwd |egrep ^”(root|mage|wang)” |cut -d: -f1,3,7 52，找出/etc/rc.d/init.d/functions文件中行首为某单词（包括下划线）后面跟一个小括号的行。 1答案：cat /etc/rc.d/init.d/functions | egrep “^[a-zA-Z_]+.*” 53，使用egrep取出/etc/rc.d/init.d/functions中其基名。 1答案：echo /etc/rc.d/init.d/functions |egrep -o “[^/]*/?$” 54，使用egrep取出上面 路径的目录名。 123答案：（方法一）echo /etc/rc.d/init.d/functions |egrep -o “/.*/”（方法二）echo /etc/rc.d/init.d/functions |egrep -o “(/).*\\1” 55，统计last命令中以root登录的每个主机IP地址登录次数。 1答案： last |egrep root |egrep “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;”|tr -s ” ” “:”|sort -t: -k3|cut -d: -f3|uniq -dc 56，利用扩展正则表达式分别表示0-9,10-99，100-199,200-249,250-255. 1答案： [0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5] 57,显示ifconfig命令结果中所有IPV4地址。 1答案： ifconfig | egrep -o “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;” 58，将此字符串：welcome to magedu linux 中的每个字符去重并排序，重复次数多的放在最前面。 1答案： echo “welcometomagedulinux” |grep -o “.”|sort|uniq -c|sort -nr 59，复制/etc/profile至/tmp/目录，用查找替换命令删除/tmp/profile文件中的行首的空白字符。 12345答案：cp /etc/profile /tmp/ vim /tmp/profile 命令模式下按“:”进入扩展模式输入 %s/^[[:space:]]*//g 60, 复制/etc/rc.d/init.d/functions文件至/tmp目录，用查找替换命令为/tmp/functions的每行开头为空白字符的行的行首添加一个#号。 1234567答案： cp /etc/rc.d/init.d/functions /tmp vim /tmp/functions 命令模式下按“:”进入扩展模式输入 %s/^[[:space:]] */#&amp;/ 或者 %s/[[:space:]]\\+.∗[[:space:]]\\+.∗/#\\1/g 61, 在VIM中设置tab缩进为4个字符。 1234567答案： vim /etc/vimrc 在文件最后添加： set ts=4 set expandtab set autoindent :wq 62，复制/etc/rc.d/init.d/functions文件至/tmp目录，替换/tmp/functions文件中的/etc/sysconfig/init为/var/log. 答案：cp /etc/rc.d/init.d/functions /tmpvim /tmp/functions命令模式下按“:”进入扩展模式输入 %s@\\/etc\\/sysconfig\\/init@\\/var\\/log@ 63, 删除/tmp/functions文件中所有以#开头，且#后面至少有一个空白字符的行的行首的#号。 答案：vim /tmp/functions命令模式下按“:”进入扩展模式输入%s@^#”“+.∗”“+.∗@\\1@ 64, 编写脚本/root/bin/systeminfo.sh,显示当前主机系统信息，包括主机名，IPV4，操作系统版本，内核版本，CPU型号，内存大小，硬盘大小。 答案： vim /root/bin/systeminfo.sh #** echo hostnameecho ifconfig ens33 | egrep -o “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]).){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])>“|head -n1 echo cat /etc/centos-release echo uname -r echo lscpu |grep “^Model name.*” |cut -d: -f2|tr -s “ “ echo cat /proc/meminfo |head -n1 echo lsblk |grep ‘^sda’|tr -s “ “ “%”|cut -d% -f4 :wq 65, 编写脚本/root/bin/backup.sh,可实现每日将/etc/目录备份到/root/etcYYY-mm-dd中。 vim /root/bin/backup.shcp -a /etc /root/etcdate +%F:wq 66,编写脚本/root/bin/disk.sh,显示当前硬盘分区中空间利用率最大的值。 答案： e=df|egrep ^/dev |tr -s “ “ “:”|cut -d: -f5|cut -d% -f1|sort -nr|head -n1 echo $e ：wq 67, 编写脚本/root/bin/links.sh ，显示正连接本主机的每个远程主机的IPV4地址和连接数，并按连接数从大到小排序。 答案： vim /root/bin/linsk.sh a=cat access_log |egrep -o &quot;\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\&gt;&quot;|sort|uniq -c|sort -nr echo $a 68, 编写脚本/root/bin/sumid.sh ,计算/etc/passwd 文件中的第10个用户和第20用户的ID之和。 答案：vim /root/bin/sumid.sha=cat /etc/passwd | head -n10 |tail -n1|cut -d: -f3 b=cat /etc/passwd | head -n20 |tail -n1|cut -d: -f3 let c=a+b 或 d=$[ a+b ] echo $d 69, 编写脚本/root/bin/sumspace.sh ,传递两个文件路径作为参数给脚本，计算这两个文件中所有空白行之和。 12345答案： vim /root/bin/sumspace.sh a=cat f1 |egrep ^[[:space:]]*$ |wc -l b=cat f2 |egrep ^[[:space:]]*$ |wc -l let c=a+b 70, 编写脚本/root/bin/sumfile.sh ,统计/etc ,/var,/usr 目录中共有多少个一级子目录和文件。 答案：vim /root/bin/sumfile.sha=ls /etc/ |wc -lb=ls /var/ |wc -l c=ls /usr/ |wc -llet d=a+b+c 71, 编写脚本/root/bin/argsnum.sh ,接受一个文件路径作为参数；如果参数个数小于1，则提示用户 “至少应该给一个参数”，并立即退出；如果参数个数不少于1，则显示第一个参数所指向的文件中的空白行数。 答案：vim /root/bin/argsnum.sh [ $# -lt 1] &amp;&amp; echo “At least one parameter should be given” &amp;&amp; exit[ $# -ge 1] &amp;&amp; echo egrep “^[[:space:]]*$” $1|wc -l 73, 编写脚本/root/bin/hostping.sh ,接受一个主机的IPV4地址做为参数，测试是否可连通。如果能ping通，则提示用户 “该IP地址可以访问” ；如果不可ping通，则提示用户 “该IP地址不可访问”。 答案：vim /root/bin/hostping.sh [[ $1 =~ “\\&lt;(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]]]).){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])>” ]] || echo { “IP error”;exit; } ping $1 &amp;&amp; echo “This address can be accessed”|| echo “This address cannot be accessed” 74, 编写脚本/root/bin/checkdisk.sh , 检查磁盘分区空间和inode使用率，如果超过80%，就发广播警告空间将满。 答案：vim /root/bin/checkdisk.sh a=df |egrep ^/dev |tr -s “ “ “:” |cut -d: -f5 |cut -d% -f1|sort -nr|head -n1[[ $a -ge 80 ]] &amp;&amp; echo “zhao huo la ” || echo { “yi qie zheng chang”;exit; } 75, 编写脚本/bin/per.sh ,判断当前用户对指定参数文件，是否不可读并且不可写。 答案：[ -not -r $1 -a -not -w $1 ] &amp;&amp; echo “bu ke du ”[ −r$1−o−w$1−r$1−o−w$1 ] || echo “ke du ” 76，编写脚本/root/bin/excute.sh ,判断参数文件是否为sh后缀的普通文件，如果是，添加所有人可执行权限，否则提示用户非脚本文件。 答案：vim /root/bin/excute.sh[[ $1 =~ .*sh$ ]] &amp;&amp; chmod +x $1 || echo “bu shi jiao ben wen jian “","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"练习题","slug":"练习题","permalink":"http://yoursite.com/tags/练习题/"}]}]}